{"Year":2023,"Venue":"syntaxfest-2023","Acronym":"ICON","Description":"Building a Large-Scale Benchmark Constituency Treebank for the Indonesian Language","Abstract":"Constituency parsing is an important task of informing how words are combined to form sentences. While constituency parsing in English has seen significant progress in the last few years, tools for constituency parsing in Indonesian remain few and far between. In this work, we publish <MASKED_ACRONYM> (Indonesian CONstituency treebank), the hitherto largest publicly-available manually-annotated benchmark constituency treebank for the Indonesian language with a size of 10,000 sentences and approximately 124,000 constituents and 182,000 tokens, which can support the training of state-of-the-art transformer-based models. We establish strong baselines on the <MASKED_ACRONYM> dataset using the Berkeley Neural Parser with transformer-based pre-trained embeddings, with the best performance of 88.85% F1 score coming from our own version of SpanBERT (IndoSpanBERT). We further analyze the predictions made by our best-performing model to reveal certain idiosyncrasies in the Indonesian language that pose challenges for constituency parsing.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"bea-2014","Acronym":"ArCADE","Description":"An Arabic Corpus of Auditory Dictation Errors","Abstract":"We present a new corpus of word-level listening errors collected from 62 native English speakers learning Arabic designed to inform models of spell checking for this learner population. While we use the corpus to assist in automated detection and correction of auditory errors in electronic dictionary lookup, the corpus can also be used as a phonological error layer, to be combined with a composition error layer in a more complex spell-checking system for non-native speakers. The corpus may be useful to instructors of Arabic as a second language, and researchers who study second language phonology and listening perception.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"acl-2007","Acronym":"PERSONAGE","Description":"Personality Generation for Dialogue","Abstract":"Over the last \ufb01fty years, the \u201cBig Five\u201d model of personality traits has become a standard in psychology, and research has systematically documented correlations between a wide range of linguistic variables and the Big Five traits. A distinct line of research has explored methods for automatically generating language that varies along personality dimensions. We present <MASKED_ACRONYM> (PERSONAlity GEnerator), the \ufb01rst highly parametrizable language generator for extraversion, an important aspect of personality. We evaluate two personality generation methods: (1) direct generation with particular parameter settings suggested by the psychology literature; and (2) overgeneration and selection using statistical models trained from judge\u2019s ratings. Results show that both methods reliably generate utterances that vary along the extraversion dimension, according to human judges.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.875}
{"Year":2012,"Venue":"acl-2012","Acronym":"PORT","Description":"a Precision-Order-Recall MT Evaluation Metric for Tuning","Abstract":"Many machine translation (MT) evaluation  metrics have been shown to correlate better  with human judgment than BLEU. In  principle, tuning on these metrics should  yield better systems than tuning on BLEU.  However, due to issues such as speed,  requirements for linguistic resources, and  optimization difficulty, they have not been  widely adopted for tuning. This paper  presents <MASKED_ACRONYM> 1, a new MT  evaluation  metric which combines precision, recall  and an ordering metric and which is  primarily designed for tuning MT systems.  <MASKED_ACRONYM> does not require external resources  and is quick to compute. It has a better  correlation with human judgment than  BLEU. We compare <MASKED_ACRONYM>-tuned MT  systems to BLEU-tuned baselines in five  experimental conditions involving four  language pairs. <MASKED_ACRONYM> tuning achieves  consistently better performance than BLEU  tuning,  according  to  four  automated  metrics (including BLEU) and to human  evaluation: in comparisons of outputs from  300 source sentences, human judges  preferred the <MASKED_ACRONYM>-tuned output 45.3% of  the  time  (vs.  32.7%  BLEU  tuning   preferences and 22.0% ties).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"acl-2012","Acronym":"FLOW","Description":"A First-Language-Oriented Writing Assistant System","Abstract":"Writing in English might be one of the most  difficult tasks for EFL (English as a Foreign  Language)  learners.  This  paper  presents  <MASKED_ACRONYM>, a writing assistance system. It is built  based on first-language-oriented input function  and context sensitive approach, aiming at  providing  immediate  and  appropriate  suggestions including translations, paraphrases,  and n-grams during composing and revising  processes. <MASKED_ACRONYM> is expected to help EFL  writers achieve their writing flow without being  interrupted  by  their  insufficient  lexical  knowledge.     1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"acl-2014","Acronym":"WINGS","Description":"Writing with Intelligent Guidance and Suggestions","Abstract":"Without inspirations, writing may be a  frustrating task for most people. In this study,  we designed and implemented <MASKED_ACRONYM>, a  Chinese  input  method  extended  on  IBus-Pinyin with intelligent writing assistance.  In addition to supporting common Chinese  input, <MASKED_ACRONYM> mainly attempts to spark users\u2019  inspirations by recommending both word  level and sentence level writing suggestions.  The main strategies used by <MASKED_ACRONYM>,  including  providing  syntactically  and  semantically related words based on word  vector representation and recommending  contextually related sentences based on LDA,  are discussed and described. Experimental  results suggest that <MASKED_ACRONYM> can facilitate  Chinese writing in an effective and creative  manner.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"lrec-2012","Acronym":"LIE","Description":"Leadership, Influence and Expertise","Abstract":"This paper describes our research into methods for inferring social and instrumental roles and relationships from document and discourse corpora. The goal is to identify the roles of initial authors and participants in internet discussions with respect to leadership, influence and expertise. Web documents, forums and blogs provide data from which the relationships between these concepts are empirically derived and compared. Using techniques from Natural Language Processing (NLP), characterizations of authority and expertise are hypothesized and then tested to see if these pick out the same or different participants as may be chosen by techniques based on social network analysis (Huffaker 2010) see if they pick out the same discourse participants for any given level of these qualities (i.e. leadership, expertise and influence). Our methods could be applied, in principle, to any domain topic, but this paper will describe an initial investigation into two subject areas where a range of differing opinions are available and which differ in the nature of their appeals to authority and truth: \u0091genetic engineering' and a \u0091Muslim Forum'. The available online corpora for these topics contain discussions from a variety of users with different levels of expertise, backgrounds and personalities.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"lrec-2012","Acronym":"CAT","Description":"the CELCT Annotation Tool","Abstract":"This paper presents <MASKED_ACRONYM> - CELCT Annotation Tool, a new general-purpose web-based tool for text annotation developed by CELCT (Center for the Evaluation of Language and Communication Technologies). The aim of <MASKED_ACRONYM> is to make text annotation an intuitive, easy and fast process. In particular, <MASKED_ACRONYM> was created to support human annotators in performing linguistic and semantic text annotation and was designed to improve productivity and reduce time spent on this task. Manual text annotation is, in fact, a time-consuming activity, and conflicts may arise with the strict deadlines annotation projects are frequently subject to. Thanks to its adaptability and user-friendly interface, <MASKED_ACRONYM> can positively contribute to improve time management in annotation project. Further, the tool has a number of features which make it an easy-to-use tool for many types of annotations. Even if the first prototype of <MASKED_ACRONYM> has been used to perform temporal and event annotation following the It-TimeML specifications, the tool is general enough to be used for annotating a broad range of linguistic and semantic phenomena. <MASKED_ACRONYM> is freely available for research purposes.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"lrec-2012","Acronym":"PEARL","Description":"ProjEction of Annotations Rule Language, a Language for Projecting (UIMA) Annotations over RDF Knowledge Bases","Abstract":"In this paper we present a language, <MASKED_ACRONYM>, for projecting annotations based on the Unstructured Information Management Architecture (UIMA) over RDF triples. The language offer is twofold: first, a query mechanism, built upon (and extending) the basic FeaturePath notation of UIMA, allows for efficient access to the standard annotation format of UIMA based on feature structures. <MASKED_ACRONYM> then provides a syntax for projecting the retrieved information onto an RDF Dataset, by using a combination of a SPARQL-like notation for matching pre-existing elements of the dataset and of meta-graph patterns, for storing new information into it. In this paper we present the basics of this language and how a <MASKED_ACRONYM> document is structured, discuss a simple use-case and introduce a wider project about automatic acquisition of knowledge, in which <MASKED_ACRONYM> plays a pivotal role.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"lrec-2012","Acronym":"Terra","Description":"a Collection of Translation Error-Annotated Corpora","Abstract":"Recently the first methods of automatic diagnostics of machine translation have emerged; since this area of research is relatively young, the efforts are not coordinated. We present a collection of translation error-annotated corpora, consisting of automatically produced translations and their detailed manual translation error analysis. Using the collected corpora we evaluate the available state-of-the-art methods of MT diagnostics and assess, how well the methods perform, how they compare to each other and whether they can be useful in practice.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8333333333}
{"Year":2012,"Venue":"lrec-2012","Acronym":"PET","Description":"a Tool for Post-editing and Assessing Machine Translation","Abstract":"Given the significant improvements in Machine Translation (MT) quality and the increasing demand for translations, post-editing of automatic translations is becoming a popular practice in the translation industry. It has been shown to allow for much larger volumes of translations to be produced, saving time and costs. In addition, the post-editing of automatic translations can help understand problems in such translations and this can be used as feedback for researchers and developers to improve MT systems. Finally, post-editing can be used as a way of evaluating the quality of translations in terms of how much post-editing effort these translations require. We describe a standalone tool that has two main purposes: facilitate the post-editing of translations from any MT system so that they reach publishable quality and collect sentence-level information from the post-editing process, e.g.: post-editing time and detailed keystroke statistics.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"eamt-2020","Acronym":"NICE","Description":"Neural Integrated Custom Engines","Abstract":"In this paper, we present a machine translation system implemented by the Translation Centre for the Bodies of the European Union (CdT). The main goal of this project is to create domain-specific machine translation engines in order to support machine translation services and applications to the Translation Centre\u2019s clients. In this article, we explain the entire implementation process of <MASKED_ACRONYM>: Neural Integrated Custom Engines. We describe the problems identified and the solutions provided, and present the final results for different language pairs. Finally, we describe the work that will be done on this project in the future.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":1999,"Venue":"mtsummit-1999","Acronym":"BITS","Description":"a method for bilingual text search over the Web","Abstract":"Parallel corpus are valuable resource for machine translation, multi-lingual text retrieval, language education and other applications, but for various reasons, its availability is very limited at present. Noticed that the World Word Web is a potential source to mine parallel text, researchers are making their efforts to explore the Web in order to get a big collection of bitext. This paper presents <MASKED_ACRONYM> (Bilingual Internet Text Search), a system which harvests multilingual texts over the World Wide Web with virtually no human intervention. The technique is simple, easy to port to any language pairs, and with high accuracy. The results of the experiments on German-English pair proved that the method is very successful.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"eacl-2014","Acronym":"PARADIGM","Description":"Paraphrase Diagnostics through Grammar Matching","Abstract":"Paraphrase evaluation is typically done either manually or through indirect, taskbased evaluation. We introduce an intrinsic evaluation <MASKED_ACRONYM> which measures the goodness of paraphrase collections that are represented using synchronous grammars. We formulate two measures that evaluate these paraphrase grammars using gold standard sentential paraphrases drawn from a monolingual parallel corpus. The \ufb01rst measure calculates how often a paraphrase grammar is able to synchronously parse the sentence pairs in the corpus. The second measure enumerates paraphrase rules from the monolingual parallel corpus and calculates the overlap between this reference paraphrase collection and the paraphrase resource being evaluated. We demonstrate the use of these evaluation metrics on paraphrase collections derived from three different data types: multiple translations of classic French novels, comparable sentence pairs drawn from different newspapers, and bilingual parallel corpora. We show that <MASKED_ACRONYM> correlates with human judgments more strongly than BLEU on a task-based evaluation of paraphrase quality.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"clinicalnlp-2020","Acronym":"MeDAL","Description":"Medical Abbreviation Disambiguation Dataset for Natural Language Understanding Pretraining","Abstract":"One of the biggest challenges that prohibit the use of many current NLP methods in clinical settings is the availability of public datasets. In this work, we present <MASKED_ACRONYM>, a large medical text dataset curated for abbreviation disambiguation, designed for natural language understanding pre-training in the medical domain. We pre-trained several models of common architectures on this dataset and empirically showed that such pre-training leads to improved performance and convergence speed when fine-tuning on downstream medical tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"paclic-2022","Acronym":"SEND","Description":"A Simple and Efficient Noise Detection Algorithm for Vietnamese Real Estate Posts","Abstract":"One of the emerging research fields in Natural Language Processing is Noise Detection (ND), the process of identifying posts containing noise information on textual data. While numerous datasets and approaches are developed for ND research in other languages, equivalent resources for the Vietnamese are limited. To the best of our knowledge, no dataset or method has been investigated or proposed to address the noise Detection tasks in the Vietnamese language. In reality, noise data is constantly present in datasets and sometimes hurts relevant model performance. To overcome this limitation, we propose ViND, a first human-annotated dataset that is available to the scientific community as a benchmark for the task of Vietnamese Noise Detection. The ViND dataset contains 12,862 posts collected from five major Vietnamese real estate news websites. This paper provides an overview of the Vietnamese Noise Detection task, the process of creating the ViND dataset, and the techniques for carrying out the baseline experiments. On the ViND dataset, the PhoBERTlarge model outperforms robust baseline models such as LSTM, Bi-LSTM, BERT, RoBERTa, XLM-R, and DistilBERT and achieves a macro F1-score of 0.9024. In addition, our proposed method also successfully improves the related task\u2019s performance, mainly Vietnamese Named Entity Recognition (NER) for real estate posts, about 0.0239 in terms of macro F1-score.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"law-2023","Acronym":"GENTLE","Description":"A Genre-Diverse Multilayer Challenge Set for English NLP and Linguistic Evaluation","Abstract":"We present <MASKED_ACRONYM>, a new mixed-genre English challenge corpus totaling 17K tokens and consisting of 8 unusual text types for out-of-domain evaluation: dictionary entries, esports commentaries, legal documents, medical notes, poetry, mathematical proofs, syllabuses, and threat letters. <MASKED_ACRONYM> is manually annotated for a variety of popular NLP tasks, including syntactic dependency parsing, entity recognition, coreference resolution, and discourse parsing. We evaluate state-of-the-art NLP systems on <MASKED_ACRONYM> and find severe degradation for at least some genres in their performance on all tasks, which indicates <MASKED_ACRONYM>\u2019s utility as an evaluation dataset for NLP systems.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2009,"Venue":"acl-2009","Acronym":"MARS","Description":"Multilingual Access and Retrieval System with Enhanced Query Translation and Document Retrieval","Abstract":"In this paper, we introduce a multilingual access and retrieval system with enhanced query  translation and multilingual document retrieval,  by mining bilingual terminologies and aligned  document directly from the set of comparable  corpora which are to be searched upon by users. By extracting bilingual terminologies and  aligning bilingual documents with similar content prior to the search process provide more  accurate translated terms for the in-domain  data and support multilingual retrieval even  without the use of translation tool during retrieval time. This system includes a userfriendly graphical user interface designed to  provide navigation and retrieval of information  in browse mode and search mode respectively.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2010,"Venue":"semeval-2010","Acronym":"MARS","Description":"A Specialized RTE System for Parser Evaluation","Abstract":"This paper describes our participation in the the SemEval-2010 Task #12, Parser Evaluation using Textual Entailment. Our system incorporated two dependency parsers, one semantic role labeler, and a deep parser based on hand-crafted grammars. The shortest path algorithm is applied on the graph representation of the parser outputs. Then, different types of features are extracted and the entailment recognition is casted into a machinelearning-based classi\ufb01cation task. The best setting of the system achieves 66.78% of accuracy, which ranks the 3rd place.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"eacl-2017","Acronym":"SMARTies","Description":"Sentiment Models for Arabic Target entities","Abstract":"We consider entity-level sentiment analysis in Arabic, a morphologically rich language with increasing resources. We present a system that is applied to complex posts written in response to Arabic newspaper articles. Our goal is to identify important entity \u201ctargets\u201d within the post along with the polarity expressed about each target. We achieve significant improvements over multiple baselines, demonstrating that the use of specific morphological representations improves the performance of identifying both important targets and their sentiment, and that the use of distributional semantic clusters further boosts performances for these representations, especially when richer linguistic resources are not available.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.875}
{"Year":2017,"Venue":"eacl-2017","Acronym":"COVER","Description":"Covering the Semantically Tractable Questions","Abstract":"In semantic parsing, natural language questions map to expressions in a meaning representation language (MRL) over some fixed vocabulary of predicates. To do this reliably, one must guarantee that for a wide class of natural language questions (the so called semantically tractable questions), correct interpretations are always in the mapped set of possibilities. In this demonstration, we introduce the system <MASKED_ACRONYM> which significantly clarifies, revises and extends the basic notion of semantic tractability. <MASKED_ACRONYM> achieves coverage of 89% while the earlier PRECISE system achieved coverage of 77% on the well known GeoQuery corpus. Like PRECISE, <MASKED_ACRONYM> requires only a simple domain lexicon and integrates off-the-shelf syntactic parsers. Beyond PRECISE, <MASKED_ACRONYM> also integrates off-the-shelf theorem provers to provide more accurate results. <MASKED_ACRONYM> is written in Python and uses the NLTK.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"eacl-2017","Acronym":"ICE","Description":"Idiom and Collocation Extractor for Research and Education","Abstract":"Collocation and idiom extraction are well-known challenges with many potential applications in Natural Language Processing (NLP). Our experimental, open-source software system, called <MASKED_ACRONYM>, is a python package for flexibly extracting collocations and idioms, currently in English. It also has a competitive POS tagger that can be used alone or as part of collocation\/idiom extraction. <MASKED_ACRONYM> is available free of cost for research and educational uses in two user-friendly formats. This paper gives an overview of <MASKED_ACRONYM> and its performance, and briefly describes the research underlying the extraction algorithms.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"wmt-2019","Acronym":"EED","Description":"Extended Edit Distance Measure for Machine Translation","Abstract":"Over the years a number of machine translation metrics have been developed in order to evaluate the accuracy and quality of machine-generated translations. Metrics such as BLEU and TER have been used for decades. However, with the rapid progress of machine translation systems, the need for better metrics is growing. This paper proposes an extension of the edit distance, which achieves better human correlation, whilst remaining fast, flexible and easy to understand.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2019,"Venue":"wmt-2019","Acronym":"SOURCE","Description":"SOURce-Conditional Elmo-style Model for Machine Translation Quality Estimation","Abstract":"Quality estimation (QE) of machine translation (MT) systems is a task of growing importance. It reduces the cost of post-editing, allowing machine-translated text to be used in formal occasions. In this work, we describe our submission system in WMT 2019 sentence-level QE task. We mainly explore the utilization of pre-trained translation models in QE and adopt a bi-directional translation-like strategy. The strategy is similar to ELMo, but additionally conditions on source sentences. Experiments on WMT QE dataset show that our strategy, which makes the pre-training slightly harder, can bring improvements for QE. In WMT-2019 QE task, our system ranked in the second place on En-De NMT dataset and the third place on En-Ru NMT dataset.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"Coach","Description":"A Coarse-to-Fine Approach for Cross-domain Slot Filling","Abstract":"As an essential task in task-oriented dialog systems, slot filling requires extensive training data in a certain domain. However, such data are not always available. Hence, cross-domain slot filling has naturally arisen to cope with this data scarcity problem. In this paper, we propose a Coarse-to-fine approach (<MASKED_ACRONYM>) for cross-domain slot filling. Our model first learns the general pattern of slot entities by detecting whether the tokens are slot entities or not. It then predicts the specific types for the slot entities. In addition, we propose a template regularization approach to improve the adaptation robustness by regularizing the representation of utterances based on utterance templates. Experimental results show that our model significantly outperforms state-of-the-art approaches in slot filling. Furthermore, our model can also be applied to the cross-domain named entity recognition task, and it achieves better adaptation performance than other existing baselines. The code is available at <a href=https:\/\/github.com\/zliucr\/coach class=acl-markup-url>https:\/\/github.com\/zliucr\/coach<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"TAG","Description":"Type Auxiliary Guiding for Code Comment Generation","Abstract":"Existing leading code comment generation approaches with the structure-to-sequence framework ignores the type information of the interpretation of the code, e.g., operator, string, etc. However, introducing the type information into the existing framework is non-trivial due to the hierarchical dependence among the type information. In order to address the issues above, we propose a Type Auxiliary Guiding encoder-decoder framework for the code comment generation task which considers the source code as an N-ary tree with type information associated with each node. Specifically, our framework is featured with a Type-associated Encoder and a Type-restricted Decoder which enables adaptive summarization of the source code. We further propose a hierarchical reinforcement learning method to resolve the training difficulties of our proposed framework. Extensive evaluations demonstrate the state-of-the-art performance of our framework with both the auto-evaluated metrics and case studies.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"MuTual","Description":"A Dataset for Multi-Turn Dialogue Reasoning","Abstract":"Non-task oriented dialogue systems have achieved great success in recent years due to largely accessible conversation data and the development of deep learning techniques. Given a context, current systems are able to yield a relevant and fluent response, but sometimes make logical mistakes because of weak reasoning capabilities. To facilitate the conversation reasoning research, we introduce <MASKED_ACRONYM>, a novel dataset for Multi-Turn dialogue Reasoning, consisting of 8,860 manually annotated dialogues based on Chinese student English listening comprehension exams. Compared to previous benchmarks for non-task oriented dialogue systems, <MASKED_ACRONYM> is much more challenging since it requires a model that be able to handle various reasoning problems. Empirical results show that state-of-the-art methods only reach 71%, which is far behind human performance of 94%, indicating that there is ample room for improving reasoning ability.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"SMART","Description":"Robust and Efficient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization","Abstract":"Transfer learning has fundamentally changed the landscape of natural language processing (NLP). Many state-of-the-art models are first pre-trained on a large text corpus and then fine-tuned on downstream tasks. However, due to limited data resources from downstream tasks and the extremely high complexity of pre-trained models, aggressive fine-tuning often causes the fine-tuned model to overfit the training data of downstream tasks and fail to generalize to unseen data. To address such an issue in a principled manner, we propose a new learning framework for robust and efficient fine-tuning for pre-trained models to attain better generalization performance. The proposed framework contains two important ingredients: 1. Smoothness-inducing regularization, which effectively manages the complexity of the model; 2. Bregman proximal point optimization, which is an instance of trust-region methods and can prevent aggressive updating. Our experiments show that the proposed framework achieves new state-of-the-art performance on a number of NLP tasks including GLUE, SNLI, SciTail and ANLI. Moreover, it also outperforms the state-of-the-art T5 model, which is the largest pre-trained model containing 11 billion parameters, on GLUE.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"ENGINE","Description":"Energy-Based Inference Networks for Non-Autoregressive Machine Translation","Abstract":"We propose to train a non-autoregressive machine translation model to minimize the energy defined by a pretrained autoregressive model. In particular, we view our non-autoregressive translation system as an inference network (Tu and Gimpel, 2018) trained to minimize the autoregressive teacher energy. This contrasts with the popular approach of training a non-autoregressive model on a distilled corpus consisting of the beam-searched outputs of such a teacher model. Our approach, which we call <MASKED_ACRONYM> (ENerGy-based Inference NEtworks), achieves state-of-the-art non-autoregressive results on the IWSLT 2014 DE-EN and WMT 2016 RO-EN datasets, approaching the performance of autoregressive models.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"SAFER","Description":"A Structure-free Approach for Certified Robustness to Adversarial Word Substitutions","Abstract":"State-of-the-art NLP models can often be fooled by human-unaware transformations such as synonymous word substitution. For security reasons, it is of critical importance to develop models with certified robustness that can provably guarantee that the prediction is can not be altered by any possible synonymous word substitution. In this work, we propose a certified robust method based on a new randomized smoothing technique, which constructs a stochastic ensemble by applying random word substitutions on the input sentences, and leverage the statistical properties of the ensemble to provably certify the robustness. Our method is simple and structure-free in that it only requires the black-box queries of the model outputs, and hence can be applied to any pre-trained models (such as BERT) and any types of models (world-level or subword-level). Our method significantly outperforms recent state-of-the-art methods for certified robustness on both IMDB and Amazon text classification tasks. To the best of our knowledge, we are the first work to achieve certified robustness on large systems such as BERT with practically meaningful certified accuracy.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"SEEK","Description":"Segmented Embedding of Knowledge Graphs","Abstract":"In recent years, knowledge graph embedding becomes a pretty hot research topic of artificial intelligence and plays increasingly vital roles in various downstream applications, such as recommendation and question answering. However, existing methods for knowledge graph embedding can not make a proper trade-off between the model complexity and the model expressiveness, which makes them still far from satisfactory. To mitigate this problem, we propose a lightweight modeling framework that can achieve highly competitive relational expressiveness without increasing the model complexity. Our framework focuses on the design of scoring functions and highlights two critical characteristics: 1) facilitating sufficient feature interactions; 2) preserving both symmetry and antisymmetry properties of relations. It is noteworthy that owing to the general and elegant design of scoring functions, our framework can incorporate many famous existing methods as special cases. Moreover, extensive experiments on public benchmarks demonstrate the efficiency and effectiveness of our framework. Source codes and data can be found at <a href=https:\/\/github.com\/Wentao-Xu\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/Wentao-Xu\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"ASSET","Description":"A Dataset for Tuning and Evaluation of Sentence Simplification Models with Multiple Rewriting Transformations","Abstract":"In order to simplify a sentence, human editors perform multiple rewriting transformations: they split it into several shorter sentences, paraphrase words (i.e. replacing complex words or phrases by simpler synonyms), reorder components, and\/or delete information deemed unnecessary. Despite these varied range of possible text alterations, current models for automatic sentence simplification are evaluated using datasets that are focused on a single transformation, such as lexical paraphrasing or splitting. This makes it impossible to understand the ability of simplification models in more realistic settings. To alleviate this limitation, this paper introduces <MASKED_ACRONYM>, a new dataset for assessing sentence simplification in English. <MASKED_ACRONYM> is a crowdsourced multi-reference corpus where each simplification was produced by executing several rewriting transformations. Through quantitative and qualitative experiments, we show that simplifications in <MASKED_ACRONYM> are better at capturing characteristics of simplicity when compared to other standard evaluation datasets for the task. Furthermore, we motivate the need for developing better methods for automatic evaluation using <MASKED_ACRONYM>, since we show that current popular metrics may not be suitable when multiple simplification transformations are performed.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"MIE","Description":"A Medical Information Extractor towards Medical Dialogues","Abstract":"Electronic Medical Records (EMRs) have become key components of modern medical care systems. Despite the merits of EMRs, many doctors suffer from writing them, which is time-consuming and tedious. We believe that automatically converting medical dialogues to EMRs can greatly reduce the burdens of doctors, and extracting information from medical dialogues is an essential step. To this end, we annotate online medical consultation dialogues in a window-sliding style, which is much easier than the sequential labeling annotation. We then propose a Medical Information Extractor (<MASKED_ACRONYM>) towards medical dialogues. <MASKED_ACRONYM> is able to extract mentioned symptoms, surgeries, tests, other information and their corresponding status. To tackle the particular challenges of the task, <MASKED_ACRONYM> uses a deep matching architecture, taking dialogue turn-interaction into account. The experimental results demonstrate <MASKED_ACRONYM> is a promising solution to extract medical information from doctor-patient dialogues.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2020,"Venue":"acl-2020","Acronym":"FLAT","Description":"Chinese NER Using Flat-Lattice Transformer","Abstract":"Recently, the character-word lattice structure has been proved to be effective for Chinese named entity recognition (NER) by incorporating the word information. However, since the lattice structure is complex and dynamic, the lattice-based models are hard to fully utilize the parallel computation of GPUs and usually have a low inference speed. In this paper, we propose <MASKED_ACRONYM>: Flat-LAttice Transformer for Chinese NER, which converts the lattice structure into a flat structure consisting of spans. Each span corresponds to a character or latent word and its position in the original lattice. With the power of Transformer and well-designed position encoding, <MASKED_ACRONYM> can fully leverage the lattice information and has an excellent parallel ability. Experiments on four datasets show <MASKED_ACRONYM> outperforms other lexicon-based models in performance and efficiency.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"HAT","Description":"Hardware-Aware Transformers for Efficient Natural Language Processing","Abstract":"Transformers are ubiquitous in Natural Language Processing (NLP) tasks, but they are difficult to be deployed on hardware due to the intensive computation. To enable low-latency inference on resource-constrained hardware platforms, we propose to design Hardware-Aware Transformers (<MASKED_ACRONYM>) with neural architecture search. We first construct a large design space with arbitrary encoder-decoder attention and heterogeneous layers. Then we train a SuperTransformer that covers all candidates in the design space, and efficiently produces many SubTransformers with weight sharing. Finally, we perform an evolutionary search with a hardware latency constraint to find a specialized SubTransformer dedicated to run fast on the target hardware. Extensive experiments on four machine translation tasks demonstrate that <MASKED_ACRONYM> can discover efficient models for different hardware (CPU, GPU, IoT device). When running WMT\u201914 translation task on Raspberry Pi-4, <MASKED_ACRONYM> can achieve 3\u00d7 speedup, 3.7\u00d7 smaller size over baseline Transformer; 2.7\u00d7 speedup, 3.6\u00d7 smaller size over Evolved Transformer with 12,041\u00d7 less search cost and no performance loss. <MASKED_ACRONYM> is open-sourced at <a href=https:\/\/github.com\/mit-han-lab\/hardware-aware-transformers class=acl-markup-url>https:\/\/github.com\/mit-han-lab\/hardware-aware-transformers<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"ESPRIT","Description":"Explaining Solutions to Physical Reasoning Tasks","Abstract":"Neural networks lack the ability to reason about qualitative physics and so cannot generalize to scenarios and tasks unseen during training. We propose <MASKED_ACRONYM>, a framework for commonsense reasoning about qualitative physics in natural language that generates interpretable descriptions of physical events. We use a two-step approach of first identifying the pivotal physical events in an environment and then generating natural language descriptions of those events using a data-to-text approach. Our framework learns to generate explanations of how the physical simulation will causally evolve so that an agent or a human can easily reason about a solution using those interpretable descriptions. Human evaluations indicate that <MASKED_ACRONYM> produces crucial fine-grained details and has high coverage of physical concepts compared to even human annotations. Dataset, code and documentation are available at <a href=https:\/\/github.com\/salesforce\/esprit class=acl-markup-url>https:\/\/github.com\/salesforce\/esprit<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8333333333}
{"Year":2020,"Venue":"acl-2020","Acronym":"TriggerNER","Description":"Learning with Entity Triggers as Explanations for Named Entity Recognition","Abstract":"Training neural models for named entity recognition (NER) in a new domain often requires additional human annotations (e.g., tens of thousands of labeled instances) that are usually expensive and time-consuming to collect. Thus, a crucial research question is how to obtain supervision in a cost-effective way. In this paper, we introduce \u201centity triggers,\u201d an effective proxy of human explanations for facilitating label-efficient learning of NER models. An entity trigger is defined as a group of words in a sentence that helps to explain why humans would recognize an entity in the sentence. We crowd-sourced 14k entity triggers for two well-studied NER datasets. Our proposed model, Trigger Matching Network, jointly learns trigger representations and soft matching module with self-attention such that can generalize to unseen sentences easily for tagging. Our framework is significantly more cost-effective than the traditional neural NER frameworks. Experiments show that using only 20% of the trigger-annotated sentences results in a comparable performance as using 70% of conventional annotated sentences.","wordlikeness":0.9,"lcsratio":1.0,"wordcoverage":0.8421052632}
{"Year":2020,"Venue":"acl-2020","Acronym":"ADVISER","Description":"A Toolkit for Developing Multi-modal, Multi-domain and Socially-engaged Conversational Agents","Abstract":"We present <MASKED_ACRONYM> - an open-source, multi-domain dialog system toolkit that enables the development of multi-modal (incorporating speech, text and vision), socially-engaged (e.g. emotion recognition, engagement level prediction and backchanneling) conversational agents. The final Python-based implementation of our toolkit is flexible, easy to use, and easy to extend not only for technically experienced users, such as machine learning researchers, but also for less technically experienced users, such as linguists or cognitive scientists, thereby providing a flexible platform for collaborative research.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"acl-2020","Acronym":"SCAR","Description":"Sentence Compression using Autoencoders for Reconstruction","Abstract":"Sentence compression is the task of shortening a sentence while retaining its meaning. Most methods proposed for this task rely on labeled or paired corpora (containing pairs of verbose and compressed sentences), which is often expensive to collect. To overcome this limitation, we present a novel unsupervised deep learning framework (<MASKED_ACRONYM>) for deletion-based sentence compression. <MASKED_ACRONYM> is primarily composed of two encoder-decoder pairs: a compressor and a reconstructor. The compressor masks the input, and the reconstructor tries to regenerate it. The model is entirely trained on unlabeled data and does not require additional inputs such as explicit syntactic information or optimal compression length. <MASKED_ACRONYM>\u2019s merit lies in the novel Linkage Loss function, which correlates the compressor and its effect on reconstruction, guiding it to drop inferable tokens. <MASKED_ACRONYM> achieves higher ROUGE scores on benchmark datasets than the existing state-of-the-art methods and baselines. We also conduct a user study to demonstrate the application of our model as a text highlighting system. Using our model to underscore salient information facilitates speed-reading and reduces the time required to skim a document.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"newsum-2021","Acronym":"EASE","Description":"Extractive-Abstractive Summarization End-to-End using the Information Bottleneck Principle","Abstract":"Current abstractive summarization systems outperform their extractive counterparts, but their widespread adoption is inhibited by the inherent lack of interpretability. Extractive summarization systems, though interpretable, suffer from redundancy and possible lack of coherence. To achieve the best of both worlds, we propose <MASKED_ACRONYM>, an extractive-abstractive framework that generates concise abstractive summaries that can be traced back to an extractive summary. Our framework can be applied to any evidence-based text generation problem and can accommodate various pretrained models in its simple architecture. We use the Information Bottleneck principle to jointly train the extraction and abstraction in an end-to-end fashion. Inspired by previous research that humans use a two-stage framework to summarize long documents (Jing and McKeown, 2000), our framework first extracts a pre-defined amount of evidence spans and then generates a summary using only the evidence. Using automatic and human evaluations, we show that the generated summaries are better than strong extractive and extractive-abstractive baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2011,"Venue":"ws-2011","Acronym":"GRASP","Description":"Grammar- and Syntax-based Pattern-Finder in CALL","Abstract":"We introduce a method for learning to  describe the attendant contexts of a given  query for language learning. In our  approach,  we  display  phraseological  information in the form of a summary of  general patterns as well as lexical bundles  anchored at the query. The method  involves syntactical analyses and inverted  file construction. At run-time, grammatical  constructions  and  their  lexical  instantiations characterizing the usage of  the  given  query  are generated and  displayed, aimed at improving learners\u2019  deep vocabulary knowledge. We present a  prototype system, <MASKED_ACRONYM>, that applies the  proposed method for enhanced collocation  learning. Preliminary experiments show  that language learners benefit more from  <MASKED_ACRONYM>  than  conventional  dictionary  lookup.  In  addition, the  information  produced by <MASKED_ACRONYM> is potentially useful  information for automatic or manual  editing process.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"PAIR","Description":"Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing","Abstract":"Counselor reflection is a core verbal skill used by mental health counselors to express understanding and affirmation of the client\u2019s experience and concerns. In this paper, we propose a system for the analysis of counselor reflections. Specifically, our system takes as input one dialog turn containing a client prompt and a counselor response, and outputs a score indicating the level of reflection in the counselor response. We compile a dataset consisting of different levels of reflective listening skills, and propose the Prompt-Aware margIn Ranking (<MASKED_ACRONYM>) framework that contrasts positive and negative prompt and response pairs using specially designed multi-gap and prompt-aware margin ranking losses. Through empirical evaluations and deployment of our system in a real-life educational environment, we show that our analysis model outperforms several baselines on different metrics, and can be used to provide useful feedback to counseling trainees.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"ToKen","Description":"Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection","Abstract":"Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its \u201cconstituent\u201d parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. ATOMIC2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"PRINCE","Description":"Prefix-Masked Decoding for Knowledge Enhanced Sequence-to-Sequence Pre-Training","Abstract":"Pre-trained Language Models (PLMs) have shown effectiveness in various Natural Language Processing (NLP) tasks. Denoising autoencoder is one of the most successful pre-training frameworks, learning to recompose the original text given a noise-corrupted one. The existing studies mainly focus on injecting noises into the input. This paper introduces a simple yet effective pre-training paradigm, equipped with a knowledge-enhanced decoder that predicts the next entity token with noises in the prefix, explicitly strengthening the representation learning of entities that span over multiple input tokens. Specifically, when predicting the next token within an entity, we feed masks into the prefix in place of some of the previous ground-truth tokens that constitute the entity. Our model achieves new state-of-the-art results on two knowledge-driven data-to-text generation tasks with up to 2% BLEU gains.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"ROSE","Description":"Robust Selective Fine-tuning for Pre-trained Language Models","Abstract":"Even though the large-scale language models have achieved excellent performances, they suffer from various adversarial attacks.A large body of defense methods has been proposed. However, they are still limited due to redundant attack search spaces and the inability to defend against various types of attacks. In this work, we present a novel fine-tuning approach called <b>RO<\/b>bust <b>SE<\/b>letive fine-tuning (<b><MASKED_ACRONYM><\/b>) to address this issue.<MASKED_ACRONYM> conducts selective updates when adapting pre-trained models to downstream tasks, filtering out invaluable and unrobust updates of parameters.Specifically, we propose two strategies: the first-order and second-order <MASKED_ACRONYM> for selecting target robust parameters.The experimental results show that <MASKED_ACRONYM> achieves significant improvements in adversarial robustness on various downstream NLP tasks, and the ensemble method even surpasses both variants above.Furthermore, <MASKED_ACRONYM> can be easily incorporated into existing fine-tuning methods to improve their adversarial robustness further.The empirical analysis confirms that <MASKED_ACRONYM> eliminates unrobust spurious updates during fine-tuning, leading to solutions corresponding to flatter and wider optima than the conventional method.Code is available at <a href=https:\/\/github.com\/jiangllan\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/jiangllan\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"TRIPS","Description":"Efficient Vision-and-Language Pre-training with Text-Relevant Image Patch Selection","Abstract":"Vision Transformers (ViTs) have been widely used in large-scale Vision and Language Pre-training (VLP) models. Though previous VLP works have proved the effectiveness of ViTs, they still suffer from computational efficiency brought by the long visual sequence. To tackle this problem, in this paper, we propose an efficient vision-and-language pre-training model with Text-Relevant Image Patch Selection, namely <MASKED_ACRONYM>, which reduces the visual sequence progressively with a text-guided patch-selection layer in the visual backbone for efficient training and inference. The patch-selection layer can dynamically compute text-dependent visual attention to identify the attentive image tokens with text guidance and fuse inattentive ones in an end-to-end manner. Meanwhile, <MASKED_ACRONYM> does not introduce extra parameters to ViTs. Experimental results on a variety of popular benchmark datasets demonstrate that <MASKED_ACRONYM> gain a speedup of 40% over previous similar VLP models, yet with competitive or better downstream task performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"FiE","Description":"Building a Global Probability Space by Leveraging Early Fusion in Encoder for Open-Domain Question Answering","Abstract":"Generative models have recently started to outperform extractive models in Open Domain Question Answering, largely by leveraging their decoder to attend over multiple encoded passages and combining their information. However, generative models tend to be larger than extractive models due to the need for a decoder, run slower during inference due to auto-regressive decoder beam search, and their generated output often suffers from hallucinations. We propose to extend transformer encoders with the ability to fuse information from multiple passages, using global representation to provide cross-sample attention over all tokens across samples. Furthermore, we propose an alternative answer span probability calculation to better aggregate answer scores in the global space of all samples. Using our proposed method, we outperform the current state-of-the-art method by 2.5 Exact Match score on the Natural Question dataset while using only 25% of parameters and 35% of the latency during inference, and 4.4 Exact Match on WebQuestions dataset. When coupled with synthetic data augmentation, we outperform larger models on the TriviaQA dataset as well. The latency and parameter savings of our method make it particularly attractive for open-domain question answering, as these models are often compute-intensive.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"PASTA","Description":"Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training","Abstract":"Fact verification has attracted a lot of attention recently, e.g., in journalism, marketing, and policymaking, as misinformation and dis- information can sway one\u2019s opinion and affect one\u2019s actions. While fact-checking is a hard task in general, in many cases, false statements can be easily debunked based on analytics over tables with reliable information. Hence, table- based fact verification has recently emerged as an important and growing research area. Yet, progress has been limited due to the lack of datasets that can be used to pre-train language models (LMs) to be aware of common table operations, such as aggregating a column or comparing tuples. To bridge this gap, this paper introduces <MASKED_ACRONYM> for table-based fact verification via pre-training with synthesized sentence\u2013table cloze questions. In particular, we design six types of common sentence\u2013table cloze tasks, including Filter, Aggregation, Superlative, Comparative, Ordinal, and Unique, based on which we synthesize a large corpus consisting of 1.2 million sentence\u2013table pairs from WikiTables. <MASKED_ACRONYM> uses a recent pre-trained LM, DeBERTaV3, and further pre- trains it on our corpus. Our experimental results show that <MASKED_ACRONYM> achieves new state-of-the-art (SOTA) performance on two table-based fact verification datasets TabFact and SEM-TAB- FACTS. In particular, on the complex set of TabFact, which contains multiple operations, <MASKED_ACRONYM> largely outperforms previous SOTA by 4.7% (85.6% vs. 80.9%), and the gap between <MASKED_ACRONYM> and human performance on the small test set is narrowed to just 1.5% (90.6% vs. 92.1%).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SEEN","Description":"Structured Event Enhancement Network for Explainable Need Detection of Information Recall Assistance","Abstract":"When recalling life experiences, people often forget or confuse life events, which necessitates information recall services. Previous work on information recall focuses on providing such assistance reactively, i.e., by retrieving the life event of a given query. Proactively detecting the need for information recall services is rarely discussed. In this paper, we use a human-annotated life experience retelling dataset to detect the right time to trigger the information recall service. We propose a pilot model\u2014structured event enhancement network (<MASKED_ACRONYM>) that detects life event inconsistency, additional information in life events, and forgotten events. A fusing mechanism is also proposed to incorporate event graphs of stories and enhance the textual representations. To explain the need detection results, <MASKED_ACRONYM> simultaneously provides support evidence by selecting the related nodes from the event graph. Experimental results show that <MASKED_ACRONYM> achieves promising performance in detecting information needs. In addition, the extracted evidence can be served as complementary information to remind users what events they may want to recall.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"RACE","Description":"Retrieval-augmented Commit Message Generation","Abstract":"Commit messages are important for software development and maintenance. Many neural network-based approaches have been proposed and shown promising results on automatic commit message generation. However, the generated commit messages could be repetitive or redundant. In this paper, we propose <MASKED_ACRONYM>, a new retrieval-augmented neural commit message generation method, which treats the retrieved similar commit as an exemplar and leverages it to generate an accurate commit message. As the retrieved commit message may not always accurately describe the content\/intent of the current code diff, we also propose an exemplar guider, which learns the semantic similarity between the retrieved and current code diff and then guides the generation of commit message based on the similarity. We conduct extensive experiments on a large public dataset with five programming languages. Experimental results show that <MASKED_ACRONYM> can outperform all baselines. Furthermore, <MASKED_ACRONYM> can boost the performance of existing Seq2Seq models in commit message generation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"GHAN","Description":"Graph-Based Hierarchical Aggregation Network for Text-Video Retrieval","Abstract":"Text-video retrieval focuses on two aspects: cross-modality interaction and video-language encoding. Currently, the mainstream approach is to train a joint embedding space for multimodal interactions. However, there are structural and semantic differences between text and video, making this approach challenging for fine-grained understanding. In order to solve this, we propose an end-to-end graph-based hierarchical aggregation network for text-video retrieval according to the hierarchy possessed by text and video. We design a token-level weighted network to refine intra-modality representations and construct a graph-based message passing attention network for global-local alignment across modality. We conduct experiments on the public datasets MSR-VTT-9K, MSR-VTT-7K and MSVD, and achieve Recall@1 of 73.0%, 65.6%, and 64.0% , which is 25.7%, 16.5%, and 14.2% better than the current state-of-the-art model.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"ATTEMPT","Description":"Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts","Abstract":"This work introduces a new multi-task, parameter-efficient language model (LM) tuning method that learns to transfer knowledge across different tasks via a mixture of soft prompts\u2014small prefix embedding vectors pre-trained for different tasks. Our method, called <MASKED_ACRONYM> (ATTEntional Mixtures of Prompt Tuning), obtains source prompts as encodings of large-scale source tasks into a small number of parameters and trains an attention module to interpolate the source prompts and a newly initialized target prompt for every instance in the target task. During training, only the target task prompt and the attention weights, which are shared between tasks in multi-task training, are updated, while the original LM and source prompts are intact. <MASKED_ACRONYM> is highly parameter-efficient (e.g., updates 2,300 times fewer parameters than full fine-tuning), while it overcomes instability of prompt tuning and achieves high task performance using learned knowledge from high-resource tasks. Moreover, it is modular using pre-trained soft prompts, and can flexibly add or remove source prompts for effective knowledge transfer. Our experimental results across 21 diverse NLP datasets show that <MASKED_ACRONYM> significantly outperforms prompt tuning and outperforms or matches fully fine-tuned or other parameter-efficient tuning approaches that use 10 times more parameters. Finally, <MASKED_ACRONYM> outperforms previous work in few-shot learning settings.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"TranSHER","Description":"Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction","Abstract":"Knowledge graph embedding methods are important for the knowledge graph completion (or link prediction) task. One state-of-the-art method, PairRE, leverages two separate vectors to model complex relations (i.e., 1-to-N, N-to-1, and N-to-N) in knowledge graphs. However, such a method strictly restricts entities on the hyper-ellipsoid surfaces which limits the optimization of entity distribution, leading to suboptimal performance of knowledge graph completion. To address this issue, we propose a novel score function <MASKED_ACRONYM>, which leverages relation-specific translations between head and tail entities to relax the constraint of hyper-ellipsoid restrictions. By introducing an intuitive and simple relation-specific translation, <MASKED_ACRONYM> can provide more direct guidance on optimization and capture more semantic characteristics of entities with complex relations. Experimental results show that <MASKED_ACRONYM> achieves state-of-the-art performance on link prediction and generalizes well to datasets in different domains and scales. Our codes are public available at <a href=https:\/\/github.com\/yizhilll\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/yizhilll\/<MASKED_ACRONYM><\/a>.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.875}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"FETA","Description":"A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue","Abstract":"Task transfer, transferring knowledge contained in related tasks, holds the promise of reducing the quantity of labeled data required to fine-tune language models. Dialogue understanding encompasses many diverse tasks, yet task transfer has not been thoroughly studied in conversational AI. This work explores conversational task transfer by introducing <MASKED_ACRONYM>: a benchmark for FEw-sample TAsk transfer in open-domain dialogue.<MASKED_ACRONYM> contains two underlying sets of conversations upon which there are 10 and 7 tasks annotated, enabling the study of intra-dataset task transfer; task transfer without domain adaptation. We utilize three popular language models and three learning algorithms to analyze the transferability between 132 source-target task pairs and create a baseline for future work. We run experiments in the single- and multi-source settings and report valuable findings, e.g., most performance trends are model-specific, and span extraction and multiple-choice tasks benefit the most from task transfer. In addition to task transfer, <MASKED_ACRONYM> can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SHARE","Description":"a System for Hierarchical Assistive Recipe Editing","Abstract":"The large population of home cooks with dietary restrictions is under-served by existing cooking resources and recipe generation models. To help them, we propose the task of controllable recipe editing: adapt a base recipe to satisfy a user-specified dietary constraint. This task is challenging, and cannot be adequately solved with human-written ingredient substitution rules or existing end-to-end recipe generation models. We tackle this problem with <MASKED_ACRONYM>: a System for Hierarchical Assistive Recipe Editing, which performs simultaneous ingredient substitution before generating natural-language steps using the edited ingredients. By decoupling ingredient and step editing, our step generator can explicitly integrate the available ingredients. Experiments on the novel RecipePairs dataset\u201483K pairs of similar recipes where each recipe satisfies one of seven dietary constraints\u2014demonstrate that <MASKED_ACRONYM> produces convincing, coherent recipes that are appropriate for a target dietary constraint. We further show through human evaluations and real-world cooking trials that recipes edited by <MASKED_ACRONYM> can be easily followed by home cooks to create appealing dishes.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"COLD","Description":"A Benchmark for Chinese Offensive Language Detection","Abstract":"Offensive language detection is increasingly crucial for maintaining a civilized social media platform and deploying pre-trained language models. However, this task in Chinese is still under exploration due to the scarcity of reliable datasets. To this end, we propose a benchmark \u2013<MASKED_ACRONYM> for Chinese offensive language analysis, including a Chinese Offensive Language Dataset \u2013<MASKED_ACRONYM>ATASET and a baseline detector \u2013<MASKED_ACRONYM>ETECTOR which is trained on the dataset. We show that the <MASKED_ACRONYM> benchmark contributes to Chinese offensive language detection which is challenging for existing resources. We then deploy the <MASKED_ACRONYM>ETECTOR and conduct detailed analyses on popular Chinese pre-trained language models. We first analyze the offensiveness of existing generative models and show that these models inevitably expose varying degrees of offensive issues. Furthermore, we investigate the factors that influence the offensive generations, and we find that anti-bias contents and keywords referring to certain groups or revealing negative attitudes trigger offensive outputs easier.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SPE","Description":"Symmetrical Prompt Enhancement for Fact Probing","Abstract":"Pretrained language models (PLMs) have been shown to accumulate factual knowledge during pretraining (Petroni et al. 2019). Recent works probe PLMs for the extent of this knowledge through prompts either in discrete or continuous forms. However, these methods do not consider symmetry of the task: object prediction and subject prediction. In this work, we propose Symmetrical Prompt Enhancement (<MASKED_ACRONYM>), a continuous prompt-based method for factual probing in PLMs that leverages the symmetry of the task by constructing symmetrical prompts for subject and object prediction. Our results on a popular factual probing dataset, LAMA, show significant improvement of <MASKED_ACRONYM> over previous probing methods.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"PAR","Description":"Political Actor Representation Learning with Social Context and Expert Knowledge","Abstract":"Modeling the ideological perspectives of political actors is an essential task in computational political science with applications in many downstream tasks. Existing approaches are generally limited to textual data and voting records, while they neglect the rich social context and valuable expert knowledge for holistic ideological analysis. In this paper, we propose <MASKED_ACRONYM>, a Political Actor Representation learning framework that jointly leverages social context and expert knowledge. Specifically, we retrieve and extract factual statements about legislators to leverage social context information. We then construct a heterogeneous information network to incorporate social context and use relational graph neural networks to learn legislator representations. Finally, we train <MASKED_ACRONYM> with three objectives to align representation learning with expert knowledge, model ideological stance consistency, and simulate the echo chamber phenomenon. Extensive experiments demonstrate that <MASKED_ACRONYM> is better at augmenting political text understanding and successfully advances the state-of-the-art in political perspective detection and roll call vote prediction. Further analysis proves that <MASKED_ACRONYM> learns representations that reflect the political reality and provide new insights into political behavior.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SPEAR","Description":"Semi-supervised Data Programming in Python","Abstract":"We present <MASKED_ACRONYM>, an open-source python library for data programming with semi supervision. The package implements several recent data programming approaches including facility to programmatically label and build training data. <MASKED_ACRONYM> facilitates weak supervision in the form of heuristics (or rules) and association of noisy labels to the training dataset. These noisy labels are aggregated to assign labels to the unlabeled data for downstream tasks. We have implemented several label aggregation approaches that aggregate the noisy labels and then train using the noisily labeled set in a cascaded manner. Our implementation also includes other approaches that jointly aggregate and train the model for text classification tasks. Thus, in our python package, we integrate several cascade and joint data-programming approaches while also providing the facility of data programming by letting the user define labeling functions or rules. The code and tutorial notebooks are available at <a href=https:\/\/github.com\/decile-team\/spear class=acl-markup-url>https:\/\/github.com\/decile-team\/spear<\/a>. Further, extensive documentation can be found at <a href=https:\/\/spear-decile.readthedocs.io\/ class=acl-markup-url>https:\/\/spear-decile.readthedocs.io\/<\/a>. Video tutorials demonstrating the usage of our package are available <a href=\"https:\/\/youtube.com\/playlist?list=PLW8agt_HvkVnOJoJAqBpaerFb-z-ZlqlP\" class=acl-markup-url>https:\/\/youtube.com\/playlist?list=PLW8agt_HvkVnOJoJAqBpaerFb-z-ZlqlP<\/a>. We also present some real-world use cases of <MASKED_ACRONYM>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"AGReE","Description":"A system for generating Automated Grammar Reading Exercises","Abstract":"We describe the <MASKED_ACRONYM> system, which takes user-submitted passages as input and automatically generates grammar practice exercises that can be completed while reading. Multiple-choice practice items are generated for a variety of different grammar constructs: punctuation, articles, conjunctions, pronouns, prepositions, verbs, and nouns. We also conducted a large-scale human evaluation with around 4,500 multiple-choice practice items. We notice for 95% of items, a majority of raters out of five were able to identify the correct answer, for 85% of cases, raters agree that there is only one correct answer among the choices. Finally, the error analysis shows that raters made the most mistakes for punctuation and conjunctions.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"ACCoRD","Description":"A Multi-Document Approach to Generating Diverse Descriptions of Scientific Concepts","Abstract":"Systems that automatically define unfamiliar terms hold the promise of improving the accessibility of scientific texts, especially for readers who may lack prerequisite background knowledge. However, current systems assume a single \u201cbest\u201d description per concept, which fails to account for the many ways a concept can be described. We present <MASKED_ACRONYM>, an end-to-end system tackling the novel task of generating sets of descriptions of scientific concepts. Our system takes advantage of the myriad ways a concept is mentioned across the scientific literature to produce distinct, diverse descriptions oftarget concepts in terms of different reference concepts. In a user study, we find that users prefer (1) descriptions produced by our end-to-end system, and (2) multiple descriptions to a single \u201cbest\u201d description. We release the <MASKED_ACRONYM> corpus which includes 1,275 labeled contexts and 1,787 expert-authored concept descriptions to support research on our task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"MIC","Description":"A Multi-task Interactive Curation Tool","Abstract":"This paper introduces <MASKED_ACRONYM>, a Multi-task Interactive Curation tool, a human-machine collaborative curation tool for multiple NLP tasks. The tool aims to borrow recent advances in literature to solve pain-points in real NLP tasks. Firstly, it supports multiple projects with multiple users which enables collaborative annotations. Secondly, <MASKED_ACRONYM> allows easy integration of pre-trained models, rules, and dictionaries to auto label the text and speed up the labeling process. Thirdly, <MASKED_ACRONYM> supports annotation at different scales (span of characters and words, tokens and lines, or document) and different types (free text, sentence labels, entity labels, and relationship triplets) with easy GUI operations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"POTATO","Description":"The Portable Text Annotation Tool","Abstract":"We present <MASKED_ACRONYM>, the Portable text annotation tool, a free, fully open-sourced annotation system that 1) supports labeling many types of text and multimodal data; 2) offers easy-to-configure features to maximize the productivity of both deployers and annotators (convenient templates for common ML\/NLP tasks, active learning, keypress shortcuts, keyword highlights, tooltips); and 3) supports a high degree of customization (editable UI, inserting pre-screening questions, attention and qualification tests). Experiments over two annotation tasks suggest that <MASKED_ACRONYM> improves labeling speed through its specially-designed productivity features, especially for long documents and complex tasks. <MASKED_ACRONYM> is available at <a href=https:\/\/github.com\/davidjurgens\/potato class=acl-markup-url>https:\/\/github.com\/davidjurgens\/potato<\/a> and will continue to be updated.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SEAL","Description":"Interactive Tool for Systematic Error Analysis and Labeling","Abstract":"With the advent of Transformers, large language models (LLMs) have saturated well-known NLP benchmarks and leaderboards with high aggregate performance. However, many times these models systematically fail on tail data or rare groups not obvious in aggregate evaluation. Identifying such problematic data groups is even more challenging when there are no explicit labels (e.g., ethnicity, gender, etc.) and further compounded for NLP datasets due to the lack of visual features to characterize failure modes (e.g., Asian males, animals indoors, waterbirds on land etc.). This paper introduces an interactive Systematic Error Analysis and Labeling (<MASKED_ACRONYM>) tool that uses a two-step approach to first identify high-error slices of data and then, in the second step, introduce methods to give human-understandable semantics to those underperforming slices. We explore a variety of methods for coming up with coherent semantics for the error groups using language models for semantic labeling and a text-to-image model for generating visual features.<MASKED_ACRONYM> is available at <a href=https:\/\/huggingface.co\/spaces\/nazneen\/seal class=acl-markup-url>https:\/\/huggingface.co\/spaces\/nazneen\/seal<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SLATE","Description":"A Sequence Labeling Approach for Task Extraction from Free-form Inked Content","Abstract":"We present <MASKED_ACRONYM>, a sequence labeling approach for extracting tasks from free-form content such as digitally handwritten (or \u201cinked\u201d) notes on a virtual whiteboard. Our approach allows us to create a single, low-latency model to simultaneously perform sentence segmentation and classification of these sentences into task\/non-task sentences. <MASKED_ACRONYM> greatly outperforms a baseline two-model (sentence segmentation followed by classification model) approach, achieving a task F1 score of 84.4%, a sentence segmentation (boundary similarity) score of 88.4% and three times lower latency compared to the baseline. Furthermore, we provide insights into tackling challenges of performing NLP on the inking domain. We release both our code and dataset for this novel task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"PILE","Description":"Pairwise Iterative Logits Ensemble for Multi-Teacher Labeled Distillation","Abstract":"Pre-trained language models have become a crucial part of ranking systems and achieved very impressive effects recently. To maintain high performance while keeping efficient computations, knowledge distillation is widely used. In this paper, we focus on two key questions in knowledge distillation for ranking models: 1) how to ensemble knowledge from multi-teacher; 2) how to utilize the label information of data in the distillation process. We propose a unified algorithm called Pairwise Iterative Logits Ensemble (<MASKED_ACRONYM>) to tackle these two questions simultaneously. <MASKED_ACRONYM> ensembles multi-teacher logits supervised by label information in an iterative way and achieved competitive performance in both offline and online experiments. The proposed method has been deployed in a real-world commercial search system.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"Grape","Description":"Knowledge Graph Enhanced Passage Reader for Open-domain Question Answering","Abstract":"A common thread of open-domain question answering (QA) models employs a retriever-reader pipeline that first retrieves a handful of relevant passages from Wikipedia and then peruses the passages to produce an answer. However, even state-of-the-art readers fail to capture the complex relationships between entities appearing in questions and retrieved passages, leading to answers that contradict the facts. In light of this, we propose a novel knowledge graph enhanced passage reader, namely <MASKED_ACRONYM>, to improve the reader performance for open-domain QA. Specifically, for each pair of question and retrieved passage, we first construct a localized bipartite graph, attributed to entity embeddings extracted from the intermediate layer of the reader model. Then, a graph neural network learns relational knowledge while fusing graph and contextual representations into the hidden states of the reader model. Experiments on three open-domain QA benchmarks show <MASKED_ACRONYM> can improve the state-of-the-art performance by up to 2.2 exact match score with a negligible overhead increase, with the same retriever and retrieved passages. Our code is publicly available at <a href=https:\/\/github.com\/jumxglhf\/GRAPE class=acl-markup-url>https:\/\/github.com\/jumxglhf\/GRAPE<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"LEMON","Description":"Language-Based Environment Manipulation via Execution-Guided Pre-training","Abstract":"Language-based environment manipulation requires agents to manipulate the environment following natural language instructions, which is challenging due to the huge space of the environments. To address this challenge, various approaches have been proposed in recent work. Although these approaches work well for their intended environments, they are difficult to generalize across environments. In this work, we propose <MASKED_ACRONYM>, a general framework for language-based environment manipulation tasks. Specifically, we first specify a general approach for language-based environment manipulation tasks, which can deal with various environments using the same generative language model. Then we propose an execution-guided pre-training strategy to inject prior knowledge of environments to the language model with a pure synthetic pre-training corpus. Experimental results on tasks including Alchemy, Scene, Tangrams, ProPara and Recipes demonstrate the effectiveness of <MASKED_ACRONYM>: it achieves new state-of-the-art results on four of the tasks, and the execution-guided pre-training strategy brings remarkable improvements on all experimental tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"CARE","Description":"Causality Reasoning for Empathetic Responses by Conditional Graph Generation","Abstract":"Recent approaches to empathetic response generation incorporate emotion causalities to enhance comprehension of both the user\u2019s feelings and experiences. However, these approaches suffer from two critical issues. First, they only consider causalities between the user\u2019s emotion and the user\u2019s experiences, and ignore those between the user\u2019s experiences. Second, they neglect interdependence among causalities and reason them independently. To solve the above problems, we expect to reason all plausible causalities interdependently and simultaneously, given the user\u2019s emotion, dialogue history, and future dialogue content. Then, we infuse these causalities into response generation for empathetic responses. Specifically, we design a new model, i.e., the Conditional Variational Graph Auto-Encoder (CVGAE), for the causality reasoning, and adopt a multi-source attention mechanism in the decoder for the causality infusion. We name the whole framework as <MASKED_ACRONYM>, abbreviated for CAusality Reasoning for Empathetic conversation. Experimental results indicate that our method achieves state-of-the-art performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"ARTIST","Description":"A Transformer-based Chinese Text-to-Image Synthesizer Digesting Linguistic and World Knowledge","Abstract":"Text-to-Image Synthesis (TIS) is a popular task to convert natural language texts into realistic images. Recently, transformer-based TIS models (such as DALL-E) have been proposed using the encoder-decoder architectures. Yet, these billion-scale TIS models are difficult to tune and deploy in resource-constrained environments. In addition, there is a lack of language-specific TIS benchmarks for Chinese, together with high-performing models with moderate sizes. In this work, we present <MASKED_ACRONYM>, A tRansformer-based Chinese Text-to-Image SynThesizer for high-resolution image generation. In <MASKED_ACRONYM>, the rich linguistic and relational knowledge facts are injected into the model to ensure better model performance without the usage of ultra-large models. We further establish a large-scale Chinese TIS benchmark with the re-production results of state-of-the-art transformer-based TIS models. Results show <MASKED_ACRONYM> outperforms previous approaches.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"TranS","Description":"Transition-based Knowledge Graph Embedding with Synthetic Relation Representation","Abstract":"Knowledge graph embedding (KGE) aims to learn continuous vector representations of relations and entities in knowledge graph (KG). Recently, transition-based KGE methods have become popular and achieved promising performance. However, scoring patterns like TransE are not suitable for complex scenarios where the same entity pair has different relations. Although some models attempt to employ entity-relation interaction or projection to improve entity representation for one-to-many\/many-to-one\/many-to-many complex relations, they still continue the traditional scoring pattern, where only a single relation vector in the relation part is used to translate the head entity to the tail entity or their variants. And recent research shows that entity representation only needs to consider entities and their interactions to achieve better performance. Thus, in this paper, we propose a novel transition-based method, <MASKED_ACRONYM>, for KGE. The single relation vector of the relation part in the traditional scoring pattern is replaced by the synthetic relation representation with entity-relation interactions to solve these issues. And the entity part still retains its independence through entity-entity interactions. Experiments on a large KG dataset, ogbl-wikikg2, show that our model achieves state-of-the-art results.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"STAR","Description":"SQL Guided Pre-Training for Context-dependent Text-to-SQL Parsing","Abstract":"In this paper, we propose a novel SQL guided pre-training framework <MASKED_ACRONYM> for context-dependent text-to-SQL parsing, which leverages contextual information to enrich natural language (NL) utterance and table schema representations for text-to-SQL conversations. Concretely, we propose two novel pre-training objectives which respectively explore the context-dependent interactions of NL utterances and SQL queries within each text-to-SQL conversation: (i) schema state tracking (SST) objective that tracks and explores the schema states of context-dependent SQL queries in the form of schema-states by predicting and updating the value of each schema slot during interaction; (ii) utterance dependency tracking (UDT) objective that employs weighted contrastive learning to pull together two semantically similar NL utterances and push away the representations of semantically dissimilar NL utterances within each conversation. In addition, we construct a high-quality large-scale context-dependent text-to-SQL conversation corpus to pre-train <MASKED_ACRONYM>. Extensive experiments show that <MASKED_ACRONYM> achieves new state-of-the-art performance on two downstream benchmarks (SParC and CoSQL), significantly outperforming previous pre-training methods and ranking first on the leaderboard. We believe the release of the constructed corpus, codebase and pre-trained <MASKED_ACRONYM> checkpoints would push forward the research in this area.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"CORE","Description":"A Retrieve-then-Edit Framework for Counterfactual Data Generation","Abstract":"Counterfactual data augmentation (CDA) \u2013 i.e., adding minimally perturbed inputs during training \u2013 helps reduce model reliance on spurious correlations and improves generalization to out-of-distribution (OOD) data. Prior work on generating counterfactuals only considered restricted classes of perturbations, limiting their effectiveness. We present Counterfactual Generation via Retrieval and Editing (<MASKED_ACRONYM>), a retrieval-augmented generation framework for creating diverse counterfactual perturbations for CDA. For each training example, <MASKED_ACRONYM> first performs a dense retrieval over a task-related unlabeled text corpus using a learned bi-encoder and extracts relevant counterfactual excerpts. <MASKED_ACRONYM> then incorporates these into prompts to a large language model with few-shot learning capabilities, for counterfactual editing. Conditioning language model edits on naturally occurring data results in more diverse perturbations. Experiments on natural language inference and sentiment analysis benchmarks show that <MASKED_ACRONYM> counterfactuals are more effective at improving generalization to OOD data compared to other DA approaches. We also show that the <MASKED_ACRONYM> retrieval framework can be used to encourage diversity in manually authored perturbations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"RaP","Description":"Redundancy-aware Video-language Pre-training for Text-Video Retrieval","Abstract":"Video language pre-training methods have mainly adopted sparse sampling techniques to alleviate the temporal redundancy of videos. Though effective, sparse sampling still suffers inter-modal redundancy: visual redundancy and textual redundancy. Compared with highly generalized text, sparsely sampled frames usually contain text-independent portions, called visual redundancy. Sparse sampling is also likely to miss important frames corresponding to some text portions, resulting in textual redundancy. Inter-modal redundancy leads to a mismatch of video and text information, hindering the model from better learning the shared semantics across modalities. To alleviate it, we propose Redundancy-aware Video-language Pre-training. We design a redundancy measurement of video patches and text tokens by calculating the cross-modal minimum dis-similarity. Then, we penalize the high-redundant video patches and text tokens through a proposed redundancy-aware contrastive learning. We evaluate our method on four benchmark datasets, MSRVTT, MSVD, DiDeMo, and LSMDC, achieving a significant improvement over the previous state-of-the-art results.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SMiLE","Description":"Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction","Abstract":"Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (<MASKED_ACRONYM>) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. The implementation of <MASKED_ACRONYM> is available at <a href=https:\/\/github.com\/GKNL\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/GKNL\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"SMASH","Description":"Improving SMAll Language Models&#39; Few-SHot Ability with Prompt-Based Distillation","Abstract":"Large-scale language models coupled with prompts have shown remarkable performance on few-shot learning. However, through systematic experiments, we find that the few-shot performance of small language models is poor, and using prompts on them brings fewer improvements than on larger ones. In this paper, we propose <MASKED_ACRONYM>, an approach to improve SMAll language models\u2019 few-SHot ability by training on intermediate tasks before prompt-based fine-tuning on downstream tasks. We design intermediate tasks for sentence-pair tasks and sentiment classification tasks by creating training examples with prompt templates similar to downstream tasks using sentences sampled from a large-scale unsupervised corpus, and apply knowledge distillation to distill from outputs of larger pre-trained models as the training objective. We conduct extensive experiments and show that <MASKED_ACRONYM> can make a 6-layer DistilRoBRETa-base achieve comparable performance on few-shot datasets with a 12-layer RoBERTa-base at a low cost.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"emnlp-2022","Acronym":"TransLIST","Description":"A Transformer-Based Linguistically Informed Sanskrit Tokenizer","Abstract":"Sanskrit Word Segmentation (SWS) is essential in making digitized texts available and in deploying downstream tasks. It is, however, non-trivial because of the sandhi phenomenon that modifies the characters at the word boundaries, and needs special treatment. Existing lexicon driven approaches for SWS make use of Sanskrit Heritage Reader, a lexicon-driven shallow parser, to generate the complete candidate solution space, over which various methods are applied to produce the most valid solution. However, these approaches fail while encountering out-of-vocabulary tokens. On the other hand, purely engineering methods for SWS have made use of recent advances in deep learning, but cannot make use of the latent word information on availability. To mitigate the shortcomings of both families of approaches, we propose Transformer based Linguistically Informed Sanskrit Tokenizer (<MASKED_ACRONYM>) consisting of (1) a module that encodes the character input along with latent-word information, which takes into account the sandhi phenomenon specific to SWS and is apt to work with partial or no candidate solutions, (2) a novel soft-masked attention to prioritize potential candidate words and (3) a novel path ranking algorithm to rectify the corrupted predictions. Experiments on the benchmark datasets for SWS show that <MASKED_ACRONYM> outperforms the current state-of-the-art system by an average 7.2 points absolute gain in terms of perfect match (PM) metric.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.875}
{"Year":2021,"Venue":"sustainlp-2021","Acronym":"Distiller","Description":"A Systematic Study of Model Distillation Methods in Natural Language Processing","Abstract":"Knowledge Distillation (KD) offers a natural way to reduce the latency and memory\/energy usage of massive pretrained models that have come to dominate Natural Language Processing (NLP) in recent years. While numerous sophisticated variants of KD algorithms have been proposed for NLP applications, the key factors underpinning the optimal distillation performance are often confounded and remain unclear. We aim to identify how different components in the KD pipeline affect the resulting performance and how much the optimal KD pipeline varies across different datasets\/tasks, such as the data augmentation policy, the loss function, and the intermediate representation for transferring the knowledge between teacher and student. To tease apart their effects, we propose <MASKED_ACRONYM>, a meta KD framework that systematically combines a broad range of techniques across different stages of the KD pipeline, which enables us to quantify each component\u2019s contribution. Within <MASKED_ACRONYM>, we unify commonly used objectives for distillation of intermediate representations under a universal mutual information (MI) objective and propose a class of MI-objective functions with better bias\/variance trade-off for estimating the MI between the teacher and the student. On a diverse set of NLP datasets, the best <MASKED_ACRONYM> configurations are identified via large-scale hyper-parameter optimization. Our experiments reveal the following: 1) the approach used to distill the intermediate representations is the most important factor in KD performance, 2) among different objectives for intermediate distillation, MI-performs the best, and 3) data augmentation provides a large boost for small training datasets or small student networks. Moreover, we find that different datasets\/tasks prefer different KD algorithms, and thus propose a simple Auto<MASKED_ACRONYM> algorithm that can recommend a good KD pipeline for a new dataset.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.9473684211}
{"Year":2018,"Venue":"coling-2018","Acronym":"SeVeN","Description":"Augmenting Word Embeddings with Unsupervised Relation Vectors","Abstract":"We present <MASKED_ACRONYM> (Semantic Vector Networks), a hybrid resource that encodes relationships between words in the form of a graph. Different from traditional semantic networks, these relations are represented as vectors in a continuous vector space. We propose a simple pipeline for learning such relation vectors, which is based on word vector averaging in combination with an ad hoc autoencoder. We show that by explicitly encoding relational information in a dedicated vector space we can capture aspects of word meaning that are complementary to what is captured by word embeddings. For example, by examining clusters of relation vectors, we observe that relational similarities can be identified at a more abstract level than with traditional word vector differences. Finally, we test the effectiveness of semantic vector networks in two tasks: measuring word similarity and neural text categorization. <MASKED_ACRONYM> is available at bitbucket.org\/luisespinosa\/seven.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2008,"Venue":"acl-2008","Acronym":"SIDE","Description":"The Summarization Integrated Development Environment","Abstract":"In this type-II demo, we introduce <MASKED_ACRONYM>1 (the  Summarization Integrated Development Environment), an infrastructure that facilitates  construction of summaries tailored to the  needs of the user. It aims to address the issue  that there is no such thing as the perfect summary for all purposes. Rather, the quality of a  summary is subjective, task dependent, and  possibly specific to a user. The <MASKED_ACRONYM> framework allows users flexibility in determining  what they find more useful in a summary,  both in terms of structure and content. As an  educational tool, it has been successfully user  tested by a class of 21 students in a graduate  course on Summarization and Personal Information Management.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2009,"Venue":"naacl-2009","Acronym":"STAT","Description":"Speech Transcription Analysis Tool","Abstract":"The Speech Transcription Analysis Tool  (<MASKED_ACRONYM>) is an open source tool for aligning  and comparing two phonetically transcribed  texts of human speech.  The output analysis is  a parameterized set of phonological differences.  These differences are based upon a selectable set of binary phonetic features such as  [voice], [continuant], [high], etc.  <MASKED_ACRONYM> was  initially  designed  to  provide  sets  of  phonological speech patterns in the comparisons of various English accents found in the  Speech Accent Archive http:\/\/accent.gmu.edu,  but its scope and utility expand to matters of  language assessment, phonetic training, forensic linguistics, and speech recognition.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2006,"Venue":"coling-2006","Acronym":"ARE","Description":"Instance Splitting Strategies for Dependency Relation-Based Information Extraction","Abstract":"Information Extraction (IE) is a fundamental technology for NLP. Previous methods  for IE were relying on co-occurrence relations, soft patterns and properties of the  target (for example, syntactic role), which  result in problems of handling paraphrasing  and alignment of instances. Our system  <MASKED_ACRONYM> (Anchor and Relation) is based on the  dependency relation model and tackles  these problems by unifying entities according to their dependency relations, which we  found to provide more invariant relations  between entities in many cases. In order to  exploit the complexity and characteristics  of relation paths, we further classify the relation paths into the categories of \u2018easy\u2019,  \u2018average\u2019 and \u2018hard\u2019, and utilize different  extraction strategies based on the characteristics of those categories. Our extraction  method leads to improvement in performance by 3% and 6% for MUC4 and MUC6  respectively as compared to the state-of-art  IE systems.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2006,"Venue":"coling-2006","Acronym":"URES","Description":"an Unsupervised Web Relation Extraction System","Abstract":"Most information extraction systems either use hand written extraction patterns  or use a machine learning algorithm that  is trained on a manually annotated corpus. Both of these approaches require  massive human effort and hence prevent  information extraction from becoming  more widely applicable. In this paper we  present <MASKED_ACRONYM> (Unsupervised Relation  Extraction System), which extracts relations from the Web in a totally unsupervised way. It takes as input the  descriptions of the target relations, which  include the names of the predicates, the  types of their attributes, and several seed  instances of the relations. Then the system downloads from the Web a large collection of pages that are likely to contain  instances of the target relations. From  those pages, utilizing the known seed instances, the system learns the relation  patterns, which are then used for extraction. We present several experiments in  which we learn patterns and extract instances of a set of several common IE relations,  comparing  several  pattern  learning and filtering setups. We demonstrate that using simple noun phrase tagger is sufficient as a base for accurate  patterns. However, having a named entity recognizer, which is able to recognize the types of the relation attributes  significantly, enhances the extraction  performance. We also compare our approach with KnowItAll\u2019s fixed generic  patterns.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"starsem-2022","Acronym":"AnaLog","Description":"Testing Analytical and Deductive Logic Learnability in Language Models","Abstract":"We investigate the extent to which pre-trained language models acquire analytical and deductive logical reasoning capabilities as a side effect of learning word prediction. We present <MASKED_ACRONYM>, a natural language inference task designed to probe models for these capabilities, controlling for different invalid heuristics the models may adopt instead of learning the desired generalisations. We test four languagemodels on <MASKED_ACRONYM>, finding that they have all learned, to a different extent, to encode information that is predictive of entailment beyond shallow heuristics such as lexical overlap and grammaticality. We closely analyse the best performing language model and show that while it performs more consistently than other language models across logical connectives and reasoning domains, it still is sensitive to lexical and syntactic variations in the realisation of logical statements.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.9230769231}
{"Year":2021,"Venue":"acl-2021","Acronym":"PENS","Description":"A Dataset and Generic Framework for Personalized News Headline Generation","Abstract":"In this paper, we formulate the personalized news headline generation problem whose goal is to output a user-specific title based on both a user\u2019s reading interests and a candidate news body to be exposed to her. To build up a benchmark for this problem, we publicize a large-scale dataset named <MASKED_ACRONYM> (PErsonalized News headlineS). The training set is collected from user impressions logs of Microsoft News, and the test set is manually created by hundreds of native speakers to enable a fair testbed for evaluating models in an offline mode. We propose a generic framework as a preparatory solution to our problem. At its heart, user preference is learned by leveraging the user behavioral data, and three kinds of user preference injections are proposed to personalize a text generator and establish personalized headlines. We investigate our dataset by implementing several state-of-the-art user modeling methods in our framework to demonstrate a benchmark score for the proposed dataset. The dataset is available at <a href=https:\/\/msnews.github.io\/pens.html class=acl-markup-url>https:\/\/msnews.github.io\/pens.html<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"BoB","Description":"BERT Over BERT for Training Persona-based Dialogue Models from Limited Personalized Data","Abstract":"Maintaining a consistent persona is essential for dialogue agents. Although tremendous advancements have been brought, the limited-scale of annotated personalized dialogue datasets is still a barrier towards training robust and consistent persona-based dialogue models. This work shows how this challenge can be addressed by disentangling persona-based dialogue generation into two sub-tasks with a novel BERT-over-BERT (<MASKED_ACRONYM>) model. Specifically, the model consists of a BERT-based encoder and two BERT-based decoders, where one decoder is for response generation, and another is for consistency understanding. In particular, to learn the ability of consistency understanding from large-scale non-dialogue inference data, we train the second decoder in an unlikelihood manner. Under different limited data settings, both automatic and human evaluations demonstrate that the proposed model outperforms strong baselines in response quality and persona consistency.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"PASS","Description":"Perturb-and-Select Summarizer for Product Reviews","Abstract":"The product reviews summarization task aims to automatically produce a short summary for a set of reviews of a given product. Such summaries are expected to aggregate a range of different opinions in a concise, coherent and informative manner. This challenging task gives rise to two shortcomings in existing work. First, summarizers tend to favor generic content that appears in reviews for many different products, resulting in template-like, less informative summaries. Second, as reviewers often disagree on the pros and cons of a given product, summarizers sometimes yield inconsistent, self-contradicting summaries. We propose the <MASKED_ACRONYM> system (Perturb-and-Select Summarizer) that employs a large pre-trained Transformer-based model (T5 in our case), which follows a few-shot fine-tuning scheme. A key component of the <MASKED_ACRONYM> system relies on applying systematic perturbations to the model\u2019s input during inference, which allows it to generate multiple different summaries per product. We develop a method for ranking these summaries according to desired criteria, coherence in our case, enabling our system to almost entirely avoid the problem of self-contradiction. We compare our system against strong baselines on publicly available datasets, and show that it produces summaries which are more informative, diverse and coherent.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"COSY","Description":"COunterfactual SYntax for Cross-Lingual Understanding","Abstract":"Pre-trained multilingual language models, e.g., multilingual-BERT, are widely used in cross-lingual tasks, yielding the state-of-the-art performance. However, such models suffer from a large performance gap between source and target languages, especially in the zero-shot setting, where the models are fine-tuned only on English but tested on other languages for the same task. We tackle this issue by incorporating language-agnostic information, specifically, universal syntax such as dependency relations and POS tags, into language models, based on the observation that universal syntax is transferable across different languages. Our approach, called COunterfactual SYntax (<MASKED_ACRONYM>), includes the design of SYntax-aware networks as well as a COunterfactual training method to implicitly force the networks to learn not only the semantics but also the syntax. To evaluate <MASKED_ACRONYM>, we conduct cross-lingual experiments on natural language inference and question answering using mBERT and XLM-R as network backbones. Our results show that <MASKED_ACRONYM> achieves the state-of-the-art performance for both tasks, without using auxiliary training data.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2021,"Venue":"acl-2021","Acronym":"COINS","Description":"Dynamically Generating COntextualized Inference Rules for Narrative Story Completion","Abstract":"Despite recent successes of large pre-trained language models in solving reasoning tasks, their inference capabilities remain opaque. We posit that such models can be made more interpretable by explicitly generating interim inference rules, and using them to guide the generation of task-specific textual outputs. In this paper we present Coins, a recursive inference framework that i) iteratively reads context sentences, ii) dynamically generates contextualized inference rules, encodes them, and iii) uses them to guide task-specific output generation. We apply to a <i>Narrative Story Completion<\/i> task that asks a model to complete a story with missing sentences, to produce a coherent story with plausible logical connections, causal relationships, and temporal dependencies. By modularizing inference and sentence generation steps in a recurrent model, we aim to make reasoning steps and their effects on next sentence generation transparent. Our automatic and manual evaluations show that the model generates better story sentences than SOTA baselines, especially in terms of coherence. We further demonstrate improved performance over strong pre-trained LMs in generating commonsense inference rules. The recursive nature of holds the potential for controlled generation of longer sequences.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"DVD","Description":"A Diagnostic Dataset for Multi-step Reasoning in Video Grounded Dialogue","Abstract":"A video-grounded dialogue system is required to understand both dialogue, which contains semantic dependencies from turn to turn, and video, which contains visual cues of spatial and temporal scene variations. Building such dialogue systems is a challenging problem, involving various reasoning types on both visual and language inputs. Existing benchmarks do not have enough annotations to thoroughly analyze dialogue systems and understand their capabilities and limitations in isolation. These benchmarks are also not explicitly designed to minimise biases that models can exploit without actual reasoning. To address these limitations, in this paper, we present <MASKED_ACRONYM>, a Diagnostic Dataset for Video-grounded Dialogue. The dataset is designed to contain minimal biases and has detailed annotations for the different types of reasoning over the spatio-temporal space of video. Dialogues are synthesized over multiple question turns, each of which is injected with a set of cross-turn semantic relationships. We use <MASKED_ACRONYM> to analyze existing approaches, providing interesting insights into their abilities and limitations. In total, <MASKED_ACRONYM> is built from 11k CATER synthetic videos and contains 10 instances of 10-round dialogues for each video, resulting in more than 100k dialogues and 1M question-answer pairs. Our code and dataset are publicly available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"BASS","Description":"Boosting Abstractive Summarization with Unified Semantic Graph","Abstract":"ive summarization for long-document or multi-document remains challenging for the Seq2Seq architecture, as Seq2Seq is not good at analyzing long-distance relations in text. In this paper, we present <MASKED_ACRONYM>, a novel framework for Boosting ive Summarization based on a unified Semantic graph, which aggregates co-referent phrases distributing across a long range of context and conveys rich relations between phrases. Further, a graph-based encoder-decoder model is proposed to improve both the document representation and summary generation process by leveraging the graph structure. Specifically, several graph augmentation methods are designed to encode both the explicit and implicit relations in the text while the graph-propagation attention mechanism is developed in the decoder to select salient content into the summary. Empirical results show that the proposed architecture brings substantial improvements for both long-document and multi-document summarization tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"SENT","Description":"Sentence-level Distant Relation Extraction via Negative Training","Abstract":"Distant supervision for relation extraction provides uniform bag labels for each sentence inside the bag, while accurate sentence labels are important for downstream applications that need the exact relation type. Directly using bag labels for sentence-level training will introduce much noise, thus severely degrading performance. In this work, we propose the use of negative training (NT), in which a model is trained using complementary labels regarding that \u201cthe instance does not belong to these complementary labels\u201d. Since the probability of selecting a true label as a complementary label is low, NT provides less noisy information. Furthermore, the model trained with NT is able to separate the noisy data from the training data. Based on NT, we propose a sentence-level framework, <MASKED_ACRONYM>, for distant relation extraction. <MASKED_ACRONYM> not only filters the noisy data to construct a cleaner dataset, but also performs a re-labeling process to transform the noisy data into useful training data, thus further benefiting the model\u2019s performance. Experimental results show the significant improvement of the proposed method over previous methods on sentence-level evaluation and de-noise effect.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"EmailSum","Description":"Abstractive Email Thread Summarization","Abstract":"Recent years have brought about an interest in the challenging task of summarizing conversation threads (meetings, online discussions, etc.). Such summaries help analysis of the long text to quickly catch up with the decisions made and thus improve our work or communication efficiency. To spur research in thread summarization, we have developed an abstractive Email Thread Summarization (<MASKED_ACRONYM>) dataset, which contains human-annotated short (&lt;30 words) and long (&lt;100 words) summaries of 2,549 email threads (each containing 3 to 10 emails) over a wide variety of topics. We perform a comprehensive empirical study to explore different summarization techniques (including extractive and abstractive methods, single-document and hierarchical models, as well as transfer and semisupervised learning) and conduct human evaluations on both short and long summary generation tasks. Our results reveal the key challenges of current abstractive summarization models in this task, such as understanding the sender\u2019s intent and identifying the roles of sender and receiver. Furthermore, we find that widely used automatic evaluation metrics (ROUGE, BERTScore) are weakly correlated with human judgments on this email thread summarization task. Hence, we emphasize the importance of human evaluation and the development of better metrics by the community.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"acl-2021","Acronym":"ADEPT","Description":"An Adjective-Dependent Plausibility Task","Abstract":"A false contract is more likely to be rejected than a contract is, yet a false key is less likely than a key to open doors. While correctly interpreting and assessing the effects of such adjective-noun pairs (e.g., false key) on the plausibility of given events (e.g., opening doors) underpins many natural language understanding tasks, doing so often requires a significant degree of world knowledge and common-sense reasoning. We introduce <MASKED_ACRONYM> \u2013 a large-scale semantic plausibility task consisting of over 16 thousand sentences that are paired with slightly modified versions obtained by adding an adjective to a noun. Overall, we find that while the task appears easier for human judges (85% accuracy), it proves more difficult for transformer-based models like RoBERTa (71% accuracy). Our experiments also show that neither the adjective itself nor its taxonomic class suffice in determining the correct plausibility judgement, emphasizing the importance of endowing automatic natural language understanding systems with more context sensitivity and common-sense reasoning.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"ROPE","Description":"Reading Order Equivariant Positional Encoding for Graph-based Document Information Extraction","Abstract":"Natural reading orders of words are crucial for information extraction from form-like documents. Despite recent advances in Graph Convolutional Networks (GCNs) on modeling spatial layout patterns of documents, they have limited ability to capture reading orders of given word-level node representations in a graph. We propose Reading Order Equivariant Positional Encoding (<MASKED_ACRONYM>), a new positional encoding technique designed to apprehend the sequential presentation of words in documents. <MASKED_ACRONYM> generates unique reading order codes for neighboring words relative to the target word given a word-level graph connectivity. We study two fundamental document entity extraction tasks including word labeling and word grouping on the public FUNSD dataset and a large-scale payment dataset. We show that <MASKED_ACRONYM> consistently improves existing GCNs with a margin up to 8.4% F1-score.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"VAULT","Description":"VAriable Unified Long Text Representation for Machine Reading Comprehension","Abstract":"Existing models on Machine Reading Comprehension (MRC) require complex model architecture for effectively modeling long texts with paragraph representation and classification, thereby making inference computationally inefficient for production use. In this work, we propose <MASKED_ACRONYM>: a light-weight and parallel-efficient paragraph representation for MRC based on contextualized representation from long document input, trained using a new Gaussian distribution-based objective that pays close attention to the partially correct instances that are close to the ground-truth. We validate our <MASKED_ACRONYM> architecture showing experimental results on two benchmark MRC datasets that require long context modeling; one Wikipedia-based (Natural Questions (NQ)) and the other on TechNotes (TechQA). <MASKED_ACRONYM> can achieve comparable performance on NQ with a state-of-the-art (SOTA) complex document modeling approach while being 16 times faster, demonstrating the efficiency of our proposed model. We also demonstrate that our model can also be effectively adapted to a completely different domain \u2013 TechQA \u2013 with large improvement over a model fine-tuned on a previously published large PLM.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"SOLID","Description":"A Large-Scale Semi-Supervised Dataset for Offensive Language Identification","Abstract":"The widespread use of offensive content in social media has led to an abundance of research in detecting language such as hate speech, cyberbullying, and cyber-aggression. Recent work presented the OLID dataset, which follows a taxonomy for offensive language identi\ufb01cation that provides meaningful information for understanding the type and the target of offensive messages. However, it is limited in size and it might be biased towards offensive language as it was collected using keywords. In this work, we present <MASKED_ACRONYM>, an expanded dataset, where the tweets were collected in a more principled manner. <MASKED_ACRONYM> contains over nine million English tweets labeled in a semisupervised fashion. We demonstrate that using <MASKED_ACRONYM> along with OLID yields sizable performance gains on the OLID test set for two different models, especially for the lower levels of the taxonomy.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"Fusion","Description":"Towards Automated ICD Coding via Feature Compression","Abstract":"ICD coding aims to automatically assign International Classification of Diseases (ICD) codes from unstructured clinical notes or discharge summaries, which saves human labor and reduces errors. Although several studies are proposed to solve this challenging task, none distinguishes the importance of different phrases with a word window. Intuitively, informative phrases should be useful for the prediction. This paper proposes a feature compressed ICD coding model named <MASKED_ACRONYM> to address this issue. In particular, we propose an attentive soft-pooling approach to compress the sparse and redundant word representations into informative and dense ones as local features. Next, we use the key-query attention mechanism for modeling the inner relations among local features to generate the global features, which are further used to predict ICD codes. Experiments on two widely used datasets demonstrate that <MASKED_ACRONYM> is comparable with baselines. We also find that none of the state-of-the-art approaches significantly perform better than others. Thus, automated ICD coding is still a challenging task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"PAIR","Description":"Leveraging Passage-Centric Similarity Relation for Improving Dense Passage Retrieval","Abstract":"Recently, dense passage retrieval has become a mainstream approach to \ufb01nding relevant information in various natural language processing tasks. A number of studies have been devoted to improving the widely adopted dual-encoder architecture. However, most of the previous studies only consider query-centric similarity relation when learning the dual-encoder retriever. In order to capture more comprehensive similarity relations, we propose a novel approach that leverages both query-centric and PAssage-centric sImilarity Relations (called <MASKED_ACRONYM>) for dense passage retrieval. To implement our approach, we make three major technical contributions by introducing formal formulations of the two kinds of similarity relations, generating high-quality pseudo labeled data via knowledge distillation, and designing an effective two-stage training procedure that incorporates passage-centric similarity relation constraint. Extensive experiments show that our approach signi\ufb01cantly outperforms previous state-of-the-art models on both MSMARCO and Natural Questions datasets1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"WIND","Description":"Weighting Instances Differentially for Model-Agnostic Domain Adaptation","Abstract":"Domain Adaptation is a fundamental problem in machine learning and natural language processing. In this paper, we study the domain adaptation problem from the perspective of instance weighting. Conventional instance weighting approaches cannot learn the weights which make the model generalize well in target domain. To tackle this problem, inspired by meta-learning, we formulate the domain adaptation problem as a bi-level optimization problem, and propose a novel differentiable modelagnostic instance weighting algorithm. Our proposed approach can automatically learn the instance weights instead of using manually designed weighting metrics. To reduce the computational complexity, we adopt the secondorder approximation technique during training. Experimental results1 on three different NLP tasks (Sentiment Classi\ufb01cation, Neural Machine Translation and Relation Extraction) illustrate the ef\ufb01cacy of our proposed method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"GEM","Description":"A General Evaluation Benchmark for Multimodal Tasks","Abstract":"In this paper, we present <MASKED_ACRONYM>1 as a General Evaluation benchmark for Multimodal tasks. Different from existing datasets such as GLUE (Wang et al., 2018), SuperGLUE (Wang et al., 2019), XGLUE (Liang et al., 2020) and XTREME (Hu et al., 2020) that mainly focus on natural language tasks, <MASKED_ACRONYM> is a largescale vision-language benchmark, which consists of <MASKED_ACRONYM>-I for image-language tasks and <MASKED_ACRONYM>-V for video-language tasks. Comparing with existing multimodal datasets such as MSCOCO (Chen et al., 2015) and Flicker30K (Vinyals et al., 2015) for image-language tasks, YouCook2 (Zhou et al., 2018) and MSR-VTT (Xu et al., 2016) for video-language tasks, <MASKED_ACRONYM> is not only the largest vision-language dataset covering image-language tasks and video-language tasks at the same time, but also labeled in multiple languages. We also provide two baseline models for this benchmark. We will release the dataset, code and baseline models, aiming to advance the development of multilingual multimodal research.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"AgreeSum","Description":"Agreement-Oriented Multi-Document Summarization","Abstract":"We aim to renew interest in a particular multidocument summarization (MDS) task which we call <MASKED_ACRONYM>: agreement-oriented multidocument summarization. Given a cluster of articles, the goal is to provide abstractive summaries that represent information common and faithful to all input articles. Given the lack of existing datasets, we create a dataset for <MASKED_ACRONYM>, and provide annotations on article-summary entailment relations for a subset of the clusters in the dataset. We aim to create strong baselines for the task by applying the top-performing pretrained singledocument summarization model PEGASUS onto <MASKED_ACRONYM>, leveraging both annotated clusters by supervised losses, and unannotated clusters by T5-based entailment-related and language-related losses. Compared to other baselines, both automatic evaluation and human evaluation show better article-summary and cluster-summary entailment in generated summaries. On a separate note, we hope that our article-summary entailment annotations contribute to the community\u2019s effort in improving abstractive summarization faithfulness.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"acl-2021","Acronym":"PROST","Description":"Physical Reasoning about Objects through Space and Time","Abstract":"We present a new probing dataset named <MASKED_ACRONYM>: Physical Reasoning about Objects Through Space and Time. This dataset contains 18,736 multiple-choice questions made from 14 manually curated templates, covering 10 physical reasoning concepts. All questions are designed to probe both causal and masked language models in a zero-shot setting. We conduct an extensive analysis which demonstrates that state-of-the-art pretrained models are inadequate at physical reasoning: they are influenced by the order in which answer options are presented to them, they struggle when the superlative in a question is inverted (e.g., most \u2194 least), and increasing the amount of pretraining data and parameters only yields minimal improvements. These results provide support for the hypothesis that current pretrained models\u2019 ability to reason about physical interactions is inherently limited by a lack of real world experience. By highlighting these limitations, we hope to motivate the development of models with a human-like understanding of the physical world.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2021,"Venue":"acl-2021","Acronym":"DialogSum","Description":"A Real-Life Scenario Dialogue Summarization Dataset","Abstract":"Proposal of large-scale datasets has facilitated research on deep neural models for news summarization. Deep learning can also be potentially useful for spoken dialogue summarization, which can bene\ufb01t a range of reallife scenarios including customer service management and medication tracking. To this end, we propose DIALOGSUM, a large-scale labeled dialogue summarization dataset. We conduct empirical analysis on DIALOGSUM using state-of-the-art neural summarizers. Experimental results show unique challenges in dialogue summarization, such as spoken terms, special discourse structures, coreferences and ellipsis, pragmatics and social common sense, which require speci\ufb01c representation learning technologies to better deal with.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2021,"Venue":"acl-2021","Acronym":"GOT","Description":"Testing for Originality in Natural Language Generation","Abstract":"We propose an approach to automatically test for originality in generation tasks where no standard automatic measures exist. Our proposal addresses original uses of language, not necessarily original ideas. We provide an algorithm for our approach and a run-time analysis. The algorithm, which finds all of the original fragments in a ground-truth corpus and can reveal whether a generated fragment copies an original without attribution, has a run-time complexity of theta(nlogn) where n is the number of sentences in the ground truth.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"PIE","Description":"A Parallel Idiomatic Expression Corpus for Idiomatic Sentence Generation and Paraphrasing","Abstract":"Idiomatic expressions (IE) play an important role in natural language, and have long been a \u201cpain in the neck\u201d for NLP systems. Despite this, text generation tasks related to IEs remain largely under-explored. In this paper, we propose two new tasks of idiomatic sentence generation and paraphrasing to fill this research gap. We introduce a curated dataset of 823 IEs, and a parallel corpus with sentences containing them and the same sentences where the IEs were replaced by their literal paraphrases as the primary resource for our tasks. We benchmark existing deep learning models, which have state-of-the-art performance on related tasks using automated and manual evaluation with our dataset to inspire further research on our proposed tasks. By establishing baseline models, we pave the way for more comprehensive and accurate modeling of IEs, both for generation and paraphrasing.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"acl-2021","Acronym":"ViTA","Description":"Visual-Linguistic Translation by Aligning Object Tags","Abstract":"Multimodal Machine Translation (MMT) enriches the source text with visual information for translation. It has gained popularity in recent years, and several pipelines have been proposed in the same direction. Yet, the task lacks quality datasets to illustrate the contribution of visual modality in the translation systems. In this paper, we propose our system under the team name Volta for the Multimodal Translation Task of WAT 2021 from English to Hindi. We also participate in the textual-only subtask of the same language pair for which we use mBART, a pretrained multilingual sequence-to-sequence model. For multimodal translation, we propose to enhance the textual input by bringing the visual information to a textual domain by extracting object tags from the image. We also explore the robustness of our system by systematically degrading the source text. Finally, we achieve a BLEU score of 44.6 and 51.6 on the test set and challenge set of the multimodal task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2014,"Venue":"amta-2014","Acronym":"QuEst","Description":"A framework for translation quality estimation","Abstract":"We present QUEST, an open source framework for translation quality estimation. QUEST provides a wide range of feature extractors from source and translation texts and external resources and tools. These go from simple, language-independent features, to advanced, linguistically motivated features. They include features that rely on information from the translation system and features that are oblivious to the way translations were produced. In addition, it provides wrappers for a well-known machine learning toolkit, scikit-learn, including techniques for feature selection and model building, as well as parameter optimisation. We also present a Web interface and functionalities for non-expert users. Using this interface, quality predictions (or internal features of the framework) can be obtained without the installation of the toolkit and the building of prediction models. The interface also provides a ranking method for multiple translations given for the same source text according to their predicted quality.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"wmt-2022","Acronym":"REUSE","Description":"REference-free UnSupervised Quality Estimation Metric","Abstract":"This paper describes our submission to the WMT2022 shared metrics task. Our unsupervised metric estimates the translation quality at chunk-level and sentence-level. Source and target sentence chunks are retrieved by using a multi-lingual chunker. The chunk-level similarity is computed by leveraging BERT contextual word embeddings and sentence similarity scores are calculated by leveraging sentence embeddings of Language-Agnostic BERT models. The final quality estimation score is obtained by mean pooling the chunk-level and sentence-level similarity scores. This paper outlines our experiments and also reports the correlation with human judgements for en-de, en-ru and zh-en language pairs of WMT17, WMT18 and WMT19 test sets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"inlg-2020","Acronym":"ExTRA","Description":"Explainable Therapy-Related Annotations","Abstract":"In this paper we report progress on a novel explainable artificial intelligence (XAI) initiative applying Natural Language Processing (NLP) with elements of codesign to develop a text classifier for application in psychotherapy training. The task is to produce a tool that will facilitate therapists to review their sessions by automatically labelling transcript text with levels of interaction for patient activation in known psychological processes, using XAI to increase their trust in the model\u2019s suggestions and client trajectory predictions. After pre-processing of the language features extracted from professionally annotated therapy session transcripts, we apply a supervised machine learning approach (CHAID) to classify interaction labels (negative, neutral, positive). Weighted samples are used to overcome class imbalanced data. The results show this initial model can make useful distinctions among the three labels of patient activation with 74% accuracy and provide insight into its reasoning. This ongoing project will additionally evaluate which XAI approaches can be used to increase the transparency of the tool to end users, exploring whether direct involvement of stakeholders improves usability of the XAI interface and therefore trust in the solution.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"lrec-2014","Acronym":"ROOTS","Description":"a toolkit for easy, fast and consistent processing of large sequential annotated data collections","Abstract":"The development of new methods for given speech and natural language processing tasks usually consists in annotating large corpora of data before applying machine learning techniques to train models or to extract information. Beyond scientific aspects, creating and managing such annotated data sets is a recurrent problem. While using human annotators is obviously expensive in time and money, relying on automatic annotation processes is not a simple solution neither. Typically, the high diversity of annotation tools and of data formats, as well as the lack of efficient middleware to interface them all together, make such processes very complex and painful to design. To circumvent this problem, this paper presents the toolkit <MASKED_ACRONYM>, a freshly released open source toolkit (<a href=http:\/\/roots-toolkit.gforge.inria.fr class=acl-markup-url>http:\/\/roots-toolkit.gforge.inria.fr<\/a>) for easy, fast and consistent management of heterogeneously annotated data. <MASKED_ACRONYM> is designed to efficiently handle massive complex sequential data and to allow quick and light prototyping, as this is often required for research purposes. To illustrate these properties, three sample applications are presented in the field of speech and language processing, though <MASKED_ACRONYM> can more generally be easily extended to other application domains.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"lrec-2014","Acronym":"GRASS","Description":"the Graz corpus of Read And Spontaneous Speech","Abstract":"This paper provides a description of the preparation, the speakers, the recordings, and the creation of the orthographic transcriptions of the first large scale speech database for Austrian German. It contains approximately 1900 minutes of (read and spontaneous) speech produced by 38 speakers. The corpus consists of three components. First, the Conversation Speech (CS) component contains free conversations of one hour length between friends, colleagues, couples, or family members. Second, the Commands Component (CC) contains commands and keywords which were either read or elicited by pictures. Third, the Read Speech (RS) component contains phonetically balanced sentences and digits. The speech of all components has been recorded at super-wideband quality in a soundproof recording-studio with head-mounted microphones, large-diaphragm microphones, a laryngograph, and with a video camera. The orthographic transcriptions, which have been created and subsequently corrected manually, contain approximately 290 000 word tokens from 15 000 different word types.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"DIRECT","Description":"Direct and Indirect Responses in Conversational Text Corpus","Abstract":"We create a large-scale dialogue corpus that provides pragmatic paraphrases to advance technology for understanding the underlying intentions of users. While neural conversation models acquire the ability to generate fluent responses through training on a dialogue corpus, previous corpora have mainly focused on the literal meanings of utterances. However, in reality, people do not always present their intentions directly. For example, if a person said to the operator of a reservation service \u201cI don\u2019t have enough budget.\u201d, they, in fact, mean \u201cplease find a cheaper option for me.\u201d Our corpus provides a total of 71,498 indirect\u2013direct utterance pairs accompanied by a multi-turn dialogue history extracted from the MultiWoZ dataset. In addition, we propose three tasks to benchmark the ability of models to recognize and generate indirect and direct utterances. We also investigated the performance of state-of-the-art pre-trained models as baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"REBEL","Description":"Relation Extraction By End-to-end Language generation","Abstract":"Extracting relation triplets from raw text is a crucial task in Information Extraction, enabling multiple applications such as populating or validating knowledge bases, factchecking, and other downstream tasks. However, it usually involves multiple-step pipelines that propagate errors or are limited to a small number of relation types. To overcome these issues, we propose the use of autoregressive seq2seq models. Such models have previously been shown to perform well not only in language generation, but also in NLU tasks such as Entity Linking, thanks to their framing as seq2seq tasks. In this paper, we show how Relation Extraction can be simplified by expressing triplets as a sequence of text and we present <MASKED_ACRONYM>, a seq2seq model based on BART that performs end-to-end relation extraction for more than 200 different relation types. We show our model\u2019s flexibility by fine-tuning it on an array of Relation Extraction and Relation Classification benchmarks, with it attaining state-of-the-art performance in most of them.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"MeLT","Description":"Message-Level Transformer with Masked Document Representations as Pre-Training for Stance Detection","Abstract":"Much of natural language processing is focused on leveraging large capacity language models, typically trained over single messages with a task of predicting one or more tokens. However, modeling human language at higher-levels of context (i.e., sequences of messages) is under-explored. In stance detection and other social media tasks where the goal is to predict an attribute of a message, we have contextual data that is loosely semantically connected by authorship. Here, we introduce Message-Level Transformer (<MASKED_ACRONYM>) \u2013 a hierarchical message-encoder pre-trained over Twitter and applied to the task of stance prediction. We focus on stance prediction as a task benefiting from knowing the context of the message (i.e., the sequence of previous messages). The model is trained using a variant of masked-language modeling; where instead of predicting tokens, it seeks to generate an entire masked (aggregated) message vector via reconstruction loss. We find that applying this pre-trained masked message-level transformer to the downstream task of stance detection achieves F1 performance of 67%.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"MURAL","Description":"Multimodal, Multitask Representations Across Languages","Abstract":"Both image-caption pairs and translation pairs provide the means to learn deep representations of and connections between languages. We use both types of pairs in <MASKED_ACRONYM> (MUltimodal, MUltitask Representations Across Languages), a dual encoder that solves two tasks: 1) image-text matching and 2) translation pair matching. By incorporating billions of translation pairs, <MASKED_ACRONYM> extends ALIGN (Jia et al.)\u2013a state-of-the-art dual encoder learned from 1.8 billion noisy image-text pairs. When using the same encoders, <MASKED_ACRONYM>\u2019s performance matches or exceeds ALIGN\u2019s cross-modal retrieval performance on well-resourced languages across several datasets. More importantly, it considerably improves performance on under-resourced languages, showing that text-text learning can overcome a paucity of image-caption examples for these languages. On the Wikipedia Image-Text dataset, for example, <MASKED_ACRONYM>-base improves zero-shot mean recall by 8.1% on average for eight under-resourced languages and by 6.8% on average when fine-tuning. We additionally show that <MASKED_ACRONYM>\u2019s text representations cluster not only with respect to genealogical connections but also based on areal linguistics, such as the Balkan Sprachbund.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"TAG","Description":"Gradient Attack on Transformer-based Language Models","Abstract":"Although distributed learning has increasingly gained attention in terms of effectively utilizing local devices for data privacy enhancement, recent studies show that publicly shared gradients in the training process can reveal the private training data (gradient leakage) to a third-party. We have, however, no systematic understanding of the gradient leakage mechanism on the Transformer based language models. In this paper, as the first attempt, we formulate the gradient attack problem on the Transformer-based language models and propose a gradient attack algorithm, <MASKED_ACRONYM>, to reconstruct the local training data. Experimental results on Transformer, TinyBERT4, TinyBERT6 BERT_BASE, and BERT_LARGE using GLUE benchmark show that compared with DLG, <MASKED_ACRONYM> works well on more weight distributions in reconstructing training data and achieves 1.5x recover rate and 2.5x ROUGE-2 over prior methods without the need of ground truth label. <MASKED_ACRONYM> can obtain up to 90% data by attacking gradients in CoLA dataset. In addition, <MASKED_ACRONYM> is stronger than previous approaches on larger models, smaller dictionary size, and smaller input length. We hope the proposed <MASKED_ACRONYM> will shed some light on the privacy leakage problem in Transformer-based NLP models.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"ARCH","Description":"Efficient Adversarial Regularized Training with Caching","Abstract":"Adversarial regularization can improve model generalization in many natural language processing tasks. However, conventional approaches are computationally expensive since they need to generate a perturbation for each sample in each epoch. We propose a new adversarial regularization method <MASKED_ACRONYM> (adversarial regularization with caching), where perturbations are generated and cached once every several epochs. As caching all the perturbations imposes memory usage concerns, we adopt a K-nearest neighbors-based strategy to tackle this issue. The strategy only requires caching a small amount of perturbations, without introducing additional training time. We evaluate our proposed method on a set of neural machine translation and natural language understanding tasks. We observe that <MASKED_ACRONYM> significantly eases the computational burden (saves up to 70% of computational time in comparison with conventional approaches). More surprisingly, by reducing the variance of stochastic gradients, <MASKED_ACRONYM> produces a notably better (in most of the tasks) or comparable model generalization. Our code is publicly available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"findings-2021","Acronym":"NICE","Description":"Neural Image Commenting with Empathy","Abstract":"Emotion and empathy are examples of human qualities lacking in many human-machine interactions. The goal of our work is to generate engaging dialogue grounded in a user-shared image with increased emotion and empathy while minimizing socially inappropriate or offensive outputs. We release the Neural Image Commenting with Empathy (<MASKED_ACRONYM>) dataset consisting of almost two million images and the corresponding human-generated comments, a set of human annotations, and baseline performance on a range of models. In-stead of relying on manually labeled emotions, we also use automatically generated linguistic representations as a source of weakly supervised labels. Based on these annotations, we define two different tasks for the <MASKED_ACRONYM> dataset. Then, we propose a novel pre-training model - Modeling Affect Generation for Image Comments (MAGIC) - which aims to generate comments for images, conditioned on linguistic representations that capture style and affect, and to help generate more empathetic, emotional, engaging and socially appropriate comments. Using this model we achieve state-of-the-art performance on one of our <MASKED_ACRONYM> tasks. The experiments show that the approach can generate more human-like and engaging image comments.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2008,"Venue":"ws-2008","Acronym":"ProPOSEL","Description":"a human-oriented prosody and PoS English lexicon for machine-learning and NLP","Abstract":"<MASKED_ACRONYM> is a prosody and PoS English lexicon,  purpose-built to integrate and leverage domain  knowledge from several well-established lexical  resources for machine learning and NLP applications. The lexicon of 104049 separate entries is  in accessible text file format, is human and machine-readable, and is intended for open source  distribution with the Natural Language ToolKit.  It is therefore supported by Python software tools  which transform <MASKED_ACRONYM> into a Python dictionary or associative array of linguistic concepts  mapped to compound lookup keys. Users can  also conduct searches on a subset of the lexicon  and access entries by word class, phonetic transcription, syllable count and lexical stress pattern. <MASKED_ACRONYM> caters for a range of different  cognitive aspects of the lexicon\uf6d9.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.9333333333}
{"Year":2013,"Venue":"naacl-2013","Acronym":"DALE","Description":"A Word Sense Disambiguation System for Biomedical Documents Trained using Automatically Labeled Examples","Abstract":"Automatic interpretation of documents is hampered by the fact that language contains terms which have multiple meanings. These ambiguities can still be found when language is restricted to a particular domain, such as biomedicine. Word Sense Disambiguation (WSD) systems attempt to resolve these ambiguities but are often only able to identify the meanings for a small set of ambiguous terms. <MASKED_ACRONYM> (Disambiguation using Automatically Labeled Examples) is a supervised WSD system that can disambiguate a wide range of ambiguities found in biomedical documents. <MASKED_ACRONYM> uses the UMLS Metathesaurus as both a sense inventory and as a source of information for automatically generating labeled training examples. <MASKED_ACRONYM> is able to disambiguate biomedical documents with the coverage of unsupervised approaches and accuracy of supervised methods.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2004,"Venue":"ws-2004","Acronym":"BioGrapher","Description":"Biography Questions as a Restricted Domain Question Answering Task","Abstract":"We address Question Answering (QA) for biographical questions, i.e., questions asking for biographical facts about persons. The domain of biographical documents differs from other restricted domains in that the available collections of biographies are inherently incomplete: a major challenge is to answer questions about persons for whom biographical information is not present in biography collections. We present <MASKED_ACRONYM>, a biographical QA system that addresses this problem by machine learning algorithms for biography classi\ufb01cation. <MASKED_ACRONYM> \ufb01rst attempts to answer a question by searching in a given collection of biographies, using techniques tailored for the restricted nature of the domain. If a biography is not found, <MASKED_ACRONYM> attempts to \ufb01nd an answer on the web: it retrieves documents using a web search engine, \ufb01lters these using the biography classi\ufb01er, and then extracts answers from documents classi\ufb01ed as biographies. Our empirical results show that biographical classi\ufb01cation, prior to answer extraction, improves the results.","wordlikeness":0.9,"lcsratio":1.0,"wordcoverage":0.8421052632}
{"Year":2022,"Venue":"ws-2022","Acronym":"ANTS","Description":"A Framework for Retrieval of Text Segments in Unstructured Documents","Abstract":"Text segmentation and extraction from unstructured documents can provide business researchers with a wealth of new information on firms and their behaviors. However, the most valuable text is often difficult to extract consistently due to substantial variations in how content can appear from document to document. Thus, the most successful way to extract this content has been through costly crowdsourcing and training of manual workers. We propose the Assisted Neural Text Segmentation (<MASKED_ACRONYM>) framework to identify pertinent text in unstructured documents from a small set of labeled examples. <MASKED_ACRONYM> leverages deep learning and transfer learning architectures to empower researchers to identify relevant text with minimal manual coding. Using a real world sample of accounting documents, we identify targeted sections 96% of the time using only 5 training examples.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"ws-2022","Acronym":"ANNA","Description":"Enhanced Language Representation for Question Answering","Abstract":"Pre-trained language models have brought significant improvements in performance in a variety of natural language processing tasks. Most existing models performing state-of-the-art results have shown their approaches in the separate perspectives of data processing, pre-training tasks, neural network modeling, or fine-tuning. In this paper, we demonstrate how the approaches affect performance individually, and that the language model performs the best results on a specific question answering task when those approaches are jointly considered in pre-training models. In particular, we propose an extended pre-training task, and a new neighbor-aware mechanism that attends neighboring tokens more to capture the richness of context for pre-training language modeling. Our best model achieves new state-of-the-art results of 95.7% F1 and 90.6% EM on SQuAD 1.1 and also outperforms existing pre-trained language models such as RoBERTa, ALBERT, ELECTRA, and XLNet on the SQuAD 2.0 benchmark.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"ws-2022","Acronym":"TransPOS","Description":"Transformers for Consolidating Different POS Tagset Datasets","Abstract":"In hope of expanding training data, researchers often want to merge two or more datasets that are created using different labeling schemes. This paper considers two datasets that label part-of-speech (POS) tags under different tagging schemes and leverage the supervised labels of one dataset to help generate labels for the other dataset. This paper further discusses the theoretical difficulties of this approach and proposes a novel supervised architecture employing Transformers to tackle the problem of consolidating two completely disjoint datasets. The results diverge from initial expectations and discourage exploration into the use of disjoint labels to consolidate datasets with different labels.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2011,"Venue":"ranlp-2011","Acronym":"Agreement","Description":"How to Reach it? Defining Language Features Leading to Agreement in Discourse","Abstract":"Consensus is the desired result in many argumentative discourses such as negotiations,  public debates, and goal-oriented forums.  However, due to the fact that usually people  are poor arguers, a support of argumentation is  necessary. Web-2 provides means for the online discussions which have their characteristic  features.  In our paper we study the features of  discourse which lead to agreement. We use an  argumentative corpus of Wikipedia discussions in order to investigate the influence of  discourse structure and language on the final  agreement. The corpus had been annotated  with rhetorical relations and rhetorical structures leading to successful and unsuccessful  discussions were analyzed. We also investigated language patterns extracted from the  corpus in order to discover which ones are indicators of the following agreement. The results of our study can be used in system designing, whose purpose is to assist on-line interlocutors in consensus building.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"wanlp-2017","Acronym":"CAT","Description":"Credibility Analysis of Arabic Content on Twitter","Abstract":"Data generated on Twitter has become a rich source for various data mining tasks. Those data analysis tasks that are dependent on the tweet semantics, such as sentiment analysis, emotion mining, and rumor detection among others, suffer considerably if the tweet is not credible, not real, or spam. In this paper, we perform an extensive analysis on credibility of Arabic content on Twitter. We also build a classification model (<MASKED_ACRONYM>) to automatically predict the credibility of a given Arabic tweet. Of particular originality is the inclusion of features extracted directly or indirectly from the author\u2019s profile and timeline. To train and test <MASKED_ACRONYM>, we annotated for credibility a data set of 9,000 Arabic tweets that are topic independent. <MASKED_ACRONYM> achieved consistent improvements in predicting the credibility of the tweets when compared to several baselines and when compared to the state-of-the-art approach with an improvement of 21% in weighted average F-measure. We also conducted experiments to highlight the importance of the user-based features as opposed to the content-based features. We conclude our work with a feature reduction experiment that highlights the best indicative features of credibility.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ws-2023","Acronym":"NEXT","Description":"An Event Schema Extension Approach for Closed-Domain Event Extraction Models","Abstract":"Event extraction from textual data is a NLP research task relevant to a plethora of domains. Most approaches aim to recognize events from a predefined event schema, consisting of event types and their corresponding arguments. For domains, such as disinformation, where new event types emerge frequently, there is a need to adapt such fixed event schemas to accommodate for new event types. We present <MASKED_ACRONYM> (New Event eXTraction) - a resource-sparse approach to extending a close-domain model to novel event types, that requires a very small number of annotated samples for fine-tuning performed on a single GPU. Furthermore, our results suggest that this approach is suitable not only for extraction of new event types, but also for recognition of existing event types, as the use of this approach on a new dataset leads to improved recall for all existing events while retaining precision.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ws-2023","Acronym":"SIGHT","Description":"A Large Annotated Dataset on Student Insights Gathered from Higher Education Transcripts","Abstract":"Lectures are a learning experience for both students and teachers. Students learn from teachers about the subject material, while teachers learn from students about how to refine their instruction. Unfortunately, online student feedback is unstructured and abundant, making it challenging for teachers to learn and improve. We take a step towards tackling this challenge. First, we contribute a dataset for studying this problem: <MASKED_ACRONYM> is a large dataset of 288 math lecture transcripts and 15,784 comments collected from the Massachusetts Institute of Technology OpenCourseWare (MIT OCW) YouTube channel. Second, we develop a rubric for categorizing feedback types using qualitative analysis. Qualitative analysis methods are powerful in uncovering domain-specific insights, however they are costly to apply to large data sources. To overcome this challenge, we propose a set of best practices for using large language models (LLMs) to cheaply classify the comments at scale. We observe a striking correlation between the model\u2019s and humans\u2019 annotation: Categories with consistent human annotations (0.9 inter-rater reliability, IRR) also display higher human-model agreement (0.7), while categories with less consistent human annotations (0.7-0.8 IRR) correspondingly demonstrate lower human-model agreement (0.3-0.5). These techniques uncover useful student feedback from thousands of comments, costing around $0.002 per comment. We conclude by discussing exciting future directions on using online student feedback and improving automated annotation techniques for qualitative research.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ws-2023","Acronym":"DISTANT","Description":"Distantly Supervised Entity Span Detection and Classification","Abstract":"We propose a distantly supervised pipeline NER which executes entity span detection and entity classification in sequence named <MASKED_ACRONYM> (DIstantly Supervised enTity spAN deTection and classification).The former entity span detector extracts possible entity mention spans by the distant supervision. Then the later entity classifier assigns each entity span to one of the positive entity types or none by employing a positive and unlabeled (PU) learning framework. Two models were built based on the pre-trained SciBERT model and fine-tuned with the silver corpus generated by the distant supervision. Experimental results on BC5CDR and NCBI-Disease datasets show that our method outperforms the end-to-end NER baselines without PU learning by a large margin. In particular, it increases the recall score effectively.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ws-2023","Acronym":"COFFEE","Description":"A Contrastive Oracle-Free Framework for Event Extraction","Abstract":"Event extraction is a complex task that involves extracting events from unstructured text. Prior classification-based methods require comprehensive entity annotations for joint training, while newer generation-based methods rely on heuristic templates containing oracle information such as event type, which is often unavailable in real-world scenarios. In this study, we consider a more realistic task setting, namely the Oracle-Free Event Extraction (OFEE) task, where only the input context is given, without any oracle information including event type, event ontology, or trigger word. To address this task, we propose a new framework, <MASKED_ACRONYM>. This framework extracts events solely based on the document context, without referring to any oracle information. In particular, <MASKED_ACRONYM> introduces a contrastive selection model to refine the generated triggers and handle multi-event instances. Our proposed <MASKED_ACRONYM> outperforms state-of-the-art approaches in the oracle-free setting of the event extraction task, as evaluated on two public variants of the ACE05 benchmark. The code used in our study has been made publicly available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ws-2023","Acronym":"ADEPT","Description":"Adapter-based Efficient Prompt Tuning Approach for Language Models","Abstract":"Fine-tuning large pre-trained models for downstream tasks can be really expensive. In the past, researchers have proposed various alternatives like adapter and prompt-based methods for tuning these large language models using minimal parameters. However, applying prompt-tuning for smaller language models has not been effective so far and not much work is done in pushing forward soft prompting for these smaller models. To improve the training efficiency of the language models and reduce the size of tuned parameters, we propose a novel Adapter-based Efficient Prompt Tuning approach (<MASKED_ACRONYM>). In this paper, we show that tuning the parameters of soft prompts with adapter modules while keeping the rest of the model frozen can be a promising method to optimize smaller language models for downstream tasks. Our method achieves up to 98% performance of full fine-tuning while using only 0.02% of total model parameters.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"LAVA","Description":"Latent Action Spaces via Variational Auto-encoding for Dialogue Policy Optimization","Abstract":"Reinforcement learning (RL) can enable task-oriented dialogue systems to steer the conversation towards successful task completion. In an end-to-end setting, a response can be constructed in a word-level sequential decision making process with the entire system vocabulary as action space. Policies trained in such a fashion do not require expert-defined action spaces, but they have to deal with large action spaces and long trajectories, making RL impractical. Using the latent space of a variational model as action space alleviates this problem. However, current approaches use an uninformed prior for training and optimize the latent distribution solely on the context. It is therefore unclear whether the latent representation truly encodes the characteristics of different actions. In this paper, we explore three ways of leveraging an auxiliary task to shape the latent variable distribution: via pre-training, to obtain an informed prior, and via multitask learning. We choose response auto-encoding as the auxiliary task, as this captures the generative factors of dialogue responses while requiring low computational cost and neither additional data nor labels. Our approach yields a more action-characterized latent representations which support end-to-end dialogue policy optimization and achieves state-of-the-art success rates. These results warrant a more wide-spread use of RL in end-to-end dialogue models.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"RatE","Description":"Relation-Adaptive Translating Embedding for Knowledge Graph Completion","Abstract":"Many graph embedding approaches have been proposed for knowledge graph completion via link prediction. Among those, translating embedding approaches enjoy the advantages of light-weight structure, high efficiency and great interpretability. Especially when extended to complex vector space, they show the capability in handling various relation patterns including symmetry, antisymmetry, inversion and composition. However, previous translating embedding approaches defined in complex vector space suffer from two main issues: 1) representing and modeling capacities of the model are limited by the translation function with rigorous multiplication of two complex numbers; and 2) embedding ambiguity caused by one-to-many relations is not explicitly alleviated. In this paper, we propose a relation-adaptive translation function built upon a novel weighted product in complex space, where the weights are learnable, relation-specific and independent to embedding size. The translation function only requires eight more scalar parameters each relation, but improves expressive power and alleviates embedding ambiguity problem. Based on the function, we then present our Relation-adaptive translating Embedding (<MASKED_ACRONYM>) approach to score each graph triple. Moreover, a novel negative sampling method is proposed to utilize both prior knowledge and self-adversarial learning for effective optimization. Experiments verify <MASKED_ACRONYM> achieves state-of-the-art performance on four link prediction benchmarks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"PoD","Description":"Positional Dependency-Based Word Embedding for Aspect Term Extraction","Abstract":"Dependency context-based word embedding jointly learns the representations of word and dependency context, and has been proved effective in aspect term extraction. In this paper, we design the positional dependency-based word embedding (<MASKED_ACRONYM>) which considers both dependency context and positional context for aspect term extraction. Specifically, the positional context is modeled via relative position encoding. Besides, we enhance the dependency context by integrating more lexical information (e.g., POS tags) along dependency paths. Experiments on SemEval 2014\/2015\/2016 datasets show that our approach outperforms other embedding methods in aspect term extraction.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"Conception","Description":"Multilingually-Enhanced, Human-Readable Concept Vector Representations","Abstract":"To date, the most successful word, word sense, and concept modelling techniques have used large corpora and knowledge resources to produce dense vector representations that capture semantic similarities in a relatively low-dimensional space. Most current approaches, however, suffer from a monolingual bias, with their strength depending on the amount of data available across languages. In this paper we address this issue and propose <MASKED_ACRONYM>, a novel technique for building language-independent vector representations of concepts which places multilinguality at its core while retaining explicit relationships between concepts. Our approach results in high-coverage representations that outperform the state of the art in multilingual and cross-lingual Semantic Word Similarity and Word Sense Disambiguation, proving particularly robust on low-resource languages. <MASKED_ACRONYM> \u2013 its software and the complete set of representations \u2013 is available at <a href=https:\/\/github.com\/SapienzaNLP\/conception class=acl-markup-url>https:\/\/github.com\/SapienzaNLP\/conception<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"SLICE","Description":"Supersense-based Lightweight Interpretable Contextual Embeddings","Abstract":"Contextualised embeddings such as BERT have become de facto state-of-the-art references in many NLP applications, thanks to their impressive performances. However, their opaqueness makes it hard to interpret their behaviour. <MASKED_ACRONYM> is a hybrid model that combines supersense labels with contextual embeddings. We introduce a weakly supervised method to learn interpretable embeddings from raw corpora and small lists of seed words. Our model is able to represent both a word and its context as embeddings into the same compact space, whose dimensions correspond to interpretable supersenses. We assess the model in a task of supersense tagging for French nouns. The little amount of supervision required makes it particularly well suited for low-resourced scenarios. Thanks to its interpretability, we perform linguistic analyses about the predicted supersenses in terms of input word and context representations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"ContraCAT","Description":"Contrastive Coreference Analytical Templates for Machine Translation","Abstract":"Recent high scores on pronoun translation using context-aware neural machine translation have suggested that current approaches work well. ContraPro is a notable example of a contrastive challenge set for English\u2192German pronoun translation. The high scores achieved by transformer models may suggest that they are able to effectively model the complicated set of inferences required to carry out pronoun translation. This entails the ability to determine which entities could be referred to, identify which entity a source-language pronoun refers to (if any), and access the target-language grammatical gender for that entity. We first show through a series of targeted adversarial attacks that in fact current approaches are not able to model all of this information well. Inserting small amounts of distracting information is enough to strongly reduce scores, which should not be the case. We then create a new template test set <MASKED_ACRONYM>, designed to individually assess the ability to handle the specific steps necessary for successful pronoun translation. Our analyses show that current approaches to context-aware NMT rely on a set of surface heuristics, which break down when translations require real reasoning. We also propose an approach for augmenting the training data, with some improvements.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.9411764706}
{"Year":2020,"Venue":"coling-2020","Acronym":"CLUE","Description":"A Chinese Language Understanding Evaluation Benchmark","Abstract":"The advent of natural language understanding (NLU) benchmarks for English, such as GLUE and SuperGLUE allows new NLU models to be evaluated across a diverse set of tasks. These comprehensive benchmarks have facilitated a broad range of research and applications in natural language processing (NLP). The problem, however, is that most such benchmarks are limited to English, which has made it difficult to replicate many of the successes in English NLU for other languages. To help remedy this issue, we introduce the first large-scale Chinese Language Understanding Evaluation (<MASKED_ACRONYM>) benchmark. <MASKED_ACRONYM> is an open-ended, community-driven project that brings together 9 tasks spanning several well-established single-sentence\/sentence-pair classification tasks, as well as machine reading comprehension, all on original Chinese text. To establish results on these tasks, we report scores using an exhaustive set of current state-of-the-art pre-trained Chinese models (9 in total). We also introduce a number of supplementary datasets and additional tools to help facilitate further progress on Chinese NLU. Our benchmark is released at <a href=https:\/\/www.cluebenchmarks.com class=acl-markup-url>https:\/\/www.cluebenchmarks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"coling-2020","Acronym":"SOME","Description":"Reference-less Sub-Metrics Optimized for Manual Evaluations of Grammatical Error Correction","Abstract":"We propose a reference-less metric trained on manual evaluations of system outputs for grammatical error correction (GEC). Previous studies have shown that reference-less metrics are promising; however, existing metrics are not optimized for manual evaluations of the system outputs because no dataset of the system output exists with manual evaluation. This study manually evaluates outputs of GEC systems to optimize the metrics. Experimental results show that the proposed metric improves correlation with the manual evaluation in both system- and sentence-level meta-evaluation. Our dataset and metric will be made publicly available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"nlp4if-2021","Acronym":"MEAN","Description":"Multi-head Entity Aware Attention Networkfor Political Perspective Detection in News Media","Abstract":"The way information is generated and disseminated has changed dramatically over the last decade. Identifying the political perspective shaping the way events are discussed in the media becomes more important due to the sharp increase in the number of news outlets and articles. Previous approaches usually only leverage linguistic information. However, news articles attempt to maintain credibility and seem impartial. Therefore, bias is introduced in subtle ways, usually by emphasizing different aspects of the story. In this paper, we propose a novel framework that considers entities mentioned in news articles and external knowledge about them, capturing the bias with respect to those entities. We explore different ways to inject entity information into the text model. Experiments show that our proposed framework achieves significant improvements over the standard text models, and is capable of identifying the difference in news narratives with different perspectives.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"lrec-2022","Acronym":"HOPE","Description":"A Task-Oriented and Human-Centric Evaluation Framework Using Professional Post-Editing Towards More Effective MT Evaluation","Abstract":"Traditional automatic evaluation metrics for machine translation have been widely criticized by linguists due to their low accuracy, lack of transparency, focus on language mechanics rather than semantics, and low agreement with human quality evaluation. Human evaluations in the form of MQM-like scorecards have always been carried out in real industry setting by both clients and translation service providers (TSPs). However, traditional human translation quality evaluations are costly to perform and go into great linguistic detail, raise issues as to inter-rater reliability (IRR) and are not designed to measure quality of worse than premium quality translations. In this work, we introduce <b><MASKED_ACRONYM><\/b>, a task-oriented and <i><b>h<\/b> <\/i>uman-centric evaluation framework for machine translation output based <i><b>o<\/b> <\/i>n professional <i><b>p<\/b> <\/i>ost-<i> <b>e<\/b> <\/i>diting annotations. It contains only a limited number of commonly occurring error types, and uses a scoring model with geometric progression of error penalty points (EPPs) reflecting error severity level to each translation unit. The initial experimental work carried out on English-Russian language pair MT outputs on marketing content type of text from highly technical domain reveals that our evaluation framework is quite effective in reflecting the MT output quality regarding both overall system-level performance and segment-level transparency, and it increases the IRR for error type interpretation. The approach has several key advantages, such as ability to measure and compare less than perfect MT output from different systems, ability to indicate human perception of quality, immediate estimation of the labor effort required to bring MT output to premium quality, low-cost and faster application, as well as higher IRR. Our experimental data is available at <a href=https:\/\/github.com\/lHan87\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/lHan87\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"lrec-2022","Acronym":"MUSS","Description":"Multilingual Unsupervised Sentence Simplification by Mining Paraphrases","Abstract":"Progress in sentence simplification has been hindered by a lack of labeled parallel simplification data, particularly in languages other than English. We introduce <MASKED_ACRONYM>, a Multilingual Unsupervised Sentence Simplification system that does not require labeled simplification data. <MASKED_ACRONYM> uses a novel approach to sentence simplification that trains strong models using sentence-level paraphrase data instead of proper simplification data. These models leverage unsupervised pretraining and controllable generation mechanisms to flexibly adjust attributes such as length and lexical complexity at inference time. We further present a method to mine such paraphrase data in any language from Common Crawl using semantic sentence embeddings, thus removing the need for labeled data. We evaluate our approach on English, French, and Spanish simplification benchmarks and closely match or outperform the previous best supervised results, despite not using any labeled simplification data. We push the state of the art further by incorporating labeled simplification data.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2022,"Venue":"lrec-2022","Acronym":"BeSt","Description":"The Belief and Sentiment Corpus","Abstract":"We present the <MASKED_ACRONYM> corpus, which records cognitive state: who believes what (i.e., factuality), and who has what sentiment towards what. This corpus is inspired by similar source-and-target corpora, specifically MPQA and FactBank. The corpus comprises two genres, newswire and discussion forums, in three languages, Chinese (Mandarin), English, and Spanish. The corpus is distributed through the LDC.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"lrec-2022","Acronym":"VISA","Description":"An Ambiguous Subtitles Dataset for Visual Scene-aware Machine Translation","Abstract":"Existing multimodal machine translation (MMT) datasets consist of images and video captions or general subtitles which rarely contain linguistic ambiguity, making visual information not so effective to generate appropriate translations. We introduce <MASKED_ACRONYM>, a new dataset that consists of 40k Japanese-English parallel sentence pairs and corresponding video clips with the following key features: (1) the parallel sentences are subtitles from movies and TV episodes; (2) the source subtitles are ambiguous, which means they have multiple possible translations with different meanings; (3) we divide the dataset into Polysemy and Omission according to the cause of ambiguity. We show that <MASKED_ACRONYM> is challenging for the latest MMT system, and we hope that the dataset can facilitate MMT research.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"lrec-2022","Acronym":"gaHealth","Description":"An English--Irish Bilingual Corpus of Health Data","Abstract":"Machine Translation is a mature technology for many high-resource language pairs. However in the context of low-resource languages, there is a paucity of parallel data datasets available for developing translation models. Furthermore, the development of datasets for low-resource languages often focuses on simply creating the largest possible dataset for generic translation. The benefits and development of smaller in-domain datasets can easily be overlooked. To assess the merits of using in-domain data, a dataset for the specific domain of health was developed for the low-resource English to Irish language pair. Our study outlines the process used in developing the corpus and empirically demonstrates the benefits of using an in-domain dataset for the health domain. In the context of translating health-related data, models developed using the <MASKED_ACRONYM> corpus demonstrated a maximum BLEU score improvement of 22.2 points (40%) when compared with top performing models from the LoResMT2021 Shared Task. Furthermore, we define linguistic guidelines for developing <MASKED_ACRONYM>, the first bilingual corpus of health data for the Irish language, which we hope will be of use to other creators of low-resource data sets. <MASKED_ACRONYM> is now freely available online and is ready to be explored for further research.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2022,"Venue":"lrec-2022","Acronym":"ASCEND","Description":"A Spontaneous Chinese-English Dataset for Code-switching in Multi-turn Conversation","Abstract":"Code-switching is a speech phenomenon occurring when a speaker switches language during a conversation. Despite the spontaneous nature of code-switching in conversational spoken language, most existing works collect code-switching data from read speech instead of spontaneous speech. <MASKED_ACRONYM> (A Spontaneous Chinese-English Dataset) is a high-quality Mandarin Chinese-English code-switching corpus built on spontaneous multi-turn conversational dialogue sources collected in Hong Kong. We report <MASKED_ACRONYM>\u2019s design and procedure for collecting the speech data, including annotations. <MASKED_ACRONYM> consists of 10.62 hours of clean speech, collected from 23 bilingual speakers of Chinese and English. Furthermore, we conduct baseline experiments using pre-trained wav2vec 2.0 models, achieving a best performance of 22.69% character error rate and 27.05% mixed error rate.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8333333333}
{"Year":2022,"Venue":"lrec-2022","Acronym":"PADDLe","Description":"a Platform to Identify Complex Words for Learners of French as a Foreign Language (FFL)","Abstract":"Annotations of word difficulty by readers provide invaluable insights into lexical complexity. Yet, there is currently a paucity of tools allowing researchers to gather such annotations in an adaptable and simple manner. This article presents <MASKED_ACRONYM>, an online platform aiming to fill that gap and designed to encourage best practices when collecting difficulty judgements. Studies crafted using the tool ask users to provide a selection of demographic information, then to annotate a certain number of texts and answer multiple-choice comprehension questions after each text. Researchers are encouraged to use a multi-level annotation scheme, to avoid the drawbacks of binary complexity annotations. Once a study is launched, its results are summarised in a visual representation accessible both to researchers and teachers, and can be downloaded in .csv format. Some findings of a pilot study designed with the tool are also provided in the article, to give an idea of the types of research questions it allows to answer.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2015,"Venue":"naacl-2015","Acronym":"HEADS","Description":"Headline Generation as Sequence Prediction Using an Abstract Feature-Rich Space","Abstract":"Feature-Rich Space Carlos A. Colmenares\u2217 Google Inc. Brandschenkestrasse 110 8002 Zurich, Switzerland crcarlos@google.com Marina Litvak Shamoon College of Engineering Beer Sheva, Israel marinal@sce.ac.il Amin Mantrach Fabrizio Silvestri Yahoo Labs. Avinguda Diagonal 177 08018 Barcelona, Spain {amantrach,silvestr}@yahoo-inc.com  Automatic headline generation is a sub-task of document summarization with many reported applications. In this study we present a sequence-prediction technique for learning how editors title their news stories. The introduced technique models the problem as a discrete optimization task in a feature-rich space. In this space the global optimum can be found in polynomial time by means of dynamic programming. We train and test our model on an extensive corpus of \ufb01nancial news, and compare it against a number of baselines by using standard metrics from the document summarization domain, as well as some new ones proposed in this work. We also assess the readability and informativeness of the generated titles through human evaluation. The obtained results are very appealing and substantiate the soundness of the approach.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2015,"Venue":"naacl-2015","Acronym":"hyp","Description":"A Toolkit for Representing, Manipulating, and Optimizing Hypergraphs","Abstract":"We present <MASKED_ACRONYM>, an open-source toolkit for the representation, manipulation, and optimization of weighted directed <MASKED_ACRONYM>ergraphs. <MASKED_ACRONYM> provides compose, project, invert functionality, k-best path algorithms, the inside and outside algorithms, and more. Finite-state machines are modeled as a special case of directed <MASKED_ACRONYM>ergraphs. <MASKED_ACRONYM> consists of a C++ API, as well as a command line tool, and is available for download at github.com\/sdl-research\/<MASKED_ACRONYM>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2015,"Venue":"naacl-2015","Acronym":"ICE","Description":"Rapid Information Extraction Customization for NLP Novices","Abstract":"We showcase <MASKED_ACRONYM>, an Integrated Customization Environment for Information Extraction. <MASKED_ACRONYM> is an easy tool for non-NLP experts to rapidly build customized IE systems for a new domain.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2015,"Venue":"naacl-2015","Acronym":"SETS","Description":"Scalable and Efficient Tree Search in Dependency Graphs","Abstract":"We present a syntactic analysis query toolkit geared speci\ufb01cally towards massive dependency parsebanks and morphologically rich languages. The query language allows arbitrary tree queries, including negated branches, and is suitable for querying analyses with rich morphological annotation. Treebanks of over a million words can be comfortably queried on a low-end netbook, and a parsebank with over 100M words on a single consumer-grade server. We also introduce a web-based interface for interactive querying. All contributions are available under open licenses.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"ws-2017","Acronym":"GRaSP","Description":"Grounded Representation and Source Perspective","Abstract":"When people or organizations provide information, they make choices regarding what information they include and how they present it. The combination of these two aspects (the content and stance provided by the source) represents a perspective. Investigating differences in perspective can provide various useful insights in the reliability of information, the way perspectives change over time, shared beliefs among groups of a similar social or political background and contrasts between other groups, etc. This paper introduces <MASKED_ACRONYM>, a generic framework for modeling perspectives and their sources.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"ws-2017","Acronym":"Frames","Description":"a corpus for adding memory to goal-oriented dialogue systems","Abstract":"This paper proposes a new dataset, <MASKED_ACRONYM>, composed of 1369 human-human dialogues with an average of 15 turns per dialogue. This corpus contains goal-oriented dialogues between users who are given some constraints to book a trip and assistants who search a database to find appropriate trips. The users exhibit complex decision-making behaviour which involve comparing trips, exploring different options, and selecting among the trips that were discussed during the dialogue. To drive research on dialogue systems towards handling such behaviour, we have annotated and released the dataset and we propose in this paper a task called frame tracking. This task consists of keeping track of different semantic frames throughout each dialogue. We propose a rule-based baseline and analyse the frame tracking task through this baseline.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2004,"Venue":"lrec-2004","Acronym":"CHeM","Description":"A System for the Automatic Analysis of e-mails in the Restoration and Conservation Domain","Abstract":"In this paper, we present the <MASKED_ACRONYM> system, Cultural Heritage e-mail Manager, a support system for the analysis of e-mails of the  Restoration and Conservation newsgroup, hosted by the  Yahoo portal from December 2000 to January 2003. The complexity of the  domain as well as the specificity of the e-mails, prompted us to build the first system prototype based on a client-side architecture, to  help less expert users in classifying information contained in e-mails. The system goal is therefore to provide an instrument capable of  classifying the  received messages, downloaded onto the users\u2019 desktops, into standard categories, based on their content, using the  well-known techniques of Data Mining and Information Retrieval. The categories thus obtained are then used to label the messages in  order to provide valuable information on the domain and therefore support specific information retrieval and produce new user groups  by an automatic generation of mailing lists. The methodology presented and the first test results are encouraging with a view to porting  the system in other similar domains.    1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"tacl-2022","Acronym":"LOT","Description":"A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation","Abstract":"Standard multi-task benchmarks are essential for developing pretraining models that can generalize to various downstream tasks. Existing benchmarks for natural language processing (NLP) usually focus only on understanding or generating short texts. However, long text modeling requires many distinct abilities in contrast to short texts, such as the modeling of long-range discourse and commonsense relations, and the coherence and controllability of generation. The lack of standardized benchmarks makes it difficult to assess these abilities of a model and fairly compare different models, especially Chinese models. Therefore, we propose a story-centric benchmark named <MASKED_ACRONYM> for evaluating Chinese long text modeling, which aggregates two understanding tasks and two generation tasks. We construct new datasets for these tasks based on human-written Chinese stories with hundreds of words. Furthermore, we release an encoder-decoder-based Chinese long text pretraining model named LongLM with up to 1 billion parameters. We pretrain LongLM on 120G Chinese novels with two generative tasks including text infilling and conditional continuation. Extensive experiments show that LongLM outperforms similar-sized pretraining models substantially on both the understanding and generation tasks in <MASKED_ACRONYM>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"ws-2012","Acronym":"EAGER","Description":"Extending Automatically Gazetteers for Entity Recognition","Abstract":"Key to named entity recognition, the manual gazetteering of entity lists is a costly, errorprone process that often yields results that are incomplete and suffer from sampling bias. Exploiting current sources of structured information, we propose a novel method for extending minimal seed lists into complete gazetteers. Like previous approaches, we value WIKIPEDIA as a huge, well-curated, and relatively unbiased source of entities. However, in contrast to previous work, we exploit not only its content, but also its structure, as exposed in DBPEDIA. We extend gazetteers through Wikipedia categories, carefully limiting the impact of noisy categorizations. The resulting gazetteers easily outperform previous approaches on named entity recognition.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"ws-2012","Acronym":"PREFER","Description":"Using a Graph-Based Approach to Generate Paraphrases for Language Learning","Abstract":"Paraphrasing is an important aspect of language  competence; however, EFL learners have long  had difficulty paraphrasing in their writing  owing to their limited language proficiency.  Therefore, automatic paraphrase suggestion  systems can be useful for writers. In this paper,  we present <MASKED_ACRONYM>1, a paraphrase reference  tool for helping language learners improve their  writing skills. In this paper, we attempt to  transform the paraphrase generation problem  into a graphical problem in which the phrases  are treated as nodes and translation similarities  as edges. We adopt the PageRank algorithm to  rank and filter the paraphrases generated by the  pivot-based paraphrase generation method. We  manually evaluate the performance of our  method and assess the effectiveness of  <MASKED_ACRONYM> in language learning. The results  show that our method successfully preserves  both the semantic meaning and syntactic  structure of the query phrase. Moreover, the  students\u2019 writing performance improve most  with the assistance of <MASKED_ACRONYM>.   1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"CRAFT","Description":"A Benchmark for Causal Reasoning About Forces and inTeractions","Abstract":"Humans are able to perceive, understand and reason about causal events. Developing models with similar physical and causal understanding capabilities is a long-standing goal of artificial intelligence. As a step towards this direction, we introduce <MASKED_ACRONYM>, a new video question answering dataset that requires causal reasoning about physical forces and object interactions. It contains 58K video and question pairs that are generated from 10K videos from 20 different virtual environments, containing various objects in motion that interact with each other and the scene. Two question categories in <MASKED_ACRONYM> include previously studied descriptive and counterfactual questions. Additionally, inspired by the Force Dynamics Theory in cognitive linguistics, we introduce a new causal question category that involves understanding the causal interactions between objects through notions like cause, enable, and prevent. Our results show that even though the questions in <MASKED_ACRONYM> are easy for humans, the tested baseline models, including existing state-of-the-art methods, do not yet deal with the challenges posed in our benchmark.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"ASSIST","Description":"Towards Label Noise-Robust Dialogue State Tracking","Abstract":"The MultiWOZ 2.0 dataset has greatly boosted the research on dialogue state tracking (DST). However, substantial noise has been discovered in its state annotations. Such noise brings about huge challenges for training DST models robustly. Although several refined versions, including MultiWOZ 2.1-2.4, have been published recently, there are still lots of noisy labels, especially in the training set. Besides, it is costly to rectify all the problematic annotations. In this paper, instead of improving the annotation quality further, we propose a general framework, named <MASKED_ACRONYM> (lAbel noiSe-robuSt dIalogue State Tracking), to train DST models robustly from noisy labels. <MASKED_ACRONYM> first generates pseudo labels for each sample in the training set by using an auxiliary model trained on a small clean dataset, then puts the generated pseudo labels and vanilla noisy labels together to train the primary model. We show the validity of <MASKED_ACRONYM> theoretically. Experimental results also demonstrate that <MASKED_ACRONYM> improves the joint goal accuracy of DST by up to 28.16% on MultiWOZ 2.0 and 8.41% on MultiWOZ 2.4, compared to using only the vanilla noisy labels.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"ELLE","Description":"Efficient Lifelong Pre-training for Emerging Data","Abstract":"Current pre-trained language models (PLM) are typically trained with static data, ignoring that in real-world scenarios, streaming data of various sources may continuously grow. This requires PLMs to integrate the information from all the sources in a lifelong manner. Although this goal could be achieved by exhaustive pre-training on all the existing data, such a process is known to be computationally expensive. To this end, we propose <MASKED_ACRONYM>, aiming at efficient lifelong pre-training for emerging data. Specifically, <MASKED_ACRONYM> consists of (1) function preserved model expansion, which flexibly expands an existing PLM\u2019s width and depth to improve the efficiency of knowledge acquisition; and (2) pre-trained domain prompts, which disentangle the versatile knowledge learned during pre-training and stimulate the proper knowledge for downstream tasks. We experiment <MASKED_ACRONYM> with streaming data from 5 domains on BERT and GPT. The results show the superiority of <MASKED_ACRONYM> over various lifelong learning baselines in both pre-training efficiency and downstream performances. The codes are publicly available at <a href=https:\/\/github.com\/thunlp\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/thunlp\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"PromptGen","Description":"Automatically Generate Prompts using Generative Models","Abstract":"Recently, prompt learning has received significant attention, where the downstream tasks are reformulated to the mask-filling task with the help of a textual prompt. The key point of prompt learning is finding the most appropriate prompt. This paper proposes a novel model <MASKED_ACRONYM>, which can automatically generate prompts conditional on the input sentence. <MASKED_ACRONYM> is the first work considering dynamic prompt generation for knowledge probing, based on a pre-trained generative model. To mitigate any label information leaking from the pre-trained generative model, when given a generated prompt, we replace the query input with \u201cNone\u201d. We pursue that this perturbed context-free prompt cannot trigger the correct label. We evaluate our model on the knowledge probing LAMA benchmark, and show that <MASKED_ACRONYM> significantly outperforms other baselines.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2022,"Venue":"findings-2022","Acronym":"TEAM","Description":"A multitask learning based Taxonomy Expansion approach for Attach and Merge","Abstract":"Taxonomy expansion is a crucial task. Most of Automatic expansion of taxonomy are of two types, attach and merge. In a taxonomy like WordNet, both merge and attach are integral parts of the expansion operations but majority of study consider them separately. This paper proposes a novel mult-task learning-based deep learning method known as Taxonomy Expansion with Attach and Merge (<MASKED_ACRONYM>) that performs both the merge and attach operations. To the best of our knowledge this is the first study which integrates both merge and attach operations in a single model. The proposed models have been evaluated on three separate WordNet taxonomies, viz., Assamese, Bangla, and Hindi. From the various experimental setups, it is shown that <MASKED_ACRONYM> outperforms its state-of-the-art counterparts for attach operation, and also provides highly encouraging performance for the merge operation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"CLEAR","Description":"Improving Vision-Language Navigation with Cross-Lingual, Environment-Agnostic Representations","Abstract":"Vision-and-Language Navigation (VLN) tasks require an agent to navigate through the environment based on language instructions. In this paper, we aim to solve two key challenges in this task: utilizing multilingual instructions for improved instruction-path grounding and navigating through new environments that are unseen during training. To address these challenges, first, our agent learns a shared and visually-aligned cross-lingual language representation for the three languages (English, Hindi and Telugu) in the Room-Across-Room dataset. Our language representation learning is guided by text pairs that are aligned by visual information. Second, our agent learns an environment-agnostic visual representation by maximizing the similarity between semantically-aligned image pairs (with constraints on object-matching) from different environments. Our environment agnostic visual representation can mitigate the environment bias induced by low-level visual information. Empirically, on the Room-Across-Room dataset, we show that our multi-lingual agent gets large improvements in all metrics over the strong baseline model when generalizing to unseen environments with the cross-lingual language representation and the environment-agnostic visual representation. Furthermore, we show that our learned language and visual representations can be successfully transferred to the Room-to-Room and Cooperative Vision-and-Dialogue Navigation task, and present detailed qualitative and quantitative generalization and grounding analysis.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"SHARP","Description":"Search-Based Adversarial Attack for Structured Prediction","Abstract":"Adversarial attack of structured prediction models faces various challenges such as the difficulty of perturbing discrete words, the sentence quality issue, and the sensitivity of outputs to small perturbations. In this work, we introduce <MASKED_ACRONYM>, a new attack method that formulates the black-box adversarial attack as a search-based optimization problem with a specially designed objective function considering sentence fluency, meaning preservation and attacking effectiveness. Additionally, three different searching strategies are analyzed and compared, i.e., Beam Search, Metropolis-Hastings Sampling, and Hybrid Search. We demonstrate the effectiveness of our attacking strategies on two challenging structured prediction tasks: Pos-tagging and dependency parsing. Through automatic and human evaluations, we show that our method performs a more potent attack compared with pioneer arts. Moreover, the generated adversarial examples can be used to successfully boost the robustness and performance of the victim model via adversarial training.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"HUE","Description":"Pretrained Model and Dataset for Understanding Hanja Documents of Ancient Korea","Abstract":"Historical records in Korea before the 20th century were primarily written in Hanja, an extinct language based on Chinese characters and not understood by modern Korean or Chinese speakers. Historians with expertise in this time period have been analyzing the documents, but that process is very difficult and time-consuming, and language models would significantly speed up the process. Toward building and evaluating language models for Hanja, we release the Hanja Understanding Evaluation dataset consisting of chronological attribution, topic classification, named entity recognition, and summary retrieval tasks. We also present BERT-based models continued training on the two major corpora from the 14th to the 19th centuries: the Annals of the Joseon Dynasty and Diaries of the Royal Secretariats. We compare the models with several baselines on all tasks and show there are significant improvements gained by training on the two corpora. Additionally, we run zero-shot experiments on the Daily Records of the Royal Court and Important Officials (DRRI). The DRRI dataset has not been studied much by the historians, and not at all by the NLP community.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"CRUSH","Description":"Contextually Regularized and User anchored Self-supervised Hate speech Detection","Abstract":"The last decade has witnessed a surge in the interaction of people through social networking platforms. While there are several positive aspects of these social platforms, their proliferation has led them to become the breeding ground for cyber-bullying and hate speech. Recent advances in NLP have often been used to mitigate the spread of such hateful content. Since the task of hate speech detection is usually applicable in the context of social networks, we introduce <MASKED_ACRONYM>, a framework for hate speech detection using User Anchored self-supervision and contextual regularization. Our proposed approach secures ~1-12% improvement in test set metrics over best performing previous approaches on two types of tasks and multiple popular English language social networking datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"LiST","Description":"Lite Prompted Self-training Makes Parameter-efficient Few-shot Learners","Abstract":"We present a new method <MASKED_ACRONYM> for efficient fine-tuning of large pre-trained language models (PLMs) in few-shot learning settings. <MASKED_ACRONYM> improves over recent methods that adopt prompt-based fine-tuning (FN) using two key techniques. The first is the use of self-training to leverage large amounts of unlabeled data for prompt-based FN in few-shot settings. We use self-training in conjunction with meta-learning for re-weighting noisy pseudo-prompt labels. Traditionally, self-training is expensive as it requires updating all the model parameters repetitively. Therefore, we use a second technique for light-weight fine-tuning where we introduce a small number of task-specific parameters that are fine-tuned during self-training while keeping the PLM encoder frozen. Our experiments show that <MASKED_ACRONYM> can effectively leverage unlabeled data to improve the model performance for few-shot learning. Additionally, the finetuning process is efficient as it only updates a small percentage of the parameters and the overall model footprint is reduced since several tasks can share a common PLM encoder as backbone. We present a comprehensive study on six NLU tasks to validate the effectiveness of <MASKED_ACRONYM>. The results show that <MASKED_ACRONYM> improves by 35% over classic fine-tuning methods and 6% over prompt-based FN with 96% reduction in number of trainable parameters when fine-tuned with no more than 30 labeled examples from each task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"Spa","Description":"On the Sparsity of Virtual Adversarial Training for Dependency Parsing","Abstract":"Virtual adversarial training (VAT) is a powerful approach to improving robustness and performance, leveraging both labeled and unlabeled data to compensate for the scarcity of labeled data. It is adopted on lots of vision and language classification tasks. However, for tasks with structured output (e.g., dependency parsing), the application of VAT is nontrivial due to the intrinsic proprieties of structures: (1) the non-sparse problem and (2) exponential complexity. Against this background, we propose the <MASKED_ACRONYM>rse Parse Adjustment (spa) algorithm and successfully applied VAT to the dependency parsing task. spa refers to the learning algorithm which combines the graph-based dependency parsing model with VAT in an exact computational manner and enhances the dependency parser with controllable and adjustable sparsity. Empirical studies show that the TreeCRF parser optimized using outperforms other methods without sparsity regularization.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"CoRAL","Description":"a Context-aware Croatian Abusive Language Dataset","Abstract":"In light of unprecedented increases in the popularity of the internet and social media, comment moderation has never been a more relevant task. Semi-automated comment moderation systems greatly aid human moderators by either automatically classifying the examples or allowing the moderators to prioritize which comments to consider first. However, the concept of inappropriate content is often subjective, and such content can be conveyed in many subtle and indirect ways. In this work, we propose <MASKED_ACRONYM> \u2013 a language and culturally aware Croatian Abusive dataset covering phenomena of implicitness and reliance on local and global context. We show experimentally that current models degrade when comments are not explicit and further degrade when language skill and context knowledge are required to interpret the comment.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"findings-2022","Acronym":"HERB","Description":"Measuring Hierarchical Regional Bias in Pre-trained Language Models","Abstract":"Fairness has become a trending topic in natural language processing (NLP) and covers biases targeting certain social groups such as genders and religions. Yet regional bias, another long-standing global discrimination problem, remains unexplored still. Consequently, we intend to provide a study to analyse the regional bias learned by the pre-trained language models (LMs) that are broadly used in NLP tasks. While verifying the existence of regional bias in LMs, we find that the biases on regional groups can be largely affected by the corresponding geographical clustering. We accordingly propose a hierarchical regional bias evaluation method (<MASKED_ACRONYM>) utilising the information from the sub-region clusters to quantify the bias in the pre-trained LMs. Experiments show that our hierarchical metric can effectively evaluate the regional bias with regard to comprehensive topics and measure the potential regional bias that can be propagated to downstream tasks. Our codes are available at <a href=https:\/\/github.com\/Bernard-Yang\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/Bernard-Yang\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2011,"Venue":"acl-2011","Acronym":"MEANT","Description":"An inexpensive, high-accuracy, semi-automatic metric for evaluating translation utility based on semantic roles","Abstract":"We introduce a novel semi-automated metric, <MASKED_ACRONYM>, that assesses translation utility by matching semantic role fillers, producing scores that correlate with human judgment as well as HTER but at much lower labor cost. As machine translation systems improve in lexical choice and fluency, the shortcomings of widespread n-gram based, fluency-oriented MT evaluation metrics such as BLEU, which fail to properly evaluate adequacy, become more apparent. But more accurate, nonautomatic adequacy-oriented MT evaluation metrics like HTER are highly labor-intensive, which bottlenecks the evaluation cycle. We first show that when using untrained monolingual readers to annotate semantic roles in MT output, the non-automatic version of the metric H<MASKED_ACRONYM> achieves a 0.43 correlation coefficient with human adequacy judgments at the sentence level, far superior to BLEU at only 0.20, and equal to the far more expensive HTER. We then replace the human semantic role annotators with automatic shallow semantic parsing to further automate the evaluation metric, and show that even the semiautomated evaluation metric achieves a 0.34 correlation coefficient with human adequacy judgment, which is still about 80% as closely correlated as HTER despite an even lower labor cost for the evaluation procedure. The results show that our proposed metric is significantly better correlated with human judgment on adequacy than current widespread automatic evaluation metrics, while being much more cost effective than HTER.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2000,"Venue":"iwpt-2000","Acronym":"SOUP","Description":"A Parser for Real-world Spontaneous Speech","Abstract":"This paper describes the key features of <MASKED_ACRONYM>, a stochastic, chart-based, top-down parser, especially engineered for real-time analysis of spoken language with very large, multi-domain semantic grammars. <MASKED_ACRONYM> achieves flexibility by encoding context-free grammars, specified for example in the Java Speech Grammar Format, as probabilistic recursive transition networks, and robustness by allowing skipping of input words at any position and producing ranked interpretations that may consist of multiple parse trees. Moreover, <MASKED_ACRONYM> is very efficient, which allows for practically instantaneous backend response.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2013,"Venue":"acl-2013","Acronym":"SORT","Description":"An Interactive Source-Rewriting Tool for Improved Translation","Abstract":"The quality of automatic translation is affected by many factors. One is the divergence between the speci\ufb01c source and target languages. Another lies in the source text itself, as some texts are more complex than others. One way to handle such texts is to modify them prior to translation. Yet, an important factor that is often overlooked is the source translatability with respect to the speci\ufb01c translation system and the speci\ufb01c model that are being used. In this paper we present an interactive system where source modi\ufb01cations are induced by con\ufb01dence estimates that are derived from the translation model in use. Modi\ufb01cations are automatically generated and proposed for the user\u2019s approval. Such a system can reduce postediting effort, replacing it by cost-effective pre-editing that can be done by monolinguals.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"clasp-2023","Acronym":"MAP","Description":"Low-data Regime Multimodal Learning with Adapter-based Pre-training and Prompting","Abstract":"Pretrained vision-language (VL) models have shown impressive results on various multi-modal downstream tasks recently. Many of the benchmark models build on pretrained causal language models (LMs), leveraging the original few-shot learning and generalization capability of the LMs trained with large text corpora. However, these models are often gigantic and require large-scale image and text data with high computational cost to train. This paper introduces a moderate-size model called <MASKED_ACRONYM> for efficient VL transfer learning through adapter-based pretraining and prompting. We aim to answer the question of how much we can complete through VL pretraining within the low-data regime while maximizing efficiency in transferring knowledge of a moderate-size frozen LM. Our experiments demonstrate that <MASKED_ACRONYM> achieves substantially better zero-shot and few-shot performance on downstream VL tasks with only 10% the size of pretraining data and a 30x lighter pretrained LM backbone compared to Frozen. <MASKED_ACRONYM> also outperforms fully trained models of comparable size at retaining its transfer learning ability when the amount of training data reduces.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"nlp4musa-2020","Acronym":"BUTTER","Description":"A Representation Learning Framework for Bi-directional Music-Sentence Retrieval and Generation","Abstract":"We propose <MASKED_ACRONYM>, a uni\ufb01ed multimodal representation learning model for Bidirectional mUsic-senTence ReTrieval and GenERation. Based on the variational autoencoder framework, our model learns three interrelated latent representations: 1) a latent music representation, which can be used to reconstruct a short piece, 2) keyword embedding of music descriptions, which can be used for caption generation, and 3) a crossmodal representation, which is disentangled into several different attributes of music by aligning the latent music representation and keyword embeddings. By mapping between different latent representations, our model can search\/generate music given an input text description, and vice versa. Moreover, the model enables controlled music transfer by partially changing the keywords of corresponding descriptions.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2000,"Venue":"acl-2000","Acronym":"Panel","Description":"Good Spelling of Vietnamese Texts, One Aspect of Computational Linguistics in Vietnam","Abstract":"There are many challenging problems for Vietnamese language processing. It will be a long time before these challenges are met. Even some apparently simple problems such as spelling correction are quite difficult and have not been approached systematically yet. In this paper, we will discuss one aspect of this type of work: designing the so-called Vietools to detect and correct spelling of Vietnamese texts by using a spelling database based on TELEX code. Vietools is also extended to serve many purposes in Vietnamese language processing.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"conll-2021","Acronym":"FAST","Description":"A carefully sampled and cognitively motivated dataset for distributional semantic evaluation","Abstract":"What is the first word that comes to your mind when you hear giraffe, or damsel, or freedom? Such free associations contain a huge amount of information on the mental representations of the corresponding concepts, and are thus an extremely valuable testbed for the evaluation of semantic representations extracted from corpora. In this paper, we present <MASKED_ACRONYM> (Free ASsociation Tasks), a free association dataset for English rigorously sampled from two standard free association norms collections (the Edinburgh Associative Thesaurus and the University of South Florida Free Association Norms), discuss two evaluation tasks, and provide baseline results. In parallel, we discuss methodological considerations concerning the desiderata for a proper evaluation of semantic representations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"TAKE","Description":"Topic-shift Aware Knowledge sElection for Dialogue Generation","Abstract":"Knowledge-grounded dialogue generation consists of two subtasks: knowledge selection and response generation. The knowledge selector generally constructs a query based on the dialogue context and selects the most appropriate knowledge to help response generation. Recent work finds that realizing who (the user or the agent) holds the initiative and utilizing the role-initiative information to instruct the query construction can help select knowledge. It depends on whether the knowledge connection between two adjacent rounds is smooth to assign the role. However, whereby the user takes the initiative only when there is a strong semantic transition between two rounds, probably leading to initiative misjudgment. Therefore, it is necessary to seek a more sensitive reason beyond the initiative role for knowledge selection. To address the above problem, we propose a Topic-shift Aware Knowledge sElector(<MASKED_ACRONYM>). Specifically, we first annotate the topic shift and topic inheritance labels in multi-round dialogues with distant supervision. Then, we alleviate the noise problem in pseudo labels through curriculum learning and knowledge distillation. Extensive experiments on WoW show that <MASKED_ACRONYM> performs better than strong baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"GRASP","Description":"Guiding Model with RelAtional Semantics Using Prompt for Dialogue Relation Extraction","Abstract":"The dialogue-based relation extraction (DialogRE) task aims to predict the relations between argument pairs that appear in dialogue. Most previous studies utilize fine-tuning pre-trained language models (PLMs) only with extensive features to supplement the low information density of the dialogue by multiple speakers. To effectively exploit inherent knowledge of PLMs without extra layers and consider scattered semantic cues on the relation between the arguments, we propose a Guiding model with RelAtional Semantics using Prompt (<MASKED_ACRONYM>). We adopt a prompt-based fine-tuning approach and capture relational semantic clues of a given dialogue with 1) an argument-aware prompt marker strategy and 2) the relational clue detection task. In the experiments, <MASKED_ACRONYM> achieves state-of-the-art performance in terms of both F1 and F1c scores on a DialogRE dataset even though our method only leverages PLMs without adding any extra layers.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"DialogueEIN","Description":"Emotion Interaction Network for Dialogue Affective Analysis","Abstract":"Emotion Recognition in Conversation (ERC) has attracted increasing attention in the affective computing research field. Previous works have mainly focused on modeling the semantic interactions in the dialogue and implicitly inferring the evolution of the speakers\u2019 emotional states. Few works have considered the emotional interactions, which directly reflect the emotional evolution of speakers in the dialogue. According to psychological and behavioral studies, the emotional inertia and emotional stimulus are important factors that affect the speaker\u2019s emotional state in conversations. In this work, we propose a novel Dialogue Emotion Interaction Network, <MASKED_ACRONYM>, to explicitly model the intra-speaker, inter-speaker, global and local emotional interactions to respectively simulate the emotional inertia, emotional stimulus, global and local emotional evolution in dialogues. Extensive experiments on four ERC benchmark datasets, IEMOCAP, MELD, EmoryNLP and DailyDialog, show that our proposed <MASKED_ACRONYM> considering emotional interaction factors can achieve superior or competitive performance compared to state-of-the-art methods. Our codes and models are released.","wordlikeness":0.9090909091,"lcsratio":1.0,"wordcoverage":0.8421052632}
{"Year":2022,"Venue":"coling-2022","Acronym":"CONCRETE","Description":"Improving Cross-lingual Fact-checking with Cross-lingual Retrieval","Abstract":"Fact-checking has gained increasing attention due to the widespread of falsified information. Most fact-checking approaches focus on claims made in English only due to the data scarcity issue in other languages. The lack of fact-checking datasets in low-resource languages calls for an effective cross-lingual transfer technique for fact-checking. Additionally, trustworthy information in different languages can be complementary and helpful in verifying facts. To this end, we present the first fact-checking framework augmented with cross-lingual retrieval that aggregates evidence retrieved from multiple languages through a cross-lingual retriever. Given the absence of cross-lingual information retrieval datasets with claim-like queries, we train the retriever with our proposed Cross-lingual Inverse Cloze Task (X-ICT), a self-supervised algorithm that creates training instances by translating the title of a passage. The goal for X-ICT is to learn cross-lingual retrieval in which the model learns to identify the passage corresponding to a given translated title. On the X-Fact dataset, our approach achieves 2.23% absolute F1 improvement in the zero-shot cross-lingual setup over prior systems. The source code and data are publicly available at <a href=https:\/\/github.com\/khuangaf\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/khuangaf\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"ConTextING","Description":"Granting Document-Wise Contextual Embeddings to Graph Neural Networks for Inductive Text Classification","Abstract":"Graph neural networks (GNNs) have been recently applied in natural language processing. Various GNN research studies are proposed to learn node interactions within the local graph of each document that contains words, sentences, or topics for inductive text classification. However, most inductive GNNs that are built on a word graph generally take global word embeddings as node features, without referring to document-wise contextual information. Consequently, we find that BERT models can perform better than inductive GNNs. An intuitive follow-up approach is used to enrich GNNs with contextual embeddings from BERT, yet there is a lack of related research. In this work, we propose a simple yet effective unified model, coined <MASKED_ACRONYM>, with a joint training mechanism to learn from both document embeddings and contextual word interactions simultaneously. Our experiments show that <MASKED_ACRONYM> outperforms pure inductive GNNs and BERT-style models. The analyses also highlight the benefits of the sub-word graph and joint training with separated classifiers.","wordlikeness":0.9,"lcsratio":1.0,"wordcoverage":0.9}
{"Year":2022,"Venue":"coling-2022","Acronym":"ArT","Description":"All-round Thinker for Unsupervised Commonsense Question Answering","Abstract":"Without labeled question-answer pairs for necessary training, unsupervised commonsense question-answering (QA) appears to be extremely challenging due to its indispensable unique prerequisite on commonsense source like knowledge bases (KBs), which are usually highly resource consuming in construction. Recently pre-trained language models (PLMs) show effectiveness as an alternative for commonsense clues when they play a role of knowledge generator. However, existing work either relies on large-scale in-domain or out-of-domain labeled data, or fails to generate knowledge of high quality in a general way. Motivated by human thinking experience, we propose an approach of All-round Thinker (<MASKED_ACRONYM>) by fully taking association during knowledge generating. In detail, our model first focuses on key parts in the given context, and then generates highly related knowledge on such a basis in an association way like human thinking. Besides, for casual reasoning, a reverse thinking mechanism is especially added to further enhance bidirectional inferring between cause and effect. <MASKED_ACRONYM> is totally unsupervised and KBs-free. We evaluate it on three commonsense QA benchmarks: COPA, SocialIQA and SCT. On all scales of PLM backbones, <MASKED_ACRONYM> shows its brilliant performance and outperforms previous advanced unsupervised models.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"CORN","Description":"Co-Reasoning Network for Commonsense Question Answering","Abstract":"Commonsense question answering (QA) requires machines to utilize the QA content and external commonsense knowledge graph (KG) for reasoning when answering questions. Existing work uses two independent modules to model the QA contextual text representation and relationships between QA entities in KG, which prevents information sharing between modules for co-reasoning. In this paper, we propose a novel model, Co-Reasoning Network (<MASKED_ACRONYM>), which adopts a bidirectional multi-level connection structure based on Co-Attention Transformer. The structure builds bridges to connect each layer of the text encoder and graph encoder, which can introduce the QA entity relationship from KG to the text encoder and bring contextual text information to the graph encoder, so that these features can be deeply interactively fused to form comprehensive text and graph node representations. Meanwhile, we propose a QA-aware node based KG subgraph construction method. The QA-aware nodes aggregate the question entity nodes and the answer entity nodes, and further guide the expansion and construction process of the subgraph to enhance the connectivity and reduce the introduction of noise. We evaluate our model on QA benchmarks in the CommonsenseQA and OpenBookQA datasets, and <MASKED_ACRONYM> achieves state-of-the-art performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"MECI","Description":"A Multilingual Dataset for Event Causality Identification","Abstract":"Event Causality Identification (ECI) is the task of detecting causal relations between events mentioned in the text. Although this task has been extensively studied for English materials, it is under-explored for many other languages. A major reason for this issue is the lack of multilingual datasets that provide consistent annotations for event causality relations in multiple non-English languages. To address this issue, we introduce a new multilingual dataset for ECI, called <MASKED_ACRONYM>. The dataset employs consistent annotation guidelines for five typologically different languages, i.e., English, Danish, Spanish, Turkish, and Urdu. Our dataset thus enable a new research direction on cross-lingual transfer learning for ECI. Our extensive experiments demonstrate high quality for <MASKED_ACRONYM> that can provide ample research challenges and directions for future research. We will publicly release <MASKED_ACRONYM> to promote research on multilingual ECI.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2022,"Venue":"coling-2022","Acronym":"LightNER","Description":"A Lightweight Tuning Paradigm for Low-resource NER via Pluggable Prompting","Abstract":"Most NER methods rely on extensive labeled data for model training, which struggles in the low-resource scenarios with limited training data. Existing dominant approaches usually suffer from the challenge that the target domain has different label sets compared with a resource-rich source domain, which can be concluded as class transfer and domain transfer. In this paper, we propose a lightweight tuning paradigm for low-resource NER via pluggable prompting (<MASKED_ACRONYM>). Specifically, we construct the unified learnable verbalizer of entity categories to generate the entity span sequence and entity categories without any label-specific classifiers, thus addressing the class transfer issue. We further propose a pluggable guidance module by incorporating learnable parameters into the self-attention layer as guidance, which can re-modulate the attention and adapt pre-trained weights. Note that we only tune those inserted module with the whole parameter of the pre-trained language model fixed, thus, making our approach lightweight and flexible for low-resource scenarios and can better transfer knowledge across domains. Experimental results show that <MASKED_ACRONYM> can obtain comparable performance in the standard supervised setting and outperform strong baselines in low-resource settings.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.9333333333}
{"Year":2022,"Venue":"coling-2022","Acronym":"CLoSE","Description":"Contrastive Learning of Subframe Embeddings for Political Bias Classification of News Media","Abstract":"Framing is a political strategy in which journalists and politicians emphasize certain aspects of a societal issue in order to influence and sway public opinion. Frameworks for detecting framing in news articles or social media posts are critical in understanding the spread of biased information in our society. In this paper, we propose <MASKED_ACRONYM>, a multi-task BERT-based model which uses contrastive learning to embed indicators of frames from news articles in order to predict political bias. We evaluate the performance of our proposed model on subframes and political bias classification tasks. We also demonstrate the model\u2019s classification accuracy on zero-shot and few-shot learning tasks, providing a promising avenue for framing detection in unlabeled data.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"AiM","Description":"Taking Answers in Mind to Correct Chinese Cloze Tests in Educational Applications","Abstract":"To automatically correct handwritten assignments, the traditional approach is to use an OCR model to recognize characters and compare them to answers. The OCR model easily gets confused on recognizing handwritten Chinese characters, and the textual information of the answers is missing during the model inference. However, teachers always have these answers in mind to review and correct assignments. In this paper, we focus on the Chinese cloze tests correction and propose a multimodal approach(named <MASKED_ACRONYM>). The encoded representations of answers interact with the visual information of students\u2019 handwriting. Instead of predicting \u2018right\u2019 or \u2018wrong\u2019, we perform the sequence labeling on the answer text to infer which answer character differs from the handwritten content in a fine-grained way. We take samples of OCR datasets as the positive samples for this task, and develop a negative sample augmentation method to scale up the training data. Experimental results show that <MASKED_ACRONYM> outperforms OCR-based methods by a large margin. Extensive studies demonstrate the effectiveness of our multimodal approach.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"WARM","Description":"A Weakly (&#43;Semi) Supervised Math Word Problem Solver","Abstract":"Solving math word problems (MWPs) is an important and challenging problem in natural language processing. Existing approaches to solving MWPs require full supervision in the form of intermediate equations. However, labeling every MWP with its corresponding equations is a time-consuming and expensive task. In order to address this challenge of equation annotation, we propose a weakly supervised model for solving MWPs by requiring only the final answer as supervision. We approach this problem by first learning to generate the equation using the problem description and the final answer, which we subsequently use to train a supervised MWP solver. We propose and compare various weakly supervised techniques to learn to generate equations directly from the problem description and answer. Through extensive experiments, we demonstrate that without using equations for supervision, our approach achieves accuracy gains of 4.5% and 32% over the current state-of-the-art weakly-supervised approach, on the standard Math23K and AllArith datasets respectively. Additionally, we curate and release new datasets of roughly 10k MWPs each in English and in Hindi (a low-resource language). These datasets are suitable for training weakly supervised models. We also present an extension of our model to semi-supervised learning and present further improvements on results, along with insights.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"KNOT","Description":"Knowledge Distillation Using Optimal Transport for Solving NLP Tasks","Abstract":"We propose a new approach, Knowledge Distillation using Optimal Transport (<MASKED_ACRONYM>), to distill the natural language semantic knowledge from multiple teacher networks to a student network. <MASKED_ACRONYM> aims to train a (global) student model by learning to minimize the optimal transport cost of its assigned probability distribution over the labels to the weighted sum of probabilities predicted by the (local) teacher models, under the constraints that the student model does not have access to teacher models\u2019 parameters or training data. To evaluate the quality of knowledge transfer, we introduce a new metric, Semantic Distance (SD), that measures semantic closeness between the predicted and ground truth label distributions. The proposed method shows improvements in the global model\u2019s SD performance over the baseline across three NLP tasks while performing on par with Entropy-based distillation on standard accuracy and F1 metrics. The implementation pertaining to this work is publicly available at <a href=https:\/\/github.com\/declare-lab\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/declare-lab\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"SUN","Description":"Exploring Intrinsic Uncertainties in Text-to-SQL Parsers","Abstract":"This paper aims to improve the performance of text-to-SQL parsing by exploring the intrinsic uncertainties in the neural network based approaches (called <MASKED_ACRONYM>). From the data uncertainty perspective, it is indisputable that a single SQL can be learned from multiple semantically-equivalent questions. Different from previous methods that are limited to one-to-one mapping, we propose a data uncertainty constraint to explore the underlying complementary semantic information among multiple semantically-equivalent questions (many-to-one) and learn the robust feature representations with reduced spurious associations. In this way, we can reduce the sensitivity of the learned representations and improve the robustness of the parser. From the model uncertainty perspective, there is often structural information (dependence) among the weights of neural networks. To improve the generalizability and stability of neural text-to-SQL parsers, we propose a model uncertainty constraint to refine the query representations by enforcing the output representations of different perturbed encoding networks to be consistent with each other. Extensive experiments on five benchmark datasets demonstrate that our method significantly outperforms strong competitors and achieves new state-of-the-art results.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"GAP","Description":"A Graph-aware Language Model Framework for Knowledge Graph-to-Text Generation","Abstract":"Recent improvements in KG-to-text generation are due to additional auxiliary pre-training tasks designed to give the fine-tune task a boost in performance. These tasks require extensive computational resources while only suggesting marginal improvements. Here, we demonstrate that by fusing graph-aware elements into existing pre-trained language models, we are able to outperform state-of-the-art models and close the gap imposed by additional pre-training tasks. We do so by proposing a mask structure to capture neighborhood information and a novel type encoder that adds a bias to the graph-attention weights depending on the connection type. Experiments on two KG-to-text benchmark datasets show our models are competitive while involving fewer parameters and no additional pre-training tasks. By formulating the problem as a framework, we can interchange the various proposed components and begin interpreting KG-to-text generative models based on the topological and type information found in a graph.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"CoLo","Description":"A Contrastive Learning Based Re-ranking Framework for One-Stage Summarization","Abstract":"Traditional training paradigms for extractive and abstractive summarization systems always only use token-level or sentence-level training objectives. However, the output summary is always evaluated from summary-level which leads to the inconsistency in training and evaluation. In this paper, we propose a Contrastive Learning based re-ranking framework for one-stage summarization called <MASKED_ACRONYM>. By modeling a contrastive objective, we show that the summarization model is able to directly generate summaries according to the summary-level score without additional modules and parameters. Extensive experiments demonstrate that <MASKED_ACRONYM> boosts the extractive and abstractive results of one-stage systems on CNN\/DailyMail benchmark to 44.58 and 46.33 ROUGE-1 score while preserving the parameter efficiency and inference efficiency. Compared with state-of-the-art multi-stage systems, we save more than 100 GPU training hours and obtaining 3x 8x speed-up ratio during inference while maintaining comparable results.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"coling-2022","Acronym":"PINEAPPLE","Description":"Personifying INanimate Entities by Acquiring Parallel Personification Data for Learning Enhanced Generation","Abstract":"A personification is a figure of speech that endows inanimate entities with properties and actions typically seen as requiring animacy. In this paper, we explore the task of personification generation. To this end, we propose <MASKED_ACRONYM>: Personifying INanimate Entities by Acquiring Parallel Personification data for Learning Enhanced generation. We curate a corpus of personifications called PersonifCorp, together with automatically generated de-personified literalizations of these personifications. We demonstrate the usefulness of this parallel corpus by training a seq2seq model to personify a given literal input. Both automatic and human evaluations show that fine-tuning with PersonifCorp leads to significant gains in personification-related qualities such as animacy and interestingness. A detailed qualitative analysis also highlights key strengths and imperfections of <MASKED_ACRONYM> over baselines, demonstrating a strong ability to generate diverse and creative personifications that enhance the overall appeal of a sentence.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"DISK","Description":"Domain-constrained Instance Sketch for Math Word Problem Generation","Abstract":"A math word problem (MWP) is a coherent narrative which reflects the underlying logic of math equations. Successful MWP generation can automate the writing of mathematics questions. Previous methods mainly generate MWP text based on inflexible pre-defined templates. In this paper, we propose a neural model for generating MWP text from math equations. Firstly, we incorporate a matching model conditioned on the domain knowledge to retrieve a MWP instance which is most consistent with the ground-truth, where the domain is a latent variable extracted with a domain summarizer. Secondly, by constructing a Quantity Cell Graph (QCG) from the retrieved MWP instance and reasoning over it, we improve the model\u2019s comprehension of real-world scenarios and derive a domain-constrained instance sketch to guide the generation. Besides, the QCG also interacts with the equation encoder to enhance the alignment between math tokens (e.g., quantities and variables) and MWP text. Experiments and empirical analysis on educational MWP set show that our model achieves impressive performance in both automatic evaluation metrics and human evaluation metrics.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"coling-2022","Acronym":"CoNTACT","Description":"A Dutch COVID-19 Adapted BERT for Vaccine Hesitancy and Argumentation Detection","Abstract":"We present <MASKED_ACRONYM>: a Dutch language model adapted to the domain of COVID-19 tweets. The model was developed by continuing the pre-training phase of RobBERT (Delobelle et al., 2020) by using 2.8M Dutch COVID-19 related tweets posted in 2021. In order to test the performance of the model and compare it to RobBERT, the two models were tested on two tasks: (1) binary vaccine hesitancy detection and (2) detection of arguments for vaccine hesitancy. For both tasks, not only Twitter but also Facebook data was used to show cross-genre performance. In our experiments, <MASKED_ACRONYM> showed statistically significant gains over RobBERT in all experiments for task 1. For task 2, we observed substantial improvements in virtually all classes in all experiments. An error analysis indicated that the domain adaptation yielded better representations of domain-specific terminology, causing <MASKED_ACRONYM> to make more accurate classification decisions. For task 2, we observed substantial improvements in virtually all classes in all experiments. An error analysis indicated that the domain adaptation yielded better representations of domain-specific terminology, causing <MASKED_ACRONYM> to make more accurate classification decisions.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2010,"Venue":"lrec-2010","Acronym":"ProPOSEC","Description":"A Prosody and PoS Annotated Spoken English Corpus","Abstract":"We have previously reported on ProPOSEL, a purpose-built Prosody and PoS English Lexicon compatible with the Python Natural Language ToolKit. <MASKED_ACRONYM> is a new corpus research resource built using this lexicon, intended for distribution with the Aix-MARSEC dataset. <MASKED_ACRONYM> comprises multi-level parallel annotations, juxtaposing prosodic and syntactic information from different versions of the Spoken English Corpus, with canonical dictionary forms, in a query format optimized for Perl, Python, and text processing programs. The order and content of fields in the text file is as follows: (1) Aix-MARSEC file number; (2) word; (3) LOB PoS-tag; (4) C5 PoS-tag; (5) Aix SAM-PA phonetic transcription; (6) SAM-PA phonetic transcription from ProPOSEL; (7) syllable count; (8) lexical stress pattern; (9) default content or function word tag; (10) DISC stressed and syllabified phonetic transcription; (11) alternative DISC representation, incorporating lexical stress pattern; (12) nested arrays of phonemes and tonic stress marks from Aix. As an experimental dataset, <MASKED_ACRONYM> can be used to study correlations between these annotation tiers, where significant findings are then expressed as additional features for phrasing models integral to Text-to-Speech and Speech Recognition. As a training set, <MASKED_ACRONYM> can be used for machine learning tasks in Information Retrieval and Speech Understanding systems.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.9333333333}
{"Year":2008,"Venue":"lrec-2008","Acronym":"FATE","Description":"a FrameNet-Annotated Corpus for Textual Entailment","Abstract":"Several studies indicate that the level of predicate-argument structure is relevant for modeling prevalent phenomena in current textual entailment corpora. Although large resources like FrameNet have recently become available, attempts to integrate this type of information into a system for textual entailment did not confirm the expected gain in performance. The reasons for this are not fully obvious; candidates include FrameNet\u0092s restricted coverage, limitations of semantic parsers, or insufficient modeling of FrameNet information. To enable further insight on this issue, in this paper we present <MASKED_ACRONYM> (FrameNet-Annotated Textual Entailment), a manually crafted, fully reliable frame-annotated RTE corpus. The annotation has been carried out over the 800 pairs of the RTE-2 test set. This dataset offers a safe basis for RTE systems to experiment, and enables researchers to develop clearer ideas on how to effectively integrate frame knowledge in semantic inferenence tasks like recognizing textual entailment. We describe and present statistics over the adopted annotation, which introduces a new schema based on full-text annotation of so called relevant frame evoking elements.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2008,"Venue":"lrec-2008","Acronym":"ProPOSEL","Description":"A Prosody and POS English Lexicon for Language Engineering","Abstract":"<MASKED_ACRONYM> is a prototype prosody and PoS (part-of-speech) English lexicon for Language Engineering, derived from the following language resources: the computer-usable dictionary CUVPlus, the CELEX-2 database, the Carnegie-Mellon Pronouncing Dictionary, and the BNC, LOB and Penn Treebank PoS-tagged corpora. The lexicon is designed for the target application of prosodic phrase break prediction but is also relevant to other machine learning and language engineering tasks. It supplements the existing record structure for wordform entries in CUVPlus with syntactic annotations from rival PoS-tagging schemes, mapped to fields for default closed and open-class word categories and for lexical stress patterns representing the rhythmic structure of wordforms and interpreted as potential new text-based features for automatic phrase break classifiers. The current version of the lexicon comes as a textfile of 104052 separate entries and is intended for distribution with the Natural Language ToolKit; it is therefore accompanied by supporting Python software for manipulating the data so that it can be used for Natural Language Processing (NLP) and corpus-based research in speech synthesis and speech recognition.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.9333333333}
{"Year":2023,"Venue":"findings-2023","Acronym":"ImaginE","Description":"An Imagination-Based Automatic Evaluation Metric for Natural Language Generation","Abstract":"Automatic evaluations for natural language generation (NLG) conventionally rely on token-level or embedding-level comparisons with text references. This differs from human language processing, for which visual imagination often improves comprehension. In this work, we propose <MASKED_ACRONYM>, an imagination-based automatic evaluation metric for natural language generation. With the help of StableDiffusion, a state-of-the-art text-to-image generator, we automatically generate an image as the embodied imagination for the text snippet and compute the imagination similarity using contextual embeddings. Experiments spanning several text generation tasks demonstrate that adding machine-generated images with our <MASKED_ACRONYM> displays great potential in introducing multi-modal information into NLG evaluation, and improves existing automatic metrics\u2019 correlations with human similarity judgments in both reference-based and reference-free evaluation scenarios.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"LED","Description":"A Dataset for Life Event Extraction from Dialogs","Abstract":"Lifelogging has gained more attention due to its wide applications, such as personalized recommendations or memory assistance. The issues of collecting and extracting personal life events have emerged. People often share their life experiences with others through conversations. However, extracting life events from conversations is rarely explored. In this paper, we present Life Event Dialog, a dataset containing fine-grained life event annotations on conversational data. In addition, we initiate a novel Conversational Life Event Extraction task and differentiate the task from the public event extraction or the life event extraction from other sources like microblogs. We explore three information extraction (IE) frameworks to address the Conversational Life Event Extraction task: OpenIE, relation extraction, and event extraction. A comprehensive empirical analysis of the three baselines is established. The results suggest that the current event extraction model still struggles with extracting life events from human daily conversations. Our proposed Life Event Dialog dataset and in-depth analysis of IE frameworks will facilitate future research on life event extraction from conversations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"MUTANT","Description":"A Multi-sentential Code-mixed Hinglish Dataset","Abstract":"The multi-sentential long sequence textual data unfolds several interesting research directions pertaining to natural language processing and generation. Though we observe several high-quality long-sequence datasets for English and other monolingual languages, there is no significant effort in building such resources for code-mixed languages such as Hinglish (code-mixing of Hindi-English). In this paper, we propose a novel task of identifying multi-sentential code-mixed text (MCT) from multilingual articles. As a use case, we leverage multilingual articles from two different data sources and build a first-of-its-kind multi-sentential code-mixed Hinglish dataset i.e., <MASKED_ACRONYM>. We propose a token-level language-aware pipeline and extend the existing metrics measuring the degree of code-mixing to a multi-sentential framework and automatically identify MCT in the multilingual articles. The <MASKED_ACRONYM> dataset comprises 67k articles with 85k identified Hinglish MCTs. To facilitate future research directions, we will make the dataset and the code publicly available upon publication.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"PLACES","Description":"Prompting Language Models for Social Conversation Synthesis","Abstract":"Collecting high quality conversational data can be very expensive for most applications and infeasible for others due to privacy, ethical, or similar concerns. A promising direction to tackle this problem is to generate synthetic dialogues by prompting large language models. In this work, we use a small set of expert-written conversations as in-context examples to synthesize a social conversation dataset using prompting. We perform several thorough evaluations of our synthetic conversations compared to human-collected conversations. This includes various dimensions of conversation quality with human evaluation directly on the synthesized conversations, and interactive human evaluation of chatbots fine-tuned on the synthetically generated dataset. We additionally demonstrate that this prompting approach is generalizable to multi-party conversations, providing potential to create new synthetic data for multi-party tasks. Our synthetic multi-party conversations were rated more favorably across all measured dimensions compared to conversation excerpts sampled from a human-collected multi-party dataset.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"PAL","Description":"Persona-Augmented Emotional Support Conversation Generation","Abstract":"Due to the lack of human resources for mental health support, there is an increasing demand for employing conversational agents for support. Recent work has demonstrated the effectiveness of dialogue models in providing emotional support. As previous studies have demonstrated that seekers\u2019 persona is an important factor for effective support, we investigate whether there are benefits to modeling such information in dialogue models for support. In this paper, our empirical analysis verifies that persona has an important impact on emotional support. Therefore, we propose a framework for dynamically inferring and modeling seekers\u2019 persona. We first train a model for inferring the seeker\u2019s persona from the conversation history. Accordingly, we propose <MASKED_ACRONYM>, a model that leverages persona information and, in conjunction with our strategy-based controllable generation method, provides personalized emotional support. Automatic and manual evaluations demonstrate that <MASKED_ACRONYM> achieves state-of-the-art results, outperforming the baselines on the studied benchmark. Our code and data are publicly available at <a href=https:\/\/github.com\/chengjl19\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/chengjl19\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"Click","Description":"Controllable Text Generation with Sequence Likelihood Contrastive Learning","Abstract":"It has always been an important yet challenging problem to control language models to avoid generating texts with undesirable attributes, such as toxic language and unnatural repetition. We introduce Leo for controllable text generation, which needs no modification to the model architecture and facilitates out-of-the-box use of trained models. It employs a contrastive loss on sequence likelihood, which fundamentally decreases the generation probability of negative samples (i.e., generations with undesirable attributes). It also adopts a novel likelihood ranking-based strategy to construct contrastive samples from model generations. On the tasks of language detoxification, sentiment steering, and repetition reduction, we show that Leo outperforms strong baselines of controllable text generation and demonstrate the superiority of Leo\u2019s sample construction strategy.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"AVATAR","Description":"A Parallel Corpus for Java-Python Program Translation","Abstract":"Program translation refers to migrating source code from one programming language to another. It has tremendous practical value in software development, as porting software across languages is time-consuming and costly. Automating program translation is of paramount importance in software migration, and recently researchers explored unsupervised approaches due to the unavailability of parallel corpora. However, the availability of pre-trained language models for programming languages enables supervised fine-tuning with a small number of labeled examples. Therefore, we present <MASKED_ACRONYM>, a collection of 9,515 programming problems and their solutions written in two popular languages, Java and Python. <MASKED_ACRONYM> is collected from competitive programming sites, online platforms, and open-source repositories. Furthermore, <MASKED_ACRONYM> includes unit tests for 250 examples to facilitate functional correctness evaluation. We benchmark several pre-trained language models fine-tuned on <MASKED_ACRONYM>. Experiment results show that the models lack in generating functionally accurate code.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"ACROSS","Description":"An Alignment-based Framework for Low-Resource Many-to-One Cross-Lingual Summarization","Abstract":"This research addresses the challenges of Cross-Lingual Summarization (CLS) in low-resource scenarios and over imbalanced multilingual data. Existing CLS studies mostly resort to pipeline frameworks or multi-task methods in bilingual settings. However, they ignore the data imbalance in multilingual scenarios and do not utilize the high-resource monolingual summarization data. In this paper, we propose the Aligned CROSs-lingual Summarization (<MASKED_ACRONYM>) model to tackle these issues. Our framework aligns low-resource cross-lingual data with high-resource monolingual data via contrastive and consistency loss, which help enrich low-resource information for high-quality summaries. In addition, we introduce a data augmentation method that can select informative monolingual sentences, which facilitates a deep exploration of high-resource information and introduce new information for low-resource languages. Experiments on the CrossSum dataset show that <MASKED_ACRONYM> outperforms baseline models and obtains consistently dominant performance on 45 language pairs.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"VoteTRANS","Description":"Detecting Adversarial Text without Training by Voting on Hard Labels of Transformations","Abstract":"Adversarial attacks reveal serious flaws in deep learning models. More dangerously, these attacks preserve the original meaning and escape human recognition. Existing methods for detecting these attacks need to be trained using original\/adversarial data. In this paper, we propose detection without training by voting on hard labels from predictions of transformations, namely, <MASKED_ACRONYM>. Specifically, <MASKED_ACRONYM> detects adversarial text by comparing the hard labels of input text and its transformation. The evaluation demonstrates that <MASKED_ACRONYM> effectively detects adversarial text across various state-of-the-art attacks, models, and datasets.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2023,"Venue":"findings-2023","Acronym":"LET","Description":"Leveraging Error Type Information for Grammatical Error Correction","Abstract":"Grammatical error correction (GEC) aims to correct errors in given sentences and is significant to many downstream natural language understanding tasks. Recent work introduces the idea of grammatical error detection (GED) to improve the GEC task performance. In contrast, these explicit multi-stage works propagate and amplify the problem of misclassification of the GED module. To introduce more convincing error type information, we propose an end-to-end framework in this paper, which Leverages Error Type (<MASKED_ACRONYM>) information in the generation process. First, the input text is fed into a classification module to obtain the error type corresponding to each token. Then, we introduce the category information into the decoder\u2019s input and cross-attention module in two ways, respectively. Experiments on various datasets show that our proposed method outperforms existing methods by a clear margin.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"PEER","Description":"Pre-training ELECTRA Extended by Ranking","Abstract":"The BERT model and its variants have made great achievements in many downstream natural language processing tasks. The achievements of these models, however, demand highly expensive pre-training computation cost. To address this pre-training efficiency issue, the ELECTRA model is proposed to use a discriminator to perform replaced token detection (RTD) task, that is, to classify whether each input token is original or replaced by a generator. The RTD task performed by the ELECTRA accelerates pre-training so substantially, such that it is very challenging to further improve the pre-training efficiency established by the ELECTRA by using or adding other pre-training tasks, as the recent comprehensive study of Bajaj et al. (2022) summarizes. To further advance this pre-training efficiency frontier, in this paper we propose to extend the RTD task into a task of ranking input tokens according to K different quality levels. Essentially, we generalize the binary classifier in the ELECTRA into a K-level ranker to undertake a more precise task with negligible additional computation cost. Our extensive experiments show that our proposed method is able to outperform the state-of-the-art pre-training efficient models including ELECTRA in downstream GLUE tasks given the same computation cost.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"TranSFormer","Description":"Slow-Fast Transformer for Machine Translation","Abstract":"Learning multiscale Transformer models has been evidenced as a viable approach to augmenting machine translation systems. Prior research has primarily focused on treating subwords as basic units in developing such systems. However, the incorporation of fine-grained character-level features into multiscale Transformer has not yet been explored. In this work, we present a <b>S<\/b>low-<b>F<\/b>ast two-stream learning model, referred to as Tran<b>SF<\/b>ormer, which utilizes a \u201cslow\u201d branch to deal with subword sequences and a \u201cfast\u201d branch to deal with longer character sequences. This model is efficient since the fast branch is very lightweight by reducing the model width, and yet provides useful fine-grained features for the slow branch. Our <MASKED_ACRONYM> shows consistent BLEU improvements (larger than 1 BLEU point) on several machine translation benchmarks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.9565217391}
{"Year":2023,"Venue":"findings-2023","Acronym":"IDOL","Description":"Indicator-oriented Logic Pre-training for Logical Reasoning","Abstract":"In the field of machine reading comprehension (MRC), existing systems have surpassed the average performance of human beings in many tasks like SQuAD. However, there is still a long way to go when it comes to logical reasoning. Although some methods for it have been put forward, they either are designed in a quite complicated way or rely too much on external structures. In this paper, we proposed <MASKED_ACRONYM> (InDicator-Oriented Logic Pre-training), an easy-to-understand but highly effective further pre-training task which logically strengthens the pre-trained models with the help of 6 types of logical indicators and a logically rich dataset LoGic Pre-training (LGP). <MASKED_ACRONYM> achieves state-of-the-art performance on ReClor and LogiQA, the two most representative benchmarks in logical reasoning MRC, and is proven to be capable of generalizing to different pre-trained models and other types of MRC benchmarks like RACE and SQuAD 2.0 while keeping competitive general language understanding ability through testing on tasks in GLUE. Besides, at the beginning of the era of large language models, we take several of them like ChatGPT into comparison and find that <MASKED_ACRONYM> still shows its advantage.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"GRACE","Description":"Gradient-guided Controllable Retrieval for Augmenting Attribute-based Text Generation","Abstract":"Attribute-based generation methods are of growing significance in controlling the generation of large pre-trained language models (PLMs). Existing studies control the generation by (1) finetuning the model with attributes or (2) guiding the inference processing toward control signals while freezing the PLM. However, finetuning approaches infuse domain bias into generation, making it hard to generate out-of-domain texts. Besides, many methods guide the inference in its word-by-word generation, pushing the word probability to the target attributes, resulting in less fluent sentences. We argue that distilling controlling information from natural texts can produce fluent sentences while maintaining high controllability. In this paper, we propose <b>GRA<\/b>dient-guided <b>C<\/b>ontrollable r<b>E<\/b>trieval (<MASKED_ACRONYM>), a retrieval-augmented generation framework to facilitate the generation of fluent sentences with high attribute relevance. <MASKED_ACRONYM> memorizes the semantic and attribute information from unlabeled corpora and applies a controllable retrieval to obtain desired information. For the generation, we design techniques to eliminate the domain bias from the retrieval results and integrate it into the generation model. Additionally, we propose a gradient-guided generation scheme that iteratively steers generation toward higher attribute relevance. Experimental results and quantities of examples verify the effectiveness of our method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"SlowBERT","Description":"Slow-down Attacks on Input-adaptive Multi-exit BERT","Abstract":"For pretrained language models such as Google\u2019s BERT, recent research designs several input-adaptive inference mechanisms to improve the efficiency on cloud and edge devices. In this paper, we reveal a new attack surface on input-adaptive multi-exit BERT, where the adversary imperceptibly modifies the input texts to drastically increase the average inference cost. Our proposed slow-down attack called <i><MASKED_ACRONYM><\/i> integrates a new rank-and-substitute adversarial text generation algorithm to efficiently search for the perturbation which maximally delays the exiting time. With no direct access to the model internals, we further devise a <i>time-based approximation algorithm<\/i> to infer the exit position as the loss oracle. Our extensive evaluation on two popular instances of multi-exit BERT for GLUE classification tasks validates the effectiveness of <MASKED_ACRONYM>. In the worst case, <MASKED_ACRONYM> increases the inference cost by <span class=tex-math>4.57\u00d7<\/span>, which would strongly hurt the service quality of multi-exit BERT in practice, e.g., increasing the real-time cloud services\u2019 response times for online users.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2023,"Venue":"findings-2023","Acronym":"AUGUST","Description":"an Automatic Generation Understudy for Synthesizing Conversational Recommendation Datasets","Abstract":"High-quality data is essential for conversational recommendation systems and serves as the cornerstone of the network architecture development and training strategy design. Existing works contribute heavy human efforts to manually labeling or designing and extending recommender dialogue templates. However, they suffer from: (i) the limited number of human annotators results in datasets can hardly capture rich and large-scale cases in the real world, (ii) the limited experience and knowledge of annotators accounts for the uninformative corpus and inappropriate recommendations. In this paper, we propose a novel automatic dataset synthesis approach that can generate large-scale and high-quality recommendation dialogues through a data2text generation process, where unstructured recommendation conversations are generated from structured graphs based on user-item information from the real world. In doing so, we comprehensively exploit: (i) rich personalized user profiles from traditional recommendation datasets, (ii) rich external knowledge from knowledge graphs, and (iii) the conversation ability contained in human-to-human conversational recommendation datasets. Extensive experiments validate the benefit brought by the automatically synthesized data under low-resource scenarios, and demonstrate the promising potential to facilitate developing a more effective conversational recommendation system.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"Nano","Description":"Nested Human-in-the-Loop Reward Learning for Few-shot Language Model Control","Abstract":"Pretrained language models have demonstrated extraordinary capabilities in language generation. However, real-world tasks often require controlling the distribution of generated text in order to mitigate bias, promote fairness, and achieve personalization. Existing techniques for controlling the distribution of generated text only work with quantified distributions, which require pre-defined categories, proportions of the distribution, or an existing corpus following the desired distributions. However, many important distributions, such as personal preferences, are unquantified. In this work, we tackle the problem of generating text following arbitrary distributions (quantified and unquantified) by proposing NANO, a few-shot human-in-the-loop training algorithm that continuously learns from human feedback. NANO achieves state-of-the-art results on single topic\/attribute as well as quantified distribution control compared to previous works. We also show that NANO is able to learn unquantified distributions, achieves personalization, and captures differences between different individuals\u2019 personal preferences with high sample efficiency.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"RISE","Description":"Leveraging Retrieval Techniques for Summarization Evaluation","Abstract":"Evaluating automatically-generated text summaries is a challenging task. While there have been many interesting approaches, they still fall short of human evaluations. We present <MASKED_ACRONYM>, a new approach for evaluating summaries by leveraging techniques from information retrieval. <MASKED_ACRONYM> is first trained as a retrieval task using a dual-encoder retrieval setup, and can then be subsequently utilized for evaluating a generated summary given an input document, without gold reference summaries. <MASKED_ACRONYM> is especially well suited when working on new datasets where one may not have reference summaries available for evaluation. We conduct comprehensive experiments on the SummEval benchmark (Fabbri et al., 2021) and a long document summarization benchmark. The results show that <MASKED_ACRONYM> consistently achieves higher correlation with human evaluations compared to many past approaches to summarization evaluation. Furthermore, <MASKED_ACRONYM> also demonstrates data-efficiency and generalizability across languages.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"findings-2023","Acronym":"DEnsity","Description":"Open-domain Dialogue Evaluation Metric using Density Estimation","Abstract":"Despite the recent advances in open-domain dialogue systems, building a reliable evaluation metric is still a challenging problem. Recent studies proposed learnable metrics based on classification models trained to distinguish the correct response. However, neural classifiers are known to make overly confident predictions for examples from unseen distributions. We propose DENSITY, which evaluates a response by utilizing density estimation on the feature space derived from a neural classifier. Our metric measures how likely a response would appear in the distribution of human conversations. Moreover, to improve the performance of DENSITY, we utilize contrastive learning to further compress the feature space. Experiments on multiple response evaluation datasets show that DENSITY correlates better with human evaluations than the existing metrics.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2009,"Venue":"eacl-2009","Acronym":"MINT","Description":"A Method for Effective and Scalable Mining of Named Entity Transliterations from Large Comparable Corpora","Abstract":"In this paper, we address the problem of mining transliterations of Named Entities (NEs)  from large comparable corpora. We leverage  the empirical fact that multilingual news articles with similar news content are rich in  Named Entity Transliteration Equivalents  (NETEs). Our mining algorithm, <MASKED_ACRONYM>, uses  a cross-language document similarity model to  align multilingual news articles and then  mines NETEs from the aligned articles using a  transliteration similarity model. We show that  our approach is highly effective on 6 different  comparable corpora between English and 4  languages from 3 different language families.  Furthermore, it performs substantially better  than a state-of-the-art competitor.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"blackboxnlp-2021","Acronym":"ProSPer","Description":"Probing Human and Neural Network Language Model Understanding of Spatial Perspective","Abstract":"Understanding perspectival language is important for applications like dialogue systems and human-robot interaction. We propose a probe task that explores how well language models understand spatial perspective. We present a dataset for evaluating perspective inference in English, <MASKED_ACRONYM>, and use it to explore how humans and Transformer-based language models infer perspective. Although the best bidirectional model performs similarly to humans, they display different strengths: humans outperform neural networks in conversational contexts, while RoBERTa excels at written genres.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"tacl-2019","Acronym":"DREAM","Description":"A Challenge Data Set and Models for Dialogue-Based Reading Comprehension","Abstract":"We present <MASKED_ACRONYM>, the first dialogue-based multiple-choice reading comprehension data set. Collected from English as a Foreign Language examinations designed by human experts to evaluate the comprehension level of Chinese learners of English, our data set contains 10,197 multiple-choice questions for 6,444 dialogues. In contrast to existing reading comprehension data sets, <MASKED_ACRONYM> is the first to focus on in-depth multi-turn multi-party dialogue understanding. <MASKED_ACRONYM> is likely to present significant challenges for existing reading comprehension systems: 84% of answers are non-extractive, 85% of questions require reasoning beyond a single sentence, and 34% of questions also involve commonsense knowledge. We apply several popular neural reading comprehension models that primarily exploit surface information within the text and find them to, at best, just barely outperform a rule-based approach. We next investigate the effects of incorporating dialogue structure and different kinds of general world knowledge into both rule-based and (neural and non-neural) machine learning-based reading comprehension models. Experimental results on the <MASKED_ACRONYM> data set show the effectiveness of dialogue structure and general world knowledge. <MASKED_ACRONYM> is available at <a href=https:\/\/dataset.org\/dream\/ class=acl-markup-url>https:\/\/dataset.org\/dream\/<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"aacl-2020","Acronym":"MaP","Description":"A Matrix-based Prediction Approach to Improve Span Extraction in Machine Reading Comprehension","Abstract":"Span extraction is an essential problem in machine reading comprehension. Most of the existing algorithms predict the start and end positions of an answer span in the given corresponding context by generating two probability vectors. In this paper, we propose a novel approach that extends the probability vector to a probability matrix. Such a matrix can cover more start-end position pairs. Precisely, to each possible start index, the method always generates an end probability vector. Besides, we propose a sampling-based training strategy to address the computational cost and memory issue in the matrix training phase. We evaluate our method on SQuAD 1.1 and three other question answering benchmarks. Leveraging the most competitive models BERT and BiDAF as the backbone, our proposed approach can get consistent improvements in all datasets, demonstrating the effectiveness of the proposed method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"nodalida-2019","Acronym":"DIM","Description":"The Database of Icelandic Morphology","Abstract":"The topic of this paper is The Database of Icelandic Morphology (<MASKED_ACRONYM>), a multipurpose linguistic resource, created for use in language technology, as a reference for the general public in Iceland, and for use in research on the Icelandic language. <MASKED_ACRONYM> contains inflectional paradigms and analysis of word formation, with a vocabulary of approx. 285,000 lemmas. <MASKED_ACRONYM> is based on The Database of Modern Icelandic Inflection, which has been in use since 2004.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"ws-2020","Acronym":"SEARCHER","Description":"Shared Embedding Architecture for Effective Retrieval","Abstract":"We describe an approach to cross lingual information retrieval that does not rely on explicit translation of either document or query terms. Instead, both queries and documents are mapped into a shared embedding space where retrieval is performed. We discuss potential advantages of the approach in handling polysemy and synonymy. We present a method for training the model, and give details of the model implementation. We present experimental results for two cases: Somali-English and Bulgarian-English CLIR.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2020,"Venue":"ws-2020","Acronym":"MAST","Description":"Multimodal Abstractive Summarization with Trimodal Hierarchical Attention","Abstract":"This paper presents <MASKED_ACRONYM>, a new model for Multimodal ive Text Summarization that utilizes information from all three modalities \u2013 text, audio and video \u2013 in a multimodal video. Prior work on multimodal abstractive text summarization only utilized information from the text and video modalities. We examine the usefulness and challenges of deriving information from the audio modality and present a sequence-to-sequence trimodal hierarchical attention-based model that overcomes these challenges by letting the model pay more attention to the text modality. <MASKED_ACRONYM> outperforms the current state of the art model (video-text) by 2.51 points in terms of Content F1 score and 1.00 points in terms of Rouge-L score on the How2 dataset for multimodal language understanding.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2016,"Venue":"ws-2016","Acronym":"VERSE","Description":"Event and Relation Extraction in the BioNLP 2016 Shared Task","Abstract":"We present the Vancouver Event and Relation System for Extraction (<MASKED_ACRONYM>)1 as a competing system for three subtasks of the BioNLP Shared Task 2016. <MASKED_ACRONYM> performs full event extraction including entity, relation and modi\ufb01cation extraction using a feature-based approach. It achieved the highest F1-score in the Bacteria Biotope (BB3) event subtask and the third highest F1-score in the Seed Development (SeeDev) binary subtask.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"ws-2016","Acronym":"MED","Description":"The LMU System for the SIGMORPHON 2016 Shared Task on Morphological Reinflection","Abstract":"This paper presents <MASKED_ACRONYM>, the main system of the LMU team for the SIGMORPHON 2016 Shared Task on Morphological Rein\ufb02ection as well as an extended analysis of how different design choices contribute to the \ufb01nal performance. We model the task of morphological rein\ufb02ection using neural encoder-decoder models together with an encoding of the input as a single sequence of the morphological tags of the source and target form as well as the sequence of letters of the source form. The Shared Task consists of three subtasks, three different tracks and covers 10 different languages to encourage the use of language-independent approaches. <MASKED_ACRONYM> was the system with the overall best performance, demonstrating our method generalizes well for the low-resource setting of the SIGMORPHON 2016 Shared Task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"ws-2016","Acronym":"CharacTer","Description":"Translation Edit Rate on Character Level","Abstract":"Recently, the capability of character-level evaluation measures for machine translation output has been con\ufb01rmed by several metrics. This work proposes translation edit rate on character level (CharacTER), which calculates the character level edit distance while performing the shift edit on word level. The novel metric shows high system-level correlation with human rankings, especially for morphologically rich languages. It outperforms the strong CHRF by up to 7% correlation on different metric tasks. In addition, we apply the hypothesis sentence length for normalizing the edit distance in CharacTER, which also provides signi\ufb01cant improvements compared to using the reference sentence length.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"ws-2021","Acronym":"HinGE","Description":"A Dataset for Generation and Evaluation of Code-Mixed Hinglish Text","Abstract":"Text generation is a highly active area of research in the computational linguistic community. The evaluation of the generated text is a challenging task and multiple theories and metrics have been proposed over the years. Unfortunately, text generation and evaluation are relatively understudied due to the scarcity of high-quality resources in code-mixed languages where the words and phrases from multiple languages are mixed in a single utterance of text and speech. To address this challenge, we present a corpus (<MASKED_ACRONYM>) for a widely popular code-mixed language Hinglish (code-mixing of Hindi and English languages). <MASKED_ACRONYM> has Hinglish sentences generated by humans as well as two rule-based algorithms corresponding to the parallel Hindi-English sentences. In addition, we demonstrate the in- efficacy of widely-used evaluation metrics on the code-mixed data. The <MASKED_ACRONYM> dataset will facilitate the progress of natural language generation research in code-mixed languages.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"ws-2021","Acronym":"FaBULOUS","Description":"Fact-checking Based on Understanding of Language Over Unstructured and Structured information","Abstract":"As part of the FEVEROUS shared task, we developed a robust and finely tuned architecture to handle the joint retrieval and entailment on text data as well as structured data like tables. We proposed two training schemes to tackle the hurdles inherent to multi-hop multi-modal datasets. The first one allows having a robust retrieval of full evidence sets, while the second one enables entailment to take full advantage of noisy evidence inputs. In addition, our work has revealed important insights and potential avenue of research for future improvement on this kind of dataset. In preliminary evaluation on the FEVEROUS shared task test set, our system achieves 0.271 FEVEROUS score, with 0.4258 evidence recall and 0.5607 entailment accuracy.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"ws-2021","Acronym":"COIN","Description":"Conversational Interactive Networks for Emotion Recognition in Conversation","Abstract":"Emotion recognition in conversation has received considerable attention recently because of its practical industrial applications. Existing methods tend to overlook the immediate mutual interaction between different speakers in the speaker-utterance level, or apply single speaker-agnostic RNN for utterances from different speakers. We propose <MASKED_ACRONYM>, a conversational interactive model to mitigate this problem by applying state mutual interaction within history contexts. In addition, we introduce a stacked global interaction module to capture the contextual and inter-dependency representation in a hierarchical manner. To improve the robustness and generalization during training, we generate adversarial examples by applying the minor perturbations on multimodal feature inputs, unveiling the benefits of adversarial examples for emotion detection. The proposed model empirically achieves the current state-of-the-art results on the IEMOCAP benchmark dataset.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"ws-2021","Acronym":"GENE","Description":"Global Event Network Embedding","Abstract":"Current methods for event representation ignore related events in a corpus-level global context. For a deep and comprehensive understanding of complex events, we introduce a new task, Event Network Embedding, which aims to represent events by capturing the connections among events. We propose a novel framework, Global Event Network Embedding (<MASKED_ACRONYM>), that encodes the event network with a multi-view graph encoder while preserving the graph topology and node semantics. The graph encoder is trained by minimizing both structural and semantic losses. We develop a new series of structured probing tasks, and show that our approach effectively outperforms baseline models on node typing, argument role classification, and event coreference resolution.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"ws-2021","Acronym":"ONE","Description":"Toward ONE model, ONE algorithm, ONE corpus dedicated to sentiment analysis of Arabic\/Arabizi and its dialects","Abstract":"Arabic is the official language of 22 countries, spoken by more than 400 million speakers. Each one of this country use at least on dialect for daily life conversation. Then, Arabic has at least 22 dialects. Each dialect can be written in Arabic or Arabizi Scripts. The most recent researches focus on constructing a language model and a training corpus for each dialect, in each script. Following this technique means constructing 46 different resources (by including the Modern Standard Arabic, MSA) for handling only one language. In this paper, we extract <MASKED_ACRONYM> corpus, and we propose <MASKED_ACRONYM> algorithm to automatically construct <MASKED_ACRONYM> training corpus using <MASKED_ACRONYM> classification model architecture for sentiment analysis MSA and different dialects. After manually reviewing the training corpus, the obtained results outperform all the research literature results for the targeted test corpora.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"tacl-2021","Acronym":"EDITOR","Description":"An Edit-Based Transformer with Repositioning for Neural Machine Translation with Soft Lexical Constraints","Abstract":"We introduce an Edit-Based TransfOrmer with Repositioning (<MASKED_ACRONYM>), which makes sequence generation flexible by seamlessly allowing users to specify preferences in output lexical choice. Building on recent models for non-autoregressive sequence generation (Gu et al., 2019), <MASKED_ACRONYM> generates new sequences by iteratively editing hypotheses. It relies on a novel reposition operation designed to disentangle lexical choice from word positioning decisions, while enabling efficient oracles for imitation learning and parallel edits at decoding time. Empirically, <MASKED_ACRONYM> uses soft lexical constraints more effectively than the Levenshtein Transformer (Gu et al., 2019) while speeding up decoding dramatically compared to constrained beam search (Post and Vilar, 2018). <MASKED_ACRONYM> also achieves comparable or better translation quality with faster decoding speed than the Levenshtein Transformer on standard Romanian-English, English-German, and English-Japanese machine translation tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2010,"Venue":"ws-2010","Acronym":"CONE","Description":"Metrics for Automatic Evaluation of Named Entity Co-Reference Resolution","Abstract":"Human annotation for Co-reference Resolution (CRR) is labor intensive and costly, and  only a handful of annotated corpora are currently available. However, corpora with  Named Entity (NE) annotations are widely  available. Also, unlike current CRR systems,  state-of-the-art NER systems have very high  accuracy and can generate NE labels that are  very close to the gold standard for unlabeled  corpora.  We propose a new set of metrics collectively called <MASKED_ACRONYM> for Named Entity Coreference Resolution (NE-CRR) that use a  subset of gold standard annotations, with the  advantage that this subset can be easily approximated using NE labels when gold standard CRR annotations are absent. We define  <MASKED_ACRONYM> B3 and <MASKED_ACRONYM> CEAF metrics based on  the traditional B3 and CEAF metrics and show  that <MASKED_ACRONYM> B3 and <MASKED_ACRONYM> CEAF scores of any  CRR system on any dataset are highly correlated with its B3 and CEAF scores respectively.  We obtain correlation factors greater than 0.6  for all CRR systems across all datasets, and a  best-case correlation factor of 0.8. We also  present a baseline method to estimate the gold  standard required by <MASKED_ACRONYM> metrics, and show  that <MASKED_ACRONYM> B3 and <MASKED_ACRONYM> CEAF scores using  this estimated gold standard are also correlated  with B3 and CEAF scores respectively. We  thus demonstrate the suitability of <MASKED_ACRONYM>  B3and <MASKED_ACRONYM> CEAF for automatic evaluation  of NE-CRR.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"ijcnlp-2022","Acronym":"WAX","Description":"A New Dataset for Word Association eXplanations","Abstract":"Word associations are among the most common paradigms to study the human mental lexicon. While their structure and types of associations have been well studied, surprisingly little attention has been given to the question of why participants produce the observed associations. Answering this question would not only advance understanding of human cognition, but could also aid machines in learning and representing basic commonsense knowledge. This paper introduces a large, crowd-sourced data set of English word associations with explanations, labeled with high-level relation types. We present an analysis of the provided explanations, and design several tasks to probe to what extent current pre-trained language models capture the underlying relations. Our experiments show that models struggle to capture the diversity of human associations, suggesting <MASKED_ACRONYM> is a rich benchmark for commonsense modeling and generation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"ijcnlp-2022","Acronym":"CLASP","Description":"Few-Shot Cross-Lingual Data Augmentation for Semantic Parsing","Abstract":"A bottleneck to developing Semantic Parsing (SP) models is the need for a large volume of human-labeled training data. Given the complexity and cost of human annotation for SP, labeled data is often scarce, particularly in multilingual settings. Large Language Models (LLMs) excel at SP given only a few examples, however LLMs are unsuitable for runtime systems which require low latency. In this work, we propose <MASKED_ACRONYM>, a simple method to improve low-resource SP for moderate-sized models: we generate synthetic data from AlexaTM 20B to augment the training set for a model 40x smaller (500M parameters). We evaluate on two datasets in low-resource settings: English PIZZA, containing either 348 or 16 real examples, and mTOP cross-lingual zero-shot, where training data is available only in English, and the model must generalize to four new languages. On both datasets, we show significant improvements over strong baseline methods.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2019,"Venue":"ijcnlp-2019","Acronym":"PaRe","Description":"A Paper-Reviewer Matching Approach Using a Common Topic Space","Abstract":"Finding the right reviewers to assess the quality of conference submissions is a time consuming process for conference organizers. Given the importance of this step, various automated reviewer-paper matching solutions have been proposed to alleviate the burden. Prior approaches including bag-of-words model and probabilistic topic model are less effective to deal with the vocabulary mismatch and partial topic overlap between the submission and reviewer. Our approach, the common topic model, jointly models the topics common to the submission and the reviewer\u2019s profile while relying on abstract topic vectors. Experiments and insightful evaluations on two datasets demonstrate that the proposed method achieves consistent improvements compared to the state-of-the-art.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2019,"Venue":"ijcnlp-2019","Acronym":"PaLM","Description":"A Hybrid Parser and Language Model","Abstract":"We present <MASKED_ACRONYM>, a hybrid parser and neural language model. Building on an RNN language model, <MASKED_ACRONYM> adds an attention layer over text spans in the left context. An unsupervised constituency parser can be derived from its attention weights, using a greedy decoding algorithm. We evaluate <MASKED_ACRONYM> on language modeling, and empirically show that it outperforms strong baselines. If syntactic annotations are available, the attention component can be trained in a supervised manner, providing syntactically-informed representations of the context, and further improving language modeling performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"ijcnlp-2019","Acronym":"CAN","Description":"Constrained Attention Networks for Multi-Aspect Sentiment Analysis","Abstract":"Aspect level sentiment classification is a fine-grained sentiment analysis task. To detect the sentiment towards a particular aspect in a sentence, previous studies have developed various attention-based methods for generating aspect-specific sentence representations. However, the attention may inherently introduce noise and downgrade the performance. In this paper, we propose constrained attention networks (<MASKED_ACRONYM>), a simple yet effective solution, to regularize the attention for multi-aspect sentiment analysis, which alleviates the drawback of the attention mechanism. Specifically, we introduce orthogonal regularization on multiple aspects and sparse regularization on each single aspect. Experimental results on two public datasets demonstrate the effectiveness of our approach. We further extend our approach to multi-task settings and outperform the state-of-the-art methods.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2019,"Venue":"ijcnlp-2019","Acronym":"ALTER","Description":"Auxiliary Text Rewriting Tool for Natural Language Generation","Abstract":"In this paper, we describe <MASKED_ACRONYM>, an auxiliary text rewriting tool that facilitates the rewriting process for natural language generation tasks, such as paraphrasing, text simplification, fairness-aware text rewriting, and text style transfer. Our tool is characterized by two features, i) recording of word-level revision histories and ii) flexible auxiliary edit support and feedback to annotators. The text rewriting assist and traceable rewriting history are potentially beneficial to the future research of natural language generation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"ijcnlp-2019","Acronym":"EGG","Description":"a toolkit for research on Emergence of lanGuage in Games","Abstract":"There is renewed interest in simulating language emergence among deep neural agents that communicate to jointly solve a task, spurred by the practical aim to develop language-enabled interactive AIs, as well as by theoretical questions about the evolution of human language. However, optimizing deep architectures connected by a discrete communication channel (such as that in which language emerges) is technically challenging. We introduce <MASKED_ACRONYM>, a toolkit that greatly simplifies the implementation of emergent-language communication games. <MASKED_ACRONYM>\u2019s modular design provides a set of building blocks that the user can combine to create new games, easily navigating the optimization and architecture space. We hope that the tool will lower the technical barrier, and encourage researchers from various backgrounds to do original work in this exciting area.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"ijcnlp-2019","Acronym":"UER","Description":"An Open-Source Toolkit for Pre-training Models","Abstract":"Existing works, including ELMO and BERT, have revealed the importance of pre-training for NLP tasks. While there does not exist a single pre-training model that works best in all cases, it is of necessity to develop a framework that is able to deploy various pre-training models efficiently. For this purpose, we propose an assemble-on-demand pre-training toolkit, namely Universal Encoder Representations (<MASKED_ACRONYM>). <MASKED_ACRONYM> is loosely coupled, and encapsulated with rich modules. By assembling modules on demand, users can either reproduce a state-of-the-art pre-training model or develop a pre-training model that remains unexplored. With <MASKED_ACRONYM>, we have built a model zoo, which contains pre-trained models based on different corpora, encoders, and targets (objectives). With proper pre-trained models, we could achieve new state-of-the-art results on a range of downstream datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2018,"Venue":"naacl-2018","Acronym":"FEVER","Description":"a Large-scale Dataset for Fact Extraction and VERification","Abstract":"In this paper we introduce a new publicly available dataset for verification against textual sources, <MASKED_ACRONYM>: Fact Extraction and VERification. It consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. The claims are classified as Supported, Refuted or NotEnoughInfo by annotators achieving 0.6841 in Fleiss kappa. For the first two classes, the annotators also recorded the sentence(s) forming the necessary evidence for their judgment. To characterize the challenge of the dataset presented, we develop a pipeline approach and compare it to suitably designed oracles. The best accuracy we achieve on labeling a claim accompanied by the correct evidence is 31.87%, while if we ignore the evidence we achieve 50.91%. Thus we believe that <MASKED_ACRONYM> is a challenging testbed that will help stimulate progress on claim verification against textual sources.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"naacl-2018","Acronym":"SHAPED","Description":"Shared-Private Encoder-Decoder for Text Style Adaptation","Abstract":"Supervised training of abstractive language generation models results in learning conditional probabilities over language sequences based on the supervised training signal. When the training signal contains a variety of writing styles, such models may end up learning an \u2018average\u2019 style that is directly influenced by the training data make-up and cannot be controlled by the needs of an application. We describe a family of model architectures capable of capturing both generic language characteristics via shared model parameters, as well as particular style characteristics via private model parameters. Such models are able to generate language according to a specific learned style, while still taking advantage of their power to model generic language phenomena. Furthermore, we describe an extension that uses a mixture of output distributions from all learned styles to perform on-the-fly style adaptation based on the textual input alone. Experimentally, we find that the proposed models consistently outperform models that encapsulate single-style or average-style language generation capabilities.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"semeval-2007","Acronym":"HIT","Description":"Web based Scoring Method for English Lexical Substitution","Abstract":"This paper describes the <MASKED_ACRONYM> system and its  participation in SemEval-2007 English  Lexical Substitution Task. Two main steps  are included in our method: candidate substitute extraction and candidate scoring. In  the first step, candidate substitutes for each  target word in a given sentence are extracted from WordNet. In the second step,  the extracted candidates are scored and  ranked using a web-based scoring method.  The substitute ranked first is selected as the  best substitute. For the multiword subtask,  a simple WordNet-based approach is employed.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"semeval-2007","Acronym":"WIT","Description":"Web People Search Disambiguation using Random Walks","Abstract":"In this paper, we describe our work on a random walks-based approach to disambiguating people in web search results, and the implementation of a system that supports such approach, which we used to participate at Semeval\u201907 Web People Search task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"findings-2020","Acronym":"GRACE","Description":"Gradient Harmonized and Cascaded Labeling for Aspect-based Sentiment Analysis","Abstract":"In this paper, we focus on the imbalance issue, which is rarely studied in aspect term extraction and aspect sentiment classification when regarding them as sequence labeling tasks. Besides, previous works usually ignore the interaction between aspect terms when labeling polarities. We propose a GRadient hArmonized and CascadEd labeling model (<MASKED_ACRONYM>) to solve these problems. Specifically, a cascaded labeling module is developed to enhance the interchange between aspect terms and improve the attention of sentiment tokens when labeling sentiment polarities. The polarities sequence is designed to depend on the generated aspect terms labels. To alleviate the imbalance issue, we extend the gradient harmonized mechanism used in object detection to the aspect-based sentiment analysis by adjusting the weight of each label dynamically. The proposed <MASKED_ACRONYM> adopts a post-pretraining BERT as its backbone. Experimental results demonstrate that the proposed model achieves consistency improvement on multiple benchmark datasets and generates state-of-the-art results.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"findings-2020","Acronym":"ZEST","Description":"Zero-shot Learning from Text Descriptions using Textual Similarity and Visual Summarization","Abstract":"We study the problem of recognizing visual entities from the textual descriptions of their classes. Specifically, given birds\u2019 images with free-text descriptions of their species, we learn to classify images of previously-unseen species based on specie descriptions. This setup has been studied in the vision community under the name zero-shot learning from text, focusing on learning to transfer knowledge about visual aspects of birds from seen classes to previously-unseen ones. Here, we suggest focusing on the textual description and distilling from the description the most relevant information to effectively match visual features to the parts of the text that discuss them. Specifically, (1) we propose to leverage the similarity between species, reflected in the similarity between text descriptions of the species. (2) we derive visual summaries of the texts, i.e., extractive summaries that focus on the visual features that tend to be reflected in images. We propose a simple attention-based model augmented with the similarity and visual summaries components. Our empirical results consistently and significantly outperform the state-of-the-art on the largest benchmarks for text-based zero-shot learning, illustrating the critical importance of texts for zero-shot image-recognition.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2020,"Venue":"findings-2020","Acronym":"LiMiT","Description":"The Literal Motion in Text Dataset","Abstract":"Motion recognition is one of the basic cognitive capabilities of many life forms, yet identifying motion of physical entities in natural language have not been explored extensively and empirically. We present the Literal-Motion-in-Text (<MASKED_ACRONYM>) dataset, a large human-annotated collection of English text sentences describing physical occurrence of motion, with annotated physical entities in motion. We describe the annotation process for the dataset, analyze its scale and diversity, and report results of several baseline models. We also present future research directions and applications of the <MASKED_ACRONYM> dataset and share it publicly as a new resource for the research community.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"findings-2020","Acronym":"TED","Description":"A Pretrained Unsupervised Summarization Model with Theme Modeling and Denoising","Abstract":"Text summarization aims to extract essential information from a piece of text and transform the text into a concise version. Existing unsupervised abstractive summarization models leverage recurrent neural networks framework while the recently proposed transformer exhibits much more capability. Moreover, most of previous summarization models ignore abundant unlabeled corpora resources available for pretraining. In order to address these issues, we propose <MASKED_ACRONYM>, a transformer-based unsupervised abstractive summarization system with pretraining on large-scale data. We first leverage the lead bias in news articles to pretrain the model on millions of unlabeled corpora. Next, we finetune <MASKED_ACRONYM> on target domains through theme modeling and a denoising autoencoder to enhance the quality of generated summaries. Notably, <MASKED_ACRONYM> outperforms all unsupervised abstractive baselines on NYT, CNN\/DM and English Gigaword datasets with various document styles. Further analysis shows that the summaries generated by <MASKED_ACRONYM> are highly abstractive, and each component in the objective function of <MASKED_ACRONYM> is highly effective.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"findings-2020","Acronym":"ConveRT","Description":"Efficient and Accurate Conversational Representations from Transformers","Abstract":"General-purpose pretrained sentence encoders such as BERT are not ideal for real-world conversational AI applications; they are computationally heavy, slow, and expensive to train. We propose <MASKED_ACRONYM> (Conversational Representations from Transformers), a pretraining framework for conversational tasks satisfying all the following requirements: it is effective, affordable, and quick to train. We pretrain using a retrieval-based response selection task, effectively leveraging quantization and subword-level parameterization in the dual encoder to build a lightweight memory- and energy-efficient model. We show that <MASKED_ACRONYM> achieves state-of-the-art performance across widely established response selection tasks. We also demonstrate that the use of extended dialog history as context yields further performance gains. Finally, we show that pretrained representations from the proposed encoder can be transferred to the intent classification task, yielding strong results across three diverse data sets. <MASKED_ACRONYM> trains substantially faster than standard sentence encoders or previous state-of-the-art dual encoders. With its reduced size and superior performance, we believe this model promises wider portability and scalability for Conversational AI applications.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"findings-2020","Acronym":"COSMIC","Description":"COmmonSense knowledge for eMotion Identification in Conversations","Abstract":"In this paper, we address the task of utterance level emotion recognition in conversations using commonsense knowledge. We propose <MASKED_ACRONYM>, a new framework that incorporates different elements of commonsense such as mental states, events, and causal relations, and build upon them to learn interactions between interlocutors participating in a conversation. Current state-of-theart methods often encounter difficulties in context propagation, emotion shift detection, and differentiating between related emotion classes. By learning distinct commonsense representations, <MASKED_ACRONYM> addresses these challenges and achieves new state-of-the-art results for emotion recognition on four different benchmark conversational datasets. Our code is available at <a href=https:\/\/github.com\/declare-lab\/conv-emotion class=acl-markup-url>https:\/\/github.com\/declare-lab\/conv-emotion<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"findings-2020","Acronym":"CLAR","Description":"A Cross-Lingual Argument Regularizer for Semantic Role Labeling","Abstract":"Semantic role labeling (SRL) identifies predicate-argument structure(s) in a given sentence. Although different languages have different argument annotations, polyglot training, the idea of training one model on multiple languages, has previously been shown to outperform monolingual baselines, especially for low resource languages. In fact, even a simple combination of data has been shown to be effective with polyglot training by representing the distant vocabularies in a shared representation space. Meanwhile, despite the dissimilarity in argument annotations between languages, certain argument labels do share common semantic meaning across languages (e.g. adjuncts have more or less similar semantic meaning across languages). To leverage such similarity in annotation space across languages, we propose a method called Cross-Lingual Argument Regularizer (<MASKED_ACRONYM>). <MASKED_ACRONYM> identifies such linguistic annotation similarity across languages and exploits this information to map the target language arguments using a transformation of the space on which source language arguments lie. By doing so, our experimental results show that <MASKED_ACRONYM> consistently improves SRL performance on multiple languages over monolingual and polyglot baselines for low resource languages.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2020,"Venue":"findings-2020","Acronym":"HoVer","Description":"A Dataset for Many-Hop Fact Extraction And Claim Verification","Abstract":"We introduce <MASKED_ACRONYM> (HOppy VERification), a dataset for many-hop evidence extraction and fact verification. It challenges models to extract facts from several Wikipedia articles that are relevant to a claim and classify whether the claim is supported or not-supported by the facts. In <MASKED_ACRONYM>, the claims require evidence to be extracted from as many as four English Wikipedia articles and embody reasoning graphs of diverse shapes. Moreover, most of the 3\/4-hop claims are written in multiple sentences, which adds to the complexity of understanding long-range dependency relations such as coreference. We show that the performance of an existing state-of-the-art semantic-matching model degrades significantly on our dataset as the number of reasoning hops increases, hence demonstrating the necessity of many-hop reasoning to achieve strong results. We hope that the introduction of this challenging dataset and the accompanying evaluation task will encourage research in many-hop fact retrieval and information verification.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.9090909091}
{"Year":2008,"Venue":"ijcnlp-2008","Acronym":"Achilles","Description":"NiCT\/ATR Chinese Morphological Analyzer for the Fourth Sighan Bakeoff","Abstract":"We created a new Chinese morphological analyzer, <MASKED_ACRONYM>, by integrating rule-based, dictionary-based, and statistical machine learning method, conditional random \ufb01elds (CRF). The rulebased method is used to recognize regular expressions: numbers, time and alphabets. The dictionary-based method is used to \ufb01nd in-vocabulary (IV) words while outof-vocabulary (OOV) words are detected by the CRFs. At last, con\ufb01dence measure based approach is used to weigh all the results and output the best ones. <MASKED_ACRONYM> was used and evaluated in the bakeoff. We participated the closed tracks of word segmentation and part-of-speech tagging for all the provided corpus. In spite of an unexpected \ufb01le encoding errors, the system exhibited a top level performance. A higher word segmentation accuracy for the corpus ckip and ncc were achieved. We are ranked at the \ufb01fth and eighth position out of all 19 and 26 submissions respectively for the two corpus. <MASKED_ACRONYM> uses a feature combined approach for partof-speech tagging. Our post-evaluation results prove the effectiveness of this approach for POS tagging.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2015,"Venue":"emnlp-2015","Acronym":"CORE","Description":"Context-Aware Open Relation Extraction with Factorization Machines","Abstract":"We propose <MASKED_ACRONYM>, a novel matrix factorization model that leverages contextual information for open relation extraction. Our model is based on factorization machines and integrates facts from various sources, such as knowledge bases or open information extractors, as well as the context in which these facts have been observed. We argue that integrating contextual information\u2014such as metadata about extraction sources, lexical context, or type information\u2014signi\ufb01cantly improves prediction performance. Open information extractors, for example, may produce extractions that are unspeci\ufb01c or ambiguous when taken out of context. Our experimental study on a large real-world dataset indicates that <MASKED_ACRONYM> has signi\ufb01cantly better prediction performance than state-ofthe-art approaches when contextual information is available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"mtsummit-2019","Acronym":"MAGMATic","Description":"A Multi-domain Academic Gold Standard with Manual Annotation of Terminology for Machine Translation Evaluation","Abstract":"This paper presents <MASKED_ACRONYM> (Multidomain Academic Gold Standard with Manual Annotation of Terminology), a novel Italian\u2013English benchmark which allows MT evaluation focused on terminology translation. The data set comprises 2,056 parallel sentences extracted from institutional academic texts, namely course unit and degree program descriptions. This text type is particularly interesting since it contains terminology from multiple domains, e.g. education and different academic disciplines described in the texts. All terms in the English target side of the data set were manually identi\ufb01ed and annotated with a domain label, for a total of 7,517 annotated terms. Due to their peculiar features, institutional academic texts represent an interesting test bed for MT. As a further contribution of this paper, we investigate the feasibility of exploiting MT for the translation of this type of documents. To this aim, we evaluate two stateof-the-art Neural MT systems on <MASKED_ACRONYM>, focusing on their ability to translate domain-speci\ufb01c terminology.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2012,"Venue":"tc-2012","Acronym":"PET","Description":"a standalone tool for assessing machine translation through post-editing","Abstract":"Machine translation (MT) post-editing is now a popular practice in the translation industry. It has been shown to allow translations to be produced at lower cost without a decrease in quality. The post-editing of automatic translations can provide useful information for MT researchers and developers to evaluate translations and systems. We describe a standalone tool that has two main purposes: allow the post-editing of translations from any MT system and collect sub-segment and segment level information from the post-editing process, e.g., detailed keystroke and time statistics.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"DATE","Description":"Detecting Anomalies in Text via Self-Supervision of Transformers","Abstract":"Leveraging deep learning models for Anomaly Detection (AD) has seen widespread use in recent years due to superior performances over traditional methods. Recent deep methods for anomalies in images learn better features of normality in an end-to-end self-supervised setting. These methods train a model to discriminate between different transformations applied to visual data and then use the output to compute an anomaly score. We use this approach for AD in text, by introducing a novel pretext task on text sequences. We learn our <MASKED_ACRONYM> model end-to-end, enforcing two independent and complementary self-supervision signals, one at the token-level and one at the sequence-level. Under this new task formulation, we show strong quantitative and qualitative results on the 20Newsgroups and AG News datasets. In the semi-supervised setting, we outperform state-of-the-art results by +13.5% and +6.9%, respectively (AUROC). In the unsupervised configuration, <MASKED_ACRONYM> surpasses all other methods even when 10% of its training data is contaminated with outliers (compared with 0% for the others).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"EaSe","Description":"A Diagnostic Tool for VQA based on Answer Diversity","Abstract":"We propose EASE, a simple diagnostic tool for Visual Question Answering (VQA) which quantifies the difficulty of an image, question sample. EASE is based on the pattern of answers provided by multiple annotators to a given question. In particular, it considers two aspects of the answers: (i) their Entropy; (ii) their Semantic content. First, we prove the validity of our diagnostic to identify samples that are easy\/hard for state-of-art VQA models. Second, we show that EASE can be successfully used to select the most-informative samples for training\/fine-tuning. Crucially, only information that is readily available in any VQA dataset is used to compute its scores.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"Edge","Description":"Enriching Knowledge Graph Embeddings with External Text","Abstract":"Knowledge graphs suffer from sparsity which degrades the quality of representations generated by various methods. While there is an abundance of textual information throughout the web and many existing knowledge bases, aligning information across these diverse data sources remains a challenge in the literature. Previous work has partially addressed this issue by enriching knowledge graph entities based on \u201chard\u201d co-occurrence of words present in the entities of the knowledge graphs and external text, while we achieve \u201csoft\u201d augmentation by proposing a knowledge graph enrichment and embedding framework named <MASKED_ACRONYM>. Given an original knowledge graph, we first generate a rich but noisy augmented graph using external texts in semantic and structural level. To distill the relevant knowledge and suppress the introduced noise, we design a graph alignment term in a shared embedding space between the original graph and augmented graph. To enhance the embedding learning on the augmented graph, we further regularize the locality relationship of target entity based on negative sampling. Experimental results on four benchmark datasets demonstrate the robustness and effectiveness of <MASKED_ACRONYM> in link prediction and node classification.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"COIL","Description":"Revisit Exact Lexical Match in Information Retrieval with Contextualized Inverted List","Abstract":"Classical information retrieval systems such as BM25 rely on exact lexical match and can carry out search efficiently with inverted list index. Recent neural IR models shifts towards soft matching all query document terms, but they lose the computation efficiency of exact match systems. This paper presents <MASKED_ACRONYM>, a contextualized exact match retrieval architecture, where scoring is based on overlapping query document tokens\u2019 contextualized representations. The new architecture stores contextualized token representations in inverted lists, bringing together the efficiency of exact match and the representation power of deep language models. Our experimental results show <MASKED_ACRONYM> outperforms classical lexical retrievers and state-of-the-art deep LM retrievers with similar or smaller latency.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"naacl-2021","Acronym":"CaSiNo","Description":"A Corpus of Campsite Negotiation Dialogues for Automatic Negotiation Systems","Abstract":"Automated systems that negotiate with humans have broad applications in pedagogy and conversational AI. To advance the development of practical negotiation systems, we present <MASKED_ACRONYM>: a novel corpus of over a thousand negotiation dialogues in English. Participants take the role of campsite neighbors and negotiate for food, water, and firewood packages for their upcoming trip. Our design results in diverse and linguistically rich negotiations while maintaining a tractable, closed-domain environment. Inspired by the literature in human-human negotiations, we annotate persuasion strategies and perform correlation analysis to understand how the dialogue behaviors are associated with the negotiation performance. We further propose and evaluate a multi-task framework to recognize these strategies in a given utterance. We find that multi-task learning substantially improves the performance for all strategy labels, especially for the ones that are the most skewed. We release the dataset, annotations, and the code to propel future work in human-machine negotiations: <a href=https:\/\/github.com\/kushalchawla\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"SOCCER","Description":"An Information-Sparse Discourse State Tracking Collection in the Sports Commentary Domain","Abstract":"In the pursuit of natural language understanding, there has been a long standing interest in tracking state changes throughout narratives. Impressive progress has been made in modeling the state of transaction-centric dialogues and procedural texts. However, this problem has been less intensively studied in the realm of general discourse where ground truth descriptions of states may be loosely defined and state changes are less densely distributed over utterances. This paper proposes to turn to simplified, fully observable systems that show some of these properties: Sports events. We curated 2,263 soccer matches including time-stamped natural language commentary accompanied by discrete events such as a team scoring goals, switching players or being penalized with cards. We propose a new task formulation where, given paragraphs of commentary of a game at different timestamps, the system is asked to recognize the occurrence of in-game events. This domain allows for rich descriptions of state while avoiding the complexities of many other real-world settings. As an initial point of performance measurement, we include two baseline methods from the perspectives of sentence classification with temporal dependence and current state-of-the-art generative model, respectively, and demonstrate that even sophisticated existing methods struggle on the state tracking task when the definition of state broadens or non-event chatter becomes prevalent.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"SCRIPT","Description":"Self-Critic PreTraining of Transformers","Abstract":"We introduce Self-CRItic Pretraining Transformers (<MASKED_ACRONYM>) for representation learning of text. The popular masked language modeling (MLM) pretraining methods like BERT replace some tokens with [MASK] and an encoder is trained to recover them, while ELECTRA trains a discriminator to detect replaced tokens proposed by a generator. In contrast, we train a language model as in MLM and further derive a discriminator or critic on top of the encoder without using any additional parameters. That is, the model itself is a critic. <MASKED_ACRONYM> combines MLM training and discriminative training for learning rich representations and compute- and sample-efficiency. We demonstrate improved sample-efficiency in pretraining and enhanced representations evidenced by improved downstream task performance on GLUE and SQuAD over strong baselines. Also, the self-critic scores can be directly used as pseudo-log-likelihood for efficient scoring.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"AVA","Description":"an Automatic eValuation Approach for Question Answering Systems","Abstract":"We introduce <MASKED_ACRONYM>, an automatic evaluation approach for Question Answering, which given a set of questions associated with Gold Standard answers (references), can estimate system Accuracy. <MASKED_ACRONYM> uses Transformer-based language models to encode question, answer, and reference texts. This allows for effectively assessing answer correctness using similarity between the reference and an automatic answer, biased towards the question semantics. To design, train, and test <MASKED_ACRONYM>, we built multiple large training, development, and test sets on public and industrial benchmarks. Our innovative solutions achieve up to 74.7% F1 score in predicting human judgment for single answers. Additionally, <MASKED_ACRONYM> can be used to evaluate the overall system Accuracy with an error lower than 7% at 95% of confidence when measured on several QA systems.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"naacl-2021","Acronym":"MediaSum","Description":"A Large-scale Media Interview Dataset for Dialogue Summarization","Abstract":"This paper introduces <MASKED_ACRONYM>, a large-scale media interview dataset consisting of 463.6K transcripts with abstractive summaries. To create this dataset, we collect interview transcripts from NPR and CNN and employ the overview and topic descriptions as summaries. Compared with existing public corpora for dialogue summarization, our dataset is an order of magnitude larger and contains complex multi-party conversations from multiple domains. We conduct statistical analysis to demonstrate the unique positional bias exhibited in the transcripts of televised and radioed interviews. We also show that <MASKED_ACRONYM> can be used in transfer learning to improve a model\u2019s performance on other dialogue summarization tasks.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"naacl-2021","Acronym":"RESIN","Description":"A Dockerized Schema-Guided Cross-document Cross-lingual Cross-media Information Extraction and Event Tracking System","Abstract":"We present a new information extraction system that can automatically construct temporal event graphs from a collection of news documents from multiple sources, multiple languages (English and Spanish for our experiment), and multiple data modalities (speech, text, image and video). The system advances state-of-the-art from two aspects: (1) extending from sentence-level event extraction to cross-document cross-lingual cross-media event extraction, coreference resolution and temporal event tracking; (2) using human curated event schema library to match and enhance the extraction output. We have made the dockerlized system publicly available for research purpose at GitHub, with a demo video.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.9090909091}
{"Year":1990,"Venue":"inlg-1990","Acronym":"Selection","Description":"Salience, Relevance and the Coupling between Domain-Level Tasks and Text Planning","Abstract":"In this paper we examine some issues pertaining to the task  of selection in text planning. We attempt to distinguish  salience and relevance, and characterize their role as  important fundamental notions governing selection. We also  formulate the problem of selection of text content in terms of  the coupling between domain-level tasks and text planning  tasks. We describe our research on generating bus route  descriptions.  Keywords: Natural Language Generation, Text Planning,  <MASKED_ACRONYM>, Salience, Relevance, Coupling, Route Descriptions  1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ldk-2023","Acronym":"MEAN","Description":"Metaphoric Erroneous ANalogies dataset for PTLMs metaphor knowledge probing","Abstract":"Despite significant progress obtained in Natural Language Processing tasks thanks to PreTrained Language Models (PTLMs), figurative knowledge remains a challenging issue. This research sets a milestone towards understanding how PTLMs learn metaphoric knowledge by providing a novel hand-crafted dataset, with metaphoric analogy pairs where per correct analogy pair, other three erroneous ones are added controlling for the semantic domain and the semantic attribute. After using our dataset to fine-tune SoTa PTLMs for the multiclass classification task we saw that they were able to choose the correct term to fit the metaphor analogy around the 80% of the times. Moreover, thanks to the added erroneous examples on the dataset we could study what kind of semantic mistakes was the model making.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"conll-2019","Acronym":"EQUATE","Description":"A Benchmark Evaluation Framework for Quantitative Reasoning in Natural Language Inference","Abstract":"Quantitative reasoning is a higher-order reasoning skill that any intelligent natural language understanding system can reasonably be expected to handle. We present <MASKED_ACRONYM> (Evaluating Quantitative Understanding Aptitude in Textual Entailment), a new framework for quantitative reasoning in textual entailment. We benchmark the performance of 9 published NLI models on <MASKED_ACRONYM>, and find that on average, state-of-the-art methods do not achieve an absolute improvement over a majority-class baseline, suggesting that they do not implicitly learn to reason with quantities. We establish a new baseline Q-REAS that manipulates quantities symbolically. In comparison to the best performing NLI model, it achieves success on numerical reasoning tests (+24.2 %), but has limited verbal reasoning capabilities (-8.1 %). We hope our evaluation framework will support the development of models of quantitative reasoning in language understanding.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2012,"Venue":"amta-2012","Acronym":"HAL","Description":"Challenging Three Key Aspects of IBM-style Statistical Machine Translation","Abstract":"The IBM schemes use weighted cooccurrence counts to iteratively improve translation and alignment probability estimates. We argue that: 1) these cooccurrence counts should be combined differently to capture word correlation; 2) alignment probabilities adopt predictable distributions; and 3) consequently, no iteration is needed. This applies equally well to word-based and phrase-based approaches. The resulting scheme, dubbed <MASKED_ACRONYM>, outperforms the IBM scheme in experiments.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2003,"Venue":"eacl-2003","Acronym":"CAST","Description":"A computer-aided summarisation tool","Abstract":"In this paper we propose computeraided summarisation (CAS) as an alternative approach to automatic summarisation, and present an ongoing project which aims to develop a CAS system. The need for such an alternative approach is justified by the relatively poor performance of fully automatic methods used in summarisation. Our system combines several summarisation methods, allowing the user of the system to interact with their parameters and output in order to improve the quality of the produced summary.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2003,"Venue":"eacl-2003","Acronym":"QUALIFIER","Description":"Question Answering by Lexical Fabric and External Resources","Abstract":"One of the major challenges in TRECstyle question-answering (QA) is to overcome the mismatch in the lexical representations in the query space and document space. This is particularly severe in QA as exact answers, rather than documents, are required in response to questions. Most current approaches overcome the mismatch problem by employing either data redundancy strategy through the use of Web or linguistic resources. This paper investigates the integration of lexical relations and Web knowledge to tackle this problem. The results obtained on TREC11 QA corpus indicate that our approach is both feasible and effective.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"eacl-2023","Acronym":"PiC","Description":"A Phrase-in-Context Dataset for Phrase Understanding and Semantic Search","Abstract":"While contextualized word embeddings have been a de-facto standard, learning contextualized phrase embeddings is less explored and being hindered by the lack of a human-annotated benchmark that tests machine understanding of phrase semantics given a context sentence or paragraph (instead of phrases alone). To fill this gap, we propose <MASKED_ACRONYM>\u2014a dataset of \u223c28K of noun phrases accompanied by their contextual Wikipedia pages and a suite of three tasks for training and evaluating phrase embeddings. Training on <MASKED_ACRONYM> improves ranking-models\u2019 accuracy and remarkably pushes span selection (SS) models (i.e., predicting the start and end index of the target phrase) near human accuracy, which is 95% Exact Match (EM) on semantic search given a query phrase and a passage. Interestingly, we find evidence that such impressive performance is because the SS models learn to better capture the common meaning of a phrase regardless of its actual context. SotA models perform poorly in distinguishing two senses of the same phrase in two contexts (\u223c60% EM) and in estimating the similarity between two different phrases in the same context (\u223c70% EM).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"eacl-2023","Acronym":"COMBO","Description":"A Complete Benchmark for Open KG Canonicalization","Abstract":"Open knowledge graph (KG) consists of (subject, relation, object) triples extracted from millions of raw text. The subject and object noun phrases and the relation in open KG have severe redundancy and ambiguity and need to be canonicalized. Existing datasets for open KG canonicalization only provide gold entity-level canonicalization for noun phrases. In this paper, we present <MASKED_ACRONYM>, a Complete Benchmark for Open KG canonicalization. Compared with existing datasets, we additionally provide gold canonicalization for relation phrases, gold ontology-level canonicalization for noun phrases, as well as source sentences from which triples are extracted. We also propose metrics for evaluating each type of canonicalization. On the <MASKED_ACRONYM> dataset, we empirically compare previously proposed canonicalization methods as well as a few simple baseline methods based on pretrained language models. We find that properly encoding the phrases in a triple using pretrained language models results in better relation canonicalization and ontology-level canonicalization of the noun phrase. We release our dataset, baselines, and evaluation scripts at path\/to\/url.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"eacl-2023","Acronym":"LoFT","Description":"Enhancing Faithfulness and Diversity for Table-to-Text Generation via Logic Form Control","Abstract":"Logical Table-to-Text (LT2T) generation is tasked with generating logically faithful sentences from tables. There currently exists two challenges in the field: 1) Faithfulness: how to generate sentences that are factually correct given the table content; 2) Diversity: how to generate multiple sentences that offer different perspectives on the table. This work proposes <MASKED_ACRONYM>, which utilizes logic forms as fact verifiers and content planners to control LT2T generation. Experimental results on the LogicNLG dataset demonstrate that <MASKED_ACRONYM> is the first model that addresses unfaithfulness and lack of diversity issues simultaneously. Our code is publicly available at <a href=https:\/\/github.com\/Yale-LILY\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/Yale-LILY\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2023,"Venue":"eacl-2023","Acronym":"CLICK","Description":"Contrastive Learning for Injecting Contextual Knowledge to Conversational Recommender System","Abstract":"Conversational recommender systems (CRSs) capture a user preference through a conversation. However, the existing CRSs lack capturing comprehensive user preferences. This is because the items mentioned in a conversation are mainly regarded as a user preference. Thus, they have limitations in identifying a user preference from a dialogue context expressed without preferred items. Inspired by the characteristic of an online recommendation community where participants identify a context of a recommendation request and then comment with appropriate items, we exploit the Reddit data. Specifically, we propose a Contrastive Learning approach for Injecting Contextual Knowledge (<MASKED_ACRONYM>) from the Reddit data to the CRS task, which facilitates the capture of a context-level user preference from a dialogue context, regardless of the existence of preferred item-entities. Moreover, we devise a relevance-enhanced contrastive learning loss to consider the fine-grained reflection of multiple recommendable items. We further develop a response generation module to generate a persuasive rationale for a recommendation. Extensive experiments on the benchmark CRS dataset show the effectiveness of <MASKED_ACRONYM>, achieving significant improvements over state-of-the-art methods.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"eacl-2023","Acronym":"FISH","Description":"A Financial Interactive System for Signal Highlighting","Abstract":"In this system demonstration, we seek to streamline the process of reviewing financial statements and provide insightful information for practitioners. We develop <MASKED_ACRONYM>, an interactive system that extracts and highlights crucial textual signals from financial statements efficiently and precisely. To achieve our goal, we integrate pre-trained BERT representations and a fine-tuned BERT highlighting model with a newly-proposed two-stage classify-then-highlight pipeline. We also conduct the human evaluation, showing <MASKED_ACRONYM> can provide accurate financial signals. <MASKED_ACRONYM> overcomes the limitations of existing research andmore importantly benefits both academics and practitioners in finance as they can leverage state-of-the-art contextualized language models with their newly gained insights. The system is available online at <a href=https:\/\/fish-web-fish.de.r.appspot.com\/ class=acl-markup-url>https:\/\/fish-web-fish.de.r.appspot.com\/<\/a>, and a short video for introduction is at <a href=https:\/\/youtu.be\/ZbvZQ09i6aw class=acl-markup-url>https:\/\/youtu.be\/ZbvZQ09i6aw<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"naacl-2019","Acronym":"BAG","Description":"Bi-directional Attention Entity Graph Convolutional Network for Multi-hop Reasoning Question Answering","Abstract":"Multi-hop reasoning question answering requires deep comprehension of relationships between various documents and queries. We propose a Bi-directional Attention Entity Graph Convolutional Network (<MASKED_ACRONYM>), leveraging relationships between nodes in an entity graph and attention information between a query and the entity graph, to solve this task. Graph convolutional networks are used to obtain a relation-aware representation of nodes for entity graphs built from documents with multi-level features. Bidirectional attention is then applied on graphs and queries to generate a query-aware nodes representation, which will be used for the final prediction. Experimental evaluation shows <MASKED_ACRONYM> achieves state-of-the-art accuracy performance on the QAngaroo WIKIHOP dataset.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"naacl-2019","Acronym":"CITE","Description":"A Corpus of Image-Text Discourse Relations","Abstract":"This paper presents a novel crowd-sourced resource for multimodal discourse: our resource characterizes inferences in image-text contexts in the domain of cooking recipes in the form of coherence relations. Like previous corpora annotating discourse structure between text arguments, such as the Penn Discourse Treebank, our new corpus aids in establishing a better understanding of natural communication and common-sense reasoning, while our findings have implications for a wide range of applications, such as understanding and generation of multimodal documents.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"naacl-2019","Acronym":"GraphIE","Description":"A Graph-Based Framework for Information Extraction","Abstract":"Most modern Information Extraction (IE) systems are implemented as sequential taggers and only model local dependencies. Non-local and non-sequential context is, however, a valuable source of information to improve predictions. In this paper, we introduce <MASKED_ACRONYM>, a framework that operates over a graph representing a broad set of dependencies between textual units (i.e. words or sentences). The algorithm propagates information between connected nodes through graph convolutions, generating a richer representation that can be exploited to improve word-level predictions. Evaluation on three different tasks \u2014 namely textual, social media and visual information extraction \u2014 shows that <MASKED_ACRONYM> consistently outperforms the state-of-the-art sequence tagging model by a significant margin.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2019,"Venue":"naacl-2019","Acronym":"DROP","Description":"A Reading Comprehension Benchmark Requiring Discrete Reasoning Over Paragraphs","Abstract":"Reading comprehension has recently seen rapid progress, with systems matching humans on the most popular datasets for the task. However, a large body of work has highlighted the brittleness of these systems, showing that there is much work left to be done. We introduce a new reading comprehension benchmark, <MASKED_ACRONYM>, which requires Discrete Reasoning Over the content of Paragraphs. In this crowdsourced, adversarially-created, 55k-question benchmark, a system must resolve references in a question, perhaps to multiple input positions, and perform discrete operations over them (such as addition, counting, or sorting). These operations require a much more comprehensive understanding of the content of paragraphs, as they remove the paraphrase-and-entity-typing shortcuts available in prior datasets. We apply state-of-the-art methods from both the reading comprehension and semantic parsing literatures on this dataset and show that the best systems only achieve 38.4% F1 on our generalized accuracy metric, while expert human performance is 96%. We additionally present a new model that combines reading comprehension methods with simple numerical reasoning to achieve 51% F1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"naacl-2019","Acronym":"BERT","Description":"Pre-training of Deep Bidirectional Transformers for Language Understanding","Abstract":"We introduce a new language representation model called <MASKED_ACRONYM>, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), <MASKED_ACRONYM> is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained <MASKED_ACRONYM> model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. <MASKED_ACRONYM> is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7% (4.6% absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2017,"Venue":"emnlp-2017","Acronym":"RACE","Description":"Large-scale ReAding Comprehension Dataset From Examinations","Abstract":"We present <MASKED_ACRONYM>, a new dataset for benchmark evaluation of methods in the reading comprehension task. Collected from the English exams for middle and high school Chinese students in the age range between 12 to 18, <MASKED_ACRONYM> consists of near 28,000 passages and near 100,000 questions generated by human experts (English instructors), and covers a variety of topics which are carefully designed for evaluating the students\u2019 ability in understanding and reasoning. In particular, the proportion of questions that requires reasoning is much larger in <MASKED_ACRONYM> than that in other benchmark datasets for reading comprehension, and there is a significant gap between the performance of the state-of-the-art models (43%) and the ceiling human performance (95%). We hope this new dataset can serve as a valuable resource for research and evaluation in machine comprehension. The dataset is freely available at <a href=http:\/\/www.cs.cmu.edu\/~glai1\/data\/race\/ class=acl-markup-url>http:\/\/www.cs.cmu.edu\/~glai1\/data\/race\/<\/a>and the code is available at <a href=https:\/\/github.com\/qizhex\/<MASKED_ACRONYM>_AR_baselines class=acl-markup-url>https:\/\/github.com\/qizhex\/<MASKED_ACRONYM>_AR_baselines<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"emnlp-2017","Acronym":"ConStance","Description":"Modeling Annotation Contexts to Improve Stance Classification","Abstract":"Manual annotations are a prerequisite for many applications of machine learning. However, weaknesses in the annotation process itself are easy to overlook. In particular, scholars often choose what information to give to annotators without examining these decisions empirically. For subjective tasks such as sentiment analysis, sarcasm, and stance detection, such choices can impact results. Here, for the task of political stance detection on Twitter, we show that providing too little context can result in noisy and uncertain annotations, whereas providing too strong a context may cause it to outweigh other signals. To characterize and reduce these biases, we develop <MASKED_ACRONYM>, a general model for reasoning about annotations across information conditions. Given conflicting labels produced by multiple annotators seeing the same instances with different contexts, <MASKED_ACRONYM> simultaneously estimates gold standard labels and also learns a classifier for new instances. We show that the classifier learned by <MASKED_ACRONYM> outperforms a variety of baselines at predicting political stance, while the model\u2019s interpretable parameters shed light on the effects of each context.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2017,"Venue":"emnlp-2017","Acronym":"NITE","Description":"A Neural Inductive Teaching Framework for Domain Specific NER","Abstract":"In domain-specific NER, due to insufficient labeled training data, deep models usually fail to behave normally. In this paper, we proposed a novel Neural Inductive TEaching framework (<MASKED_ACRONYM>) to transfer knowledge from existing domain-specific NER models into an arbitrary deep neural network in a teacher-student training manner. <MASKED_ACRONYM> is a general framework that builds upon transfer learning and multiple instance learning, which collaboratively not only transfers knowledge to a deep student network but also reduces the noise from teachers. <MASKED_ACRONYM> can help deep learning methods to effectively utilize existing resources (i.e., models, labeled and unlabeled data) in a small domain. The experiment resulted on Disease NER proved that without using any labeled data, <MASKED_ACRONYM> can significantly boost the performance of a CNN-bidirectional LSTM-CRF NER neural network nearly over 30% in terms of F1-score.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2017,"Venue":"emnlp-2017","Acronym":"DOC","Description":"Deep Open Classification of Text Documents","Abstract":"Traditional supervised learning makes the closed-world assumption that the classes appeared in the test data must have appeared in training. This also applies to text learning or text classification. As learning is used increasingly in dynamic open environments where some new\/test documents may not belong to any of the training classes, identifying these novel documents during classification presents an important problem. This problem is called open-world classification or open classification. This paper proposes a novel deep learning based approach. It outperforms existing state-of-the-art techniques dramatically.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2002,"Venue":"conll-2002","Acronym":"GraSp","Description":"Grammar Learning from Unlabelled Speech Corpora","Abstract":"This paper presents the ongoing project Computational Models of First Language Acquisition, together with its current product, the learning algorithm <MASKED_ACRONYM>. <MASKED_ACRONYM>  is  designed  specifically  for inducing grammars from large, unlabelled corpora of spontaneous (i.e. unscripted) speech. The learning algorithm does not assume  a  predefined  grammatical taxonomy; rather the determination of categories and their relations is considered as part of the learning task. While <MASKED_ACRONYM> learning can be used for a range of practical tasks, the long-term goal of the project is to contribute to the debate of innate linguistic knowledge \u2013 under the hypothesis that there is no such.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":1994,"Venue":"ws-1994","Acronym":"CORECT","Description":"Combining CSCW with Natural Language Generation for Collaborative Requirement Capture","Abstract":"In the <MASKED_ACRONYM> project, we are building a computer-  based requirements capture tool for custom-built elec-  tronic testing systems. The requirements capture pro-  cess involves the participation of a wide range of different  types of people - the customer, the salesperson, systems  engineers, quality assurance, marketing, and so on. Our  aim is to build a Computer-Supported Cooperative Work-  ing (CSCW) system which will allow these participants to  define an Automatic Test System (ATS) collaboratively  by adding data and making changes to an evolving de-  sign. The collected information about the design will  form a large knowledge pool, all of which is pertinent  to the design as a whole, but most of which is irrelevant  to any particular person engaged in the design process.  We will therefore be using natural language generation  (NLG) technology to create documents from the central  knowledge pool which are tailored to the particular infor-  mation needs of the participants. These documents will  give the users a snapshot of the developing design and  will enable them to see how it can be improved and fur-  ther developed. This paper gives an introduction to the  problem we are tackling and how we are trying to solve  it, and argues that combining CSCW for input with NLG  for output in this way solves some of the problems which  are encountered when trying to use either technology on  its own.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.9230769231}
{"Year":2021,"Venue":"ranlp-2021","Acronym":"RED","Description":"A Novel Dataset for Romanian Emotion Detection from Tweets","Abstract":"In Romanian language there are some resources for automatic text comprehension, but for Emotion Detection, not lexicon-based, there are none. To cover this gap, we extracted data from Twitter and created the first dataset containing tweets annotated with five types of emotions: joy, fear, sadness, anger and neutral, with the intent of being used for opinion mining and analysis tasks. In this article we present some features of our novel dataset, and create a benchmark to achieve the first supervised machine learning model for automatic Emotion Detection in Romanian short texts. We investigate the performance of four classical machine learning models: Multinomial Naive Bayes, Logistic Regression, Support Vector Classification and Linear Support Vector Classification. We also investigate more modern approaches like fastText, which makes use of subword information. Lastly, we fine-tune the Romanian BERT for text classification and our experiments show that the BERT-based model has the best performance for the task of Emotion Detection from Romanian tweets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"coling-2016","Acronym":"TASTY","Description":"Interactive Entity Linking As-You-Type","Abstract":"We introduce <MASKED_ACRONYM> (Tag-as-you-type), a novel text editor for interactive entity linking as part of the writing process. Tasty supports the author of a text with complementary information about the mentioned entities shown in a \u2018live\u2019 exploration view. The system is automatically triggered by keystrokes, recognizes mention boundaries and disambiguates the mentioned entities to Wikipedia articles. The author can use seven operators to interact with the editor and refine the results according to his specific intention while writing. Our implementation captures syntactic and semantic context using a robust end-to-end LSTM sequence learner and word embeddings. We demonstrate the applicability of our system in English and German language for encyclopedic or medical text. Tasty is currently being tested in interactive applications for text production, such as scientific research, news editorial, medical anamnesis, help desks and product reviews.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"coling-2016","Acronym":"ACE","Description":"Automatic Colloquialism, Typographical and Orthographic Errors Detection for Chinese Language","Abstract":"We present a system called <MASKED_ACRONYM> for Automatic Colloquialism and Errors detection for written Chinese. <MASKED_ACRONYM> is based on the combination of N-gram model and rule-base model. Although it focuses on detecting colloquial Cantonese (a dialect of Chinese) at the current stage, it can be extended to detect other dialects. We chose Cantonese becauase it has many interesting properties, such as unique grammar system and huge colloquial terms, that turn the detection task extremely challenging. We conducted experiments using real data and synthetic data. The results indicated that <MASKED_ACRONYM> is highly reliable and effective.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"law-2007","Acronym":"GrAF","Description":"A Graph-based Format for Linguistic Annotations","Abstract":"In this paper we describe the Graph Annotation Format (<MASKED_ACRONYM>) and show how it is  used represent not only independent linguistic annotations, but also sets of merged  annotations as a single graph. To demonstrate this, we have automatically transduced several different annotations of the  Wall Street Journal corpus into <MASKED_ACRONYM> and  show how the annotations can then be  merged, analyzed, and visualized using  standard graph algorithms and tools. We  also discuss how, as a standard graph representation, it allows for the application of  well-established  graph  traversal  and  analysis algorithms to produce information  about  interactions  and  commonalities  among merged annotations. <MASKED_ACRONYM> is an  extension of the Linguistic Annotation  Framework (LAF) (Ide and Romary, 2004,  2006) developed within ISO TC37 SC4  and as such, implements state-of-the-art  best practice guidelines for representing  linguistic annotations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2004,"Venue":"acl-2004","Acronym":"Dyna","Description":"A Language for Weighted Dynamic Programming","Abstract":"We present the \ufb01rst version of a new declarative programming language. <MASKED_ACRONYM> has many uses but was designed especially for rapid development of new statistical NLP systems. A <MASKED_ACRONYM> program is a small set of equations, resembling Prolog inference rules, that specify the abstract structure of a dynamic programming algorithm. It compiles into ef\ufb01cient, portable, C++ classes that can be easily invoked from a larger application. By default, these classes run a generalization of agendabased parsing, prioritizing the partial parses by some \ufb01gure of merit. The classes can also perform an exact backward (outside) pass in the service of parameter training. The compiler already knows several implementation tricks, algorithmic transforms, and numerical optimization techniques. It will acquire more over time: we intend for it to generalize and encapsulate best practices, and serve as a testbed for new practices. <MASKED_ACRONYM> is now being used for parsing, machine translation, morphological analysis, grammar induction, and \ufb01nite-state modeling.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"sigdial-2021","Acronym":"CIDER","Description":"Commonsense Inference for Dialogue Explanation and Reasoning","Abstract":"Commonsense inference to understand and explain human language is a fundamental research problem in natural language processing. Explaining human conversations poses a great challenge as it requires contextual understanding, planning, inference, and several aspects of reasoning including causal, temporal, and commonsense reasoning. In this work, we introduce <MASKED_ACRONYM> \u2013 a manually curated dataset that contains dyadic dialogue explanations in the form of implicit and explicit knowledge triplets inferred using contextual commonsense inference. Extracting such rich explanations from conversations can be conducive to improving several downstream applications. The annotated triplets are categorized by the type of commonsense knowledge present (e.g., causal, conditional, temporal). We set up three different tasks conditioned on the annotated dataset: Dialogue-level Natural Language Inference, Span Extraction, and Multi-choice Span Selection. Baseline results obtained with transformer-based models reveal that the tasks are difficult, paving the way for promising future research. The dataset and the baseline implementations are publicly available at <a href=https:\/\/github.com\/declare-lab\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/declare-lab\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"emnlp-2019","Acronym":"GEM","Description":"Generative Enhanced Model for adversarial attacks","Abstract":"We present our Generative Enhanced Model (<MASKED_ACRONYM>) that we used to create samples awarded the first prize on the FEVER 2.0 Breakers Task. <MASKED_ACRONYM> is the extended language model developed upon GPT-2 architecture. The addition of novel target vocabulary input to the already existing context input enabled controlled text generation. The training procedure resulted in creating a model that inherited the knowledge of pretrained GPT-2, and therefore was ready to generate natural-like English sentences in the task domain with some additional control. As a result, <MASKED_ACRONYM> generated malicious claims that mixed facts from various articles, so it became difficult to classify their truthfulness.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2002,"Venue":"ws-2002","Acronym":"SALT","Description":"An XML Application for Web-based Multimodal Dialog Management","Abstract":"This  paper  describes  the  Speech  Application Language Tags, or <MASKED_ACRONYM>, an  XML based spoken dialog standard for  multimodal or speech-only applications. A  key premise in <MASKED_ACRONYM> design is that  speech-enabled user interface shares a lot  of the design principles and computational  requirements with the graphical user  interface (GUI). As a result, it is logical to  introduce into speech the object-oriented,  event-driven model that is known to be  flexible and powerful enough in meeting  the  requirements  for  realizing  sophisticated GUIs. By reusing this rich  infrastructure,  dialog  designers  are  relieved from having to develop the  underlying computing infrastructure and  can focus more on the core user interface  design issues than on the computer and  software engineering details. The paper  focuses the discussion on the Web-based  distributed computing environment and  elaborates how <MASKED_ACRONYM> can be used to  implement multimodal dialog systems.  How advanced dialog effects (e.g.,  cross-modality  reference  resolution,  implicit  confirmation,  multimedia  synchronization) can be realized in <MASKED_ACRONYM>  is also discussed.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"GOLD","Description":"Improving Out-of-Scope Detection in Dialogues using Data Augmentation","Abstract":"Practical dialogue systems require robust methods of detecting out-of-scope (OOS) utterances to avoid conversational breakdowns and related failure modes. Directly training a model with labeled OOS examples yields reasonable performance, but obtaining such data is a resource-intensive process. To tackle this limited-data problem, previous methods focus on better modeling the distribution of in-scope (INS) examples. We introduce <MASKED_ACRONYM> as an orthogonal technique that augments existing data to train better OOS detectors operating in low-data regimes. <MASKED_ACRONYM> generates pseudo-labeled candidates using samples from an auxiliary dataset and keeps only the most beneficial candidates for training through a novel filtering mechanism. In experiments across three target benchmarks, the top <MASKED_ACRONYM> model outperforms all existing methods on all key metrics, achieving relative gains of 52.4%, 48.9% and 50.3% against median baseline performance. We also analyze the unique properties of OOS data to identify key factors for optimally applying our proposed method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"SHAPE","Description":"Shifted Absolute Position Embedding for Transformers","Abstract":"Position representation is crucial for building position-aware representations in Transformers. Existing position representations suffer from a lack of generalization to test data with unseen lengths or high computational cost. We investigate shifted absolute position embedding (<MASKED_ACRONYM>) to address both issues. The basic idea of <MASKED_ACRONYM> is to achieve shift invariance, which is a key property of recent successful position representations, by randomly shifting absolute positions during training. We demonstrate that <MASKED_ACRONYM> is empirically comparable to its counterpart while being simpler and faster.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"TEMP","Description":"Taxonomy Expansion with Dynamic Margin Loss through Taxonomy-Paths","Abstract":"As an essential form of knowledge representation, taxonomies are widely used in various downstream natural language processing tasks. However, with the continuously rising of new concepts, many existing taxonomies are unable to maintain coverage by manual expansion. In this paper, we propose <MASKED_ACRONYM>, a self-supervised taxonomy expansion method, which predicts the position of new concepts by ranking the generated taxonomy-paths. For the first time, <MASKED_ACRONYM> employs pre-trained contextual encoders in taxonomy construction and hypernym detection problems. Experiments prove that pre-trained contextual embeddings are able to capture hypernym-hyponym relations. To learn more detailed differences between taxonomy-paths, we train the model with dynamic margin loss by a novel dynamic margin function. Extensive evaluations exhibit that <MASKED_ACRONYM> outperforms prior state-of-the-art taxonomy expansion approaches by 14.3% in accuracy and 15.8% in mean reciprocal rank on three public benchmarks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"CATE","Description":"A Contrastive Pre-trained Model for Metaphor Detection with Semi-supervised Learning","Abstract":"Metaphors are ubiquitous in natural language, and detecting them requires contextual reasoning about whether a semantic incongruence actually exists. Most existing work addresses this problem using pre-trained contextualized models. Despite their success, these models require a large amount of labeled data and are not linguistically-based. In this paper, we proposed a ContrAstive pre-Trained modEl (<MASKED_ACRONYM>) for metaphor detection with semi-supervised learning. Our model first uses a pre-trained model to obtain a contextual representation of target words and employs a contrastive objective to promote an increased distance between target words\u2019 literal and metaphorical senses based on linguistic theories. Furthermore, we propose a simple strategy to collect large-scale candidate instances from the general corpus and generalize the model via self-training. Extensive experiments show that <MASKED_ACRONYM> achieves better performance against state-of-the-art baselines on several benchmark datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"CAST","Description":"Enhancing Code Summarization with Hierarchical Splitting and Reconstruction of Abstract Syntax Trees","Abstract":"Code summarization aims to generate concise natural language descriptions of source code, which can help improve program comprehension and maintenance. Recent studies show that syntactic and structural information extracted from abstract syntax trees (ASTs) is conducive to summary generation. However, existing approaches fail to fully capture the rich information in ASTs because of the large size\/depth of ASTs. In this paper, we propose a novel model <MASKED_ACRONYM> that hierarchically splits and reconstructs ASTs. First, we hierarchically split a large AST into a set of subtrees and utilize a recursive neural network to encode the subtrees. Then, we aggregate the embeddings of subtrees by reconstructing the split ASTs to get the representation of the complete AST. Finally, AST representation, together with source code embedding obtained by a vanilla code token encoder, is used for code summarization. Extensive experiments, including the ablation study and the human evaluation, on benchmarks have demonstrated the power of <MASKED_ACRONYM>. To facilitate reproducibility, our code and data are available at <a href=https:\/\/github.com\/DeepSoftwareAnalytics\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/DeepSoftwareAnalytics\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"TransferNet","Description":"An Effective and Transparent Framework for Multi-hop Question Answering over Relation Graph","Abstract":"Multi-hop Question Answering (QA) is a challenging task because it requires precise reasoning with entity relations at every step towards the answer. The relations can be represented in terms of labels in knowledge graph (e.g., spouse) or text in text corpus (e.g., they have been married for 26 years). Existing models usually infer the answer by predicting the sequential relation path or aggregating the hidden graph features. The former is hard to optimize, and the latter lacks interpretability. In this paper, we propose <MASKED_ACRONYM>, an effective and transparent model for multi-hop QA, which supports both label and text relations in a unified framework. <MASKED_ACRONYM> jumps across entities at multiple steps. At each step, it attends to different parts of the question, computes activated scores for relations, and then transfer the previous entity scores along activated relations in a differentiable way. We carry out extensive experiments on three datasets and demonstrate that <MASKED_ACRONYM> surpasses the state-of-the-art models by a large margin. In particular, on MetaQA, it achieves 100% accuracy in 2-hop and 3-hop questions. By qualitative analysis, we show that <MASKED_ACRONYM> has transparent and interpretable intermediate results.","wordlikeness":0.9090909091,"lcsratio":1.0,"wordcoverage":0.8421052632}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"AVocaDo","Description":"Strategy for Adapting Vocabulary to Downstream Domain","Abstract":"During the fine-tuning phase of transfer learning, the pretrained vocabulary remains unchanged, while model parameters are updated. The vocabulary generated based on the pretrained data is suboptimal for downstream data when domain discrepancy exists. We propose to consider the vocabulary as an optimizable parameter, allowing us to update the vocabulary by expanding it with domain specific vocabulary based on a tokenization statistic. Furthermore, we preserve the embeddings of the added words from overfitting to downstream data by utilizing knowledge learned from a pretrained language model with a regularization term. Our method achieved consistent performance improvements on diverse domains (i.e., biomedical, computer science, news, and reviews).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"RAST","Description":"Domain-Robust Dialogue Rewriting as Sequence Tagging","Abstract":"The task of dialogue rewriting aims to reconstruct the latest dialogue utterance by copying the missing content from the dialogue context. Until now, the existing models for this task suffer from the robustness issue, i.e., performances drop dramatically when testing on a different dataset. We address this robustness issue by proposing a novel sequence-tagging-based model so that the search space is significantly reduced, yet the core of this task is still well covered. As a common issue of most tagging models for text generation, the model\u2019s outputs may lack fluency. To alleviate this issue, we inject the loss signal from BLEU or GPT-2 under a REINFORCE framework. Experiments show huge improvements of our model over the current state-of-the-art systems when transferring to another dataset.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"IGA","Description":"An Intent-Guided Authoring Assistant","Abstract":"While large-scale pretrained language models have significantly improved writing assistance functionalities such as autocomplete, more complex and controllable writing assistants have yet to be explored. We leverage advances in language modeling to build an interactive writing assistant that generates and rephrases text according to fine-grained author specifications. Users provide input to our Intent-Guided Assistant (<MASKED_ACRONYM>) in the form of text interspersed with tags that correspond to specific rhetorical directives (e.g., adding description or contrast, or rephrasing a particular sentence). We fine-tune a language model on a dataset heuristically-labeled with author intent, which allows <MASKED_ACRONYM> to fill in these tags with generated text that users can subsequently edit to their liking. A series of automatic and crowdsourced evaluations confirm the quality of <MASKED_ACRONYM>\u2019s generated outputs, while a small-scale user study demonstrates author preference for <MASKED_ACRONYM> over baseline methods in a creative writing task. We release our dataset, code, and demo to spur further research into AI-assisted writing.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"CLIFF","Description":"Contrastive Learning for Improving Faithfulness and Factuality in Abstractive Summarization","Abstract":"We study generating abstractive summaries that are faithful and factually consistent with the given articles. A novel contrastive learning formulation is presented, which leverages both reference summaries, as positive training data, and automatically generated erroneous summaries, as negative training data, to train summarization systems that are better at distinguishing between them. We further design four types of strategies for creating negative samples, to resemble errors made commonly by two state-of-the-art models, BART and PEGASUS, found in our new human annotations of summary errors. Experiments on XSum and CNN\/Daily Mail show that our contrastive learning framework is robust across datasets and models. It consistently produces more factual summaries than strong comparisons with post error correction, entailment-based reranking, and unlikelihood training, according to QA-based factuality evaluation. Human judges echo the observation and find that our model summaries correct more errors.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"CLASSIC","Description":"Continual and Contrastive Learning of Aspect Sentiment Classification Tasks","Abstract":"This paper studies continual learning (CL) of a sequence of aspect sentiment classification (ASC) tasks in a particular CL setting called domain incremental learning (DIL). Each task is from a different domain or product. The DIL setting is particularly suited to ASC because in testing the system needs not know the task\/domain to which the test data belongs. To our knowledge, this setting has not been studied before for ASC. This paper proposes a novel model called <MASKED_ACRONYM>. The key novelty is a contrastive continual learning method that enables both knowledge transfer across tasks and knowledge distillation from old tasks to the new task, which eliminates the need for task ids in testing. Experimental results show the high effectiveness of <MASKED_ACRONYM>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"MATE","Description":"Multi-view Attention for Table Transformer Efficiency","Abstract":"This work presents a sparse-attention Transformer architecture for modeling documents that contain large tables. Tables are ubiquitous on the web, and are rich in information. However, more than 20% of relational tables on the web have 20 or more rows (Cafarella et al., 2008), and these large tables present a challenge for current Transformer models, which are typically limited to 512 tokens. Here we propose <MASKED_ACRONYM>, a novel Transformer architecture designed to model the structure of web tables. <MASKED_ACRONYM> uses sparse attention in a way that allows heads to efficiently attend to either rows or columns in a table. This architecture scales linearly with respect to speed and memory, and can handle documents containing more than 8000 tokens with current accelerators. <MASKED_ACRONYM> also has a more appropriate inductive bias for tabular data, and sets a new state-of-the-art for three table reasoning datasets. For HybridQA (Chen et al., 2020), a dataset that involves large documents containing tables, we improve the best prior result by 19 points.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"RAP","Description":"Robustness-Aware Perturbations for Defending against Backdoor Attacks on NLP Models","Abstract":"Backdoor attacks, which maliciously control a well-trained model\u2019s outputs of the instances with specific triggers, are recently shown to be serious threats to the safety of reusing deep neural networks (DNNs). In this work, we propose an efficient online defense mechanism based on robustness-aware perturbations. Specifically, by analyzing the backdoor training process, we point out that there exists a big gap of robustness between poisoned and clean samples. Motivated by this observation, we construct a word-based robustness-aware perturbation to distinguish poisoned samples from clean samples to defend against the backdoor attacks on natural language processing (NLP) models. Moreover, we give a theoretical analysis about the feasibility of our robustness-aware perturbation-based defense method. Experimental results on sentiment analysis and toxic detection tasks show that our method achieves better defending performance and much lower computational costs than existing online defense methods. Our code is available at <a href=https:\/\/github.com\/lancopku\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/lancopku\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"FAME","Description":"Feature-Based Adversarial Meta-Embeddings for Robust Input Representations","Abstract":"Combining several embeddings typically improves performance in downstream tasks as different embeddings encode different information. It has been shown that even models using embeddings from transformers still benefit from the inclusion of standard word embeddings. However, the combination of embeddings of different types and dimensions is challenging. As an alternative to attention-based meta-embeddings, we propose feature-based adversarial meta-embeddings (<MASKED_ACRONYM>) with an attention function that is guided by features reflecting word-specific properties, such as shape and frequency, and show that this is beneficial to handle subword-based embeddings. In addition, <MASKED_ACRONYM> uses adversarial training to optimize the mappings of differently-sized embeddings to the same space. We demonstrate that <MASKED_ACRONYM> works effectively across languages and domains for sequence labeling and sentence classification, in particular in low-resource settings. <MASKED_ACRONYM> sets the new state of the art for POS tagging in 27 languages, various NER settings and question classification in different domains.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"STaCK","Description":"Sentence Ordering with Temporal Commonsense Knowledge","Abstract":"Sentence order prediction is the task of finding the correct order of sentences in a randomly ordered document. Correctly ordering the sentences requires an understanding of coherence with respect to the chronological sequence of events described in the text. Document-level contextual understanding and commonsense knowledge centered around these events are often essential in uncovering this coherence and predicting the exact chronological order. In this paper, we introduce <MASKED_ACRONYM> \u2014 a framework based on graph neural networks and temporal commonsense knowledge to model global information and predict the relative order of sentences. Our graph network accumulates temporal evidence using knowledge of \u2018past\u2019 and \u2018future\u2019 and formulates sentence ordering as a constrained edge classification problem. We report results on five different datasets, and empirically show that the proposed method is naturally suitable for order prediction. The implementation of this work is available at: <a href=https:\/\/github.com\/declare-lab\/sentence-ordering class=acl-markup-url>https:\/\/github.com\/declare-lab\/sentence-ordering<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"PASTE","Description":"A Tagging-Free Decoding Framework Using Pointer Networks for Aspect Sentiment Triplet Extraction","Abstract":"Aspect Sentiment Triplet Extraction (ASTE) deals with extracting opinion triplets, consisting of an opinion target or aspect, its associated sentiment, and the corresponding opinion term\/span explaining the rationale behind the sentiment. Existing research efforts are majorly tagging-based. Among the methods taking a sequence tagging approach, some fail to capture the strong interdependence between the three opinion factors, whereas others fall short of identifying triplets with overlapping aspect\/opinion spans. A recent grid tagging approach on the other hand fails to capture the span-level semantics while predicting the sentiment between an aspect-opinion pair. Different from these, we present a tagging-free solution for the task, while addressing the limitations of the existing works. We adapt an encoder-decoder architecture with a Pointer Network-based decoding framework that generates an entire opinion triplet at each time step thereby making our solution end-to-end. Interactions between the aspects and opinions are effectively captured by the decoder by considering their entire detected spans while predicting their connecting sentiment. Extensive experiments on several benchmark datasets establish the better efficacy of our proposed approach, especially in recall, and in predicting multiple and aspect\/opinion-overlapped triplets from the same review sentence. We report our results both with and without BERT and also demonstrate the utility of domain-specific BERT post-training for the task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"PAUSE","Description":"Positive and Annealed Unlabeled Sentence Embedding","Abstract":"Sentence embedding refers to a set of effective and versatile techniques for converting raw text into numerical vector representations that can be used in a wide range of natural language processing (NLP) applications. The majority of these techniques are either supervised or unsupervised. Compared to the unsupervised methods, the supervised ones make less assumptions about optimization objectives and usually achieve better results. However, the training requires a large amount of labeled sentence pairs, which is not available in many industrial scenarios. To that end, we propose a generic and end-to-end approach \u2013 <MASKED_ACRONYM> (Positive and Annealed Unlabeled Sentence Embedding), capable of learning high-quality sentence embeddings from a partially labeled dataset. We experimentally show that <MASKED_ACRONYM> achieves, and sometimes surpasses, state-of-the-art results using only a small fraction of labeled sentence pairs on various benchmark tasks. When applied to a real industrial use case where labeled samples are scarce, <MASKED_ACRONYM> encourages us to extend our dataset without the burden of extensive manual annotation work.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"GeneSis","Description":"A Generative Approach to Substitutes in Context","Abstract":"The lexical substitution task aims at generating a list of suitable replacements for a target word in context, ideally keeping the meaning of the modified text unchanged. While its usage has increased in recent years, the paucity of annotated data prevents the finetuning of neural models on the task, hindering the full fruition of recently introduced powerful architectures such as language models. Furthermore, lexical substitution is usually evaluated in a framework that is strictly bound to a limited vocabulary, making it impossible to credit appropriate, but out-of-vocabulary, substitutes. To assess these issues, we proposed <MASKED_ACRONYM> (Generating Substitutes in contexts), the first generative approach to lexical substitution. Thanks to a seq2seq model, we generate substitutes for a word according to the context it appears in, attaining state-of-the-art results on different benchmarks. Moreover, our approach allows silver data to be produced for further improving the performances of lexical substitution systems. Along with an extensive analysis of <MASKED_ACRONYM> results, we also present a human evaluation of the generated substitutes in order to assess their quality. We release the fine-tuned models, the generated datasets, and the code to reproduce the experiments at <a href=https:\/\/github.com\/SapienzaNLP\/genesis class=acl-markup-url>https:\/\/github.com\/SapienzaNLP\/genesis<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"MiSS","Description":"An Assistant for Multi-Style Simultaneous Translation","Abstract":"In this paper, we present <b><MASKED_ACRONYM><\/b>, an assistant for multi-style simultaneous translation. Our proposed translation system has five key features: highly accurate translation, simultaneous translation, translation for multiple text styles, back-translation for translation quality evaluation, and grammatical error correction. With this system, we aim to provide a complete translation experience for machine translation users. Our design goals are high translation accuracy, real-time translation, flexibility, and measurable translation quality. Compared with the free commercial translation systems commonly used, our translation assistance system regards the machine translation application as a more complete and fully-featured tool for users. By incorporating additional features and giving the user better control over their experience, we improve translation efficiency and performance. Additionally, our assistant system combines machine translation, grammatical error correction, and interactive edits, and uses a crowdsourcing mode to collect more data for further training to improve both the machine translation and grammatical error correction models. A short video demonstrating our system is available at <a href=\"https:\/\/www.youtube.com\/watch?v=ZGCo7KtRKd8\" class=acl-markup-url>https:\/\/www.youtube.com\/watch?v=ZGCo7KtRKd8<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"DRIFT","Description":"A Toolkit for Diachronic Analysis of Scientific Literature","Abstract":"In this work, we present to the NLP community, and to the wider research community as a whole, an application for the diachronic analysis of research corpora. We open source an easy-to-use tool coined <MASKED_ACRONYM>, which allows researchers to track research trends and development over the years. The analysis methods are collated from well-cited research works, with a few of our own methods added for good measure. Succinctly put, some of the analysis methods are: keyword extraction, word clouds, predicting declining\/stagnant\/growing trends using Productivity, tracking bi-grams using Acceleration plots, finding the Semantic Drift of words, tracking trends using similarity, etc. To demonstrate the utility and efficacy of our tool, we perform a case study on the cs.CL corpus of the arXiv repository and draw inferences from the analysis methods. The toolkit and the associated code are available here: <a href=https:\/\/github.com\/rajaswa\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/rajaswa\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"emnlp-2021","Acronym":"FAST","Description":"Fast Annotation tool for SmarT devices","Abstract":"Working with a wide range of annotators with the same attributes is crucial, as in real-world applications. Although such application cases often use crowd-sourcing mechanisms to gather a variety of annotators, most real-world users use mobile devices. In this paper, we propose \u201c<MASKED_ACRONYM>,\u201d an annotation tool for application tasks that focuses on the user experience of mobile devices, which has not yet been focused on thus far. We designed <MASKED_ACRONYM> as a web application for use on any device with a flexible interface that can be customized to fit various tasks. In our experiments, we conducted crowd-sourced annotation for a sentiment analysis task with several annotators and evaluated annotation metrics such as speed, quality, and ease of use from the tool\u2019s logs and user surveys. Based on the results of our experiments, we conclude that our system can annotate faster than existing methods while maintaining the annotation quality.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"lrec-2016","Acronym":"IRIS","Description":"English-Irish Machine Translation System","Abstract":"We describe <MASKED_ACRONYM>, a statistical machine translation (SMT) system for translating from English into Irish and vice versa. Since Irish is considered an under-resourced language with a limited amount of machine-readable text, building a machine translation system that produces reasonable translations is rather challenging. As translation is a difficult task, current research in SMT focuses on obtaining statistics either from a large amount of parallel, monolingual or other multilingual resources. Nevertheless, we collected available English-Irish data and developed an SMT system aimed at supporting human translators and enabling cross-lingual language technology tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"lrec-2016","Acronym":"InScript","Description":"Narrative texts annotated with script information","Abstract":"This paper presents the <MASKED_ACRONYM> corpus (Narrative Texts Instantiating Script structure). <MASKED_ACRONYM> is a corpus of 1,000 stories centered around 10 different scenarios. Verbs and noun phrases are annotated with event and participant types, respectively. Additionally, the text is annotated with coreference information. The corpus shows rich lexical variation and will serve as a unique resource for the study of the role of script knowledge in natural language processing.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2016,"Venue":"lrec-2016","Acronym":"SCALE","Description":"A Scalable Language Engineering Toolkit","Abstract":"In this paper we present <MASKED_ACRONYM>, a new Python toolkit that contains two extensions to n-gram language models. The first extension is a novel technique to model compound words called Semantic Head Mapping (SHM). The second extension, Bag-of-Words Language Modeling (BagLM), bundles popular models such as Latent Semantic Analysis and Continuous Skip-grams. Both extensions scale to large data and allow the integration into first-pass ASR decoding. The toolkit is open source, includes working examples and can be found on <a href=http:\/\/github.com\/jorispelemans\/scale class=acl-markup-url>http:\/\/github.com\/jorispelemans\/scale<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"lrec-2016","Acronym":"SPA","Description":"Web-based Platform for easy Access to Speech Processing Modules","Abstract":"This paper presents <MASKED_ACRONYM>, a web-based Speech Analytics platform that integrates several speech processing modules and that makes it possible to use them through the web. It was developed with the aim of facilitating the usage of the modules, without the need to know about software dependencies and specific configurations. Apart from being accessed by a web-browser, the platform also provides a REST API for easy integration with other applications. The platform is flexible, scalable, provides authentication for access restrictions, and was developed taking into consideration the time and effort of providing new services. The platform is still being improved, but it already integrates a considerable number of audio and text processing modules, including: Automatic transcription, speech disfluency classification, emotion detection, dialog act recognition, age and gender classification, non-nativeness detection, hyper-articulation detection, dialog act recognition, and two external modules for feature extraction and DTMF detection. This paper describes the <MASKED_ACRONYM> architecture, presents the already integrated modules, and provides a detailed description for the ones most recently integrated.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"lrec-2016","Acronym":"SPLIT","Description":"Smart Preprocessing (Quasi) Language Independent Tool","Abstract":"Text preprocessing is an important and necessary task for all NLP applications. A simple variation in any preprocessing step may drastically affect the final results. Moreover replicability and comparability, as much as feasible, is one of the goals of our scientific enterprise, thus building systems that can ensure the consistency in our various pipelines would contribute significantly to our goals. The problem has become quite pronounced with the abundance of NLP tools becoming more and more available yet with different levels of specifications. In this paper, we present a dynamic unified preprocessing framework and tool, <MASKED_ACRONYM>, that is highly configurable based on user requirements which serves as a preprocessing tool for several tools at once. <MASKED_ACRONYM> aims to standardize the implementations of the most important preprocessing steps by allowing for a unified API that could be exchanged across different researchers to ensure complete transparency in replication. The user is able to select the required preprocessing tasks among a long list of preprocessing steps. The user is also able to specify the order of execution which in turn affects the final preprocessing output.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"ws-2007","Acronym":"WIRE","Description":"A Wearable Spoken Language Understanding System for the Military","Abstract":"In this paper, we present the <MASKED_ACRONYM> system for  human intelligence reporting and discuss challenges of deploying spoken language understanding systems for the military, particularly  for  dismounted  warfighters.  Using  the  PARADISE evaluation paradigm, we show that  performance models derived using standard  metrics can account for 68% of the variance of  User Satisfaction. We discuss the implication of  these results and how the evaluation paradigm  may be modified for the military domain.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"ws-2007","Acronym":"ConText","Description":"An Algorithm for Identifying Contextual Features from Clinical Text","Abstract":"Applications using automatically indexed  clinical conditions must account for contextual features such as whether a condition  is negated, historical or hypothetical, or  experienced by someone other than the patient. We developed and evaluated an algorithm called <MASKED_ACRONYM>, an extension of the  NegEx negation algorithm, which relies on  trigger terms, pseudo-trigger terms, and  termination terms for identifying the values  of three contextual features. In spite of its  simplicity, <MASKED_ACRONYM> performed well at  identifying negation and hypothetical status.  <MASKED_ACRONYM> performed moderately at identifying whether a condition was experienced  by someone other than the patient and  whether the condition occurred historically.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2007,"Venue":"ws-2007","Acronym":"METEOR","Description":"An Automatic Metric for MT Evaluation with High Levels of Correlation with Human Judgments","Abstract":"Meteor is an automatic metric for Machine Translation evaluation which has been demonstrated to have high levels of correlation with human judgments of translation quality, signi\ufb01cantly outperforming the more commonly used Bleu metric. It is one of several automatic metrics used in this year\u2019s shared task within the ACL WMT-07 workshop. This paper recaps the technical details underlying the metric and describes recent improvements in the metric. The latest release includes improved metric parameters and extends the metric to support evaluation of MT output in Spanish, French and German, in addition to English.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"louhi-2018","Acronym":"CAS","Description":"French Corpus with Clinical Cases","Abstract":"Textual corpora are extremely important for various NLP applications as they provide information necessary for creating, setting and testing these applications and the corresponding tools. They are also crucial for designing reliable methods and reproducible results. Yet, in some areas, such as the medical area, due to confidentiality or to ethical reasons, it is complicated and even impossible to access textual data representative of those produced in these areas. We propose the <MASKED_ACRONYM> corpus built with clinical cases, such as they are reported in the published scientific literature in French. We describe this corpus, currently containing over 397,000 word occurrences, and the existing linguistic and semantic annotations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"acl-2019","Acronym":"GEAR","Description":"Graph-based Evidence Aggregating and Reasoning for Fact Verification","Abstract":"Fact verification (FV) is a challenging task which requires to retrieve relevant evidence from plain text and use the evidence to verify given claims. Many claims require to simultaneously integrate and reason over several pieces of evidence for verification. However, previous work employs simple models to extract information from evidence without letting evidence communicate with each other, e.g., merely concatenate the evidence for processing. Therefore, these methods are unable to grasp sufficient relational and logical information among the evidence. To alleviate this issue, we propose a graph-based evidence aggregating and reasoning (<MASKED_ACRONYM>) framework which enables information to transfer on a fully-connected evidence graph and then utilizes different aggregators to collect multi-evidence information. We further employ BERT, an effective pre-trained language representation model, to improve the performance. Experimental results on a large-scale benchmark dataset FEVER have demonstrated that <MASKED_ACRONYM> could leverage multi-evidence information for FV and thus achieves the promising result with a test FEVER score of 67.10%. Our code is available at <a href=https:\/\/github.com\/thunlp\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/thunlp\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2019,"Venue":"acl-2019","Acronym":"SLATE","Description":"A Super-Lightweight Annotation Tool for Experts","Abstract":"Many annotation tools have been developed, covering a wide variety of tasks and providing features like user management, pre-processing, and automatic labeling. However, all of these tools use Graphical User Interfaces, and often require substantial effort to install and configure. This paper presents a new annotation tool that is designed to fill the niche of a lightweight interface for users with a terminal-based workflow. <MASKED_ACRONYM> supports annotation at different scales (spans of characters, tokens, and lines, or a document) and of different types (free text, labels, and links), with easily customisable keybindings, and unicode support. In a user study comparing with other tools it was consistently the easiest to install and use. <MASKED_ACRONYM> fills a need not met by existing systems, and has already been used to annotate two corpora, one of which involved over 250 hours of annotation effort.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"PARADISE","Description":"Exploiting Parallel Data for Multilingual Sequence-to-Sequence Pretraining","Abstract":"Despite the success of multilingual sequence-to-sequence pretraining, most existing approaches rely on monolingual corpora and do not make use of the strong cross-lingual signal contained in parallel data. In this paper, we present <MASKED_ACRONYM> (PARAllel &amp;Denoising Integration in SEquence-to-sequence models), which extends the conventional denoising objective used to train these models by (i) replacing words in the noised sequence according to a multilingual dictionary, and (ii) predicting the reference translation according to a parallel corpus instead of recovering the original sequence. Our experiments on machine translation and cross-lingual natural language inference show an average improvement of 2.0 BLEU points and 6.7 accuracy points from integrating parallel data into pretraining, respectively, obtaining results that are competitive with several popular models at a fraction of their computational cost.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"GRAM","Description":"Fast Fine-tuning of Pre-trained Language Models for Content-based Collaborative Filtering","Abstract":"Content-based collaborative filtering (CCF) predicts user-item interactions based on both users\u2019 interaction history and items\u2019 content information. Recently, pre-trained language models (PLM) have been used to extract high-quality item encodings for CCF. However, it is resource-intensive to train a PLM-based CCF model in an end-to-end (E2E) manner, since optimization involves back-propagating through every content encoding within a given user interaction sequence. To tackle this issue, we propose <MASKED_ACRONYM> (GRadient Accumulation for Multi-modality in CCF), which exploits the fact that a given item often appears multiple times within a batch of interaction histories. Specifically, Single-step <MASKED_ACRONYM> aggregates each item encoding\u2019s gradients for back-propagation, with theoretic equivalence to the standard E2E training. As an extension of Single-step <MASKED_ACRONYM>, we propose Multi-step <MASKED_ACRONYM>, which increases the gradient update latency, achieving a further speedup with drastically less GPU memory. <MASKED_ACRONYM> significantly improves training efficiency (up to 146x) on five datasets from two task domains of Knowledge Tracing and News Recommendation. Our code is available at <a href=https:\/\/github.com\/yoonseok312\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/yoonseok312\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"WALNUT","Description":"A Benchmark on Semi-weakly Supervised Learning for Natural Language Understanding","Abstract":"Building machine learning models for natural language understanding (NLU) tasks relies heavily on labeled data. Weak supervision has been proven valuable when large amount of labeled data is unavailable or expensive to obtain. Existing works studying weak supervision for NLU either mostly focus on a specific task or simulate weak supervision signals from ground-truth labels. It is thus hard to compare different approaches and evaluate the benefit of weak supervision without access to a unified and systematic benchmark with diverse tasks and real-world weak labeling rules. In this paper, we propose such a benchmark, named <MASKED_ACRONYM>, to advocate and facilitate research on weak supervision for NLU. <MASKED_ACRONYM> consists of NLU tasks with different types, including document-level and token-level prediction tasks. <MASKED_ACRONYM> is the first semi-weakly supervised learning benchmark for NLU, where each task contains weak labels generated by multiple real-world weak sources, together with a small set of clean labels. We conduct baseline evaluations on <MASKED_ACRONYM> to systematically evaluate the effectiveness of various weak supervision methods and model architectures. Our results demonstrate the benefit of weak supervision for low-resource NLU tasks and highlight interesting patterns across tasks. We expect <MASKED_ACRONYM> to stimulate further research on methodologies to leverage weak supervision more effectively. The benchmark and code for baselines are available at aka.ms\/walnut_benchmark.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"KAT","Description":"A Knowledge Augmented Transformer for Vision-and-Language","Abstract":"The primary focus of recent work with large-scale transformers has been on optimizing the amount of information packed into the model\u2019s parameters. In this work, we ask a complementary question: Can multimodal transformers leverage explicit knowledge in their reasoning? Existing, primarily unimodal, methods have explored approaches under the paradigm of knowledge retrieval followed by answer prediction, but leave open questions about the quality and relevance of the retrieved knowledge used, and how the reasoning processes over implicit and explicit knowledge should be integrated. To address these challenges, we propose a - Knowledge Augmented Transformer (<MASKED_ACRONYM>) - which achieves a strong state-of-the-art result (+6% absolute) on the open-domain multimodal task of OK-VQA. Our approach integrates implicit and explicit knowledge in an encoder-decoder architecture, while still jointly reasoning over both knowledge sources during answer generation. Additionally, explicit knowledge integration improves interpretability of model predictions in our analysis.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"ScAN","Description":"Suicide Attempt and Ideation Events Dataset","Abstract":"Suicide is an important public health concern and one of the leading causes of death worldwide. Suicidal behaviors, including suicide attempts (SA) and suicide ideations (SI), are leading risk factors for death by suicide. Information related to patients\u2019 previous and current SA and SI are frequently documented in the electronic health record (EHR) notes. Accurate detection of such documentation may help improve surveillance and predictions of patients\u2019 suicidal behaviors and alert medical professionals for suicide prevention efforts. In this study, we first built Suicide Attempt and Ideation Events (<MASKED_ACRONYM>) dataset, a subset of the publicly available MIMIC III dataset spanning over 12k+ EHR notes with 19k+ annotated SA and SI events information. The annotations also contain attributes such as method of suicide attempt. We also provide a strong baseline model <MASKED_ACRONYM>ER (Suicide Attempt and Ideation Events Retriever), a multi-task RoBERTa-based model with a retrieval module to extract all the relevant suicidal behavioral evidences from EHR notes of an hospital-stay and, and a prediction module to identify the type of suicidal behavior (SA and SI) concluded during the patient\u2019s stay at the hospital. <MASKED_ACRONYM>ER achieved a macro-weighted F1-score of 0.83 for identifying suicidal behavioral evidences and a macro F1-score of 0.78 and 0.60 for classification of SA and SI for the patient\u2019s hospital-stay, respectively. <MASKED_ACRONYM> and <MASKED_ACRONYM>ER are publicly available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"SKILL","Description":"Structured Knowledge Infusion for Large Language Models","Abstract":"Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pre-trained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3x improvement of exact match score on MetaQA task. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"OPERA","Description":"Operation-Pivoted Discrete Reasoning over Text","Abstract":"Machine reading comprehension (MRC) that requires discrete reasoning involving symbolic operations, e.g., addition, sorting, and counting, is a challenging task. According to this nature, semantic parsing-based methods predict interpretable but complex logical forms. However, logical form generation is nontrivial and even a little perturbation in a logical form will lead to wrong answers. To alleviate this issue, multi-predictor -based methods are proposed to directly predict different types of answers and achieve improvements. However, they ignore the utilization of symbolic operations and encounter a lack of reasoning ability and interpretability. To inherit the advantages of these two types of methods, we propose <MASKED_ACRONYM>, an operation-pivoted discrete reasoning framework, where lightweight symbolic operations (compared with logical forms) as neural modules are utilized to facilitate the reasoning ability and interpretability. Specifically, operations are first selected and then softly executed to simulate the answer reasoning procedure. Extensive experiments on both DROP and RACENum datasets show the reasoning ability of <MASKED_ACRONYM>. Moreover, further analysis verifies its interpretability.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"TIE","Description":"Topological Information Enhanced Structural Reading Comprehension on Web Pages","Abstract":"Recently, the structural reading comprehension (SRC) task on web pages has attracted increasing research interests. Although previous SRC work has leveraged extra information such as HTML tags or XPaths, the informative topology of web pages is not effectively exploited. In this work, we propose a Topological Information Enhanced model (<MASKED_ACRONYM>), which transforms the token-level task into a tag-level task by introducing a two-stage process (i.e. node locating and answer refining). Based on that, <MASKED_ACRONYM> integrates Graph Attention Network (GAT) and Pre-trained Language Model (PLM) to leverage the topological information of both logical structures and spatial structures. Experimental results demonstrate that our model outperforms strong baselines and achieves state-of-the-art performances on the web-based SRC benchmark WebSRC at the time of writing. The code of <MASKED_ACRONYM> will be publicly available at <a href=https:\/\/github.com\/X-LANCE\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/X-LANCE\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"DEGREE","Description":"A Data-Efficient Generation-Based Event Extraction Model","Abstract":"Event extraction requires high-quality expert human annotations, which are usually expensive. Therefore, learning a data-efficient event extraction model that can be trained with only a few labeled examples has become a crucial challenge. In this paper, we focus on low-resource end-to-end event extraction and propose <MASKED_ACRONYM>, a data-efficient model that formulates event extraction as a conditional generation problem. Given a passage and a manually designed prompt, <MASKED_ACRONYM> learns to summarize the events mentioned in the passage into a natural sentence that follows a predefined pattern. The final event predictions are then extracted from the generated sentence with a deterministic algorithm. <MASKED_ACRONYM> has three advantages to learn well with less training data. First, our designed prompts provide semantic guidance for <MASKED_ACRONYM> to leverage <MASKED_ACRONYM> and thus better capture the event arguments. Moreover, <MASKED_ACRONYM> is capable of using additional weakly-supervised information, such as the description of events encoded in the prompts. Finally, <MASKED_ACRONYM> learns triggers and arguments jointly in an end-to-end manner, which encourages the model to better utilize the shared knowledge and dependencies among them. Our experimental results demonstrate the strong performance of <MASKED_ACRONYM> for low-resource event extraction.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"SAIS","Description":"Supervising and Augmenting Intermediate Steps for Document-Level Relation Extraction","Abstract":"Stepping from sentence-level to document-level, the research on relation extraction (RE) confronts increasing text length and more complicated entity interactions. Consequently, it is more challenging to encode the key information sources\u2014relevant contexts and entity types. However, existing methods only implicitly learn to model these critical information sources while being trained for RE. As a result, they suffer the problems of ineffective supervision and uninterpretable model predictions. In contrast, we propose to explicitly teach the model to capture relevant contexts and entity types by supervising and augmenting intermediate steps (<MASKED_ACRONYM>) for RE. Based on a broad spectrum of carefully designed tasks, our proposed <MASKED_ACRONYM> method not only extracts relations of better quality due to more effective supervision, but also retrieves the corresponding supporting evidence more accurately so as to enhance interpretability. By assessing model uncertainty, <MASKED_ACRONYM> further boosts the performance via evidence-based data augmentation and ensemble inference while reducing the computational cost. Eventually, <MASKED_ACRONYM> delivers state-of-the-art RE results on three benchmarks (DocRED, CDR, and GDA) and outperforms the runner-up by 5.04% relatively in F1 score in evidence retrieval on DocRED.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"naacl-2022","Acronym":"LUNA","Description":"Learning Slot-Turn Alignment for Dialogue State Tracking","Abstract":"Dialogue state tracking (DST) aims to predict the current dialogue state given the dialogue history. Existing methods generally exploit the utterances of all dialogue turns to assign value for each slot. This could lead to suboptimal results due to the information introduced from irrelevant utterances in the dialogue history, which may be useless and can even cause confusion. To address this problem, we propose <MASKED_ACRONYM>, a SLot-TUrN Alignment enhanced approach. It first explicitly aligns each slot with its most relevant utterance, then further predicts the corresponding value based on this aligned utterance instead of all dialogue utterances. Furthermore, we design a slot ranking auxiliary task to learn the temporal correlation among slots which could facilitate the alignment. Comprehensive experiments are conducted on three multi-domain task-oriented dialogue datasets, MultiWOZ 2.0, MultiWOZ 2.1, and MultiWOZ 2.2. The results show that <MASKED_ACRONYM> achieves new state-of-the-art results on these datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"CHEF","Description":"A Pilot Chinese Dataset for Evidence-Based Fact-Checking","Abstract":"The explosion of misinformation spreading in the media ecosystem urges for automated fact-checking. While misinformation spans both geographic and linguistic boundaries, most work in the field has focused on English. Datasets and tools available in other languages, such as Chinese, are limited. In order to bridge this gap, we construct <MASKED_ACRONYM>, the first CHinese Evidence-based Fact-checking dataset of 10K real-world claims. The dataset covers multiple domains, ranging from politics to public health, and provides annotated evidence retrieved from the Internet. Further, we develop established baselines and a novel approach that is able to model the evidence retrieval as a latent variable, allowing jointly training with the veracity prediction model in an end-to-end fashion. Extensive experiments show that <MASKED_ACRONYM> will provide a challenging testbed for the development of fact-checking systems designed to retrieve and reason over non-English claims.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"FRUIT","Description":"Faithfully Reflecting Updated Information in Text","Abstract":"Textual knowledge bases such as Wikipedia require considerable effort to keep up to date and consistent. While automated writing assistants could potentially ease this burden, the problem of suggesting edits grounded in external knowledge has been under-explored. In this paper, we introduce the novel generation task of *faithfully reflecting updated information in text* (<MASKED_ACRONYM>) where the goal is to update an existing article given new evidence. We release the <MASKED_ACRONYM>-WIKI dataset, a collection of over 170K distantly supervised data produced from pairs of Wikipedia snapshots, along with our data generation pipeline and a gold evaluation set of 914 instances whose edits are guaranteed to be supported by the evidence. We provide benchmark results for popular generation systems as well as EDIT5 \u2013 a T5-based approach tailored to editing we introduce that establishes the state of the art. Our analysis shows that developing models that can update articles faithfully requires new capabilities for neural generation models, and opens doors to many new applications.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"EASE","Description":"Entity-Aware Contrastive Learning of Sentence Embedding","Abstract":"We present <MASKED_ACRONYM>, a novel method for learning sentence embeddings via contrastive learning between sentences and their related entities. The advantage of using entity supervision is twofold: (1) entities have been shown to be a strong indicator of text semantics and thus should provide rich training signals for sentence embeddings; (2) entities are defined independently of languages and thus offer useful cross-lingual alignment supervision. We evaluate <MASKED_ACRONYM> against other unsupervised models both in monolingual and multilingual settings. We show that <MASKED_ACRONYM> exhibits competitive or better performance in English semantic textual similarity (STS) and short text clustering (STC) tasks and it significantly outperforms baseline methods in multilingual settings on a variety of tasks. Our source code, pre-trained models, and newly constructed multi-lingual STC dataset are available at <a href=https:\/\/github.com\/studio-ousia\/ease class=acl-markup-url>https:\/\/github.com\/studio-ousia\/ease<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"FOAM","Description":"A Follower-aware Speaker Model For Vision-and-Language Navigation","Abstract":"The speaker-follower models have proven to be effective in vision-and-language navigation, where a speaker model is used to synthesize new instructions to augment the training data for a follower navigation model. However, in previous work, the speaker model is follower-agnostic and fails to take the state of the follower into consideration. In this paper, we present <MASKED_ACRONYM>, a FOllower-Aware speaker Model that is constantly updated given the follower feedback, so that the generated instructions can be more suitable to the current learning state of the follower. Specifically, we optimize the speaker using a bi-level optimization framework and obtain its training signals by evaluating the follower on labeled data. Experimental results on the Room-to-Room and Room-across-Room datasets demonstrate that our methods can outperform strong baseline models across settings. Analyses also reveal that our generated instructions are of higher quality than the baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"SURF","Description":"Semantic-level Unsupervised Reward Function for Machine Translation","Abstract":"The performance of Reinforcement Learning (RL) for natural language tasks including Machine Translation (MT) is crucially dependent on the reward formulation. This is due to the intrinsic difficulty of the task in the high-dimensional discrete action space as well as the sparseness of the standard reward functions defined for limited set of ground-truth sequences biased towards singular lexical choices. To address this issue, we formulate <MASKED_ACRONYM>, a maximally dense semantic-level unsupervised reward function which mimics human evaluation by considering both sentence fluency and semantic similarity. We demonstrate the strong potential of <MASKED_ACRONYM> to leverage a family of Actor-Critic Transformer-based Architectures with synchronous and asynchronous multi-agent variants. To tackle the problem of large action-state spaces, each agent is equipped with unique exploration strategies, promoting diversity during its exploration of the hypothesis space. When BLEU scores are compared, our dense unsupervised reward outperforms the standard sparse reward by 2% on average for in- and out-of-domain settings.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"GenIE","Description":"Generative Information Extraction","Abstract":"Structured and grounded representation of text is typically formalized by closed information extraction, the problem of extracting an exhaustive set of (subject, relation, object) triplets that are consistent with a predefined set of entities and relations from a knowledge base schema. Most existing works are pipelines prone to error accumulation, and all approaches are only applicable to unrealistically small numbers of entities and relations. We introduce <MASKED_ACRONYM> (generative information extraction), the first end-to-end autoregressive formulation of closed information extraction. <MASKED_ACRONYM> naturally exploits the language knowledge from the pre-trained transformer by autoregressively generating relations and entities in textual form. Thanks to a new bi-level constrained generation strategy, only triplets consistent with the predefined knowledge base schema are produced. Our experiments show that <MASKED_ACRONYM> is state-of-the-art on closed information extraction, generalizes from fewer training data points than baselines, and scales to a previously unmanageable number of entities and relations. With this work, closed information extraction becomes practical in realistic scenarios, providing new opportunities for downstream tasks. Finally, this work paves the way towards a unified end-to-end approach to the core tasks of information extraction.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"naacl-2022","Acronym":"DUCK","Description":"Rumour Detection on Social Media by Modelling User and Comment Propagation Networks","Abstract":"Social media rumours, a form of misinformation, can mislead the public and cause significant economic and social disruption. Motivated by the observation that the user network \u2014 which captures <span class=tex-math><em>who<\/em><\/span> engage with a story \u2014 and the comment network \u2014 which captures <span class=tex-math><em>how<\/em><\/span> they react to it \u2014 provide complementary signals for rumour detection, in this paper, we propose <MASKED_ACRONYM> (rumour <span class=tex-math>\u00a0\u0332d<\/span>etection with <span class=tex-math>\u00a0\u0332u<\/span>ser and <span class=tex-math>\u00a0\u0332c<\/span>omment networ<span class=tex-math>\u00a0\u0332k<\/span>s) for rumour detection on social media. We study how to leverage transformers and graph attention networks to jointly model the contents and structure of social media conversations, as well as the network of users who engaged in these conversations. Over four widely used benchmark rumour datasets in English and Chinese, we show that <MASKED_ACRONYM> produces superior performance for detecting rumours, creating a new state-of-the-art. Source code for <MASKED_ACRONYM> is available at: <a href=https:\/\/github.com\/ltian678\/<MASKED_ACRONYM>-code class=acl-markup-url>https:\/\/github.com\/ltian678\/<MASKED_ACRONYM>-code<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"naacl-2022","Acronym":"QuALITY","Description":"Question Answering with Long Input Texts, Yes!","Abstract":"To enable building and testing models on long-document comprehension, we introduce <MASKED_ACRONYM>, a multiple-choice QA dataset with context passages in English that have an average length of about 5,000 tokens, much longer than typical current models can process. Unlike in prior work with passages, our questions are written and validated by contributors who have read the entire passage, rather than relying on summaries or excerpts. In addition, only half of the questions are answerable by annotators working under tight time constraints, indicating that skimming and simple search are not enough to consistently perform well. Our baseline models perform poorly on this task (55.4%) and significantly lag behind human performance (93.5%).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2006,"Venue":"eacl-2006","Acronym":"ASSIST","Description":"Automated Semantic Assistance for Translators","Abstract":"The problem we address in this paper is that of providing contextual examples of translation equivalents for words from the general lexicon using comparable corpora and semantic annotation that is uniform for the source and target languages. For a sentence, phrase or a query expression in the source language the tool detects the semantic type of the situation in question and gives examples of similar contexts from the target language corpus.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":1999,"Venue":"ws-1999","Acronym":"FAME","Description":"a Functional Annotation Meta-scheme for multi-modal and multi-lingual Parsing Evaluation","Abstract":"The paper describes <MASKED_ACRONYM>, a functional annota-  tion meta-scheme for comparison and evaluation of  existing syntactic annotation schemes, intended to  be used as a flexible yardstick in multi-lingual and  multi-modal parser evaluation campaigns. We show  that <MASKED_ACRONYM> complies with a variety of non-trivial  methodological requirements, and has the potential  for being effectively used as an \"interlingua\" between  different syntactic representation formats.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"iwcs-2023","Acronym":"RaTE","Description":"a Reproducible automatic Taxonomy Evaluation by Filling the Gap","Abstract":"Taxonomies are an essential knowledge representation, yet most studies on automatic taxonomy construction (ATC) resort to manual evaluation to score proposed algorithms. We argue that automatic taxonomy evaluation (ATE) is just as important as taxonomy construction. We propose <MASKED_ACRONYM>, an automatic label-free taxonomy scoring procedure, which relies on a large pre-trained language model. We apply our evaluation procedure to three state-of-the-art ATC algorithms with which we built seven taxonomies from the Yelp domain, and show that 1) <MASKED_ACRONYM> correlates well with human judgments and 2) artificially degrading a taxonomy leads to decreasing <MASKED_ACRONYM> score.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":1995,"Venue":"eacl-1995","Acronym":"ProFIT","Description":"Prolog with Features, Inheritance and Templates","Abstract":"<MASKED_ACRONYM> is an extension of Standard Pro-  log with Features, Inheritance and Tem-  plates. <MASKED_ACRONYM> Mlows the programmer  or grammar developer to declare an in-  heritance hierarchy, features and tem-  plates. Sorted feature terms can be used  in <MASKED_ACRONYM> programs together with Pro-  log terms to provide a clearer descrip-  tion language for linguistic structures.  <MASKED_ACRONYM> compiles all sorted feature terms  into a Prolog term representation, so  that the built-in Prolog term unification  can be used for the unification of sorted  feature structures, and no special uni-  fication algorithm is needed.  <MASKED_ACRONYM>  programs are compiled into Prolog pro-  grams, so that no meta-interpreter is  needed for their execution. <MASKED_ACRONYM> thus  provides a direct step from grammars de-  veloped with sorted feature terms to Pro-  log programs usable for practical NLP  systems.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"ranlp-2023","Acronym":"LeSS","Description":"A Computationally-Light Lexical Simplifier for Spanish","Abstract":"Due to having knowledge of only basic vocabulary, many people cannot understand up-to-date written information and thus make informed decisions and fully participate in the society. We propose <MASKED_ACRONYM>, a modular lexical simplification architecture that outperforms state-of-the-art lexical simplification systems for Spanish. In addition to its state-of-the-art performance, <MASKED_ACRONYM> is computationally light, using much less disk space, CPU and GPU, and having faster loading and execution time than the transformer-based lexical simplification models which are predominant in the field.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"ETC","Description":"Encoding Long and Structured Inputs in Transformers","Abstract":"Transformer models have advanced the state of the art in many Natural Language Processing (NLP) tasks. In this paper, we present a new Transformer architecture, \u201cExtended Transformer Construction\u201d (<MASKED_ACRONYM>), that addresses two key challenges of standard Transformer architectures, namely scaling input length and encoding structured inputs. To scale attention to longer inputs, we introduce a novel global-local attention mechanism between global tokens and regular input tokens. We also show that combining global-local attention with relative position encodings and a \u201cContrastive Predictive Coding\u201d (CPC) pre-training objective allows <MASKED_ACRONYM> to encode structured inputs. We achieve state-of-the-art results on four natural language datasets requiring long and\/or structured inputs.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"PAIR","Description":"Planning and Iterative Refinement in Pre-trained Transformers for Long Text Generation","Abstract":"Pre-trained Transformers have enabled impressive breakthroughs in generating long and fluent text, yet their outputs are often \u201crambling\u201d without coherently arranged content. In this work, we present a novel content-controlled text generation framework, <MASKED_ACRONYM>, with planning and iterative refinement, which is built upon a large model, BART. We first adapt the BERT model to automatically construct the content plans, consisting of keyphrase assignments and their corresponding sentence-level positions. The BART model is employed for generation without modifying its structure. We then propose a refinement algorithm to gradually enhance the generation quality within the sequence-to-sequence framework. Evaluation with automatic metrics shows that adding planning consistently improves the generation quality on three distinct domains, with an average of 20 BLEU points and 12 METEOR points improvements. In addition, human judges rate our system outputs to be more relevant and coherent than comparisons without planning.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"MUTANT","Description":"A Training Paradigm for Out-of-Distribution Generalization in Visual Question Answering","Abstract":"While progress has been made on the visual question answering leaderboards, models often utilize spurious correlations and priors in datasets under the i.i.d. setting. As such, evaluation on out-of-distribution (OOD) test samples has emerged as a proxy for generalization. In this paper, we present <i><MASKED_ACRONYM><\/i>, a training paradigm that exposes the model to perceptually similar, yet semantically distinct <i>mutations<\/i> of the input, to improve OOD generalization, such as the VQA-CP challenge. Under this paradigm, models utilize a consistency-constrained training objective to understand the effect of semantic changes in input (question-image pair) on the output (answer). Unlike existing methods on VQA-CP, <i><MASKED_ACRONYM><\/i> does not rely on the knowledge about the nature of train and test answer distributions. <i><MASKED_ACRONYM><\/i> establishes a new state-of-the-art accuracy on VQA-CP with a 10.57% improvement. Our work opens up avenues for the use of semantic input mutations for OOD generalization in question answering.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"TORQUE","Description":"A Reading Comprehension Dataset of Temporal Ordering Questions","Abstract":"A critical part of reading is being able to understand the temporal relationships between events described in a passage of text, even when those relationships are not explicitly stated. However, current machine reading comprehension benchmarks have practically no questions that test temporal phenomena, so systems trained on these benchmarks have no capacity to answer questions such as \u201cwhat happened before\/after [some event]?\u201d We introduce <MASKED_ACRONYM>, a new English reading comprehension benchmark built on 3.2k news snippets with 21k human-generated questions querying temporal relationships. Results show that RoBERTa-large achieves an exact-match score of 51% on the test set of <MASKED_ACRONYM>, about 30% behind human performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"BiST","Description":"Bi-directional Spatio-Temporal Reasoning for Video-Grounded Dialogues","Abstract":"Video-grounded dialogues are very challenging due to (i) the complexity of videos which contain both spatial and temporal variations, and (ii) the complexity of user utterances which query different segments and\/or different objects in videos over multiple dialogue turns. However, existing approaches to video-grounded dialogues often focus on superficial temporal-level visual cues, but neglect more fine-grained spatial signals from videos. To address this drawback, we proposed Bi-directional Spatio-Temporal Learning (<MASKED_ACRONYM>), a vision-language neural framework for high-resolution queries in videos based on textual cues. Specifically, our approach not only exploits both spatial and temporal-level information, but also learns dynamic information diffusion between the two feature spaces through spatial-to-temporal and temporal-to-spatial reasoning. The bidirectional strategy aims to tackle the evolving semantics of user queries in the dialogue setting. The retrieved visual cues are used as contextual information to construct relevant responses to the users. Our empirical results and comprehensive qualitative analysis show that <MASKED_ACRONYM> achieves competitive performance and generates reasonable responses on a large-scale AVSD benchmark. We also adapt our <MASKED_ACRONYM> models to the Video QA setting, and substantially outperform prior approaches on the TGIF-QA benchmark.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"Discern","Description":"Discourse-Aware Entailment Reasoning Network for Conversational Machine Reading","Abstract":"Document interpretation and dialog understanding are the two major challenges for conversational machine reading. In this work, we propose \u201c<MASKED_ACRONYM>\u201d, a discourse-aware entailment reasoning network to strengthen the connection and enhance the understanding of both document and dialog. Specifically, we split the document into clause-like elementary discourse units (EDU) using a pre-trained discourse segmentation model, and we train our model in a weakly-supervised manner to predict whether each EDU is entailed by the user feedback in a conversation. Based on the learned EDU and entailment representations, we either reply to the user our final decision \u201cyes\/no\/irrelevant\u201d of the initial question, or generate a follow-up question to inquiry more information. Our experiments on the ShARC benchmark (blind, held-out test set) show that <MASKED_ACRONYM> achieves state-of-the-art results of 78.3% macro-averaged accuracy on decision making and 64.0 BLEU1 on follow-up question generation. Code and models are released at <a href=https:\/\/github.com\/Yifan-Gao\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/Yifan-Gao\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"EXAMS","Description":"A Multi-subject High School Examinations Dataset for Cross-lingual and Multilingual Question Answering","Abstract":"We propose <MASKED_ACRONYM> \u2013 a new benchmark dataset for cross-lingual and multilingual question answering for high school examinations. We collected more than 24,000 high-quality high school exam questions in 16 languages, covering 8 language families and 24 school subjects from Natural Sciences and Social Sciences, among others.<MASKED_ACRONYM> offers unique fine-grained evaluation framework across multiple languages and subjects, which allows precise analysis and comparison of the proposed models. We perform various experiments with existing top-performing multilingual pre-trained models and show that <MASKED_ACRONYM> offers multiple challenges that require multilingual knowledge and reasoning in multiple domains. We hope that <MASKED_ACRONYM> will enable researchers to explore challenging reasoning and knowledge transfer methods and pre-trained models for school question answering in various languages which was not possible by now. The data, code, pre-trained models, and evaluation are available at <a href=http:\/\/github.com\/mhardalov\/exams-qa class=acl-markup-url>http:\/\/github.com\/mhardalov\/exams-qa<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"TeMP","Description":"Temporal Message Passing for Temporal Knowledge Graph Completion","Abstract":"Inferring missing facts in temporal knowledge graphs (TKGs) is a fundamental and challenging task. Previous works have approached this problem by augmenting methods for static knowledge graphs to leverage time-dependent representations. However, these methods do not explicitly leverage multi-hop structural information and temporal facts from recent time steps to enhance their predictions. Additionally, prior work does not explicitly address the temporal sparsity and variability of entity distributions in TKGs. We propose the Temporal Message Passing (<MASKED_ACRONYM>) framework to address these challenges by combining graph neural networks, temporal dynamics models, data imputation and frequency-based gating techniques. Experiments on standard TKG tasks show that our approach provides substantial gains compared to the previous state of the art, achieving a 10.7% average relative improvement in Hits@10 across three standard benchmarks. Our analysis also reveals important sources of variability both within and across TKG datasets, and we introduce several simple but strong baselines that outperform the prior state of the art in certain settings.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"HIT","Description":"Nested Named Entity Recognition via Head-Tail Pair and Token Interaction","Abstract":"Named Entity Recognition (NER) is a fundamental task in natural language processing. In order to identify entities with nested structure, many sophisticated methods have been recently developed based on either the traditional sequence labeling approaches or directed hypergraph structures. Despite being successful, these methods often fall short in striking a good balance between the expression power for nested structure and the model complexity. To address this issue, we present a novel nested NER model named <MASKED_ACRONYM>. Our proposed <MASKED_ACRONYM> model leverages two key properties pertaining to the (nested) named entity, including (1) explicit boundary tokens and (2) tight internal connection between tokens within the boundary. Specifically, we design (1) Head-Tail Detector based on the multi-head self-attention mechanism and bi-affine classifier to detect boundary tokens, and (2) Token Interaction Tagger based on traditional sequence labeling approaches to characterize the internal token connection within the boundary. Experiments on three public NER datasets demonstrate that the proposed <MASKED_ACRONYM> achieves state-of-the-art performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"PARADE","Description":"A New Dataset for Paraphrase Identification Requiring Computer Science Domain Knowledge","Abstract":"We present a new benchmark dataset called <MASKED_ACRONYM> for paraphrase identification that requires specialized domain knowledge. <MASKED_ACRONYM> contains paraphrases that overlap very little at the lexical and syntactic level but are semantically equivalent based on computer science domain knowledge, as well as non-paraphrases that overlap greatly at the lexical and syntactic level but are not semantically equivalent based on this domain knowledge. Experiments show that both state-of-the-art neural models and non-expert human annotators have poor performance on <MASKED_ACRONYM>. For example, BERT after fine-tuning achieves an F1 score of 0.709, which is much lower than its performance on other paraphrase identification datasets. <MASKED_ACRONYM> can serve as a resource for researchers interested in testing models that incorporate domain knowledge. We make our data and code freely available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"VolTAGE","Description":"Volatility Forecasting via Text Audio Fusion with Graph Convolution Networks for Earnings Calls","Abstract":"Natural language processing has recently made stock movement forecasting and volatility forecasting advances, leading to improved financial forecasting. Transcripts of companies\u2019 earnings calls are well studied for risk modeling, offering unique investment insight into stock performance. However, vocal cues in the speech of company executives present an underexplored rich source of natural language data for estimating financial risk. Additionally, most existing approaches ignore the correlations between stocks. Building on existing work, we introduce a neural model for stock volatility prediction that accounts for stock interdependence via graph convolutions while fusing verbal, vocal, and financial features in a semi-supervised multi-task risk forecasting formulation. Our proposed model, <MASKED_ACRONYM>, outperforms existing methods demonstrating the effectiveness of multimodal learning for volatility prediction.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8333333333}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"META","Description":"Metadata-Empowered Weak Supervision for Text Classification","Abstract":"Recent advances in weakly supervised learning enable training high-quality text classifiers by only providing a few user-provided seed words. Existing methods mainly use text data alone to generate pseudo-labels despite the fact that metadata information (e.g., author and timestamp) is widely available across various domains. Strong label indicators exist in the metadata and it has been long overlooked mainly due to the following challenges: (1) metadata is multi-typed, requiring systematic modeling of different types and their combinations, (2) metadata is noisy, some metadata entities (e.g., authors, venues) are more compelling label indicators than others. In this paper, we propose a novel framework, <MASKED_ACRONYM>, which goes beyond the existing paradigm and leverages metadata as an additional source of weak supervision. Specifically, we organize the text data and metadata together into a text-rich network and adopt network motifs to capture appropriate combinations of metadata. Based on seed words, we rank and filter motif instances to distill highly label-indicative ones as \u201cseed motifs\u201d, which provide additional weak supervision. Following a bootstrapping manner, we train the classifier and expand the seed words and seed motifs iteratively. Extensive experiments and case studies on real-world datasets demonstrate superior performance and significant advantages of leveraging metadata as weak supervision.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"PALM","Description":"Pre-training an Autoencoding\\&amp;Autoregressive Language Model for Context-conditioned Generation","Abstract":"Self-supervised pre-training, such as BERT, MASS and BART, has emerged as a powerful technique for natural language understanding and generation. Existing pre-training techniques employ autoencoding and\/or autoregressive objectives to train Transformer-based models by recovering original word tokens from corrupted text with some masked tokens. The training goals of existing techniques are often inconsistent with the goals of many language generation tasks, such as generative question answering and conversational response generation, for producing new text given context. This work presents <MASKED_ACRONYM> with a novel scheme that jointly pre-trains an autoencoding and autoregressive language model on a large unlabeled corpus, specifically designed for generating new text conditioned on context. The new scheme alleviates the mismatch introduced by the existing denoising scheme between pre-training and fine-tuning where generation is more than reconstructing original text. An extensive set of experiments show that <MASKED_ACRONYM> achieves new state-of-the-art results on a variety of language generation benchmarks covering generative question answering (Rank 1 on the official MARCO leaderboard), abstractive summarization on CNN\/DailyMail as well as Gigaword, question generation on SQuAD, and conversational response generation on Cornell Movie Dialogues.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"UNION","Description":"An Unreferenced Metric for Evaluating Open-ended Story Generation","Abstract":"Despite the success of existing referenced metrics (e.g., BLEU and MoverScore), they correlate poorly with human judgments for open-ended text generation including story or dialog generation because of the notorious one-to-many issue: there are many plausible outputs for the same input, which may differ substantially in literal or semantics from the limited number of given references. To alleviate this issue, we propose <MASKED_ACRONYM>, a learnable UNreferenced metrIc for evaluating Open-eNded story generation, which measures the quality of a generated story without any reference. Built on top of BERT, <MASKED_ACRONYM> is trained to distinguish human-written stories from negative samples and recover the perturbation in negative stories. We propose an approach of constructing negative samples by mimicking the errors commonly observed in existing NLG models, including repeated plots, conflicting logic, and long-range incoherence. Experiments on two story datasets demonstrate that <MASKED_ACRONYM> is a reliable measure for evaluating the quality of generated stories, which correlates better with human judgments and is more generalizable than existing state-of-the-art metrics.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"GRADE","Description":"Automatic Graph-Enhanced Coherence Metric for Evaluating Open-Domain Dialogue Systems","Abstract":"Automatically evaluating dialogue coherence is a challenging but high-demand ability for developing high-quality open-domain dialogue systems. However, current evaluation metrics consider only surface features or utterance-level semantics, without explicitly considering the fine-grained topic transition dynamics of dialogue flows. Here, we first consider that the graph structure constituted with topics in a dialogue can accurately depict the underlying communication logic, which is a more natural way to produce persuasive metrics. Capitalized on the topic-level dialogue graph, we propose a new evaluation metric <MASKED_ACRONYM>, which stands for Graph-enhanced Representations for Automatic Dialogue Evaluation. Specifically, <MASKED_ACRONYM> incorporates both coarse-grained utterance-level contextualized representations and fine-grained topic-level graph representations to evaluate dialogue coherence. The graph representations are obtained by reasoning over topic-level dialogue graphs enhanced with the evidence from a commonsense graph, including k-hop neighboring representations and hop-attention weights. Experimental results show that our <MASKED_ACRONYM> significantly outperforms other state-of-the-art metrics on measuring diverse dialogue models in terms of the Pearson and Spearman correlations with human judgments. Besides, we release a new large-scale human evaluation benchmark to facilitate future research on automatic metrics.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"emnlp-2020","Acronym":"HUMAN","Description":"Hierarchical Universal Modular ANnotator","Abstract":"A lot of real-world phenomena are complex and cannot be captured by single task annotations. This causes a need for subsequent annotations, with interdependent questions and answers describing the nature of the subject at hand. Even in the case a phenomenon is easily captured by a single task, the high specialisation of most annotation tools can result in having to switch to another tool if the task only slightly changes. We introduce <MASKED_ACRONYM>, a novel web-based annotation tool that addresses the above problems by a) covering a variety of annotation tasks on both textual and image data, and b) the usage of an internal deterministic state machine, allowing the researcher to chain different annotation tasks in an interdependent manner. Further, the modular nature of the tool makes it easy to define new annotation tasks and integrate machine learning algorithms e.g., for active learning. <MASKED_ACRONYM> comes with an easy-to-use graphical user interface that simplifies the annotation task and management.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2015,"Venue":"acl-2015","Acronym":"SOLAR","Description":"Scalable Online Learning Algorithms for Ranking","Abstract":"Traditional learning to rank methods learn ranking models from training data in a batch and of\ufb02ine learning mode, which suffers from some critical limitations, e.g., poor scalability as the model has to be retrained from scratch whenever new training data arrives. This is clearly nonscalable for many real applications in practice where training data often arrives sequentially and frequently. To overcome the limitations, this paper presents <MASKED_ACRONYM> \u2014 a new framework of Scalable Online Learning Algorithms for Ranking, to tackle the challenge of scalable learning to rank. Speci\ufb01cally, we propose two novel <MASKED_ACRONYM> algorithms and analyze their IR measure bounds theoretically. We conduct extensive empirical studies by comparing our <MASKED_ACRONYM> algorithms with conventional learning to rank algorithms on benchmark testbeds, in which promising results validate the ef\ufb01cacy and scalability of the proposed novel <MASKED_ACRONYM> algorithms.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":1991,"Venue":"mtsummit-1991","Acronym":"ULTRA","Description":"A Multi-lingual Machine Translator","Abstract":"<MASKED_ACRONYM> (Universal Language TRAnslator) is a multilingual, interlingual machine translation system currently under development at the Computing Research Laboratory at New Mexico State University. It translates between five languages (Chinese, English, German, Japanese, Spanish) with vocabularies in each language based on approximately 10,000 word senses. The major design criteria are that the system be robust and general purpose with simple to use utilities for customization to suit the needs of particular users. This paper describes the central characteristics of the system: the intermediate representation, the language components, semantic and pragmatic processes, and supporting lexical entry tools.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"SPEECH","Description":"Structured Prediction with Energy-Based Event-Centric Hyperspheres","Abstract":"Event-centric structured prediction involves predicting structured outputs of events. In most NLP cases, event structures are complex with manifold dependency, and it is challenging to effectively represent these complicated structured events. To address these issues, we propose Structured Prediction with Energy-based Event-Centric Hyperspheres (<MASKED_ACRONYM>). <MASKED_ACRONYM> models complex dependency among event structured components with energy-based modeling, and represents event classes with simple but effective hyperspheres. Experiments on two unified-annotated event datasets indicate that <MASKED_ACRONYM> is predominant in event detection and event-relation extraction tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"ALERT","Description":"Adapt Language Models to Reasoning Tasks","Abstract":"Recent advancements in large language models have enabled them to perform well on complex tasks that require step-by-step reasoning with few-shot learning. However, it is unclear whether these models are applying reasoning skills they have learnt during pre-training , or if they are simply memorizing their training corpus at finer granularity and have learnt to better understand their context. To address this question, we introduce {pasted macro \u2018OUR\u2019}model, a benchmark and suite of analyses for evaluating reasoning skills of language models. {pasted macro \u2018OUR\u2019}model enables comparing pre-trained and finetuned models on complex tasks that require reasoning skills to solve. Our benchmark provides a test bed to asses any language model on fine-grained reasoning skills, which spans over 20 datasets and covers 10 different reasoning skills. By using {pasted macro \u2018OUR\u2019}model we further investigate <i>the role of finetuning<\/i>. Our extensive empirical analysis shows that language models learn more reasoning skills such as textual entailment, abductive reasoning, and analogical reasoning during the finetuning stage compared to pretraining stage. However, we also find that when language models are finetuned they tend to overfit to the prompt template, which hurts the robustness of models causing generalization problems.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"REV","Description":"Information-Theoretic Evaluation of Free-Text Rationales","Abstract":"Generating free-text rationales is a promising step towards explainable NLP, yet evaluating such rationales remains a challenge. Existing metrics have mostly focused on measuring the association between the rationale and a given label. We argue that an ideal metric should focus on the new information uniquely provided in the rationale that is otherwise not provided in the input or the label. We investigate this research problem from an information-theoretic perspective using conditional V-information (Hewitt et al., 2021). More concretely, we propose a metric called <MASKED_ACRONYM> (Rationale Evaluation with conditional V-information), to quantify the amount of new, label-relevant information in a rationale beyond the information already available in the input or the label. Experiments across four benchmarks with reasoning tasks, including chain-of-thought, demonstrate the effectiveness of <MASKED_ACRONYM> in evaluating rationale-label pairs, compared to existing metrics. We further demonstrate <MASKED_ACRONYM> is consistent with human judgments on rationale evaluations and provides more sensitive measurements of new information in free-text rationales. When used alongside traditional performance metrics, <MASKED_ACRONYM> provides deeper insights into models\u2019 reasoning and prediction processes.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"BREAK","Description":"Breaking the Dialogue State Tracking Barrier with Beam Search and Re-ranking","Abstract":"Despite the recent advances in dialogue state tracking (DST), the joint goal accuracy (JGA) of the existing methods on MultiWOZ 2.1 still remains merely 60%. In our preliminary error analysis, we find that beam search produces a pool of candidates that is likely to include the correct dialogue state. Motivated by this observation, we introduce a novel framework, called <MASKED_ACRONYM> (Beam search and RE-rAnKing), that achieves outstanding performance on DST. <MASKED_ACRONYM> performs DST in two stages: (i) generating k-best dialogue state candidates with beam search and (ii) re-ranking the candidates to select the correct dialogue state. This simple yet powerful framework shows state-of-the-art performance on all versions of MultiWOZ and M2M datasets. Most notably, we push the joint goal accuracy to 80-90% on MultiWOZ 2.1-2.4, which is an improvement of 23.6%, 26.3%, 21.7%, and 10.8% over the previous best-performing models, respectively. The data and code will be available at <a href=https:\/\/github.com\/tony-won\/DST-<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CATS","Description":"A Pragmatic Chinese Answer-to-Sequence Dataset with Large Scale and High Quality","Abstract":"There are three problems existing in the popular data-to-text datasets. First, the large-scale datasets either contain noise or lack real application scenarios. Second, the datasets close to real applications are relatively small in size. Last, current datasets bias in the English language while leaving other languages underexplored.To alleviate these limitations, in this paper, we present <MASKED_ACRONYM>, a pragmatic Chinese answer-to-sequence dataset with large scale and high quality. The dataset aims to generate textual descriptions for the answer in the practical TableQA system. Further, to bridge the structural gap between the input SQL and table and establish better semantic alignments, we propose a Unified Graph Transformation approach to establish a joint encoding space for the two hybrid knowledge resources and convert this task to a graph-to-text problem. The experiment results demonstrate the effectiveness of our proposed method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CORE","Description":"Cooperative Training of Retriever-Reranker for Effective Dialogue Response Selection","Abstract":"Establishing retrieval-based dialogue systems that can select appropriate responses from the pre-built index has gained increasing attention. Recent common practice is to construct a two-stage pipeline with a fast retriever (e.g., bi-encoder) for first-stage recall followed by a smart response reranker (e.g., cross-encoder) for precise ranking. However, existing studies either optimize the retriever and reranker in independent ways, or distill the knowledge from a pre-trained reranker into the retriever in an asynchronous way, leading to sub-optimal performance of both modules. Thus, an open question remains about how to train them for a better combination of the best of both worlds. To this end, we present a cooperative training of the response retriever and the reranker whose parameters are dynamically optimized by the ground-truth labels as well as list-wise supervision signals from each other. As a result, the two modules can learn from each other and evolve together throughout the training. Experimental results on two benchmarks demonstrate the superiority of our method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"DOC","Description":"Improving Long Story Coherence With Detailed Outline Control","Abstract":"We propose the Detailed Outline Control (<MASKED_ACRONYM>) framework for improving long-range plot coherence when automatically generating several-thousand-word-long stories. <MASKED_ACRONYM> consists of two complementary components: a detailed outliner and a detailed controller. The detailed outliner creates a more detailed, hierarchically structured outline, shifting creative burden from the main drafting procedure to the planning stage. The detailed controller ensures the more detailed outline is still respected during generation by controlling story passages to align with outline details. In human evaluations of automatically generated stories, <MASKED_ACRONYM> substantially outperforms a strong Re3 baseline (Yang et al., 2022) on plot coherence (22.5% absolute gain), outline relevance (28.2%), and interestingness (20.7%). Humans also judged <MASKED_ACRONYM> to be much more controllable in an interactive generation setting.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"DAMP","Description":"Doubly Aligned Multilingual Parser for Task-Oriented Dialogue","Abstract":"Modern virtual assistants use internal semantic parsing engines to convert user utterances to actionable commands. However, prior work has demonstrated multilingual models are less robust for semantic parsing compared to other tasks. In global markets such as India and Latin America, robust multilingual semantic parsing is critical as codeswitching between languages is prevalent for bilingual users. In this work we dramatically improve the zero-shot performance of a multilingual and codeswitched semantic parsing system using two stages of multilingual alignment. First, we show that contrastive alignment pretraining improves <i>both<\/i> English performance and transfer efficiency. We then introduce a constrained optimization approach for hyperparameter-free adversarial alignment during finetuning. Our Doubly Aligned Multilingual Parser (<MASKED_ACRONYM>) improves mBERT transfer performance by 3x, 6x, and 81x on the Spanglish, Hinglish and Multilingual Task Oriented Parsing benchmarks respectively and outperforms XLM-R and mT5-Large using 3.2x fewer parameters.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"MANNER","Description":"A Variational Memory-Augmented Model for Cross Domain Few-Shot Named Entity Recognition","Abstract":"This paper focuses on the task of cross domain few-shot named entity recognition (NER), which aims to adapt the knowledge learned from source domain to recognize named entities in target domain with only a few labeled examples. To address this challenging task, we propose <MASKED_ACRONYM>, a variational memory-augmented few-shot NER model. Specifically, <MASKED_ACRONYM> uses a memory module to store information from the source domain and then retrieve relevant information from the memory to augment few-shot task in the target domain. In order to effectively utilize the information from memory, <MASKED_ACRONYM> uses optimal transport to retrieve and process information from memory, which can explicitly adapt the retrieved information from source domain to target domain and improve the performance in the cross domain few-shot setting. We conduct experiments on English and Chinese cross domain few-shot NER datasets, and the experimental results demonstrate that <MASKED_ACRONYM> can achieve superior performance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"MASSIVE","Description":"A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages","Abstract":"We present the <MASKED_ACRONYM> dataset\u2013Multilingual Amazon Slu resource package (SLURP) for Slot-filling, Intent classification, and Virtual assistant Evaluation. <MASKED_ACRONYM> contains 1M realistic, parallel, labeled virtual assistant utterances spanning 51 languages, 18 domains, 60 intents, and 55 slots. <MASKED_ACRONYM> was created by tasking professional translators to localize the English-only SLURP dataset into 50 typologically diverse languages from 29 genera. We also present modeling results on XLM-R and mT5, including exact match accuracy, intent classification accuracy, and slot-filling F1 score. We have released our dataset, modeling code, and models publicly.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"ACCENT","Description":"An Automatic Event Commonsense Evaluation Metric for Open-Domain Dialogue Systems","Abstract":"Commonsense reasoning is omnipresent in human communications and thus is an important feature for open-domain dialogue systems. However, evaluating commonsense in dialogue systems is still an open challenge. We take the first step by focusing on <i>event commonsense<\/i> that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning. We propose <b><MASKED_ACRONYM><\/b>, an event commonsense evaluation metric empowered by commonsense knowledge bases (CSKBs). <MASKED_ACRONYM> first extracts event-relation tuples from a dialogue, and then evaluates the response by scoring the tuples in terms of their compatibility with the CSKB. To evaluate <MASKED_ACRONYM>, we construct the first public event commonsense evaluation dataset for open-domain dialogues.Our experiments show that <MASKED_ACRONYM> is an efficient metric for event commonsense evaluation, which achieves higher correlations with human judgments than existing baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CAME","Description":"Confidence-guided Adaptive Memory Efficient Optimization","Abstract":"Adaptive gradient methods, such as Adam and LAMB, have demonstrated excellent performance in the training of large language models. Nevertheless, the need for adaptivity requires maintaining second-moment estimates of the per-parameter gradients, which entails a high cost of extra memory overheads. To solve this problem, several memory-efficient optimizers (e.g., Adafactor) have been proposed to obtain a drastic reduction in auxiliary memory usage, but with a performance penalty. In this paper, we first study a confidence-guided strategy to reduce the instability of existing memory efficient optimizers. Based on this strategy, we propose <MASKED_ACRONYM> to simultaneously achieve two goals: fast convergence as in traditional adaptive methods, and low memory usage as in memory-efficient methods. Extensive experiments demonstrate the training stability and superior performance of <MASKED_ACRONYM> across various NLP tasks such as BERT and GPT-2 training. Notably, for BERT pre-training on the large batch size of 32,768, our proposed optimizer attains faster convergence and higher accuracy compared with the Adam optimizer. The implementation of <MASKED_ACRONYM> is publicly available.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"COLA","Description":"Contextualized Commonsense Causal Reasoning from the Causal Inference Perspective","Abstract":"Detecting commonsense causal relations (causation) between events has long been an essential yet challenging task. Given that events are complicated, an event may have different causes under various contexts. Thus, exploiting context plays an essential role in detecting causal relations. Meanwhile, previous works about commonsense causation only consider two events and ignore their context, simplifying the task formulation. This paper proposes a new task to detect commonsense causation between two events in an event sequence (i.e., context), called contextualized commonsense causal reasoning. We also design a zero-shot framework: <MASKED_ACRONYM> (Contextualized Commonsense Causality Reasoner) to solve the task from the causal inference perspective. This framework obtains rich incidental supervision from temporality and balances covariates from multiple timestamps to remove confounding effects. Our extensive experiments show that <MASKED_ACRONYM> can detect commonsense causality more accurately than baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2023,"Venue":"acl-2023","Acronym":"SQuARe","Description":"A Large-Scale Dataset of Sensitive Questions and Acceptable Responses Created through Human-Machine Collaboration","Abstract":"The potential social harms that large language models pose, such as generating offensive content and reinforcing biases, are steeply rising. Existing works focus on coping with this concern while interacting with ill-intentioned users, such as those who explicitly make hate speech or elicit harmful responses. However, discussions on sensitive issues can become toxic even if the users are well-intentioned. For safer models in such scenarios, we present the Sensitive Questions and Acceptable Response (<MASKED_ACRONYM>) dataset, a large-scale Korean dataset of 49k sensitive questions with 42k acceptable and 46k non-acceptable responses. The dataset was constructed leveraging HyperCLOVA in a human-in-the-loop manner based on real news headlines. Experiments show that acceptable response generation significantly improves for HyperCLOVA and GPT-3, demonstrating the efficacy of this dataset.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"FLamE","Description":"Few-shot Learning from Natural Language Explanations","Abstract":"Natural language explanations have the potential to provide rich information that in principle guides model reasoning. Yet, recent work by Lampinen et al. has shown limited utility of natural language explanations in improving classification. To effectively learn from explanations, we present <MASKED_ACRONYM>, a two-stage few-shot learning framework that first generates explanations using GPT-3, and then fine-tunes a smaller model (e.g., RoBERTa) with generated explanations. Our experiments on natural language inference demonstrate effectiveness over strong baselines, increasing accuracy by 17.6% over GPT-3 Babbage and 5.7% over GPT-3 Davinci in e-SNLI.Despite improving classification performance, human evaluation surprisingly reveals that the majority of generated explanations does not adequately justify classification decisions. Additional analyses point to the important role of label-specific cues (e.g., \u201cnot know\u201d for the neutral label) in generated explanations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"DIP","Description":"Dead code Insertion based Black-box Attack for Programming Language Model","Abstract":"Automatic processing of source code, such as code clone detection and software vulnerability detection, is very helpful to software engineers. Large pre-trained Programming Language (PL) models (such as CodeBERT, GraphCodeBERT, CodeT5, etc.), show very powerful performance on these tasks. However, these PL models are vulnerable to adversarial examples that are generated with slight perturbation. Unlike natural language, an adversarial example of code must be semantic-preserving and compilable. Due to the requirements, it is hard to directly apply the existing attack methods for natural language models. In this paper, we propose <MASKED_ACRONYM> (Dead code Insertion based Black-box Attack for Programming Language Model), a high-performance and effective black-box attack method to generate adversarial examples using dead code insertion. We evaluate our proposed method on 9 victim downstream-task large code models. Our method outperforms the state-of-the-art black-box attack in both attack efficiency and attack quality, while generated adversarial examples are compiled preserving semantic functionality.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CONE","Description":"An Efficient COarse-to-fiNE Alignment Framework for Long Video Temporal Grounding","Abstract":"This paper tackles an emerging and challenging problem of long video temporal grounding (VTG) that localizes video moments related to a natural language (NL) query. Compared with short videos, long videos are also highly demanded but less explored, which brings new challenges in higher inference computation cost and weaker multi-modal alignment. To address these challenges, we propose <MASKED_ACRONYM>, an efficient COarse-to-fiNE alignment framework. <MASKED_ACRONYM> is a plug-and-play framework on top of existing VTG models to handle long videos through a sliding window mechanism. Specifically, <MASKED_ACRONYM> (1) introduces a query-guided window selection strategy to speed up inference, and (2) proposes a coarse-to-fine mechanism via a novel incorporation of contrastive learning to enhance multi-modal alignment for long videos. Extensive experiments on two large-scale long VTG benchmarks consistently show both substantial performance gains (e.g., from 3.13 to 6.87% on MAD) and state-of-the-art results. Analyses also reveal higher efficiency as the query-guided window selection mechanism accelerates inference time by 2x on Ego4D-NLQ and 15x on MAD while keeping SOTA results. Codes have been released at <a href=https:\/\/github.com\/houzhijian\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/houzhijian\/<MASKED_ACRONYM><\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"ORGAN","Description":"Observation-Guided Radiology Report Generation via Tree Reasoning","Abstract":"This paper explores the task of radiology report generation, which aims at generating free-text descriptions for a set of radiographs. One significant challenge of this task is how to correctly maintain the consistency between the images and the lengthy report. Previous research explored solving this issue through planning-based methods, which generate reports only based on high-level plans. However, these plans usually only contain the major observations from the radiographs (e.g., lung opacity), lacking much necessary information, such as the observation characteristics and preliminary clinical diagnoses. To address this problem, the system should also take the image information into account together with the textual plan and perform stronger reasoning during the generation process. In this paper, we propose an Observation-guided radiology Report Generation framework (ORGan). It first produces an observation plan and then feeds both the plan and radiographs for report generation, where an observation graph and a tree reasoning mechanism are adopted to precisely enrich the plan information by capturing the multi-formats of each observation. Experimental results demonstrate that our framework outperforms previous state-of-the-art methods regarding text quality and clinical efficacy.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CASE","Description":"Aligning Coarse-to-Fine Cognition and Affection for Empathetic Response Generation","Abstract":"Empathetic conversation is psychologically supposed to be the result of conscious alignment and interaction between the cognition and affection of empathy. However, existing empathetic dialogue models usually consider only the affective aspect or treat cognition and affection in isolation, which limits the capability of empathetic response generation. In this work, we propose the <MASKED_ACRONYM> model for empathetic dialogue generation. It first builds upon a commonsense cognition graph and an emotional concept graph and then aligns the user\u2019s cognition and affection at both the coarse-grained and fine-grained levels. Through automatic and manual evaluation, we demonstrate that <MASKED_ACRONYM> outperforms state-of-the-art baselines of empathetic dialogues and can generate more empathetic and informative responses.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"RECAP","Description":"Retrieval-Enhanced Context-Aware Prefix Encoder for Personalized Dialogue Response Generation","Abstract":"Endowing chatbots with a consistent persona is essential to an engaging conversation, yet it remains an unresolved challenge. In this work, we propose a new retrieval-enhanced approach for personalized response generation. Specifically, we design a hierarchical transformer retriever trained on dialogue domain data to perform personalized retrieval and a context-aware prefix encoder that fuses the retrieved information to the decoder more effectively. Extensive experiments on a real-world dataset demonstrate the effectiveness of our model at generating more fluent and personalized responses. We quantitatively evaluate our model\u2019s performance under a suite of human and automatic metrics and find it to be superior compared to state-of-the-art baselines on English Reddit conversations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"BLIND","Description":"Bias Removal With No Demographics","Abstract":"Models trained on real-world data tend to imitate and amplify social biases. Common methods to mitigate biases require prior information on the types of biases that should be mitigated (e.g., gender or racial bias) and the social groups associated with each data sample. In this work, we introduce <MASKED_ACRONYM>, a method for bias removal with no prior knowledge of the demographics in the dataset. While training a model on a downstream task, <MASKED_ACRONYM> detects biased samples using an auxiliary model that predicts the main model\u2019s success, and down-weights those samples during the training process. Experiments with racial and gender biases in sentiment classification and occupation classification tasks demonstrate that <MASKED_ACRONYM> mitigates social biases without relying on a costly demographic annotation process. Our method is competitive with other methods that require demographic information and sometimes even surpasses them.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"SWiPE","Description":"A Dataset for Document-Level Simplification of Wikipedia Pages","Abstract":"Text simplification research has mostly focused on sentence-level simplification, even though many desirable edits - such as adding relevant background information or reordering content - may require document-level context. Prior work has also predominantly framed simplification as a single-step, input-to-output task, only implicitly modeling the fine-grained, span-level edits that elucidate the simplification process. To address both gaps, we introduce the <MASKED_ACRONYM> dataset, which reconstructs the document-level editing process from English Wikipedia (EW) articles to paired Simple Wikipedia (SEW) articles. In contrast to prior work, <MASKED_ACRONYM> leverages the entire revision history when pairing pages in order to better identify simplification edits. We work with Wikipedia editors to annotate 5,000 EW-SEW document pairs, labeling more than 40,000 edits with proposed 19 categories. To scale our efforts, we propose several models to automatically label edits, achieving an F-1 score of up to 70.9, indicating that this is a tractable but challenging NLU task. Finally, we categorize the edits produced by several simplification models and find that <MASKED_ACRONYM>-trained models generate more complex edits while reducing unwanted edits.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CHEER","Description":"Centrality-aware High-order Event Reasoning Network for Document-level Event Causality Identification","Abstract":"Document-level Event Causality Identification (DECI) aims to recognize causal relations between events within a document. Recent studies focus on building a document-level graph for cross-sentence reasoning, but ignore important causal structures \u2014 there are one or two \u201ccentral\u201d events that prevail throughout the document, with most other events serving as either their cause or consequence. In this paper, we manually annotate central events for a systematical investigation and propose a novel DECI model, <MASKED_ACRONYM>, which performs high-order reasoning while considering event centrality. First, we summarize a general GNN-based DECI model and provide a unified view for better understanding. Second, we design an Event Interaction Graph (EIG) involving the interactions among events (e.g., coreference) and event pairs, e.g., causal transitivity, cause(A, B) AND cause(B, C) \u2192 cause(A, C). Finally, we incorporate event centrality information into the EIG reasoning network via well-designed features and multi-task learning. We have conducted extensive experiments on two benchmark datasets. The results present great improvements (5.9% F1 gains on average) and demonstrate the effectiveness of each main component.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"TART","Description":"Improved Few-shot Text Classification Using Task-Adaptive Reference Transformation","Abstract":"Meta-learning has emerged as a trending technique to tackle few-shot text classification and achieve state-of-the-art performance. However, the performance of existing approaches heavily depends on the inter-class variance of the support set. As a result, it can perform well on tasks when the semantics of sampled classes are distinct while failing to differentiate classes with similar semantics. In this paper, we propose a novel Task-Adaptive Reference Transformation (<MASKED_ACRONYM>) network, aiming to enhance the generalization by transforming the class prototypes to per-class fixed reference points in task-adaptive metric spaces. To further maximize divergence between transformed prototypes in task-adaptive metric spaces, <MASKED_ACRONYM> introduces a discriminative reference regularization among transformed prototypes. Extensive experiments are conducted on four benchmark datasets and our method demonstrates clear superiority over the state-of-the-art models in all the datasets. In particular, our model surpasses the state-of-the-art method by 7.4% and 5.4% in 1-shot and 5-shot classification on the 20 Newsgroups dataset, respectively.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2023,"Venue":"acl-2023","Acronym":"HINT","Description":"Hypernetwork Instruction Tuning for Efficient Zero- and Few-Shot Generalisation","Abstract":"Recent NLP models have shown the remarkable ability to effectively generalise \u2018zero-shot\u2019 to new tasks using only natural language instructions as guidance. However, many of these approaches suffer from high computational costs due to their reliance on concatenating lengthy instructions with every input example, resulting in costly reprocessing of the instruction. To avoid this, we introduce Hypernetworks for INstruction Tuning (<MASKED_ACRONYM>), which convert task instructions and examples into parameter-efficient modules inserted into an underlying model using a pretrained text encoder, eliminating the need to include instructions in the model input. The hypernetwork in <MASKED_ACRONYM> also produces an encoded instruction, which we concatenate with encoded inputs during decoding to further improve performance. <MASKED_ACRONYM> models outperform strong state-of-the-art baselines by over 10% when controlling for compute (measured in FLOPs). By converting instructions into modules, <MASKED_ACRONYM> models can effectively disregard the length of instructions and few-shot example inputs in terms of compute usage. As a result, <MASKED_ACRONYM> can enhance its performance by up to 25% by incorporating additional few-shot data, while utilizing only up to 5% more compute. This combines the strengths of parameter-efficient fine-tuning and in-context learning.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"GIFT","Description":"Graph-Induced Fine-Tuning for Multi-Party Conversation Understanding","Abstract":"Addressing the issues of who saying what to whom in multi-party conversations (MPCs) has recently attracted a lot of research attention. However, existing methods on MPC understanding typically embed interlocutors and utterances into sequential information flows, or utilize only the superficial of inherent graph structures in MPCs. To this end, we present a plug-and-play and lightweight method named graph-induced fine-tuning (<MASKED_ACRONYM>) which can adapt various Transformer-based pre-trained language models (PLMs) for universal MPC understanding. In detail, the full and equivalent connections among utterances in regular Transformer ignore the sparse but distinctive dependency of an utterance on another in MPCs. To distinguish different relationships between utterances, four types of edges are designed to integrate graph-induced signals into attention mechanisms to refine PLMs originally designed for processing sequential texts. We evaluate <MASKED_ACRONYM> by implementing it into three PLMs, and test the performance on three downstream tasks including addressee recognition, speaker identification and response selection. Experimental results show that <MASKED_ACRONYM> can significantly improve the performance of three PLMs on three downstream tasks and two benchmarks with only 4 additional parameters per encoding layer, achieving new state-of-the-art performance on MPC understanding.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"PromptNER","Description":"Prompt Locating and Typing for Named Entity Recognition","Abstract":"Prompt learning is a new paradigm for utilizing pre-trained language models and has achieved great success in many tasks. To adopt prompt learning in the NER task, two kinds of methods have been explored from a pair of symmetric perspectives, populating the template by enumerating spans to predict their entity types or constructing type-specific prompts to locate entities. However, these methods not only require a multi-round prompting manner with a high time overhead and computational cost, but also require elaborate prompt templates, that are difficult to apply in practical scenarios. In this paper, we unify entity locating and entity typing into prompt learning, and design a dual-slot multi-prompt template with the position slot and type slot to prompt locating and typing respectively. Multiple prompts can be input to the model simultaneously, and then the model extracts all entities by parallel predictions on the slots. To assign labels for the slots during training, we design a dynamic template filling mechanism that uses the extended bipartite graph matching between prompts and the ground-truth entities. We conduct experiments in various settings, including resource-rich flat and nested NER datasets and low-resource in-domain and cross-domain datasets. Experimental results show that the proposed model achieves a significant performance improvement, especially in the cross-domain few-shot setting, which outperforms the state-of-the-art model by +7.7% on average.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2023,"Venue":"acl-2023","Acronym":"ETHICIST","Description":"Targeted Training Data Extraction Through Loss Smoothed Soft Prompting and Calibrated Confidence Estimation","Abstract":"Large pre-trained language models achieve impressive results across many tasks. However, recent works point out that pre-trained language models may memorize a considerable fraction of their training data, leading to the privacy risk of information leakage. In this paper, we propose a method named Ethicist for targeted training data extraction through loss smoothed soft prompting and calibrated confidence estimation, investigating how to recover the suffix in the training data when given a prefix. To elicit memorization in the attacked model, we tune soft prompt embeddings while keeping the model fixed. We further propose a smoothing loss that smooths the loss distribution of the suffix tokens to make it easier to sample the correct suffix. In order to select the most probable suffix from a collection of sampled suffixes and estimate the prediction confidence, we propose a calibrated confidence estimation method, which normalizes the confidence of the generated suffixes with a local estimation. We show that Ethicist significantly improves the extraction performance on a recently proposed public benchmark. We also investigate several factors influencing the data extraction performance, including decoding strategy, model scale, prefix length, and suffix length. Our code is availabel at <a href=https:\/\/github.com\/thu-coai\/Targeted-Data-Extraction class=acl-markup-url>https:\/\/github.com\/thu-coai\/Targeted-Data-Extraction<\/a>.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2023,"Venue":"acl-2023","Acronym":"BUMP","Description":"A Benchmark of Unfaithful Minimal Pairs for Meta-Evaluation of Faithfulness Metrics","Abstract":"The proliferation of automatic faithfulness metrics for summarization has produced a need for benchmarks to evaluate them. While existing benchmarks measure the correlation with human judgements of faithfulness on model-generated summaries, they are insufficient for diagnosing whether metrics are: 1) consistent, i.e., indicate lower faithfulness as errors are introduced into a summary, 2) effective on human-written texts, and 3) sensitive to different error types (as summaries can contain multiple errors). To address these needs, we present a benchmark of unfaithful minimal pairs (<MASKED_ACRONYM>), a dataset of 889 human-written, minimally different summary pairs, where a single error is introduced to a summary from the CNN\/DailyMail dataset to produce an unfaithful summary. We find <MASKED_ACRONYM> complements existing benchmarks in a number of ways: 1) the summaries in <MASKED_ACRONYM> are harder to discriminate and less probable under SOTA summarization models, 2) unlike non-pair-based datasets, <MASKED_ACRONYM> can be used to measure the consistency of metrics, and reveals that the most discriminative metrics tend not to be the most consistent, and 3) unlike datasets containing generated summaries with multiple errors, <MASKED_ACRONYM> enables the measurement of metrics\u2019 performance on individual error types.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"RADE","Description":"Reference-Assisted Dialogue Evaluation for Open-Domain Dialogue","Abstract":"Evaluating open-domain dialogue systems is challenging for reasons such as the one-to-many problem, i.e., many appropriate responses other than just the golden response. As of now, automatic evaluation methods need better consistency with humans, while reliable human evaluation can be time- and cost-intensive. To this end, we propose the Reference-Assisted Dialogue Evaluation (<MASKED_ACRONYM>) approach under the multi-task learning framework, which leverages the pre-created utterance as reference other than the gold response to relief the one-to-many problem. Specifically, <MASKED_ACRONYM> explicitly compares reference and the candidate response to predict their overall scores. Moreover, an auxiliary response generation task enhances prediction via a shared encoder. To support <MASKED_ACRONYM>, we extend three datasets with additional rated responses other than just a golden response by human annotation. Experiments on our three datasets and two existing benchmarks demonstrate the effectiveness of our method, where Pearson, Spearman, and Kendall correlations with human evaluation outperform state-of-the-art baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2023,"Venue":"acl-2023","Acronym":"BITE","Description":"Textual Backdoor Attacks with Iterative Trigger Injection","Abstract":"Backdoor attacks have become an emerging threat to NLP systems. By providing poisoned training data, the adversary can embed a \u201cbackdoor\u201d into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary\u2019s choice. In this paper, we demonstrate that it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate). We propose <MASKED_ACRONYM>, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of \u201ctrigger words\u201d. These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations. The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor. Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data. We further propose a defense method named De<MASKED_ACRONYM> based on potential trigger word removal, which outperforms existing methods in defending against <MASKED_ACRONYM> and generalizes well to handling other backdoor attacks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CAT","Description":"A Contextualized Conceptualization and Instantiation Framework for Commonsense Reasoning","Abstract":"Commonsense reasoning, aiming at endowing machines with a human-like ability to make situational presumptions, is extremely challenging to generalize. For someone who barely knows about \u201cmeditation,\u201d while is knowledgeable about \u201csinging,\u201d he can still infer that \u201cmeditation makes people relaxed\u201d from the existing knowledge that \u201csinging makes people relaxed\u201d by first conceptualizing \u201csinging\u201d as a \u201crelaxing event\u201d and then instantiating that event to \u201cmeditation.\u201dThis process, known as conceptual induction and deduction, is fundamental to commonsense reasoning while lacking both labeled data and methodologies to enhance commonsense modeling. To fill such a research gap, we propose <MASKED_ACRONYM> (Contextualized ConceptuAlization and InsTantiation),a semi-supervised learning framework that integrates event conceptualization and instantiation to conceptualize commonsense knowledge bases at scale. Extensive experiments show that our framework achieves state-of-the-art performances on two conceptualization tasks, and the acquired abstract commonsense knowledge can significantly improve commonsense inference modeling. Our code, data, and fine-tuned models are publicly available at [<a href=https:\/\/github.com\/HKUST-KnowComp\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/HKUST-KnowComp\/<MASKED_ACRONYM><\/a>](<a href=https:\/\/github.com\/HKUST-KnowComp\/<MASKED_ACRONYM> class=acl-markup-url>https:\/\/github.com\/HKUST-KnowComp\/<MASKED_ACRONYM><\/a>).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"UniCoRN","Description":"Unified Cognitive Signal ReconstructioN bridging cognitive signals and human language","Abstract":"Decoding text stimuli from cognitive signals (e.g. fMRI) enhances our understanding of the human language system, paving the way for building versatile Brain-Computer Interface. However, existing studies largely focus on decoding individual word-level fMRI volumes from a restricted vocabulary, which is far too idealized for real-world application. In this paper, we propose fMRI2text, the first open-vocabulary task aiming to bridge fMRI time series and human language. Furthermore, to explore the potential of this new task, we present a baseline solution, <MASKED_ACRONYM>: the Unified Cognitive Signal ReconstructioN for Brain Decoding. By reconstructing both individual time points and time series, <MASKED_ACRONYM> establishes a robust encoder for cognitive signals (fMRI & EEG). Leveraging a pre-trained language model as decoder, <MASKED_ACRONYM> proves its efficacy in decoding coherent text from fMRI series across various split settings. Our model achieves a 34.77% BLEU score on fMRI2text, and a 37.04% BLEU when generalized to EEG-to-text decoding, thereby surpassing the former baseline. Experimental results indicate the feasibility of decoding consecutive fMRI volumes, and the effectiveness of decoding different cognitive signals using a unified structure.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"PaCE","Description":"Unified Multi-modal Dialogue Pre-training with Progressive and Compositional Experts","Abstract":"Perceiving multi-modal information and fulfilling dialogues with humans is a long-term goal of artificial intelligence. Pre-training is commonly regarded as an effective approach for multi-modal dialogue. However, due to the limited availability of multi-modal dialogue data, there is still scarce research on multi-modal dialogue pre-training. Yet another intriguing challenge emerges from the encompassing nature of multi-modal dialogue, which involves various modalities and tasks. Moreover, new forms of tasks may arise at unpredictable points in the future. Hence, it is essential for designed multi-modal dialogue models to possess sufficient flexibility to adapt to such scenarios. This paper proposes <MASKED_ACRONYM>, a unified, structured, compositional multi-modal dialogue pre-training framework. It utilizes a combination of several fundamental experts to accommodate multiple dialogue-related tasks and can be pre-trained using limited dialogue and extensive non-dialogue multi-modal data. Furthermore, we propose a progressive training method where old experts from the past can assist new experts, facilitating the expansion of their capabilities. Experimental results demonstrate that <MASKED_ACRONYM> achieves state-of-the-art results on eight multi-modal dialog benchmarks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"EPIC","Description":"Multi-Perspective Annotation of a Corpus of Irony","Abstract":"We present <MASKED_ACRONYM> (English Perspectivist Irony Corpus), the first annotated corpus for irony analysis based on the principles of data perspectivism. The corpus contains short conversations from social media in five regional varieties of English, and it is annotated by contributors from five countries corresponding to those varieties. We analyse the resource along the perspectives induced by the diversity of the annotators, in terms of origin, age, and gender, and the relationship between these dimensions, irony, and the topics of conversation. We validate <MASKED_ACRONYM> by creating perspective-aware models that encode the perspectives of annotators grouped according to their demographic characteristics. Firstly, the performance of perspectivist models confirms that different annotators induce very different models. Secondly, in the classification of ironic and non-ironic texts, perspectivist models prove to be generally more confident than the non-perspectivist ones. Furthermore, comparing the performance on a perspective-based test set with those achieved on a gold standard test set, we can observe how perspectivist models tend to detect more precisely the positive class, showing their ability to capture the different perceptions of irony. Thanks to these models, we are moreover able to show interesting insights about the variation in the perception of irony by the different groups of annotators, such as among different generations and nationalities.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"QUEST","Description":"A Retrieval Dataset of Entity-Seeking Queries with Implicit Set Operations","Abstract":"Formulating selective information needs results in queries that implicitly specify set operations, such as intersection, union, and difference. For instance, one might search for \u201cshorebirds that are not sandpipers\u201d or \u201cscience-fiction films shot in England\u201d. To study the ability of retrieval systems to meet such information needs, we construct <MASKED_ACRONYM>, a dataset of 3357 natural language queries with implicit set operations, that map to a set of entities corresponding to Wikipedia documents. The dataset challenges models to match multiple constraints mentioned in queries with corresponding evidence in documents and correctly perform various set operations. The dataset is constructed semi-automatically using Wikipedia category names. Queries are automatically composed from individual categories, then paraphrased and further validated for naturalness and fluency by crowdworkers. Crowdworkers also assess the relevance of entities based on their documents and highlight attribution of query constraints to spans of document text. We analyze several modern retrieval systems, finding that they often struggle on such queries. Queries involving negation and conjunction are particularly challenging and systems are further challenged with combinations of these operations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"NOTABLE","Description":"Transferable Backdoor Attacks Against Prompt-based NLP Models","Abstract":"Prompt-based learning is vulnerable to backdoor attacks. Existing backdoor attacks against prompt-based models consider injecting backdoors into the entire embedding layers or word embedding vectors. Such attacks can be easily affected by retraining on downstream tasks and with different prompting strategies, limiting the transferability of backdoor attacks. In this work, we propose transferable backdoor attacks against prompt-based models, called <MASKED_ACRONYM>, which is independent of downstream tasks and prompting strategies. Specifically, <MASKED_ACRONYM> injects backdoors into the encoders of PLMs by utilizing an adaptive verbalizer to bind triggers to specific words (i.e., anchors). It activates the backdoor by pasting input with triggers to reach adversary-desired anchors, achieving independence from downstream tasks and prompting strategies. We conduct experiments on six NLP tasks, three popular models, and three prompting strategies. Empirical results show that <MASKED_ACRONYM> achieves superior attack performance (i.e., attack success rate over 90% on all the datasets), and outperforms two state-of-the-art baselines. Evaluations on three defenses show the robustness of <MASKED_ACRONYM>. Our code can be found at <a href=https:\/\/github.com\/RU-System-Software-and-Security\/Notable class=acl-markup-url>https:\/\/github.com\/RU-System-Software-and-Security\/Notable<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"DICE","Description":"Data-Efficient Clinical Event Extraction with Generative Models","Abstract":"Event extraction for the clinical domain is an under-explored research area. The lack of training data along with the high volume of domain-specific terminologies with vague entity boundaries makes the task especially challenging. In this paper, we introduce <MASKED_ACRONYM>, a robust and data-efficient generative model for clinical event extraction. <MASKED_ACRONYM> frames event extraction as a conditional generation problem and introduces a contrastive learning objective to accurately decide the boundaries of biomedical mentions. <MASKED_ACRONYM> also trains an auxiliary mention identification task jointly with event extraction tasks to better identify entity mention boundaries, and further introduces special markers to incorporate identified entity mentions as trigger and argument candidates for their respective tasks. To benchmark clinical event extraction, we compose MACCROBAT-EE, the first clinical event extraction dataset with argument annotation, based on an existing clinical information extraction dataset MACCROBAT. Our experiments demonstrate state-of-the-art performances of <MASKED_ACRONYM> for clinical and news domain event extraction, especially under low data settings.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"LENS","Description":"A Learnable Evaluation Metric for Text Simplification","Abstract":"Training learnable metrics using modern language models has recently emerged as a promising method for the automatic evaluation of machine translation. However, existing human evaluation datasets for text simplification have limited annotations that are based on unitary or outdated models, making them unsuitable for this approach. To address these issues, we introduce the SimpEval corpus that contains: SimpEval_past, comprising 12K human ratings on 2.4K simplifications of 24 past systems, and SimpEval_2022, a challenging simplification benchmark consisting of over 1K human ratings of 360 simplifications including GPT-3.5 generated text. Training on SimpEval, we present <MASKED_ACRONYM>, a Learnable Evaluation Metric for Text Simplification. Extensive empirical results show that <MASKED_ACRONYM> correlates much better with human judgment than existing metrics, paving the way for future progress in the evaluation of text simplification. We also introduce Rank & Rate, a human evaluation framework that rates simplifications from several models in a list-wise manner using an interactive interface, which ensures both consistency and accuracy in the evaluation process and is used to create the SimpEval datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"BOLT","Description":"Fast Energy-based Controlled Text Generation with Tunable Biases","Abstract":"Energy-based models (EBMs) have gained popularity for controlled text generation due to their high applicability to a wide range of constraints. However, sampling from EBMs is non-trivial, as it often requires a large number of iterations to converge to plausible text, which slows down the decoding process and makes it less practical for real-world applications. In this work, we propose <MASKED_ACRONYM>, which relies on tunable biases to directly adjust the language model\u2019s output logits. Unlike prior work, <MASKED_ACRONYM> maintains the generator\u2019s autoregressive nature to assert a strong control on token-wise conditional dependencies and overall fluency, and thus converges faster. When compared with state-of-the-arts on controlled generation tasks using both soft constraints (e.g., sentiment control) and hard constraints (e.g., keyword-guided topic control), <MASKED_ACRONYM> demonstrates significantly improved efficiency and fluency. On sentiment control, <MASKED_ACRONYM> is 7x faster than competitive baselines, and more fluent in 74.4% of the evaluation samples according to human judges.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"RAMP","Description":"Retrieval and Attribute-Marking Enhanced Prompting for Attribute-Controlled Translation","Abstract":"Attribute-controlled translation (ACT) is a subtask of machine translation that involves controlling stylistic or linguistic attributes (like formality and gender) of translation outputs. While ACT has garnered attention in recent years due to its usefulness in real-world applications, progress in the task is currently limited by dataset availability, since most prior approaches rely on supervised methods. To address this limitation, we propose Retrieval and Attribute-Marking enhanced Prompting (<MASKED_ACRONYM>), which leverages large multilingual language models to perform ACT in few-shot and zero-shot settings. <MASKED_ACRONYM> improves generation accuracy over the standard prompting approach by (1) incorporating a semantic similarity retrieval component for selecting similar in-context examples, and (2) marking in-context examples with attribute annotations. Our comprehensive experiments show that <MASKED_ACRONYM> is a viable approach in both zero-shot and few-shot settings.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"CARE","Description":"Collaborative AI-Assisted Reading Environment","Abstract":"Recent years have seen impressive progress in AI-assisted writing, yet the developments in AI-assisted reading are lacking. We propose inline commentary as a natural vehicle for AI-based reading assistance, and present <MASKED_ACRONYM>: the first open integrated platform for the study of inline commentary and reading. <MASKED_ACRONYM> facilitates data collection for inline commentaries in a commonplace collaborative reading environment, and provides a framework for enhancing reading with NLP-based assistance, such as text classification, generation or question answering. The extensible behavioral logging allows unique insights into the reading and commenting behavior, and flexible configuration makes the platform easy to deploy in new scenarios. To evaluate <MASKED_ACRONYM> in action, we apply the platform in a user study dedicated to scholarly peer review. <MASKED_ACRONYM> facilitates the data collection and study of inline commentary in NLP, extrinsic evaluation of NLP assistance, and application prototyping. We invite the community to explore and build upon the open source implementation of <MASKED_ACRONYM>.Github Repository: <a href=https:\/\/github.com\/UKPLab\/<MASKED_ACRONYM>Public class=acl-markup-url>https:\/\/github.com\/UKPLab\/<MASKED_ACRONYM>Public<\/a> Live Demo: <a href=https:\/\/care.ukp.informatik.tu-darmstadt.de class=acl-markup-url>https:\/\/care.ukp.informatik.tu-darmstadt.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"SaFER","Description":"A Robust and Efficient Framework for Fine-tuning BERT-based Classifier with Noisy Labels","Abstract":"Learning on noisy datasets is a challenging problem when pre-trained language models are applied to real-world text classification tasks. In numerous industrial applications, acquiring task-specific datasets with 100% accurate labels is difficult, thus many datasets are accompanied by label noise at different levels. Previous work has shown that existing noise-handling methods could not improve the peak performance of BERT on noisy datasets, and might even deteriorate it. In this paper, we propose <MASKED_ACRONYM>, a robust and efficient fine-tuning framework for BERT-based text classifiers, combating label noises without access to any clean data for training or validation. Utilizing a label-agnostic early-stopping strategy and self-supervised learning, our proposed framework achieves superior performance in terms of both accuracy and speed on multiple text classification benchmarks. The trained model is finally fully deployed in several industrial biomedical literature mining tasks and demonstrates high effectiveness and efficiency.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"acl-2023","Acronym":"BADGE","Description":"Speeding Up BERT Inference after Deployment via Block-wise Bypasses and Divergence-based Early Exiting","Abstract":"Early exiting can reduce the average latency of pre-trained language models (PLMs) via its adaptive inference mechanism and work with other inference speed-up methods like model pruning, thus drawing much attention from the industry. In this work, we propose a novel framework, <MASKED_ACRONYM>, which consists of two off-the-shelf methods for improving PLMs\u2019 early exiting. We first address the issues of training a multi-exit PLM, the backbone model for early exiting. We propose the novel architecture of block-wise bypasses, which can alleviate the conflicts in jointly training multiple intermediate classifiers and thus improve the overall performances of multi-exit PLM while introducing negligible additional flops to the model. Second, we propose a novel divergence-based early exiting (DGE) mechanism, which obtains early exiting signals by comparing the predicted distributions of two adjacent layers\u2019 exits. Extensive experiments on three proprietary datasets and three GLUE benchmark tasks demonstrate that our method can obtain a better speedup-performance trade-off than the existing baseline methods.\\footnote{Code will be made publicly available to the research community upon acceptance.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2009,"Venue":"ws-2009","Acronym":"GREAT","Description":"A Finite-State Machine Translation Toolkit Implementing a Grammatical Inference Approach for Transducer Inference (GIATI)","Abstract":"<MASKED_ACRONYM> is a \ufb01nite-state toolkit which is devoted to Machine Translation and that learns structured models from bilingual data. The training procedure is based on grammatical inference techniques to obtain stochastic transducers that model both the structure of the languages and the relationship between them. The inference of grammars from natural language causes the models to become larger when a less restrictive task is involved; even more if a bilingual modelling is being considered. <MASKED_ACRONYM> has been successful to implement the GIATI learning methodology, using different scalability issues to be able to deal with corpora of high volume of data. This is reported with experiments on the EuroParl corpus, which is a state-of-theart task in Statistical Machine Translation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2009,"Venue":"ws-2009","Acronym":"UDel","Description":"Generating Referring Expressions Guided by Psycholinguistc Findings","Abstract":"We present an approach to generating referring expressions in context utilizing feature selection informed by psycholinguistic research. Features suggested by studies on pronoun interpretation were used to train a classi\ufb01er system which determined the most appropriate selection from a list of possible references. This application demonstrates one way to help bridge the gap between computational and empirical means of reference generation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8571428571}
{"Year":2009,"Venue":"ws-2009","Acronym":"GenERRate","Description":"Generating Errors for Use in Grammatical Error Detection","Abstract":"This paper explores the issue of automatically generated ungrammatical data and its use in error detection, with a focus on the task of classifying a sentence as grammatical or ungrammatical. We present an error generation tool called <MASKED_ACRONYM> and show how <MASKED_ACRONYM> can be used to improve the performance of a classi\ufb01er on learner data. We describe initial attempts to replicate Cambridge Learner Corpus errors using <MASKED_ACRONYM>.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.9411764706}
{"Year":2021,"Venue":"eacl-2021","Acronym":"DRAG","Description":"Director-Generator Language Modelling Framework for Non-Parallel Author Stylized Rewriting","Abstract":"Author stylized rewriting is the task of rewriting an input text in a particular author\u2019s style. Recent works in this area have leveraged Transformer-based language models in a denoising autoencoder setup to generate author stylized text without relying on a parallel corpus of data. However, these approaches are limited by the lack of explicit control of target attributes and being entirely data-driven. In this paper, we propose a Director-Generator framework to rewrite content in the target author\u2019s style, specifically focusing on certain target attributes. We show that our proposed framework works well even with a limited-sized target author corpus. Our experiments on corpora consisting of relatively small-sized text authored by three distinct authors show significant improvements upon existing works to rewrite input texts in target author\u2019s style. Our quantitative and qualitative analyses further show that our model has better meaning retention and results in more fluent generations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"eacl-2021","Acronym":"FAST","Description":"Financial News and Tweet Based Time Aware Network for Stock Trading","Abstract":"Designing profitable trading strategies is complex as stock movements are highly stochastic; the market is influenced by large volumes of noisy data across diverse information sources like news and social media. Prior work mostly treats stock movement prediction as a regression or classification task and is not directly optimized towards profit-making. Further, they do not model the fine-grain temporal irregularities in the release of vast volumes of text that the market responds to quickly. Building on these limitations, we propose a novel hierarchical, learning to rank approach that uses textual data to make time-aware predictions for ranking stocks based on expected profit. Our approach outperforms state-of-the-art methods by over 8% in terms of cumulative profit and risk-adjusted returns in trading simulations on two benchmarks: English tweets and Chinese financial news spanning two major stock indexes and four global markets. Through ablative and qualitative analyses, we build the case for our method as a tool for daily stock trading.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"eacl-2021","Acronym":"PHASE","Description":"Learning Emotional Phase-aware Representations for Suicide Ideation Detection on Social Media","Abstract":"Recent psychological studies indicate that individuals exhibiting suicidal ideation increasingly turn to social media rather than mental health practitioners. Contextualizing the build-up of such ideation is critical for the identification of users at risk. In this work, we focus on identifying suicidal intent in tweets by augmenting linguistic models with emotional phases modeled from users\u2019 historical context. We propose <MASKED_ACRONYM>, a time-and phase-aware framework that adaptively learns features from a user\u2019s historical emotional spectrum on Twitter for preliminary screening of suicidal risk. Building on clinical studies, <MASKED_ACRONYM> learns phase-like progressions in users\u2019 historical Plutchik-wheel-based emotions to contextualize suicidal intent. While outperforming state-of-the-art methods, we show the utility of temporal and phase-based emotional contextual cues for suicide ideation detection. We further discuss practical and ethical considerations.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"eacl-2021","Acronym":"ADePT","Description":"Auto-encoder based Differentially Private Text Transformation","Abstract":"Privacy is an important concern when building statistical models on data containing personal information. Differential privacy offers a strong definition of privacy and can be used to solve several privacy concerns. Multiple solutions have been proposed for the differentially-private transformation of datasets containing sensitive information. However, such transformation algorithms offer poor utility in Natural Language Processing (NLP) tasks due to noise added in the process. This paper addresses this issue by providing a utility-preserving differentially private text transformation algorithm using auto-encoders. Our algorithm transforms text to offer robustness against attacks and produces transformations with high semantic quality that perform well on downstream NLP tasks. We prove our algorithm\u2019s theoretical privacy guarantee and assess its privacy leakage under Membership Inference Attacks (MIA) on models trained with transformed data. Our results show that the proposed model performs better against MIA attacks while offering lower to no degradation in the utility of the underlying transformation process compared to existing baselines.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"eacl-2021","Acronym":"STAR","Description":"Cross-modal [STA]tement [R]epresentation for selecting relevant mathematical premises","Abstract":"Mathematical statements written in natural language are usually composed of two different modalities: mathematical elements and natural language. These two modalities have several distinct linguistic and semantic properties. State-of-the-art representation techniques have demonstrated an inability in capturing such an entangled style of discourse. In this work, we propose <MASKED_ACRONYM>, a model that uses cross-modal attention to learn how to represent mathematical text for the task of Natural Language Premise Selection. This task uses conjectures written in both natural and mathematical language to recommend premises that most likely will be relevant to prove a particular statement. We found that <MASKED_ACRONYM> not only outperforms baselines that do not distinguish between natural language and mathematical elements, but it also achieves better performance than state-of-the-art models.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2021,"Venue":"eacl-2021","Acronym":"InterpreT","Description":"An Interactive Visualization Tool for Interpreting Transformers","Abstract":"With the increasingly widespread use of Transformer-based models for NLU\/NLP tasks, there is growing interest in understanding the inner workings of these models, why they are so effective at a wide range of tasks, and how they can be further tuned and improved. To contribute towards this goal of enhanced explainability and comprehension, we present <MASKED_ACRONYM>, an interactive visualization tool for interpreting Transformer-based models. In addition to providing various mechanisms for investigating general model behaviours, novel contributions made in <MASKED_ACRONYM> include the ability to track and visualize token embeddings through each layer of a Transformer, highlight distances between certain token embeddings through illustrative plots, and identify task-related functions of attention heads by using new metrics. <MASKED_ACRONYM> is a task agnostic tool, and its functionalities are demonstrated through the analysis of model behaviours for two disparate tasks: Aspect Based Sentiment Analysis (ABSA) and the Winograd Schema Challenge (WSC).","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"semeval-2014","Acronym":"haLF","Description":"Comparing a Pure CDSM Approach with a Standard Machine Learning System for RTE","Abstract":"In this paper, we describe our submission to the Shared Task #1. We tried to follow the underlying idea of the task, that is, evaluating the gap of full-\ufb02edged recognizing textual entailment systems with respect to compositional distributional semantic models (CDSMs) applied to this task. We thus submitted two runs: 1) a system obtained with a machine learning approach based on the feature spaces of rules with variables and 2) a system completely based on a CDSM that mixes structural and syntactic information by using distributed tree kernels. Our analysis shows that, under the same conditions, the fully CDSM system is still far from being competitive with more complex methods.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"semeval-2014","Acronym":"SAIL","Description":"Sentiment Analysis using Semantic Similarity and Contrast Features","Abstract":"This paper describes our submission to SemEval2014 Task 9: Sentiment Analysis in Twitter. Our model is primarily a lexicon based one, augmented by some preprocessing, including detection of MultiWord Expressions, negation propagation and hashtag expansion and by the use of pairwise semantic similarity at the tweet level. Feature extraction is repeated for sub-strings and contrasting sub-string features are used to better capture complex phenomena like sarcasm. The resulting supervised system, using a Naive Bayes model, achieved high performance in classifying entire tweets, ranking 7th on the main set and 2nd when applied to sarcastic tweets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"semeval-2014","Acronym":"SNAP","Description":"A Multi-Stage XML-Pipeline for Aspect Based Sentiment Analysis","Abstract":"This paper describes the <MASKED_ACRONYM> system, which participated in Task 4 of SemEval2014: Aspect Based Sentiment Analysis. We use an XML-based pipeline that combines several independent components to perform each subtask. Key resources used by the system are Bing Liu\u2019s sentiment lexicon, Stanford CoreNLP, RFTagger, several machine learning algorithms and WordNet. <MASKED_ACRONYM> achieved satisfactory results in the evaluation, placing in the top half of the \ufb01eld for most subtasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"emnlp-2018","Acronym":"DeClarE","Description":"Debunking Fake News and False Claims using Evidence-Aware Deep Learning","Abstract":"Misinformation such as fake news is one of the big challenges of our society. Research on automated fact-checking has proposed methods based on supervised learning, but these approaches do not consider external evidence apart from labeled training instances. Recent approaches counter this deficit by considering external sources related to a claim. However, these methods require substantial feature modeling and rich lexicons. This paper overcomes these limitations of prior work with an end-to-end model for evidence-aware credibility assessment of arbitrary textual claims, without any human intervention. It presents a neural network model that judiciously aggregates signals from external evidence articles, the language of these articles and the trustworthiness of their sources. It also derives informative features for generating user-comprehensible explanations that makes the neural network predictions transparent to the end-user. Experiments with four datasets and ablation studies show the strength of our method.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"emnlp-2018","Acronym":"RESIDE","Description":"Improving Distantly-Supervised Neural Relation Extraction using Side Information","Abstract":"Distantly-supervised Relation Extraction (RE) methods train an extractor by automatically aligning relation instances in a Knowledge Base (KB) with unstructured text. In addition to relation instances, KBs often contain other relevant side information, such as aliases of relations (e.g., founded and co-founded are aliases for the relation founderOfCompany). RE models usually ignore such readily available side information. In this paper, we propose <MASKED_ACRONYM>, a distantly-supervised neural relation extraction method which utilizes additional side information from KBs for improved relation extraction. It uses entity type and relation alias information for imposing soft constraints while predicting relations. <MASKED_ACRONYM> employs Graph Convolution Networks (GCN) to encode syntactic information from text and improves performance even when limited side information is available. Through extensive experiments on benchmark datasets, we demonstrate <MASKED_ACRONYM>\u2019s effectiveness. We have made <MASKED_ACRONYM>\u2019s source code available to encourage reproducible research.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"emnlp-2018","Acronym":"ICON","Description":"Interactive Conversational Memory Network for Multimodal Emotion Detection","Abstract":"Emotion recognition in conversations is crucial for building empathetic machines. Present works in this domain do not explicitly consider the inter-personal influences that thrive in the emotional dynamics of dialogues. To this end, we propose Interactive COnversational memory Network (<MASKED_ACRONYM>), a multimodal emotion detection framework that extracts multimodal features from conversational videos and hierarchically models the self- and inter-speaker emotional influences into global memories. Such memories generate contextual summaries which aid in predicting the emotional orientation of utterance-videos. Our model outperforms state-of-the-art networks on multiple classification and regression tasks in two benchmark datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"emnlp-2018","Acronym":"ExtRA","Description":"Extracting Prominent Review Aspects from Customer Feedback","Abstract":"Many existing systems for analyzing and summarizing customer reviews about products or service are based on a number of prominent review aspects. Conventionally, the prominent review aspects of a product type are determined manually. This costly approach cannot scale to large and cross-domain services such as Amazon.com, Taobao.com or Yelp.com where there are a large number of product types and new products emerge almost every day. In this paper, we propose a novel framework, for extracting the most prominent aspects of a given product type from textual reviews. The proposed framework, <MASKED_ACRONYM>, extracts K most prominent aspect terms or phrases which do not overlap semantically automatically without supervision. Extensive experiments show that <MASKED_ACRONYM> is effective and achieves the state-of-the-art performance on a dataset consisting of different product types.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"icon-2022","Acronym":"PAR","Description":"Persona Aware Response in Conversational Systems","Abstract":"To make the Human Computer Interaction more user friendly and persona aligned, detection of user persona is of utmost significance. Towards achieving this objective, we describe a novel approach to select the persona of a user from pre-determine list of personas and utilize it to generate personalized responses. This is achieved in two steps. Firstly, closest matching persona is detected from a set of pre-determined persona for the user. The second step involves the use of a fine-tuned natural language generation (NLG) model to generate persona compliant responses. Through experiments, we demonstrate that the proposed architecture generates better responses than current approaches by using a detected persona. Experimental evaluation on the PersonaChat dataset has demonstrated notable performance in terms of perplexity and F1-score.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"emnlp-2014","Acronym":"GloVe","Description":"Global Vectors for Word Representation","Abstract":"Recent methods for learning vector space representations of words have succeeded in capturing \ufb01ne-grained semantic and syntactic regularities using vector arithmetic, but the origin of these regularities has remained opaque. We analyze and make explicit the model properties needed for such regularities to emerge in word vectors. The result is a new global logbilinear regression model that combines the advantages of the two major model families in the literature: global matrix factorization and local context window methods. Our model ef\ufb01ciently leverages statistical information by training only on the nonzero elements in a word-word cooccurrence matrix, rather than on the entire sparse matrix or on individual context windows in a large corpus. The model produces a vector space with meaningful substructure, as evidenced by its performance of 75% on a recent word analogy task. It also outperforms related models on similarity tasks and named entity recognition.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"lrec-2020","Acronym":"SOLO","Description":"A Corpus of Tweets for Examining the State of Being Alone","Abstract":"The state of being alone can have a substantial impact on our lives, though experiences with time alone diverge significantly among individuals. Psychologists distinguish between the concept of solitude, a positive state of voluntary aloneness, and the concept of loneliness, a negative state of dissatisfaction with the quality of one\u2019s social interactions. Here, for the first time, we conduct a large-scale computational analysis to explore how the terms associated with the state of being alone are used in online language. We present <MASKED_ACRONYM> (State of Being Alone), a corpus of over 4 million tweets collected with query terms solitude, lonely, and loneliness. We use <MASKED_ACRONYM> to analyze the language and emotions associated with the state of being alone. We show that the term solitude tends to co-occur with more positive, high-dominance words (e.g., enjoy, bliss) while the terms lonely and loneliness frequently co-occur with negative, low-dominance words (e.g., scared, depressed), which confirms the conceptual distinctions made in psychology. We also show that women are more likely to report on negative feelings of being lonely as compared to men, and there are more teenagers among the tweeters that use the word lonely than among the tweeters that use the word solitude.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"lrec-2020","Acronym":"TRANSLIT","Description":"A Large-scale Name Transliteration Resource","Abstract":"Transliteration is the process of expressing a proper name from a source language in the characters of a target language (e.g. from Cyrillic to Latin characters). We present <MASKED_ACRONYM>, a large-scale corpus with approx. 1.6 million entries in more than 180 languages with about 3 million variations of person and geolocation names. The corpus is based on various public data sources, which have been transformed into a unified format to simplify their usage, plus a newly compiled dataset from Wikipedia. In addition, we apply several machine learning methods to establish baselines for automatically detecting transliterated names in various languages. Our best systems achieve an accuracy of 92% on identification of transliterated pairs.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":0.9333333333}
{"Year":2020,"Venue":"lrec-2020","Acronym":"SpiCE","Description":"A New Open-Access Corpus of Conversational Bilingual Speech in Cantonese and English","Abstract":"This paper describes the design, collection, orthographic transcription, and phonetic annotation of <MASKED_ACRONYM>, a new corpus of conversational Cantonese-English bilingual speech recorded in Vancouver, Canada. The corpus includes high-quality recordings of 34 early bilinguals in both English and Cantonese\u2014to date, 27 have been recorded for a total of 19 hours of participant speech. Participants completed a sentence reading task, storyboard narration, and conversational interview in each language. Transcription and annotation for the corpus are currently underway. Transcripts produced with Google Cloud Speech-to-Text are available for all participants, and will be included in the initial <MASKED_ACRONYM> corpus release. Hand-corrected orthographic transcripts and force-aligned phonetic transcripts will be released periodically, and upon completion for all recordings, comprise the second release of the corpus. As an open-access language resource, <MASKED_ACRONYM> will promote bilingualism research for a typologically distinct pair of languages, of which Cantonese remains understudied despite there being millions of speakers around the world. The <MASKED_ACRONYM> corpus is especially well-suited for phonetic research on conversational speech, and enables researchers to study cross-language within-speaker phenomena for a diverse group of early Cantonese-English bilinguals. These are areas with few existing high-quality resources.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"lrec-2020","Acronym":"MaSS","Description":"A Large and Clean Multilingual Corpus of Sentence-aligned Spoken Utterances Extracted from the Bible","Abstract":"The CMU Wilderness Multilingual Speech Dataset (Black, 2019) is a newly published multilingual speech dataset based on recorded readings of the New Testament. It provides data to build Automatic Speech Recognition (ASR) and Text-to-Speech (TTS) models for potentially 700 languages. However, the fact that the source content (the Bible) is the same for all the languages is not exploited to date. Therefore, this article proposes to add multilingual links between speech segments in different languages, and shares a large and clean dataset of 8,130 parallel spoken utterances across 8 languages (56 language pairs). We name this corpus <MASKED_ACRONYM> (Multilingual corpus of Sentence-aligned Spoken utterances). The covered languages (Basque, English, Finnish, French, Hungarian, Romanian, Russian and Spanish) allow researches on speech-to-speech alignment as well as on translation for typologically different language pairs. The quality of the final corpus is attested by human evaluation performed on a corpus subset (100 utterances, 8 language pairs). Lastly, we showcase the usefulness of the final product on a bilingual speech retrieval task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2020,"Venue":"lrec-2020","Acronym":"CoCo","Description":"A Tool for Automatically Assessing Conceptual Complexity of Texts","Abstract":"Traditional text complexity assessment usually takes into account only syntactic and lexical text complexity. The task of automatic assessment of conceptual text complexity, important for maintaining reader\u2019s interest and text adaptation for struggling readers, has only been proposed recently. In this paper, we present <MASKED_ACRONYM> - a tool for automatic assessment of conceptual text complexity, based on using the current state-of-the-art unsupervised approach. We make the code and API freely available for research purposes, and describe the code and the possibility for its personalization and adaptation in details. We compare the current implementation with the state of the art, discussing the influence of the choice of entity linker on the performances of the tool. Finally, we present results obtained on two widely used text simplification corpora, discussing the full potential of the tool.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2005,"Venue":"ws-2005","Acronym":"METEOR","Description":"An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments","Abstract":"We describe <MASKED_ACRONYM>, an automatic  metric for machine translation evaluation  that is based on a generalized concept of  unigram matching between the machineproduced translation and human-produced  reference translations. Unigrams can be  matched based on their surface forms,  stemmed forms, and meanings; furthermore, <MASKED_ACRONYM> can be easily extended to  include more advanced matching strategies.  Once all generalized unigram  matches between the two strings have  been found, <MASKED_ACRONYM> computes a score  for this matching using a combination of  unigram-precision, unigram-recall, and a  measure of fragmentation that is designed  to directly capture how well-ordered the  matched words in the machine translation  are in relation to the reference.  We  evaluate <MASKED_ACRONYM> by measuring the correlation between the metric scores and  human judgments of translation quality.   We compute the Pearson R correlation  value between its scores and human quality assessments of the LDC TIDES 2003  Arabic-to-English and Chinese-to-English  datasets.  We perform segment-bysegment correlation, and show that  <MASKED_ACRONYM> gets an R correlation value of  0.347 on the Arabic data and 0.331 on the  Chinese data.  This is shown to be an improvement on using simply unigramprecision, unigram-recall and their harmonic F1 combination. We also perform  experiments to show the relative contributions of the various mapping modules.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"coling-2014","Acronym":"RED","Description":"A Reference Dependency Based MT Evaluation Metric","Abstract":"Most of the widely-used automatic evaluation metrics consider only the local fragments of the references and translations, and they ignore the evaluation on the syntax level. Current syntaxbased evaluation metrics try to introduce syntax information but suffer from the poor parsing results of the noisy machine translations. To alleviate this problem, we propose a novel dependency-based evaluation metric which only employs the dependency information of the references. We use two kinds of reference dependency structures: headword chain to capture the long distance dependency information, and \ufb01xed and \ufb02oating structures to capture the local continuous ngram. Experiment results show that our metric achieves higher correlations with human judgments than BLEU, TER and HWCM on WMT 2012 and WMT 2013. By introducing extra linguistic resources and tuning parameters, the new metric gets the state-of-the-art performance which is better than METEOR and SEMPOS on system level, and is comparable with METEOR on sentence level on WMT 2012 and WMT 2013.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"lrec-2018","Acronym":"ESCAPE","Description":"a Large-scale Synthetic Corpus for Automatic Post-Editing","Abstract":"Training models for the automatic correction of machine-translated text usually relies on data consisting of (source, MT, human postedit) triplets providing, for each source sentence, examples of translation errors with the corresponding corrections made by a human post-editor. Ideally, a large amount of data of this kind should allow the model to learn reliable correction patterns and effectively apply them at test stage on unseen (source, MT) pairs. In practice, however, their limited availability calls for solutions that also integrate in the training process other sources of knowledge. Along this direction, state-of-the-art results have been recently achieved by systems that, in addition to a limited amount of available training data, exploit arti\ufb01cial corpora that approximate elements of the \u201cgold\u201d training instances with automatic translations. Following this idea, we present eSCAPE, the largest freely-available Synthetic Corpus for Automatic Post-Editing released so far. eSCAPE consists of millions of entries in which the MT element of the training triplets has been obtained by translating the source side of publicly-available parallel corpora, and using the target side as an arti\ufb01cial human post-edit. Translations are obtained both with phrase-based and neural models. For each MT paradigm, eSCAPE contains 7.2 million triplets for English\u2013German and 3.3 millions for English\u2013Italian, resulting in a total of 14,4 and 6,6 million instances respectively. The usefulness of eSCAPE is proved through experiments in a general-domain scenario, the most challenging one for automatic post-editing. For both language directions, the models trained on our arti\ufb01cial data always improve MT quality with statistically signi\ufb01cant gains. The current version of eSCAPE can be freely downloaded from: http:\/\/hltshare.fbk.eu\/QT21\/eSCAPE.html. Keywords: Automatic Post-editing, Machine Translation 1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"lrec-2018","Acronym":"CONDUCT","Description":"An Expressive Conducting Gesture Dataset for Sound Control","Abstract":"Recent research in music-gesture relationship has paid more attention on the sound variations and its corresponding gesture expressiveness. In this study we are interested by gestures performed by orchestral conductors, with a focus on the expressive gestures made by the non dominant hand. We make the assumption that these gestures convey some meaning shared by most of conductors, and that they implicitly correspond to sound effects which can be encoded in musical scores. Following this hypothesis, we de\ufb01ned a collection of gestures for musical direction. These gestures are designed to correspond to well known functional effect on sounds, and they can be modulated to vary this effect by simply modifying one of their structural component (hand movement or hand shape). This paper presents the design of the gesture and sound sets and the protocol that has led to the database construction. The relevant musical excerpts and the related expressive gestures have been \ufb01rst de\ufb01ned by one expert musician. The gestures were then recorded through motion capture by two non experts who performed them along with recorded music. This database will serve as a basis for training gesture recognition system for live sound control and modulation. Keywords: Corpus, sound-control gestures, expressive gesture, conducting 1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"lrec-2018","Acronym":"CATS","Description":"A Tool for Customized Alignment of Text Simplification Corpora","Abstract":"In text simpli\ufb01cation (TS), parallel corpora consisting of original sentences and their manually simpli\ufb01ed counterparts are very scarce and small in size, which impedes building supervised automated TS systems with suf\ufb01cient coverage. Furthermore, the existing corpora usually do not distinguish sentence pairs which present full matches (both sentences contain the same information), and those that present only partial matches (the two sentences share the meaning only partially), thus not allowing for building customized automated TS systems which would separately model different simpli\ufb01cation transformations. In this paper, we present our freely available, language-independent tool for sentence alignment from parallel\/comparable TS resources (document-aligned resources), which additionally offers the possibility for \ufb01ltering sentences depending on the level of their semantic overlap. We perform in-depth human evaluation of the tool\u2019s performance on English and Spanish corpora, and explore its capacities for classi\ufb01cation of sentence pairs according to the simpli\ufb01cation operation they model. Keywords: text simpli\ufb01cation, tools and resources, sentence similarity 1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2018,"Venue":"lrec-2018","Acronym":"VAST","Description":"A Corpus of Video Annotation for Speech Technologies","Abstract":"The Video Annotation for Speech Technologies (<MASKED_ACRONYM>) corpus contains approximately 2900 hours of video data  collected and labeled to support the development of speech technologies such as speech activity detection, language  identification, speaker identification, and speech recognition. The bulk of the data comes from amateur video content  harvested from the web. Collection was designed to ensure that the videos cover a diverse range of communication  domains, data sources and video resolutions and to include three primary languages (English, Mandarin Chinese and  Arabic) plus supplemental data in 7 additional languages\/dialects to support language recognition research. Portions of  the collected data were annotated for speech activity, speaker identity, speaker sex, language identification, diarization,  and transcription. A description of the data collection and each of the annotation types is presented in this paper. The  corpus represents a challenging data set for language technology development due to the informal nature of the majority  of the data, as well as the variety of languages, noise conditions, topics, and speakers present in the collection.   Keywords: speech corpora, video corpora, multilingual resources  1.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2014,"Venue":"ws-2014","Acronym":"BEER","Description":"BEtter Evaluation as Ranking","Abstract":"We present the UvA-ILLC submission of the <MASKED_ACRONYM> metric to WMT 14 metrics task. <MASKED_ACRONYM> is a sentence level metric that can incorporate a large number of features combined in a linear model. Novel contributions are (1) ef\ufb01cient tuning of a large number of features for maximizing correlation with human system ranking, and (2) novel features that give smoother sentence level scores.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2006,"Venue":"lrec-2006","Acronym":"ROTE","Description":"A Tool to Support Users in Defining the Relative Importance of Quality Characteristics","Abstract":"This paper describes the Relative Ordering Tool for Evaluation (<MASKED_ACRONYM>) which is designed to support the process of building a parameterised quality model for evaluation. It is a very simple tool which enables users to specify the relative importance of quality characteristics (and associated metrics) to reflect the users' particular requirements. The tool allows users to order any number of quality characteristics by comparing them in a pair-wise fashion. The tool was developed in the context of a collaborative project developing a text mining system. A full scale evaluation of the text mining system was designed and executed for three different users and the <MASKED_ACRONYM> tool was successfully applied by those users during that process. The tool will be made available for general use by the evaluation community.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2006,"Venue":"lrec-2006","Acronym":"SKELETON","Description":"Specialised knowledge retrieval on the basis of terms and conceptual relations","Abstract":"The main goal of this paper is to present a first approach to an automatic detection of conceptual relations between two terms in specialised written text. Previous experiments on the basis of the manual analysis lead the authors to implement an automatic query strategy combining the term candidates proposed by an extractor together with a list of verbal syntactic patterns used for the relations refinement. Next step on the research will be the integration of the results into the term extractor in order to attain more restrictive pieces of information directly reused for the ontology building task.","wordlikeness":0.875,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2006,"Venue":"lrec-2006","Acronym":"MOOD","Description":"A Modular Object-Oriented Decoder for Statistical Machine Translation","Abstract":"We present an Open Source framework called <MASKED_ACRONYM> developed in order tofacilitate the development of a Statistical Machine Translation Decoder.<MASKED_ACRONYM> has been modularized using an object-oriented approach which makes itespecially suitable for the fast development of state-of-the-art decoders. Asa proof of concept, a clone of the pharaoh decoder has been implemented andevaluated. This clone named ramses is part of the current distribution of <MASKED_ACRONYM>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2004,"Venue":"coling-2004","Acronym":"ORANGE","Description":"a Method for Evaluating Automatic Evaluation Metrics for Machine Translation","Abstract":"Comparisons of automatic evaluation metrics  for machine translation are usually conducted  on corpus level using correlation statistics  such as Pearson\u2019s product moment correlation  coefficient  or  Spearman\u2019s  rank  order  correlation coefficient between human scores  and  automatic  scores.  However,  such  comparisons rely on human judgments of  translation qualities such as adequacy and  fluency. Unfortunately, these judgments are  often inconsistent and very expensive to  acquire. In this paper, we introduce a new  evaluation method, <MASKED_ACRONYM>, for evaluating  automatic machine translation evaluation  metrics automatically without extra human  involvement other than using a set of reference  translations. We also show the results of  comparing several existing automatic metrics  and three new automatic metrics using  <MASKED_ACRONYM>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"gwc-2016","Acronym":"CILI","Description":"the Collaborative Interlingual Index","Abstract":"This paper introduces the motivation for and design of the Collaborative InterLingual Index (<MASKED_ACRONYM>). It is designed to make possible coordination between multiple loosely coupled wordnet projects. The structure of the <MASKED_ACRONYM> is based on the Interlingual index first proposed in the EuroWordNet project with several pragmatic extensions: an explicit open license, definitions in English and links to wordnets in the Global Wordnet Grid.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
{"Year":2022,"Venue":"sigdial-2022","Acronym":"TREND","Description":"Trigger-Enhanced Relation-Extraction Network for Dialogues","Abstract":"The goal of dialogue relation extraction (DRE) is to identify the relation between two entities in a given dialogue. During conversations, speakers may expose their relations to certain entities by explicit or implicit clues, such evidences called \u201ctriggers\u201d. However, trigger annotations may not be always available for the target data, so it is challenging to leverage such information for enhancing the performance. Therefore, this paper proposes to learn how to identify triggers from the data with trigger annotations and then transfers the trigger-finding capability to other datasets for better performance. The experiments show that the proposed approach is capable of improving relation extraction performance of unseen relations and also demonstrate the transferability of our proposed trigger-finding model across different domains and datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2013,"Venue":"semeval-2013","Acronym":"REACTION","Description":"A naive machine learning approach for sentiment classification","Abstract":"We evaluate a naive machine learning approach to sentiment classi\ufb01cation focused on Twitter in the context of the sentiment analysis task of SemEval-2013. We employ a classi\ufb01er based on the Random Forests algorithm to determine whether a tweet expresses overall positive, negative or neutral sentiment. The classi\ufb01er was trained only with the provided dataset and uses as main features word vectors and lexicon word counts. Our average F-score for all three classes on the Twitter evaluation dataset was 51.55%. The average F-score of both positive and negative classes was 45.01%. For the optional SMS evaluation dataset our overall average F-score was 58.82%. The average between positive and negative Fscores was 50.11%.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2013,"Venue":"semeval-2013","Acronym":"CU","Description":"Computational Assessment of Short Free Text Answers - A Tool for Evaluating Students&#39; Understanding","Abstract":"Assessing student understanding by evaluating their free text answers to posed questions is a very important task. However, manually, it is time-consuming and computationally, it is dif\ufb01cult. This paper details our shallow NLP approach to computationally assessing student free text answers when a reference answer is provided. For four out of the \ufb01ve test sets, our system achieved an overall accuracy above the median and mean.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2010,"Venue":"paclic-2010","Acronym":"GRASP","Description":"Grammar- and Syntax-based Pattern-Finder for Collocation and Phrase Learning","Abstract":". We introduce a method for learning to find the representative syntax-based  context of a given collocation\/phrase. In our approach, grammatical patterns are extracted  for query terms aimed at accelerating lexicographers\u2019 and language learners\u2019 navigation  through the word usage and learning process. The method involves automatically  lemmatizing, part-of-speech tagging and shallowly parsing the sentences of a large-sized  general corpus, and automatically constructing inverted files for quick search. At run-time,  contextual grammar patterns are retrieved and presented to users with their corresponding  statistical analyses. We present a prototype system, <MASKED_ACRONYM> (grammar- and syntax-based  pattern-finder), that applies the method to computer-assisted language learning. Preliminary  results show that the extracted patterns not only resemble phrases in grammar books (e.g.,  make up one\u2019s mind) but help to assist the process of language learning and sentence  composition\/translation.  Keywords: Computer-assisted language learning, collocation, part-of-speech tagging,  grammatical patterns, and inverted files.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2016,"Venue":"naacl-2016","Acronym":"SODA","Description":"Service Oriented Domain Adaptation Architecture for Microblog Categorization","Abstract":"We demonstrate <MASKED_ACRONYM> (Service Oriented Domain Adaptation) for ef\ufb01cient and scalable cross-domain microblog categorization which works on the principle of transfer learning. It is developed on a novel similarity-based iterative domain adaptation algorithm while extended with features such as active learning and interactive GUI to be used by business professionals. <MASKED_ACRONYM> demonstrates ef\ufb01cient classi\ufb01cation accuracy on new collections while minimizing and sometimes eliminating the need for expensive data labeling efforts. <MASKED_ACRONYM> also implements an active learning (AL) technique to select informative instances from the new collection to seek annotations, if a small amount of labeled data is required by the adaptation algorithm.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2023,"Venue":"sigdial-2023","Acronym":"CONVERSER","Description":"Few-shot Conversational Dense Retrieval with Synthetic Data Generation","Abstract":"Conversational search provides a natural interface for information retrieval (IR). Recent approaches have demonstrated promising results in applying dense retrieval to conversational IR. However, training dense retrievers requires large amounts of in-domain paired data. This hinders the development of conversational dense retrievers, as abundant in-domain conversations are expensive to collect. In this paper, we propose Converser, a framework for training conversational dense retrievers with at most 6 examples of in-domain dialogues. Specifically, we utilize the in-context learning capability of large language models to generate conversational queries given a passage in the retrieval corpus. Experimental results on conversational retrieval benchmarks OR-QuAC and TREC CAsT 19 show that the proposed Converser achieves comparable performance to fully-supervised models, demonstrating the effectiveness of our proposed framework in few-shot conversational dense retrieval. All source code and generated datasets are available: https:\/\/github.","wordlikeness":0.8888888889,"lcsratio":1.0,"wordcoverage":0.9411764706}
{"Year":2023,"Venue":"sigdial-2023","Acronym":"MERCY","Description":"Multiple Response Ranking Concurrently in Realistic Open-Domain Conversational Systems","Abstract":"Automatic Evaluation (AE) and Response Selection (RS) models assign quality scores to various candidate responses and rank them in conversational setups. Prior response ranking research compares various models\u2019 performance on synthetically generated test sets. In this work, we investigate the performance of model-based reference-free AE and RS models on our constructed response ranking datasets that mirror real-case scenarios of ranking candidates during inference time. Metrics\u2019 unsatisfying performance can be interpreted as their low generalizability over more pragmatic conversational domains such as human-chatbot dialogs. To alleviate this issue we propose a novel RS model called <MASKED_ACRONYM> that simulates human behavior in selecting the best candidate by taking into account distinct candidates concurrently and learns to rank them. In addition, <MASKED_ACRONYM> leverages natural language feedback as another component to help the ranking task by explaining why each candidate response is relevant\/irrelevant to the dialog context. These feedbacks are generated by prompting large language models in a few-shot setup. Our experiments show the better performance of <MASKED_ACRONYM> over baselines for the response ranking task in our curated realistic datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"DEEP","Description":"DEnoising Entity Pre-training for Neural Machine Translation","Abstract":"It has been shown that machine translation models usually generate poor translations for named entities that are infrequent in the training corpus. Earlier named entity translation methods mainly focus on phonetic transliteration, which ignores the sentence context for translation and is limited in domain and language coverage. To address this limitation, we propose <MASKED_ACRONYM>, a DEnoising Entity Pre-training method that leverages large amounts of monolingual data and a knowledge base to improve named entity translation accuracy within sentences. Besides, we investigate a multi-task learning strategy that finetunes a pre-trained neural machine translation model on both entity-augmented monolingual data and parallel data to further improve entity translation. Experimental results on three language pairs demonstrate that <MASKED_ACRONYM> results in significant improvements over strong denoising auto-encoding baselines, with a gain of up to 1.3 BLEU and up to 9.2 entity accuracy points for English-Russian translation.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"PLANET","Description":"Dynamic Content Planning in Autoregressive Transformers for Long-form Text Generation","Abstract":"Despite recent progress of pre-trained language models on generating fluent text, existing methods still suffer from incoherence problems in long-form text generation tasks that require proper content control and planning to form a coherent high-level logical flow. In this work, we propose <MASKED_ACRONYM>, a novel generation framework leveraging autoregressive self-attention mechanism to conduct content planning and surface realization dynamically. To guide the generation of output sentences, our framework enriches the Transformer decoder with latent representations to maintain sentence-level semantic plans grounded by bag-of-words. Moreover, we introduce a new coherence-based contrastive learning objective to further improve the coherence of output. Extensive experiments are conducted on two challenging long-form text generation tasks including counterargument generation and opinion article generation. Both automatic and human evaluations show that our method significantly outperforms strong baselines and generates more coherent texts with richer contents.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"ExtEnD","Description":"Extractive Entity Disambiguation","Abstract":"Local models for Entity Disambiguation (ED) have today become extremely powerful, in most part thanks to the advent of large pre-trained language models. However, despite their significant performance achievements, most of these approaches frame ED through classification formulations that have intrinsic limitations, both computationally and from a modeling perspective. In contrast with this trend, here we propose <MASKED_ACRONYM>, a novel local formulation for ED where we frame this task as a text extraction problem, and present two Transformer-based architectures that implement it. Based on experiments in and out of domain, and training over two different data regimes, we find our approach surpasses all its competitors in terms of both data efficiency and raw performance. <MASKED_ACRONYM> outperforms its alternatives by as few as 6 F1 points on the more constrained of the two data regimes and, when moving to the other higher-resourced regime, sets a new state of the art on 4 out of 4 benchmarks under consideration, with average improvements of 0.7 F1 points overall and 1.1 F1 points out of domain. In addition, to gain better insights from our results, we also perform a fine-grained evaluation of our performances on different classes of label frequency, along with an ablation study of our architectural choices and an error analysis. We release our code and models for research purposes at <a href=https:\/\/github.com\/SapienzaNLP\/extend class=acl-markup-url>https:\/\/github.com\/SapienzaNLP\/extend<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"CAKE","Description":"A Scalable Commonsense-Aware Framework For Multi-View Knowledge Graph Completion","Abstract":"Knowledge graphs store a large number of factual triples while they are still incomplete, inevitably. The previous knowledge graph completion (KGC) models predict missing links between entities merely relying on fact-view data, ignoring the valuable commonsense knowledge. The previous knowledge graph embedding (KGE) techniques suffer from invalid negative sampling and the uncertainty of fact-view link prediction, limiting KGC\u2019s performance. To address the above challenges, we propose a novel and scalable Commonsense-Aware Knowledge Embedding (<MASKED_ACRONYM>) framework to automatically extract commonsense from factual triples with entity concepts. The generated commonsense augments effective self-supervision to facilitate both high-quality negative sampling (NS) and joint commonsense and fact-view link prediction. Experimental results on the KGC task demonstrate that assembling our framework could enhance the performance of the original KGE models, and the proposed commonsense-aware NS module is superior to other NS techniques. Besides, our proposed framework could be easily adaptive to various KGE models and explain the predicted results.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"FIBER","Description":"Fill-in-the-Blanks as a Challenging Video Understanding Evaluation Framework","Abstract":"We propose fill-in-the-blanks as a video understanding evaluation framework and introduce <MASKED_ACRONYM> \u2013 a novel dataset consisting of 28,000 videos and descriptions in support of this evaluation framework. The fill-in-the-blanks setting tests a model\u2019s understanding of a video by requiring it to predict a masked noun phrase in the caption of the video, given the video and the surrounding text. The <MASKED_ACRONYM> benchmark does not share the weaknesses of the current state-of-the-art language-informed video understanding tasks, namely: (1) video question answering using multiple-choice questions, where models perform relatively well because they exploit linguistic biases in the task formulation, thus making our framework challenging for the current state-of-the-art systems to solve; and (2) video captioning, which relies on an open-ended evaluation framework that is often inaccurate because system answers may be perceived as incorrect if they differ in form from the ground truth. The <MASKED_ACRONYM> dataset and our code are available at <a href=https:\/\/lit.eecs.umich.edu\/fiber\/ class=acl-markup-url>https:\/\/lit.eecs.umich.edu\/fiber\/<\/a>.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"ePiC","Description":"Employing Proverbs in Context as a Benchmark for Abstract Language Understanding","Abstract":"While large language models have shown exciting progress on several NLP benchmarks, evaluating their ability for complex analogical reasoning remains under-explored. Here, we introduce a high-quality crowdsourced dataset of narratives for employing proverbs in context as a benchmark for abstract language understanding. The dataset provides fine-grained annotation of aligned spans between proverbs and narratives, and contains minimal lexical overlaps between narratives and proverbs, ensuring that models need to go beyond surface-level reasoning to succeed. We explore three tasks: (1) proverb recommendation and alignment prediction, (2) narrative generation for a given proverb and topic, and (3) identifying narratives with similar motifs. Our experiments show that neural language models struggle on these tasks compared to humans, and these tasks pose multiple learning challenges.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"SPoT","Description":"Better Frozen Model Adaptation through Soft Prompt Transfer","Abstract":"There has been growing interest in parameter-efficient methods to apply pre-trained language models to downstream tasks. Building on the Prompt Tuning approach of Lester et al. (2021), which learns task-specific soft prompts to condition a frozen pre-trained model to perform different tasks, we propose a novel prompt-based transfer learning approach called <MASKED_ACRONYM>: Soft Prompt Transfer. <MASKED_ACRONYM> first learns a prompt on one or more source tasks and then uses it to initialize the prompt for a target task. We show that <MASKED_ACRONYM> significantly boosts the performance of Prompt Tuning across many tasks. More remarkably, across all model sizes, <MASKED_ACRONYM> matches or outperforms standard Model Tuning (which fine-tunes all model parameters) on the SuperGLUE benchmark, while using up to 27,000\u00d7 fewer task-specific parameters. To understand where <MASKED_ACRONYM> is most effective, we conduct a large-scale study on task transferability with 26 NLP tasks in 160 combinations, and demonstrate that many tasks can benefit each other via prompt transfer. Finally, we propose an efficient retrieval approach that interprets task prompts as task embeddings to identify similar tasks and predict the most transferable source tasks for a novel target task.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"RoMe","Description":"A Robust Metric for Evaluating Natural Language Generation","Abstract":"Evaluating Natural Language Generation (NLG) systems is a challenging task. Firstly, the metric should ensure that the generated hypothesis reflects the reference\u2019s semantics. Secondly, it should consider the grammatical quality of the generated sentence. Thirdly, it should be robust enough to handle various surface forms of the generated sentence. Thus, an effective evaluation metric has to be multifaceted. In this paper, we propose an automatic evaluation metric incorporating several core aspects of natural language understanding (language competence, syntactic and semantic variation). Our proposed metric, <MASKED_ACRONYM>, is trained on language features such as semantic similarity combined with tree edit distance and grammatical acceptability, using a self-supervised neural network to assess the overall quality of the generated sentence. Moreover, we perform an extensive robustness analysis of the state-of-the-art methods and <MASKED_ACRONYM>. Empirical results suggest that <MASKED_ACRONYM> has a stronger correlation to human judgment over state-of-the-art metrics in evaluating system-generated sentences across several NLG tasks.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":1.0}
{"Year":2022,"Venue":"acl-2022","Acronym":"ASPECTNEWS","Description":"Aspect-Oriented Summarization of News Documents","Abstract":"Generic summaries try to cover an entire document and query-based summaries try to answer document-specific questions. But real users\u2019 needs often fall in between these extremes and correspond to aspects, high-level topics discussed among similar types of documents. In this paper, we collect a dataset of realistic aspect-oriented summaries, AspectNews, which covers different subtopics about articles in news sub-domains. We annotate data across two domains of articles, earthquakes and fraud investigations, where each article is annotated with two distinct summaries focusing on different aspects for each domain. A system producing a single generic summary cannot concisely satisfy both aspects. Our focus in evaluation is how well existing techniques can generalize to these domains without seeing in-domain training data, so we turn to techniques to construct synthetic training data that have been used in query-focused summarization work. We compare several training schemes that differ in how strongly keywords are used and how oracle summaries are extracted. Our evaluation shows that our final approach yields (a) focused summaries, better than those from a generic summarization system or from keyword matching; (b) a system sensitive to the choice of keywords.","wordlikeness":0.9,"lcsratio":1.0,"wordcoverage":0.8235294118}
{"Year":2022,"Venue":"acl-2022","Acronym":"PARE","Description":"A Simple and Strong Baseline for Monolingual and Multilingual Distantly Supervised Relation Extraction","Abstract":"Neural models for distantly supervised relation extraction (DS-RE) encode each sentence in an entity-pair bag separately. These are then aggregated for bag-level relation prediction. Since, at encoding time, these approaches do not allow information to flow from other sentences in the bag, we believe that they do not utilize the available bag data to the fullest. In response, we explore a simple baseline approach (<MASKED_ACRONYM>) in which all sentences of a bag are concatenated into a passage of sentences, and encoded jointly using BERT. The contextual embeddings of tokens are aggregated using attention with the candidate relation as query \u2013 this summary of whole passage predicts the candidate relation. We find that our simple baseline solution outperforms existing state-of-the-art DS-RE models in both monolingual and multilingual DS-RE datasets.","wordlikeness":1.0,"lcsratio":1.0,"wordcoverage":0.8888888889}
