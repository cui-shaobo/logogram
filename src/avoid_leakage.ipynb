{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/single_word_with_replacement_\"\n",
    "train_df = pd.read_json(path+\"train.jsonl\", lines=True)\n",
    "val_df = pd.read_json(path+\"val.jsonl\", lines=True)\n",
    "test_df = pd.read_json(path+\"test.jsonl\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the acronym with a mask regardless of the capitalization\n",
    "def replace_with_mask(s):\n",
    "    insensitive_acronym = re.compile(re.escape(s[\"Acronym\"]), re.IGNORECASE)\n",
    "    s[\"Abstract\"] = insensitive_acronym.sub(\"<MASKED_ACRONYM>\", s[\"Abstract\"])\n",
    "    return s[\"Abstract\"]\n",
    "\n",
    "train_df[\"Abstract\"] = train_df.apply(replace_with_mask, axis=1)\n",
    "val_df[\"Abstract\"] = val_df.apply(replace_with_mask, axis=1)\n",
    "test_df[\"Abstract\"] = test_df.apply(replace_with_mask, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In criminal proceedings, sometimes it is not easy to evaluate the sincerity of oral testimonies. <MASKED_ACRONYM> - DEception in COURt corpus - has been built with the aim of training models suitable to discriminate, from a stylometric point of view, between sincere and deceptive statements. <MASKED_ACRONYM> is a collection of hearings held in four Italian Courts, in which the speakers lie in front of the judge. These hearings become the object of a specific criminal proceeding for calumny or false testimony, in which the deceptiveness of the statements of the defendant is ascertained. Thanks to the final Court judgment, that points out which lies are told, each utterance of the corpus has been annotated as true, uncertain or false, according to its degree of truthfulness. Since the judgment of deceptiveness follows a judicial inquiry, the annotation has been realized with a greater degree of confidence than ever before. Moreover, in Italy this is the first corpus of deceptive texts not relying on \\x91mock' lies created in laboratory conditions, but which has been collected in a natural environment.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3177][\"Abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace each <MASKED_ACRONYM> with a random word from the abstract (other than <MASKED_ACRONYM>)\n",
    "def replace_mask_with_random_word(s):\n",
    "    # Extract all unique words from the abstract, excluding <MASKED_ACRONYM>\n",
    "    words = set(s[\"Abstract\"].replace('<MASKED_ACRONYM>', '').split())\n",
    "    \n",
    "    # Remove empty strings, if any\n",
    "    words.discard('')\n",
    "\n",
    "    # Replace each <MASKED_ACRONYM> with a random word from the list\n",
    "    while '<MASKED_ACRONYM>' in s[\"Abstract\"]:\n",
    "        random_word = random.choice(list(words))\n",
    "        s[\"Abstract\"] = s[\"Abstract\"].replace('<MASKED_ACRONYM>', random_word, 1)\n",
    "    \n",
    "    return s[\"Abstract\"]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Abstract\"] = train_df.apply(replace_mask_with_random_word, axis=1)\n",
    "val_df[\"Abstract\"] = val_df.apply(replace_mask_with_random_word, axis=1)\n",
    "test_df[\"Abstract\"] = test_df.apply(replace_mask_with_random_word, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In criminal proceedings, sometimes it is not easy to evaluate the sincerity of oral testimonies. uncertain - DEception in COURt corpus - has been built with the aim of training models suitable to discriminate, from a stylometric point of view, between sincere and deceptive statements. judicial is a collection of hearings held in four Italian Courts, in which the speakers lie in front of the judge. These hearings become the object of a specific criminal proceeding for calumny or false testimony, in which the deceptiveness of the statements of the defendant is ascertained. Thanks to the final Court judgment, that points out which lies are told, each utterance of the corpus has been annotated as true, uncertain or false, according to its degree of truthfulness. Since the judgment of deceptiveness follows a judicial inquiry, the annotation has been realized with a greater degree of confidence than ever before. Moreover, in Italy this is the first corpus of deceptive texts not relying on \\x91mock' lies created in laboratory conditions, but which has been collected in a natural environment.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3177][\"Abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all words not in the start of a sentence to lowercase\n",
    "# Function to convert all letters of words not at the start of a sentence to lowercase\n",
    "def convert_to_lowercase(s):\n",
    "    # Split the text into sentences\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', s[\"Abstract\"])\n",
    "    converted_sentences = []\n",
    "\n",
    "    for sentence in sentences:\n",
    "        # Split each sentence into words and ensure only the first character of the first word is uppercase\n",
    "        words = sentence.split()\n",
    "        if words:\n",
    "            converted_sentence = [words[0].capitalize()] + [word.lower() for word in words[1:]]\n",
    "            converted_sentences.append(\" \".join(converted_sentence))\n",
    "\n",
    "    # Join the converted sentences back into a single text\n",
    "    return \" \".join(converted_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Abstract\"] = train_df.apply(convert_to_lowercase, axis=1)\n",
    "val_df[\"Abstract\"] = val_df.apply(convert_to_lowercase, axis=1)\n",
    "test_df[\"Abstract\"] = test_df.apply(convert_to_lowercase, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In criminal proceedings, sometimes it is not easy to evaluate the sincerity of oral testimonies. Uncertain - deception in court corpus - has been built with the aim of training models suitable to discriminate, from a stylometric point of view, between sincere and deceptive statements. Judicial is a collection of hearings held in four italian courts, in which the speakers lie in front of the judge. These hearings become the object of a specific criminal proceeding for calumny or false testimony, in which the deceptiveness of the statements of the defendant is ascertained. Thanks to the final court judgment, that points out which lies are told, each utterance of the corpus has been annotated as true, uncertain or false, according to its degree of truthfulness. Since the judgment of deceptiveness follows a judicial inquiry, the annotation has been realized with a greater degree of confidence than ever before. Moreover, in italy this is the first corpus of deceptive texts not relying on \\x91mock' lies created in laboratory conditions, but which has been collected in a natural environment.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[3177][\"Abstract\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_json(path+\"al_train.jsonl\", orient='records', lines=True)\n",
    "val_df.to_json(path+\"al_val.jsonl\", orient='records', lines=True)\n",
    "test_df.to_json(path+\"al_test.jsonl\", orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "em-condisa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
