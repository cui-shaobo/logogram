{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "SPLICE", "Title": "Fully Tractable Hierarchical Extension of ICA with Pooling", "Abstract": "We present a novel probabilistic framework for a hierarchical extension of independent component analysis (ICA), with a particular motivation in neuroscientific data analysis and modeling. The framework incorporates a general subspace pooling with linear ICA-like layers stacked recursively. Unlike related previous models, our generative model is fully tractable: both the likelihood and the posterior estimates of latent variables can readily be computed with analytically simple formulae. The model is particularly simple in the case of complex-valued data since the pooling can be reduced to taking the modulus of complex numbers. Experiments on electroencephalography (EEG) and natural images demonstrate the validity of the method."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Adversarial Variational Bayes", "Title": "Unifying Variational Autoencoders and Generative Adversarial Networks", "Abstract": "Variational Autoencoders (VAEs) are expressive latent variable models that can be used to learn complex probability distributions from training data. However, the quality of the resulting model crucially relies on the expressiveness of the inference model. We introduce Adversarial Variational Bayes (AVB), a technique for training Variational Autoencoders  with arbitrarily expressive inference models. We achieve this by introducing an auxiliary discriminative network that allows to rephrase the maximum-likelihood-problem as a two-player game, hence establishing a principled connection between VAEs and Generative Adversarial Networks (GANs). We show that in the nonparametric limit our method yields an exact maximum-likelihood assignment for the parameters of the generative model, as well as the exact posterior distribution over the latent variables given an observation. Contrary to competing approaches which combine VAEs with GANs, our approach has a clear theoretical justification, retains most advantages of standard Variational Autoencoders and is easy to implement."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Online Partial Least Square Optimization", "Title": "Dropping Convexity for Better Efficiency and Scalability", "Abstract": "Multiview representation learning is popular for latent factor analysis. Many existing approaches formulate the multiview representation learning as convex optimization problems, where global optima can be obtained by certain algorithms in polynomial time. However, many evidences have corroborated that heuristic nonconvex approaches also have good empirical computational performance and convergence to the global optima, although there is a lack of theoretical justification. Such a gap between theory and practice motivates us to study a nonconvex formulation for multiview representation learning, which can be efficiently solved by a simple stochastic gradient descent method. By analyzing the dynamics of the algorithm based on diffusion processes, we establish a global rate of convergence to the global optima. Numerical experiments are provided to support our theory."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "GSOS", "Title": "Gauss-Seidel Operator Splitting Algorithm for Multi-Term Nonsmooth Convex Composite Optimization", "Abstract": "In this paper, we propose a fast {\\bf{G}}auss-{\\bf{S}}eidel {\\bf{O}}perator {\\bf{S}}plitting (GSOS) algorithm for addressing multi-term nonsmooth convex composite optimization, which has wide applications in machine learning, signal processing and statistics. The proposed GSOS algorithm inherits the advantage of the Gauss-Seidel technique to accelerate the optimization procedure, and leverages the operator splitting technique to reduce the computational complexity. In addition, we develop a new technique to establish the global convergence of the GSOS algorithm. To be specific, we first reformulate the iterations of GSOS as a two-step iterations algorithm by employing the tool of operator optimization theory. Subsequently, we establish the convergence of GSOS based on the two-step iterations algorithm reformulation. At last, we apply the proposed GSOS algorithm to solve overlapping group Lasso and graph-guided fused Lasso problems. Numerical experiments show that our proposed GSOS algorithm is superior to the state-of-the-art algorithms in terms of both efficiency and effectiveness."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Ordinal Graphical Models", "Title": "A Tale of Two Approaches", "Abstract": "Undirected graphical models or Markov random fields (MRFs) are widely used for modeling multivariate probability distributions. Much of the work on MRFs has focused on continuous variables, and nominal variables (that is, unordered categorical variables). However, data from many real world applications involve ordered categorical variables also known as ordinal variables, e.g., movie ratings on Netflix which can be ordered from 1 to 5 stars. \nWith respect to univariate ordinal distributions, as we detail in the paper, there are two main categories of distributions; while there have been efforts to extend these to multivariate ordinal distributions, the resulting distributions are typically very complex, with either a large number of parameters, or with non-convex likelihoods. While there have been some work on tractable approximations, these do not come with strong statistical guarantees, and moreover are relatively computationally expensive.\nIn this paper, we theoretically investigate two classes of graphical models for ordinal data, corresponding to the two main categories of univariate ordinal distributions. In contrast to previous work, our theoretical developments allow us to provide correspondingly two classes of estimators that are not only computationally efficient but also have strong statistical guarantees."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Warped Convolutions", "Title": "Efficient Invariance to Spatial Transformations", "Abstract": "Convolutional Neural Networks (CNNs) are extremely efficient, since they exploit the inherent translation-invariance of natural images. However, translation is just one of a myriad of useful spatial transformations. Can the same efficiency be attained when considering other spatial invariances? Such generalized convolutions have been considered in the past, but at a high computational cost. We present a construction that is simple and exact, yet has the same computational complexity that standard convolutions enjoy. It consists of a constant image warp followed by a simple convolution, which are standard blocks in deep learning toolboxes. With a carefully crafted warp, the resulting architecture can be made equivariant to a wide range of two-parameter spatial transformations. We show encouraging results in realistic scenarios, including the estimation of vehicle poses in the Google Earth dataset (rotation and scale), and face poses in Annotated Facial Landmarks in the Wild (3D rotations under perspective)."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "McGan", "Title": "Mean and Covariance Feature Matching GAN", "Abstract": "We introduce new families of Integral Probability\nMetrics (IPM) for training Generative Adversarial\nNetworks (GAN). Our IPMs are based on\nmatching statistics of distributions embedded in\na finite dimensional feature space. Mean and covariance feature matching IPMs allow for stable\ntraining of GANs, which we will call McGan. McGan minimizes a meaningful loss between distributions."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Random Fourier Features for Kernel Ridge Regression", "Title": "Approximation Bounds and Statistical Guarantees", "Abstract": "Random Fourier features is one of the most popular techniques for scaling up kernel methods, such as kernel ridge regression. However, despite impressive empirical results, the statistical properties of random Fourier features are still not well understood. In this paper we take steps toward filling this gap. Specifically, we approach random Fourier features from a spectral matrix approximation point of view, give tight bounds on the number of Fourier features required to achieve a spectral approximation, and show how spectral matrix approximation bounds imply statistical guarantees for kernel ridge regression."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Re-revisiting Learning on Hypergraphs", "Title": "Confidence Interval and Subgradient Method", "Abstract": "We revisit semi-supervised learning on hypergraphs. Same as previous approaches, our method uses a convex program whose objective function is not everywhere differentiable.  We exploit the non-uniqueness of the optimal solutions, and consider  confidence intervals which give the exact ranges that unlabeled vertices take in any optimal solution. Moreover, we give a much simpler approach for solving the convex program based on the subgradient method. Our experiments on real-world datasets confirm that our confidence interval approach on hypergraphs outperforms existing methods, and our sub-gradient method gives faster running times when the number of vertices is much larger than the number of edges."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "SplitNet", "Title": "Learning to Semantically Split Deep Networks for Parameter Reduction and Model Parallelization", "Abstract": "We propose a novel deep neural network that is both lightweight and effectively structured for model parallelization. Our network, which we name as SplitNet, automatically learns to split the network weights into either a set or a hierarchy of multiple groups that use disjoint sets of features, by learning both the class-to-group and feature-to-group assignment matrices along with the network weights. This produces a tree-structured network that involves no connection between branched subtrees of semantically disparate class groups. SplitNet thus greatly reduces the number of parameters and requires significantly less computations, and is also embarrassingly model parallelizable at test time, since the network evaluation for each subnetwork is completely independent except for the shared lower layer weights that can be duplicated over multiple processors. We validate our method with two deep network models (ResNet and AlexNet) on two different datasets (CIFAR-100 and ILSVRC 2012) for image classification, on which our method obtains networks with significantly reduced number of parameters while achieving comparable or superior classification accuracies over original full deep networks, and accelerated test speed with multiple GPUs."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "No Spurious Local Minima in Nonconvex Low Rank Problems", "Title": "A Unified Geometric Analysis", "Abstract": "In this paper we develop a new framework that captures the common landscape underlying the common non-convex low-rank matrix problems including matrix sensing, matrix completion and robust PCA. In particular, we show for all above problems (including asymmetric cases): 1) all local minima are also globally optimal; 2) no high-order saddle points exists. These results explain why simple algorithms such as stochastic gradient descent have global converge, and efficiently optimize these non-convex objective functions in practice. Our framework connects and simplifies the existing analyses on optimization landscapes for matrix sensing and symmetric matrix completion. The framework naturally leads to new results for asymmetric matrix completion and robust PCA."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Coherence Pursuit", "Title": "Fast, Simple, and Robust Subspace Recovery", "Abstract": "This paper presents a remarkably simple, yet powerful, algorithm for robust Principal Component Analysis (PCA). In the proposed approach, an outlier is set apart from an inlier by comparing their coherence with the rest of the data points. As inliers lie on a low dimensional subspace, they are likely to have strong mutual coherence provided there are enough inliers. By contrast, outliers do not typically admit low dimensional structures, wherefore an outlier is unlikely to bear strong resemblance with a large number of data points. The mutual coherences are computed by forming the Gram matrix of normalized data points. Subsequently, the subspace is recovered from the span of a small subset of the data points that exhibit strong coherence with the rest of the data. As coherence pursuit only involves one simple matrix multiplication, it is significantly faster than the state of-the-art robust PCA algorithms. We provide a mathematical analysis of the proposed algorithm under a random model for the distribution of the inliers and outliers. It is shown that the proposed method can recover the correct subspace even if the data is predominantly outliers. To the best of our knowledge, this is the first provable robust PCA algorithm that is simultaneously non-iterative, can tolerate a large number of outliers and is robust to linearly dependent outliers."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "AdaNet", "Title": "Adaptive Structural Learning of Artificial Neural Networks", "Abstract": "We present a new framework for analyzing and learning artificial neural networks. Our approach simultaneously and adaptively learns both the structure of the network as well as its weights. The methodology is based upon and accompanied by strong data-dependent theoretical learning guarantees, so that the final network architecture provably adapts to the complexity of any given problem."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "DARLA", "Title": "Improving Zero-Shot Transfer in Reinforcement Learning", "Abstract": "Domain adaptation is an important open problem in deep reinforcement learning (RL). In many scenarios of interest data is hard to obtain, so agents may learn a source policy in a setting where data is readily available, with the hope that it generalises well to the target domain. We propose a new multi-stage RL agent, DARLA (DisentAngled Representation Learning Agent), which learns to see before learning to act. DARLA’s vision is based on learning a disentangled representation of the observed environment. Once DARLA can see, it is able to acquire source policies that are robust to many domain shifts - even with no access to the target domain. DARLA significantly outperforms conventional baselines in zero-shot domain adaptation scenarios, an effect that holds across a variety of RL environments (Jaco arm, DeepMind Lab) and base RL algorithms (DQN, A3C and EC)."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "From Patches to Images", "Title": "A Nonparametric Generative Model", "Abstract": "We propose a hierarchical generative model that captures the self-similar structure of image regions as well as how this structure is shared across image collections. Our model is based on a novel, variational interpretation of the popular expected patch log-likelihood (EPLL) method as a model for randomly positioned grids of image patches. While previous EPLL methods modeled image patches with finite Gaussian mixtures, we use nonparametric Dirichlet process (DP) mixtures to create models whose complexity grows as additional images are observed. An extension based on the hierarchical DP then captures repetitive and self-similar structure via image-specific variations in cluster frequencies. We derive a structured variational inference algorithm that adaptively creates new patch clusters to more accurately model novel image textures. Our denoising performance on standard benchmarks is superior to EPLL and comparable to the state-of-the-art, and provides novel statistical justifications for common image processing heuristics. We also show accurate image inpainting results."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Schema Networks", "Title": "Zero-shot Transfer with a Generative Causal Model of Intuitive Physics", "Abstract": "The recent adaptation of deep neural network-based methods to reinforcement learning and planning domains has yielded remarkable progress on individual tasks. Nonetheless, progress on task-to-task transfer remains limited. In pursuit of efficient and robust generalization, we introduce the Schema Network, an object-oriented generative physics simulator capable of disentangling multiple causes of events and reasoning backward through causes to achieve goals. The richly structured architecture of the Schema Network can learn the dynamics of an environment directly from data. We compare Schema Networks with Asynchronous Advantage Actor-Critic and Progressive Networks on a suite of Breakout variations, reporting results on training efficiency and zero-shot generalization, consistently demonstrating faster, more robust learning and better transfer. We argue that generalizing from limited data and learning causal relationships are essential abilities on the path toward generally intelligent systems."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Neural Taylor Approximations", "Title": "Convergence and Exploration in Rectifier Networks", "Abstract": "Modern convolutional networks, incorporating rectifiers and max-pooling, are neither smooth nor convex; standard guarantees therefore do not apply. Nevertheless, methods from convex optimization such as gradient descent and Adam are widely used as building blocks for deep learning algorithms. This paper provides the first convergence guarantee applicable to modern convnets, which furthermore matches a lower bound for convex nonsmooth functions. The key technical tool is the neural Taylor approximation -- a straightforward application of Taylor expansions to neural networks -- and the associated Taylor loss. Experiments on a range of optimizers, layers, and tasks provide evidence that the analysis accurately captures the dynamics of neural optimization. The second half of the paper applies the Taylor approximation to isolate the main difficulty in training rectifier nets -- that gradients are shattered --  and investigates the hypothesis that, by exploring the space of activation configurations more thoroughly, adaptive optimizers such as RMSProp and Adam are able to converge to better solutions."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "The Shattered Gradients Problem", "Title": "If resnets are the answer, then what is the question?", "Abstract": "A long-standing obstacle to progress in deep learning is the problem of vanishing and exploding gradients. Although, the problem has largely been overcome via carefully constructed initializations and batch normalization, architectures incorporating skip-connections such as highway and resnets perform much better than standard feedforward architectures despite well-chosen initialization and batch normalization. In this paper, we identify the shattered gradients problem. Specifically, we show that the correlation between gradients in standard feedforward networks decays exponentially with depth resulting in gradients that resemble white noise whereas, in contrast, the gradients in architectures with skip-connections are far more resistant to shattering, decaying sublinearly. Detailed empirical evidence is presented in support of the analysis, on both fully-connected networks and convnets. Finally, we present a new ``looks linear'' (LL) initialization that prevents shattering, with preliminary experiments showing the new initialization allows to train very deep networks without the addition of skip-connections."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Orthogonalized ALS", "Title": "A Theoretically Principled Tensor Decomposition Algorithm for Practical Use", "Abstract": "The popular Alternating Least Squares (ALS) algorithm for tensor decomposition is efficient and easy to implement, but often converges to poor local optima---particularly when the weights of the factors are non-uniform. We propose a modification of the ALS approach that is as efficient as standard ALS, but provably recovers the true factors with random initialization under standard incoherence assumptions on the factors of the tensor. We demonstrate the significant practical superiority of our approach over traditional ALS for a variety of tasks on synthetic data---including tensor factorization on exact, noisy and over-complete tensors, as well as tensor completion---and for computing word embeddings from a third-order word tri-occurrence tensor."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Learning Gradient Descent", "Title": "Better Generalization and Longer Horizons", "Abstract": "Training deep neural networks is a highly nontrivial task, involving carefully selecting appropriate training algorithms, scheduling step sizes and tuning other hyperparameters. Trying different combinations can be quite labor-intensive and time consuming. Recently, researchers have tried to use deep learning algorithms to exploit the landscape of the loss function of the training problem of interest, and learn how to optimize over it in an automatic way. In this paper, we propose a new learning-to-learn model and some useful and practical tricks. Our optimizer outperforms generic, hand-crafted optimization algorithms and state-of-the-art learning-to-learn optimizers by DeepMind in many tasks. We demonstrate the effectiveness of our algorithms on a number of tasks, including deep MLPs, CNNs, and simple LSTMs."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Adaptive Feature Selection", "Title": "Computationally Efficient Online Sparse Linear Regression under RIP", "Abstract": "Online sparse linear regression is an online problem where an algorithm repeatedly chooses a subset of coordinates to observe in an adversarially chosen feature vector, makes a real-valued prediction, receives the true label, and incurs the squared loss. The goal is to design an online learning algorithm with sublinear regret to the best sparse linear predictor in hindsight. Without any assumptions, this problem is known to be computationally intractable. In this paper, we make the assumption that data matrix satisfies restricted isometry property, and show that this assumption leads to computationally efficient algorithms with sublinear regret for two variants of the problem. In the first variant, the true label is generated according to a sparse linear model with additive Gaussian noise. In the second, the true label is chosen adversarially."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Emulating the Expert", "Title": "Inverse Optimization through Online Learning", "Abstract": "In this paper, we demonstrate how to learn the objective function of a decision maker while only observing the problem input data and the decision maker's corresponding decisions over multiple rounds. Our approach is based on online learning techniques and works for linear objectives over arbitrary sets for which we have a linear optimization oracle and as such generalizes previous work based on KKT-system decomposition and dualization approaches. The applicability of our framework for learning linear constraints is also discussed briefly. Our algorithm converges at a rate of O(1/sqrt(T)), and we demonstrate its effectiveness and applications in preliminary computational results. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "SARAH", "Title": "A Novel Method for Machine Learning Problems Using Stochastic Recursive Gradient", "Abstract": "In this paper, we propose a StochAstic Recursive grAdient algoritHm (SARAH), as well as its practical variant SARAH+, as a novel approach to the finite-sum minimization problems. Different from the vanilla SGD and other modern stochastic methods such as SVRG, S2GD, SAG and SAGA, SARAH admits a simple recursive framework for updating stochastic gradient estimates; when comparing to SAG/SAGA, SARAH does not require a storage of past gradients. The linear convergence rate of SARAH is proven under strong convexity assumption. We also prove a linear convergence rate (in the strongly convex case) for an inner loop of SARAH, the property that SVRG does not possess. Numerical experiments demonstrate the efficiency of our algorithm."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Improving Viterbi is Hard", "Title": "Better Runtimes Imply Faster Clique Algorithms", "Abstract": "The classic algorithm of Viterbi computes the most likely path in a Hidden Markov Model (HMM) that results in a given sequence of observations. It runs in time O(Tn^2) given a sequence of T observations from a HMM with n states. Despite significant interest in the problem and prolonged effort by different communities, no known algorithm achieves more than a polylogarithmic speedup. In this paper, we explain this difficulty by providing matching conditional lower bounds. Our lower bounds are based on assumptions that the best known algorithms for the All-Pairs Shortest Paths problem (APSP) and for the Max-Weight k-Clique problem in edge-weighted graphs are essentially tight. Finally, using a recent algorithm by Green Larsen and Williams for online Boolean matrix-vector multiplication, we get a 2^{Omega(sqrt{log n})} speedup for the Viterbi algorithm when there are few distinct transition probabilities in the HMM."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Towards K-means-friendly Spaces", "Title": "Simultaneous Deep Learning and Clustering", "Abstract": "Most learning approaches treat dimensionality reduction (DR) and clustering separately (i.e., sequentially), but recent research has shown that optimizing the two tasks jointly can substantially improve the performance of both. The premise behind the latter genre is that the data samples are obtained via linear transformation of latent representations that are easy to cluster; but in practice, the transformation from the latent space to the data can be more complicated. In this work, we assume that this transformation is an unknown and possibly nonlinear function. To recover the ‘clustering-friendly’ latent representations and to better cluster the data, we propose a joint DR and K-means clustering approach in which DR is accomplished via learning a deep neural network (DNN). The motivation is to keep the advantages of jointly optimizing the two tasks, while exploiting the deep neural network’s ability to approximate any nonlinear function. This way, the pro- posed approach can work well for a broad class of generative models. Towards this end, we carefully design the DNN structure and the associated joint optimization criterion, and propose an effective and scalable algorithm to handle the formulated optimization problem. Experiments using different real datasets are employed to showcase the effectiveness of the proposed approach."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Know-Evolve", "Title": "Deep Temporal Reasoning for Dynamic Knowledge Graphs", "Abstract": "The availability of large scale event data with time stamps has given rise to dynamically evolving knowledge graphs that contain temporal information for each edge. Reasoning over time in such dynamic knowledge graphs is not yet well understood.\nTo this end, we present Know-Evolve, a novel deep evolutionary knowledge network that learns non-linearly evolving entity representations over time. The occurrence of a fact (edge) is modeled as a multivariate point process whose intensity function is modulated by the score for that fact computed based on the learned entity embeddings. We demonstrate significantly improved performance over various relational learning approaches on two large scale real-world datasets. Further, our method effectively predicts occurrence or recurrence time of a fact which is novel compared to prior reasoning approaches in multi-relational setting."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Input Switched Affine Networks", "Title": "An RNN Architecture Designed for Interpretability", "Abstract": "There exist many problem domains where the interpretability of neural network models is essential for deployment. Here we introduce a recurrent architecture composed of input-switched affine transformations - in other words an RNN without any explicit nonlinearities, but with input-dependent recurrent weights. This simple form allows the RNN to be analyzed via straightforward linear methods: we can exactly characterize the linear contribution of each input to the model predictions; we can use a change-of-basis to disentangle input, output, and computational hidden unit subspaces; we can fully reverse-engineer the architecture's solution to a simple task. Despite this ease of interpretation, the input switched affine network achieves reasonable performance on a text modeling tasks, and allows greater computational efficiency than networks with standard nonlinearities."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "StingyCD", "Title": "Safely Avoiding Wasteful Updates in Coordinate Descent", "Abstract": "Coordinate descent (CD) is a scalable and simple algorithm for solving many optimization problems in machine learning.\nDespite this fact, CD can also be very computationally wasteful. \nDue to sparsity in sparse regression problems, for example, the majority of CD updates often result in no progress toward the solution.\nTo address this inefficiency, we propose a modified CD algorithm named \"StingyCD.\"\nBy skipping over many updates that are guaranteed to not decrease the objective value, StingyCD significantly reduces convergence times.\nSince StingyCD only skips updates with this guarantee, however, StingyCD does not fully exploit the problem's sparsity.\nFor this reason, we also propose StingyCD+, an algorithm that achieves further speed-ups by skipping updates more aggressively.\nSince StingyCD and StingyCD+ rely on simple modifications to CD, it is also straightforward to use these algorithms with other approaches to scaling optimization.\nIn empirical comparisons, StingyCD and StingyCD+ improve convergence times considerably for several L1-regularized optimization problems."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "ChoiceRank", "Title": "Identifying Preferences from Node Traffic in Networks", "Abstract": "Understanding how users navigate in a network is of high interest in many applications. We consider a setting where only aggregate node-level traffic is observed and tackle the task of learning edge transition probabilities. We cast it as a preference learning problem, and we study a model where choices follow Luce's axiom. In this case, the O(n) marginal counts of node visits are a sufficient statistic for the O(n^2) transition probabilities. We show how to make the inference problem well-posed regardless of the network's structure, and we present ChoiceRank, an iterative algorithm that scales to networks that contains billions of nodes and edges. We apply the model to two clickstream datasets and show that it successfully recovers the transition probabilities using only the network structure and marginal (node-level) traffic data. Finally, we also consider an application to mobility networks and apply the model to one year of rides on New York City's bicycle-sharing system."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Sequence Tutor", "Title": "Conservative fine-tuning of sequence generation models with KL-control", "Abstract": "This paper proposes a general method for improving the structure and quality of sequences generated by a recurrent neural network (RNN), while maintaining information originally learned from data, as well as sample diversity. An RNN is first pre-trained on data using maximum likelihood estimation (MLE), and the probability distribution over the next token in the sequence learned by this model is treated as a prior policy. Another RNN is then trained using reinforcement learning (RL) to generate higher-quality outputs that account for domain-specific incentives while retaining proximity to the prior policy of the MLE RNN. To formalize this objective, we derive novel off-policy RL methods for RNNs from KL-control. The effectiveness of the approach is demonstrated on two applications; 1) generating novel musical melodies, and 2) computational molecular generation. For both problems, we show that the proposed method improves the desired properties and structure of the generated sequences, while maintaining information learned from data. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Statistical Inference for Incomplete Ranking Data", "Title": "The Case of Rank-Dependent Coarsening", "Abstract": "We consider the problem of statistical inference for ranking data, specifically rank aggregation, under the assumption that samples are incomplete in the sense of not comprising all choice alternatives. In contrast to most existing methods, we explicitly model the process of turning a full ranking into an incomplete one, which we call the coarsening process. To this end, we propose the concept of rank-dependent coarsening, which assumes that incomplete rankings are produced by projecting a full ranking to a random subset of ranks. For a concrete instantiation of our model, in which full rankings are drawn from a Plackett-Luce distribution and observations take the form of pairwise preferences, we study the performance of various rank aggregation methods. In addition to predictive accuracy in the finite sample setting, we address the theoretical question of consistency, by which we mean the ability to recover a target ranking when the sample size goes to infinity, despite a potential bias in the observations caused by the (unknown) coarsening."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Deep Voice", "Title": "Real-time Neural Text-to-Speech", "Abstract": "We present Deep Voice, a production-quality text-to-speech system constructed entirely from deep neural networks. Deep Voice lays the groundwork for truly end-to-end neural speech synthesis. The system comprises five major building blocks: a segmentation model for locating phoneme boundaries, a grapheme-to-phoneme conversion model, a phoneme duration prediction model, a fundamental frequency prediction model, and an audio synthesis model. For the segmentation model, we propose a novel way of performing phoneme boundary detection with deep neural networks using connectionist temporal classification (CTC) loss. For the audio synthesis model, we implement a variant of WaveNet that requires fewer parameters and trains faster than the original. By using a neural network for each component, our system is simpler and more flexible than traditional text-to-speech systems, where each component requires laborious feature engineering and extensive domain expertise. Finally, we show that inference with our system can be performed faster than real time and describe optimized WaveNet inference kernels on both CPU and GPU that achieve up to 400x speedups over existing implementations."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Globally Induced Forest", "Title": "A Prepruning Compression Scheme", "Abstract": "Tree-based ensemble models are heavy memory-wise. An undesired state of affairs\nconsidering nowadays datasets, memory-constrained environment and\nfitting/prediction times.  In this paper, we propose the Globally Induced Forest\n(GIF) to remedy this problem. GIF is a fast prepruning approach to build\nlightweight ensembles by iteratively deepening the current forest. It mixes\nlocal and global optimizations to produce accurate predictions under memory\nconstraints in reasonable time.  We show that the proposed method is more than\ncompetitive with standard tree-based ensembles under corresponding constraints,\nand can sometimes even surpass much larger models."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "DeepBach", "Title": "a Steerable Model for Bach Chorales Generation", "Abstract": "This paper introduces DeepBach, a graphical model aimed at modeling polyphonic music and specifically hymn-like pieces. \nWe claim that, after being trained on the chorale harmonizations by Johann Sebastian Bach, our model is capable of generating highly convincing chorales in the style of Bach.\nDeepBach's strength comes from the use of pseudo-Gibbs sampling coupled with an adapted representation of musical data. This is in contrast with many automatic music composition approaches  which tend to compose music sequentially. Our model is also steerable in the sense that a user can constrain the generation by imposing positional constraints such as notes, rhythms or cadences in the generated score. We also provide a plugin on top of the MuseScore music editor making the interaction with DeepBach easy to use."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Sparse + Group-Sparse Dirty Models", "Title": "Statistical Guarantees without Unreasonable Conditions and a Case for Non-Convexity", "Abstract": "Imposing sparse + group-sparse superposition structures in high-dimensional parameter estimation is known to provide flexible regularization  that is more realistic for many real-world problems. For example, such a superposition enables partially-shared support sets in multi-task learning, thereby striking the right balance between parameter overlap across tasks and task specificity. Existing theoretical results on estimation consistency, however, are problematic as they require too stringent an assumption: the incoherence between sparse and group-sparse superposed components.  In this paper, we fill the gap between the practical success and suboptimal analysis of sparse + group-sparse models, by providing the first consistency results that do not require unrealistic assumptions. We also study non-convex counterparts of sparse + group-sparse models. Interestingly, we show that these are guaranteed to recover the true support set under much milder conditions and with smaller sample size than convex models, which might be critical in practical applications as illustrated by our experiments."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Variational Boosting", "Title": "Iteratively Refining Posterior Approximations", "Abstract": "We propose a black-box variational inference method to approximate intractable distributions with an increasingly rich approximating class.  Our method, variational boosting, iteratively refines an existing variational approximation by solving a sequence of optimization problems, allowing a trade-off between computation time and accuracy.  We expand the variational approximating class by incorporating additional covariance structure and by introducing new components to form a mixture.  We apply variational boosting to synthetic and real statistical models, and show that the resulting posterior inferences compare favorably to existing variational algorithms."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Cognitive Psychology for Deep Neural Networks", "Title": "A Shape Bias Case Study", "Abstract": "Deep neural networks (DNNs) have advanced performance on a wide range of complex tasks, rapidly outpacing our understanding of the nature of their solutions. While past work sought to advance our understanding of these models, none has made use of the rich history of problem descriptions, theories, and experimental methods developed by cognitive psychologists to study the human mind. To explore the potential value of these tools, we chose a well-established analysis from developmental psychology that explains how children learn word labels for objects, and applied that analysis to DNNs. Using datasets of stimuli inspired by the original cognitive psychology experiments, we find that state-of-the-art one shot learning models trained on ImageNet exhibit a similar bias to that observed in humans: they prefer to categorize objects according to shape rather than color. The magnitude of this shape bias varies greatly among architecturally identical, but differently seeded models, and even fluctuates within seeds throughout training, despite nearly equivalent classification performance. These results demonstrate the capability of tools from cognitive psychology for exposing hidden computational properties of DNNs, while concurrently providing us with a computational model for human word learning."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Sequence to Better Sequence", "Title": "Continuous Revision of Combinatorial Structures", "Abstract": "We present a model that, after learning on observations of (sequence, outcome) pairs, can be efficiently used to revise a new sequence in order to improve its associated outcome.  Our framework requires neither example improvements, nor additional evaluation of outcomes for proposed revisions.  To avoid combinatorial-search over sequence elements, we specify a generative model with continuous latent factors, which is learned via joint approximate inference using a recurrent variational autoencoder (VAE) and an outcome-predicting neural network module.  Under this model, gradient methods can be used to efficiently optimize the continuous latent factors with respect to inferred outcomes.  By appropriately constraining this optimization and using the VAE decoder to generate a revised sequence, we ensure the revision is fundamentally similar to the original sequence, is associated with better outcomes, and looks natural. These desiderata are proven to hold with high probability under our approach, which is empirically demonstrated for revising natural language sentences."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "RobustFill", "Title": "Neural Program Learning under Noisy I/O", "Abstract": "The problem of automatically generating a computer program from some specification has been studied since the early days of AI. Recently, two competing approaches for 'automatic program learning' have received significant attention: (1) 'neural program synthesis', where a neural network is conditioned on input/output (I/O) examples and learns to generate a program, and (2) 'neural program induction', where a neural network generates new outputs directly using a latent program representation. Here, for the first time, we directly compare both approaches on a large-scale, real-world learning task and we additionally contrast to rule-based program synthesis, which uses hand-crafted semantics to guide the program generation. \nOur neural models use a modified attention RNN to allow encoding of variable-sized sets of I/O pairs, which achieve 92% accuracy on a real-world test set, compared to the 34% accuracy of the previous best neural synthesis approach. The synthesis model also outperforms a comparable induction model on this task, but we more importantly demonstrate that the strength of each approach is highly dependent on the evaluation metric and end-user application. Finally, we show that we can train our neural models to remain very robust to the type of noise expected in real-world data (e.g., typos), while a highly-engineered rule-based system fails entirely."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Visualizing and Understanding Multilayer Perceptron Models", "Title": "A Case Study in Speech Processing", "Abstract": "Despite the recent success of deep learning, the nature of the transformations they apply to the input features remains poorly understood. This study provides an empirical framework to study the encoding properties of node activations in various layers of the network, and to construct the exact function applied to each data point in the form of a linear transform. These methods are used to discern and quantify properties of feed-forward neural networks trained to map acoustic features to phoneme labels. We show a selective and nonlinear warping of the feature space, achieved by forming prototypical functions to account for the possible variation of each class. This study provides a joint framework where the properties of node activations and the functions implemented by the network can be linked together. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Innovation Pursuit", "Title": "A New Approach to the Subspace Clustering Problem", "Abstract": "This paper presents a new scalable approach, termed Innovation Pursuit (iPursuit), to the problem of subspace clustering. iPursuit rests on a new geometrical idea whereby each subspace is identified based on its novelty with respect to the other subspaces. The subspaces are identified consecutively by solving a series of simple linear optimization problems, each searching for a direction of innovation in the span of the data. A detailed mathematical analysis is provided establishing sufficient conditions for the proposed approach to correctly cluster the data points. Moreover, the proposed direction search approach can be integrated with spectral clustering to yield a new variant of spectral-clustering-based algorithms. Remarkably, the proposed approach can provably yield exact clustering even when the subspaces have significant intersections. The numerical simulations demonstrate that iPursuit can often outperform the state-of-the-art subspace clustering algorithms – more so for subspaces with significant intersections – along with substantial reductions in computational complexity."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Uncorrelation and Evenness", "Title": "a New Diversity-Promoting Regularizer", "Abstract": "Latent space models (LSMs) provide a principled and effective way to extract hidden patterns from observed data. To cope with two challenges in LSMs: (1) how to capture infrequent patterns when pattern frequency is imbalanced and (2) how to reduce model size without sacrificing their expressiveness, several studies have been proposed\nto \"diversify\" LSMs, which design regularizers to encourage the components therein to be \"diverse\". In light of the limitations of existing approaches, we design a new diversity-promoting regularizer by considering two factors: uncorrelation and evenness, which encourage the components to be uncorrelated and to play equally important roles in modeling data. Formally, this amounts to encouraging the covariance matrix of the components to have more uniform eigenvalues. We apply the regularizer to two LSMs and develop an efficient optimization algorithm. Experiments on healthcare, image and text data demonstrate the effectiveness of the regularizer."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Gradient Coding", "Title": "Avoiding Stragglers in Distributed Learning", "Abstract": "We propose a novel coding theoretic framework for mitigating stragglers in distributed learning. We show how carefully replicating data blocks and coding across gradients can provide tolerance to failures and stragglers for synchronous Gradient Descent. We implement our schemes in python (using MPI) to run on Amazon EC2, and show how we compare against baseline approaches in running time and generalization error."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Latent LSTM Allocation", "Title": "Joint clustering and non-linear dynamic modeling of sequence data", "Abstract": "Recurrent neural networks, such as long-short term memory (LSTM) networks, are powerful tools for modeling sequential data like user browsing history (Tan et al., 2016; Korpusik et al., 2016) or natural language text (Mikolov et al., 2010). However, to generalize across different user types, LSTMs require a large number of parameters, notwithstanding the simplicity of the underlying dynamics, rendering it uninterpretable, which is highly undesirable in user modeling. The increase in complexity and parameters arises due to a large action space in which many of the actions have similar intent or topic. In this paper, we introduce Latent LSTM Allocation (LLA) for user modeling combining hierarchical Bayesian models with LSTMs. In LLA, each user is modeled as a sequence of actions, and the model jointly groups actions into topics and learns the temporal dynamics over the topic sequence, instead of action space directly. This leads to a model that is highly interpretable, concise, and can capture intricate dynamics. We present an efficient Stochastic EM inference algorithm for our model that scales to millions of users/documents. Our experimental evaluations show that the proposed model compares favorably with several state-of-the-art baselines."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Sketched Ridge Regression", "Title": "Optimization Perspective, Statistical Perspective, and Model Averaging", "Abstract": "We address the statistical and optimization impacts of using classical sketch versus Hessian sketch to solve approximately the Matrix Ridge Regression (MRR) problem. Prior research has considered the effects of classical sketch on least squares regression (LSR), a strictly simpler problem. We establish that classical sketch has a similar effect upon the optimization properties of MRR as it does on those of LSR---namely, it recovers nearly optimal solutions. In contrast, Hessian sketch does not have this guarantee; instead, the approximation error is governed by a subtle interplay between the ``mass'' in the responses and the optimal objective value. For both types of approximations, the regularization in the sketched MRR problem gives it significantly different statistical properties from the sketched LSR problem. In particular, there is a bias-variance trade-off in sketched MRR that is not present in sketched LSR. We provide upper and lower bounds on the biases and variances of sketched MRR; these establish that the variance is significantly increased when classical sketches are used, while the bias is significantly increased when using Hessian sketches. Empirically, sketched MRR solutions can have risks that are higher by an order-of-magnitude than those of the optimal MRR solutions. We establish theoretically and empirically that model averaging greatly decreases this gap. Thus, in the distributed setting, sketching combined with model averaging is a powerful technique that quickly obtains near-optimal solutions to the MRR problem while greatly mitigating the statistical risks incurred by sketching."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "OptNet", "Title": "Differentiable Optimization as a Layer in Neural Networks", "Abstract": "This paper presents OptNet, a network architecture that integrates\n  optimization problems (here, specifically in the form of quadratic programs)\n  as individual layers in larger end-to-end trainable deep networks.\n  These layers encode constraints and complex dependencies\n  between the hidden states that traditional convolutional and\n  fully-connected layers often cannot capture.\n  In this paper, we explore the foundations for such an architecture:\n  we show how techniques from sensitivity analysis, bilevel\n  optimization, and implicit differentiation can be used to\n  exactly differentiate through these layers and with respect\n  to layer parameters;\n  we develop a highly efficient solver for these layers that exploits fast\n  GPU-based batch solves within a primal-dual interior point method, and which\n  provides backpropagation gradients with virtually no additional cost on top of\n  the solve;\n  and we highlight the application of these approaches in several problems.\n  In one notable example, we show that the method is\n  capable of learning to play mini-Sudoku (4x4) given just input and output games,\n  with no a priori information about the rules of the game;\n  this highlights the ability of our architecture to learn hard\n  constraints better than other neural architectures."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Clustering by Sum of Norms", "Title": "Stochastic Incremental Algorithm, Convergence and Cluster Recovery", "Abstract": "Standard clustering methods such as K-means,  Gaussian mixture models, and hierarchical clustering are beset by local minima, which are sometimes drastically suboptimal. Moreover the number of clusters K must be known in advance. The recently introduced the sum-of-norms (SON) or Clusterpath convex relaxation of k-means and hierarchical clustering shrinks cluster centroids toward one another and ensure a unique global minimizer. We give a scalable stochastic incremental algorithm based on proximal iterations to solve the SON problem with convergence guarantees. We also show that the algorithm recovers clusters under quite general conditions which have a similar form to the unifying proximity condition introduced in the approximation algorithms community (that covers paradigm cases such as Gaussian mixtures and planted partition models). We give experimental results to confirm that our algorithm scales much better than previous methods while producing clusters of comparable quality."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Joint Dimensionality Reduction and Metric Learning", "Title": "A Geometric Take", "Abstract": "To be tractable and robust to data noise, existing metric learning algorithms commonly rely on PCA as a pre-processing step. How can we know, however, that PCA, or any other specific dimensionality reduction technique, is the method of choice for the problem at hand? The answer is simple: We cannot! To address this issue, in this paper, \nwe develop a Riemannian framework to jointly learn a mapping performing dimensionality reduction and a metric in the induced space.\nOur experiments evidence that, while we directly work on high-dimensional features, our approach yields competitive runtimes with and higher accuracy than state-of-the-art metric learning algorithms."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "ProtoNN", "Title": "Compressed and Accurate kNN for Resource-scarce Devices", "Abstract": "Several real-world applications require real-time prediction on resource-scarce devices such as an Internet of Things (IoT) sensor. Such applications demand prediction models with small storage and computational complexity that do not compromise significantly on accuracy.  In this work, we propose ProtoNN, a novel algorithm that addresses the problem of real-time and accurate prediction on resource-scarce devices. ProtoNN is inspired by k-Nearest Neighbor (KNN) but has several orders lower storage and prediction complexity. ProtoNN models can be deployed even on devices with puny storage and computational power (e.g. an Arduino UNO with 2kB RAM) to get excellent prediction accuracy. \nProtoNN derives its strength from three key ideas: a) learning a small number of prototypes to represent the entire training set, b) sparse low dimensional projection of data, c) joint discriminative learning of the projection and prototypes with explicit model size constraint. We conduct systematic empirical evaluation of ProtoNN on a variety of supervised learning tasks (binary, multi-class, multi-label classification) and show that it gives nearly state-of-the-art prediction accuracy on resource-scarce devices while consuming several orders lower storage, and using minimal working memory. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Fractional Langevin Monte Carlo", "Title": "Exploring Levy Driven Stochastic Differential Equations for MCMC", "Abstract": "Along with the recent advances in scalable Markov Chain Monte Carlo methods, sampling techniques that are based on Langevin diffusions have started receiving increasing attention. These so called Langevin Monte Carlo (LMC) methods are based on diffusions driven by a Brownian motion, which gives rise to Gaussian proposal distributions in the resulting algorithms. Even though these approaches have proven successful in many applications, their performance can be limited by the light-tailed nature of the Gaussian proposals. In this study, we extend classical LMC and develop a novel Fractional LMC (FLMC) framework that is based on a family of heavy-tailed distributions, called alpha-stable Levy distributions. As opposed to classical approaches, the proposed approach can possess large jumps while targeting the correct distribution, which would be beneficial for efficient exploration of the state space. We develop novel computational methods that can scale up to large-scale problems and we provide formal convergence analysis of the proposed scheme. Our experiments support our theory: FLMC can provide superior performance in multi-modal settings, improved convergence rates, and robustness to algorithm parameters. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Priv’IT", "Title": "Private and Sample Efficient Identity Testing", "Abstract": "We develop differentially private hypothesis testing methods for the small sample regime. Given a sample D from a categorical distribution p over some domain Sigma, an explicitly described distribution q over Sigma, some privacy parameter epsilon, accuracy parameter alpha, and requirements betaI$ and  betaII for the type I and type II errors of our test, the goal is to distinguish between p=q and dtv(p,q) > alpha. We provide theoretical bounds for the sample size |D| so that our method both satisfies (epsilon,0)-differential privacy, and guarantees betaI and betaII type I and type II errors. We show that differential privacy may come for free in some regimes of parameters, and we always beat the sample complexity resulting from running the chi^2-test with noisy counts, or standard approaches such as repetition for endowing non-private chi^2-style statistics with differential privacy guarantees. We experimentally compare  the sample complexity of our method to that of recently proposed methods for private hypothesis testing."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Learning from Clinical Judgments", "Title": "Semi-Markov-Modulated Marked Hawkes Processes for Risk Prognosis", "Abstract": "Critically ill patients in regular wards are vulnerable to unanticipated adverse events which require prompt transfer to the intensive care unit (ICU). To allow for accurate prognosis of deteriorating patients, we develop a novel continuous-time probabilistic model for a monitored patient's temporal sequence of physiological data. Our model captures \"informatively sampled\" patient episodes: the clinicians' decisions on when to observe a hospitalized patient's vital signs and lab tests over time are represented by a marked Hawkes process, with intensity parameters that are modulated by the patient's latent clinical states, and with observable physiological data (mark process) modeled as a switching multi-task Gaussian process. In addition, our model captures \"informatively censored\" patient episodes by representing the patient's latent clinical states as an absorbing semi-Markov jump process. The model parameters are learned from offline patient episodes in the electronic health records via an EM-based algorithm. Experiments conducted on a cohort of patients admitted to a major medical center over a 3-year period show that risk prognosis based on our model significantly outperforms the currently deployed medical risk scores and other baseline machine learning algorithms."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "MEC", "Title": "Memory-efficient Convolution for Deep Neural Network", "Abstract": "Convolution  is a critical component in modern deep neural networks, thus several algorithms for convolution have been developed.\nDirect convolution is simple but suffers from poor performance. As an alternative, multiple indirect\nmethods have been proposed including im2col-based convolution,\nFFT-based convolution, or Winograd-based algorithm.\nHowever, all these indirect methods have high memory overhead,\nwhich  creates performance degradation and offers a poor trade-off between performance and memory consumption.\nIn this work, we propose a memory-efficient convolution or MEC with compact lowering,\nwhich  reduces memory overhead substantially and accelerates convolution process.\nMEC lowers the input matrix in a simple yet efficient/compact way (i.e., much less memory overhead), and then\nexecutes  multiple small matrix multiplications in parallel to get convolution completed.\nAdditionally, the reduced memory footprint improves memory sub-system efficiency, improving performance.\nOur experimental results show that MEC reduces memory consumption significantly with\ngood speedup on both mobile and server platforms, compared with other indirect convolution algorithms."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Differentially Private Submodular Maximization", "Title": "Data Summarization in Disguise", "Abstract": "Many data summarization applications are captured by the general framework of submodular maximization. As a consequence,  a wide range of efficient approximation algorithms have been developed. However, when such applications involve sensitive data about individuals, their privacy concerns are not automatically addressed. To remedy this problem, we propose a general and systematic study of differentially private submodular maximization. We present privacy-preserving algorithms for both monotone and non-monotone submodular maximization under cardinality, matroid, and p-extendible system constraints, with guarantees that are competitive with optimal. Along the way, we analyze a new algorithm for non-monotone submodular maximization, which is the first (even non-privately) to achieve a constant approximation ratio while running in linear time. We additionally provide two concrete experiments to validate the efficacy of these algorithms. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Beyond Filters", "Title": "Compact Feature Map for Portable Deep Model", "Abstract": "Convolutional neural networks (CNNs) have shown extraordinary performance in a number of applications, but they are usually of heavy design for the accuracy reason. Beyond compressing the filters in CNNs, this paper focuses on the redundancy in the feature maps derived from the large number of filters in a layer. We propose to extract intrinsic representation of the feature maps and preserve the discriminability of the features. Circulant matrix is employed to formulate the feature map transformation, which only requires O(dlog d) computation complexity to embed a d-dimensional feature map. The filter is then re-configured to establish the mapping from original input to the new compact feature map, and the resulting network can preserve intrinsic information of the original network with significantly fewer parameters, which not only decreases the online memory for launching CNN but also accelerates the computation speed. Experiments on benchmark image datasets demonstrate the superiority of the proposed algorithm over state-of-the-art methods."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "iSurvive", "Title": "An Interpretable, Event-time Prediction Model for mHealth", "Abstract": "An important mobile health (mHealth) task is the use of multimodal data, such as sensor streams and self-report, to construct interpretable time-to-event predictions of, for example, lapse to alcohol or illicit drug use.  Interpretability of the prediction model is important for acceptance and adoption by domain scientists, enabling model outputs and parameters to inform theory and guide intervention design.  Temporal latent state models are therefore attractive, and so we adopt the continuous time hidden Markov model (CT-HMM) due to its ability to describe irregular arrival times of event data.  Standard CT-HMMs, however, are not specialized for predicting the time to a future event, the key variable for mHealth interventions.  Also, standard emission models lack a sufficiently rich structure to describe multimodal data and incorporate domain knowledge.  We present iSurvive, an extension of classical survival analysis to a CT-HMM.  We present a parameter learning method for GLM emissions and survival model fitting, and present promising results on both synthetic data and an mHealth drug use dataset."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Learning Sleep Stages from Radio Signals", "Title": "A Conditional Adversarial Architecture", "Abstract": "We focus on predicting sleep stages from radio measurements without any attached sensors on subjects. \nWe introduce a new predictive model that combines convolutional and recurrent neural networks to extract sleep-specific subject-invariant features from RF signals and capture the temporal progression of sleep.  A key innovation underlying our approach is a modified adversarial training regime that discards extraneous information specific to individuals or measurement conditions, while retaining all information relevant to the predictive task.\nWe analyze our game theoretic setup and empirically demonstrate that our model achieves significant improvements over state-of-the-art solutions."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "The Predictron", "Title": "End-To-End Learning and Planning", "Abstract": "One of the key challenges of artificial intelligence is to learn models that are effective in the context of planning. In this document we introduce the predictron architecture. The predictron consists of a fully abstract model, represented by a Markov reward process, that can be rolled forward multiple \"imagined\" planning steps. Each forward pass of the predictron accumulates internal rewards and values over multiple planning depths. The predictron is trained end-to-end so as to make these accumulated values accurately approximate the true value function. We applied the predictron to procedurally generated random mazes and a simulator for the game of pool. The predictron yielded significantly more accurate predictions than conventional deep neural network architectures."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Soft-DTW", "Title": "a Differentiable Loss Function for Time-Series", "Abstract": "We propose in this paper a differentiable learning loss between time series, building upon the celebrated dynamic time warping (DTW) discrepancy. Unlike the Euclidean distance, DTW can compare time series of variable size and is robust to shifts or dilatations across the time dimension. To compute DTW, one typically solves a minimal-cost alignment problem between two time series using dynamic programming. Our work takes advantage of a smoothed formulation\nof DTW, called soft-DTW, that computes the soft-minimum of all alignment costs. We show in this paper that soft-DTW is a \\emph{differentiable} loss function, and that both its value and gradient can be computed with quadratic time/space complexity (DTW has quadratic time but linear space complexity). We show that this regularization is particularly well suited to average and cluster time series under the DTW geometry, a task for which our proposal\nsignificantly outperforms existing baselines~\\citep{petitjean2011global}. Next, we propose to tune the parameters of a machine that outputs time series by minimizing its fit with ground-truth labels in a soft-DTW sense. Source code is available at \\url{https://github.com/mblondel/soft-dtw}."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Averaged-DQN", "Title": "Variance Reduction and Stabilization for Deep Reinforcement Learning", "Abstract": "Instability and variability of Deep Reinforcement\nLearning (DRL) algorithms tend to adversely affect\ntheir performance. Averaged-DQN is a simple\nextension to the DQN algorithm, based on\naveraging previously learned Q-values estimates,\nwhich leads to a more stable training procedure\nand improved performance by reducing approximation\nerror variance in the target values. To understand\nthe effect of the algorithm, we examine\nthe source of value function estimation errors and\nprovide an analytical comparison within a simplified\nmodel. We further present experiments\non the Arcade Learning Environment benchmark\nthat demonstrate significantly improved stability\nand performance due to the proposed extension."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Estimating individual treatment effect", "Title": "generalization bounds and algorithms", "Abstract": "There is intense interest in applying machine learning to problems of causal inference in fields such as healthcare, economics and education. In particular, individual-level causal inference has important applications such as precision medicine. We give a new theoretical analysis and family of algorithms for predicting individual treatment effect (ITE) from observational data, under the assumption known as strong ignorability. The algorithms learn a ``balanced'' representation such that the induced treated and control distributions look similar, and we give a novel and intuitive generalization-error bound showing the expected ITE estimation error of a representation is bounded by a sum of the standard generalization-error of that representation and the distance between the treated and control distributions induced by the representation. We use Integral Probability Metrics to measure distances between distributions, deriving explicit bounds for the Wasserstein and Maximum Mean Discrepancy (MMD) distances. Experiments on real and simulated data show the new algorithms match or outperform the state-of-the-art."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Deletion-Robust Submodular Maximization", "Title": "Data Summarization with \"the Right to be Forgotten\"", "Abstract": "How can we summarize a dynamic data stream when elements selected for the summary can be deleted at any time? This is an important challenge in online services, where the users generating the data may decide to exercise their right to restrict the service provider from using (part of) their data due to privacy concerns. Motivated by this challenge, we introduce the dynamic deletion-robust submodular maximization problem. We develop the first resilient streaming algorithm, called ROBUST-STREAMING, with a constant factor approximation guarantee to the optimum solution. We evaluate the effectiveness of our approach on several real-world applica tions, including summarizing (1) streams of geo-coordinates (2); streams of images; and (3) click-stream log data, consisting of 45 million feature vectors from a news recommendation task."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "World of Bits", "Title": "An Open-Domain Platform for Web-Based Agents", "Abstract": "While simulated game environments have greatly accelerated research in reinforcement learning, existing environments lack the open-domain realism of tasks in computer vision or natural language processing, which operate on artifacts created by humans in natural, organic settings. To foster reinforcement learning research in such settings, we introduce the World of Bits (WoB), a platform in which agents complete tasks on the Internet by performing low-level keyboard and mouse actions. The two main challenges are: (i) to curate a large, diverse set of interesting web-based tasks, and (ii) to ensure that these tasks have a well-defined reward structure and are reproducible despite the transience of the web. To do this, we develop a methodology in which crowdworkers create tasks defined by natural language questions and provide demonstrations of how to answer the question on real websites using keyboard and mouse; HTTP traffic is cached to create a reproducible offline approximation of the web site. Finally, we show that agents trained via behavioral cloning and reinforcement learning can successfully complete a range of our web-based tasks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Deciding How to Decide", "Title": "Dynamic Routing in Artificial Neural Networks", "Abstract": "We propose and systematically evaluate three strategies for training dynamically-routed artificial neural networks: graphs of learned transformations through which different input signals may take different paths. Though some approaches have advantages over others, the resulting networks are often qualitatively similar. We find that, in dynamically-routed networks trained to classify images, layers and branches become specialized to process distinct categories of images. Additionally, given a fixed computational budget, dynamically-routed networks tend to perform better than comparable statically-routed networks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Deeply AggreVaTeD", "Title": "Differentiable Imitation Learning for Sequential Prediction", "Abstract": "Recently, researchers have demonstrated state-of-the-art performance on sequential prediction problems using deep neural networks and Reinforcement Learning (RL). For some of these problems, oracles that can demonstrate good performance may be available during training, but are not used by plain RL methods. To take advantage of this extra information, we propose AggreVaTeD, an extension of the Imitation Learning (IL) approach of Ross & Bagnell (2014). AggreVaTeD allows us to use expressive differentiable policy representations such as deep networks, while leveraging training-time oracles to achieve faster and more accurate solutions with less training data. Specifically, we present two gradient procedures that can learn neural network policies for several problems, including a sequential prediction task and several high-dimensional robotics control problems. We also provide a comprehensive theoretical study of IL that demonstrates that we can expect up to exponentially-lower sample complexity for learning with AggreVaTeD than with plain RL algorithms. Our results and theory indicate that IL (and AggreVaTeD in particular) can be a more effective strategy for sequential prediction than plain RL. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "Deep IV", "Title": "A Flexible Approach for Counterfactual Prediction", "Abstract": "Counterfactual prediction requires understanding causal relationships between so-called treatment and outcome variables. This paper provides a recipe for augmenting deep learning methods to accurately characterize such relationships in the presence of instrument variables (IVs) -- sources of treatment randomization that are conditionally independent from the outcomes.  Our IV specification resolves into two prediction tasks that can be solved with deep neural nets: a first-stage network for treatment prediction and a second-stage network whose  loss function involves integration over the conditional treatment distribution.  This Deep IV framework allows us to take advantage of off-the-shelf supervised learning techniques to estimate causal effects by adapting the loss function. Experiments show that it outperforms existing machine learning approaches. "}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "ICML", "Abbreviation": "ZipML", "Title": "Training Linear Models with End-to-End Low Precision, and a Little Bit of Deep Learning", "Abstract": "Recently there has been significant interest in training machine-learning models at low precision: by reducing precision, one can reduce computation and communication by one order of magnitude. We examine training at reduced precision, both from a theoretical and practical perspective, and ask: is it possible to train models at end-to-end low precision with provable guarantees? Can this lead to consistent order-of-magnitude speedups? We mainly focus on linear models, and the answer is yes for linear models. We develop a simple framework called ZipML based on one simple but novel strategy called double sampling. Our ZipML framework is able to execute training at low precision with no bias, guaranteeing convergence, whereas naive quantization would introduce significant bias. We validate our framework across a range of applications, and show that it enables an FPGA prototype that is up to 6.5× faster than an implementation using full 32-bit precision. We further develop a variance-optimal stochastic quantization strategy and show that it can make a significant difference in a variety of settings. When applied to linear models together with double sampling, we save up to another 1.7× in data movement compared with uniform quantization. When training deep networks with quantized models, we achieve higher accuracy than the state-of-the-art XNOR-Net."}
