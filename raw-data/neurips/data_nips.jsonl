{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spatial Organization of Neural Networks", "Title": "A Probabilistic Modeling Approach", "Abstract": "The  aim  of  this  paper  is  to  explore  the  spatial  organization  of  neural  networks  under  Markovian  assumptions,  in  what  concerns  the be(cid:173) haviour  of  individual  cells  and  the  interconnection  mechanism.  Space(cid:173) organizational  properties  of  neural  nets  are  very  relevant  in  image  modeling  and  pattern  analysis,  where  spatial  computations  on  stocha(cid:173) stic  two-dimensional  image  fields  are  involved.  As  a  first  approach  we  develop  a  random  neural  network  model,  based  upon  simple  probabi(cid:173) listic  assumptions,  whose  organization  is  studied  by  means  of  dis(cid:173) crete-event  simulation.  We  then  investigate  the  possibility  of  ap(cid:173) proXimating  the  random  network's  behaviour  by  using  an  analytical  ap(cid:173) proach  originating  from  the  theory  of  general  product-form  queueing  networks.  The  neural  network  is  described  by  an  open  network  of  no(cid:173) des,  in  which  customers  moving  from  node  to  node  represent  stimula(cid:173) tions  and  connections  between  nodes  are  expressed  in  terms  of  sui(cid:173) tably  selected  routing  probabilities.  We  obtain  the  solution  of  the  model  under  different  disciplines  affecting  the  time  spent  by  a  sti(cid:173) mulation  at  each  node  visited.  Results  concerning  the  distribution  of  excitation  in  the  network  as  a  function  of  network  topology  and  external  stimulation  arrival  pattern  are  compared  with  measures  ob(cid:173) tained  from  the  simulation  and  validate  the  approach  followed."}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimization with Artificial Neural Network Systems", "Title": "A Mapping Principle and a Comparison to Gradient Based Methods", "Abstract": "equations  associated with artificial  neural  networks  are  presented.  A comparison is  made  to  optim(cid:173) ization using gradient-search methods.  The perfonnance  measure  is  the  settling time  from  an  initial  state  to  a  target  state.  A  simple  analytical  example  illustrates  a situation  where  dynamical  systems  representing  artificial  neural  network  methods  would  settle  faster  than  those  representing  gradient(cid:173) search.  Settling  time  was  investigated  for  a  more  complicated  optimization  problem  using  com(cid:173) puter  simulations.  The  problem  was  a  simplified  version  of a problem  in  medical  imaging:  deter(cid:173) mining  loci  of cerebral  activity  from  electromagnetic  measurements  at  the  scalp.  The  simulations  showed  that  gradient  based  systems  typically  settled  50  to  100  times  faster  than  systems  based  on  current neural  network optimization methods."}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Computer Simulation of Cerebral Neocortex", "Title": "Computational Capabilities of Nonlinear Neural Networks", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cycles", "Title": "A Simulation Tool for Studying Cyclic Neural Networks", "Abstract": "networks containing cyclic connection paths with  the aid of a  powerful graphics(cid:173) based interface.  Numerous cycles have been studied, including cycles with one or  more activation points, non-interruptible cycles, cycles with variable path lengths,  and interacting cycles.  The final  class,  interacting cycles,  is  important due to its  ability to implement time-dependent goal processing in neural networks."}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HOW THE CATFISH TRACKS ITS PREY", "Title": "AN INTERACTIVE \"PIPELINED\" PROCESSING SYSTEM MAY DIRECT FORAGING VIA RETICULOSPINAL NEURONS", "Abstract": "of"}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MURPHY", "Title": "A Robot that Learns by Doing", "Abstract": "MURPHY consists of a camera looking at a robot arm, with a connectionist network  architecture situated in between. By moving its arm through a small, representative  sample of the 1 billion possible joint configurations, MURPHY learns the relationships,  backwards and forwards, between the positions of its joints and the state of its visual field.  MURPHY can use its internal model in the forward direction to \"envision\" sequences  of actions for planning purposes, such as in grabbing a visually presented object, or in  the reverse direction to \"imitate\", with its arm, autonomous activity in its visual field.  Furthermore, by taking explicit advantage of continuity in the mappings between visual  space and joint space, MURPHY is able to learn non-linear mappings with only a single  layer of modifiable weights."}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "An Artificial Neural Network for Spatio-Temporal Bipolar Patterns", "Title": "Application to Phoneme Classification", "Abstract": "An  artificial  neural  network  is  developed  to  recognize  spatio-temporal  bipolar patterns  associatively.  The  function  of a formal  neuron is  generalized by  replacing  multiplication  with  convolution,  weights  with  transfer  functions,  and  thresholding  with  nonlinear  transform  following  adaptation.  The Hebbian  learn(cid:173) ing  rule  and  the  delta  learning  rule  are  generalized  accordingly,  resulting  in  the  learning  of weights  and  delays.  The  neural  network  which  was  first  developed  for  spatial  patterns  was  thus  generalized  for  spatio-temporal  patterns.  It  was  tested  using  a  set  of bipolar input patterns  derived from  speech  signals,  showing  robust classification of 30 model phonemes."}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Teaching Artificial Neural Systems to Drive", "Title": "Manual Training Techniques for Autonomous Systems", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Networks for Template Matching", "Title": "Application to Real-Time Classification of the Action Potentials of Real Neurons", "Abstract": "extracellulary  sampled  neural  signals  (i .e.  action  potentials)  recorded  from  the  brains  of ex(cid:173) perimental animals.  In  most  neurophysiology  laboratories this classification  task  is  simplified  by  limiting  investigations  to  single,  electrically  well-isolated  neurons recorded  one  at  a  time.  However, for those interested in sampling the activities of many single neurons simultaneously,  waveform  classification  becomes  a  serious  concern.  In  this  paper  we  describe  and  constrast  three  approaches  to  this  problem  each  designed  not  only  to  recognize  isolated  neural  events,  but also  to separately classify temporally overlapping events in real time.  First we  present two  formulations  of  waveform  classification  using  a  neural network  template  matching  approach.  These  two  formulations  are  then  compared  to  a  simple  template  matching  implementation.  Analysis with real neural signals reveals  that simple template matching is  a  better solution to  this  problem  than either neural network  approach."}
{"Type": "conference", "Year": "1987", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Minkowski-r Back-Propagation", "Title": "Learning in Connectionist Models with Non-Euclidian Error Signals", "Abstract": "Many connectionist learning models are implemented using a gradient descent  in a least squares error function of the output and teacher signal.  The present model  Fneralizes. in particular. back-propagation [1]  by using Minkowski-r power metrics.  For  small  r's  a  \"city-block\"  error  metric  is  approximated  and  for  large  r's  the  \"maximum\" or \"supremum\"  metric is  approached.  while  for r=2  the  standard  back(cid:173) propagation  model  results.  An  implementation  of Minkowski-r back-propagation  is  described.  and  several  experiments  are  done  which  show  that  different values  of r  may be desirable for various purposes. Different r values may be appropriate for the  reduction  of  the  effects  of outliers  (noise).  modeling  the  input  space  with  more  compact clusters. or modeling  the statistics of a particular domain more naturally or  in a way that may be more perceptually or psychologically meaningful (e.g. speech or  vision)."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Control of Sensory Acquisition", "Title": "The Vestibulo-Ocular Reflex", "Abstract": "We present a new hypothesis that the cerebellum plays a key role in ac(cid:173) tively controlling the acquisition of sensory infonnation by the nervous  system.  In this paper we explore this idea by examining the function of  a  simple  cerebellar-related  behavior,  the  vestibula-ocular  reflex  or  VOR, in  which  eye movements  are generated to minimize image slip  on  the  retina  during  rapid  head  movements.  Considering  this  system  from  the point of view of statistical estimation theory, our results  sug(cid:173) gest that the transfer function of the VOR, often regarded as a static or  slowly  modifiable  feature  of the  system,  should  actually  be  continu(cid:173) ously and rapidly changed during head movements. We further suggest  that these changes are under the direct control of the cerebellar cortex  and propose experiments to test this hypothesis."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Boltzmann Perceptron Network", "Title": "A Multi-Layered Feed-Forward Network Equivalent to the Boltzmann Machine", "Abstract": "The  concept  of  the  stochastic  Boltzmann  machine  (BM)  is  auractive  for  decision  making  and  pattern  classification  purposes  since  the  probability  of  attaining  the network  states  is a  function  of the network energy.  Hence,  the  probability of attaining particular energy minima  may be associated  with  the  probabilities  of  making  certain  decisions  (or  classifications).  However,  because of its stochastic  nature,  the complexity of the BM is fairly  high and  therefore  such  networks  are  not  very  likely  to  be  used  in  practice.  In  this  paper  we  suggest  a  way  to  alleviate  this  drawback  by  converting  the  sto(cid:173) chastic  BM into  a  deterministic  network  which  we  call  the  Boltzmann  Per(cid:173) ceptron  Network  (BPN).  The BPN is functionally  equivalent  to  the  BM but  has  a  feed-forward  structure  and  low  complexity.  No annealing  is required.  The  conditions  under  which  such  a  convmion  is  feasible  are  given.  A  learning  algorithm  for  the  BPN based  on  the  conjugate  gradient  method  is  also provided which is somewhat akin  to the backpropagation algorithm."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Skeletonization", "Title": "A Technique for Trimming the Fat from a Network via Relevance Assessment", "Abstract": "This paper proposes a means of using the knowledge in a network to  determine the functionality or relevance of individual units, both for  the purpose of understanding the network's behavior and improving its  performance. The basic idea is to iteratively train the network to a cer(cid:173) tain performance criterion, compute a measure of relevance that identi(cid:173) fies which input or hidden units are most critical to performance, and  automatically trim the least relevant units. This skeletonization tech(cid:173) nique can be used to simplify networks by eliminating units that con(cid:173) vey redundant information; to improve learning performance by first  learning with spare hidden units and then trimming the unnecessary  ones away, thereby constraining generalization; and to understand the  behavior of networks in terms of minimal \"rules.\""}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Linear Learning", "Title": "Landscapes and Algorithms", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GENESIS", "Title": "A System for Simulating Neural Networks", "Abstract": "intended  for  use"}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ALVINN", "Title": "An Autonomous Land Vehicle in a Neural Network", "Abstract": "ALVINN (Autonomous Land Vehicle In a Neural Network) is a 3-layer  back-propagation network designed for the task of road following. Cur(cid:173) rently ALVINN takes images from a camera and a laser range finder as input  and produces as output the direction the vehicle should travel in order to  follow the road. Training has been conducted using simulated road images.  Successful tests on the Carnegie Mellon autonomous navigation test vehicle  indicate that the network can effectively follow real roads under certain field  conditions. The representation developed to perfOIm the task differs dra(cid:173) matically when the networlc is trained under various conditions, suggesting  the possibility of a novel adaptive autonomous navigation system capable of  tailoring its processing to the conditions at hand."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GEMINI", "Title": "Gradient Estimation Through Matrix Inversion After Noise Injection", "Abstract": "Learning procedures that measure how random perturbations of unit ac(cid:173) tivities correlate with changes in reinforcement are inefficient but simple  to implement in hardware. Procedures like back-propagation (Rumelhart,  Hinton and Williams, 1986) which compute how changes in activities af(cid:173) fect the output error are much more efficient, but require more complex  hardware. GEMINI is a hybrid procedure for multilayer networks, which  shares many of the implementation advantages of correlational reinforce(cid:173) ment procedures but is more efficient. GEMINI injects noise only at the  first hidden layer and measures the resultant effect on the output error.  A linear network associated with each hidden layer iteratively inverts the  matrix which relates the noise to the error change, thereby obtaining  the error-derivatives. No back-propagation is involved, thus allowing un(cid:173) known non-linearities in the system. Two simulations demonstrate the  effectiveness of GEMINI."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Speech Recognition", "Title": "Statistical and Neural Information Processing Approaches", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Models of Ocular Dominance Column Formation", "Title": "Analytical and Computational Results", "Abstract": "cal model  for  formation  of ocular  dominance  columns  in  mammalian  visual  cortex.  The  model  provides  a  com(cid:173) mon framework  in  which a  variety  of activity-dependent  biological machanisms can be studied.  Analytic and com(cid:173) putational  results  together  now  reveal  the  following:  if  inputs  specific  to  each eye  are  locally  correlated  in  their  firing,  and are not  anticorrelated within an arbor radius,  monocular  cells  will  robustly  form  and  be  organized  by  intra-cortical  interactions  into  columns.  Broader  corre(cid:173) lations  withln  each  eye,  or anti-correlations  between the  eyes, create a  more purely monocular cortex; positive cor(cid:173) relation  over  an  arbor  radius  yields  an  almost  perfectly  monocular cortex.  Most features of the model can be un(cid:173) derstood  analytically  through  decomposition  into  eigen(cid:173) functions and linear stability analysis.  This allows predic(cid:173) tion of the widths of the columns and other features from  measurable biological parameters."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Further Explorations in Visually-Guided Reaching", "Title": "Making MURPHY Smarter", "Abstract": "MURPHY  is  a  vision-based  kinematic  controller  and  path  planner  based  on  a  connectionist  architecture,  and  implemented  with  a  video  camera and  Rhino XR-series robot  arm.  Imitative of the layout of sen(cid:173) sory  and motor maps in  cerebral cortex,  MURPHY'S internal representa(cid:173) tions  consist of four  coarse-coded populations of simple units represent(cid:173) ing both static and  dynamic aspects of the sensory-motor environment.  In previously reported work [4],  MURPHY first  learned a direct kinematic  model of his  camera-arm system during  a  period  of extended  practice,  and  then  used  this  \"mental  model\"  to  heuristically  guide  his  hand  to  unobstructed  visual  targets.  MURPHY  has  since  been  extended  in  two  ways:  First, he  now  learns the inverse differential-kinematics of his  arm  in  addition to ordinary direct  kinematics, which  allows  him to push  his  hand  directly towards  a  visual  target  without  the need  for  search.  Sec(cid:173) ondly,  he now  deals with the much more difficult problem of reaching in  the presence of obstacles."}
{"Type": "conference", "Year": "1988", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scaling and Generalization in Neural Networks", "Title": "A Case Study", "Abstract": "The  issues  of scaling  and  generalization  have  emerged  as  key  issues  in  current studies of supervised learning from examples in neural networks.  Questions such  as  how  many  training  patterns  and  training  cycles  are  needed for  a problem of a given size  and difficulty,  how  to represent the  inllUh  and how  to choose useful training exemplars,  are of considerable  theoretical  and  practical  importance.  Several  intuitive  rules  of thumb  have been obtained from empirical studies, but as yet there are few  rig(cid:173) orous  results.  In  this  paper we  summarize  a  study Qf generalization in  the simplest possible case-perceptron networks learning linearly separa(cid:173) ble  functions.  The  task  chosen  was  the majority function  (i.e.  return  a  1  if a  majority  of the  input  units  are  on),  a  predicate  with  a  num(cid:173) ber  of useful  properties.  We  find  that  many  aspects  of.generalization  in  multilayer  networks  learning  large,  difficult  tasks  are  reproduced  in  this simple domain, in which  concrete numerical results and even some  analytic understanding can be achieved."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Development and Regeneration of Eye-Brain Maps", "Title": "A Computational Model", "Abstract": "We outline a computational model  of the development and regenera(cid:173) tion of specific eye-brain circuits. The model comprises a self-organiz(cid:173) ing map-forming network which uses local Hebb rules. constrained by  molecular markers.  Various  simulations of the development of eye(cid:173) brain maps in fish and frogs are described."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predicting Weather Using a Genetic Memory", "Title": "A Combination of Kanerva's Sparse Distributed Memory with Holland's Genetic Algorithms", "Abstract": "Kanerva's  sparse distributed  memory  (SDM)  is  an  associative-memo(cid:173) ry  model  based  on  the  mathematical  properties  of  high-dimensional  binary address  spaces.  Holland's genetic  algorithms are  a  search  tech(cid:173) nique  for  high-dimensional  spaces  inspired  by  evolutionary  processes  of DNA.  \"Genetic  Memory\"  is  a  hybrid  of the  above  two  systems,  in  which  the  memory  uses  a  genetic  algorithm  to  dynamically  recon(cid:173) figure  its  physical  storage  locations  to  reflect  correlations  between  the  stored  addresses  and  data.  For  example,  when  presented  with  raw  weather station  data,  the  Genetic  Memory  discovers  specific  fea(cid:173) tures  in  the  weather  data  which  correlate  well  with  upcoming  rain,  and  reconfigures  the  memory  to  utilize  this  information  effectively.  This  architecture  is  designed  to  maximize  the  ability  of the  system  to scale-up to handle real-world problems."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Networks", "Title": "The Early Days", "Abstract": "A short account is  given of various  investigations of neural  network  properties,  beginning  with  the  classic  work of McCulloch  & Pitts.  Early work on neurodynamics and statistical mechanics, analogies with  magnetic materials, fault tolerance via parallel distributed processing,  memory, learning,  and pattern recognition,  is described."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Acoustic-Imaging Computations by Echolocating Bats", "Title": "Unification of Diversely-Represented Stimulus Features into Whole Images", "Abstract": "the  same  psychological"}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neuronal Group Selection Theory", "Title": "A Grounding in Robotics", "Abstract": "(1 - p)N  (see  Fig.  1)."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Computational Efficiency", "Title": "A Common Organizing Principle for Parallel Computer Maps and Brain Maps?", "Abstract": "It is  well-known  that  neural  responses  in  particular  brain  regions  are  spatially  organized,  but  no  general  principles  have  been  de(cid:173) veloped  that  relate  the structure of a  brain  map  to  the nature of  the associated computation.  On parallel computers, maps of a sort  quite similar to brain maps arise when a computation is distributed  across  multiple  processors.  In  this  paper  we  will  discuss  the rela(cid:173) tionship  between  maps and computations on these  computers and  suggest how similar considerations might also apply to maps in the  brain."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization and Parameter Estimation in Feedforward Nets", "Title": "Some Experiments", "Abstract": "We have done an empirical study of the relation of the number of  parameters (weights) in a feedforward net to generalization perfor(cid:173) mance. Two experiments are reported. In one, we use simulated data  sets with well-controlled parameters, such as the signal-to-noise ratio  of continuous-valued data. In the second, we train the network on  vector-quantized mel cepstra from real speech samples. In each case,  we use back-propagation to train the feedforward net to discriminate in  a multiple class pattern classification problem. We report the results of  these studies, and show the application of cross-validation techniques  to prevent overfitting."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sigma-Pi Learning", "Title": "On Radial Basis Functions and Cortical Associative Learning", "Abstract": "The  goal  in  this  work  has  been  to  identify  the  neuronal  elements  of the cortical column that are most likely to support  the learning  of nonlinear associative  maps.  We show that  a  particular style  of  network learning algorithm based on locally-tuned  receptive fields  maps  naturally  onto cortical  hardware,  and  gives  coherence  to  a  variety of features  of cortical anatomy,  physiology,  and  biophysics  whose  relations to learning remain poorly understood."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Effect of Catecholamines on Performance", "Title": "From Unit to System Behavior", "Abstract": "At the level of individual neurons. catecholamine release increases  the  responsivity  of cells  to  excitatory and  inhibitory  inputs.  We  present a  model  of catecholamine effects  in  a  network  of neural-like  elements.  We  argue  that  changes  in  the  responsivity  of individual  elements  do  not  affect  their  ability  to  detect  a  signal  and  ignore  noise.  However.  the same changes in cell responsivity in a network of such elements do  improve the signal detection performance of the network as a whole.  We  show how  this result can be used in a computer simulation of behavior  to  account  for  the  effect  of eNS  stimulants  on  the  signal  detection  performance of human subjects."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dataflow Architectures", "Title": "Flexible Platforms for Neural Network Simulation", "Abstract": "Dataflow Architectures:  Flexible Platforms for Neural Network Simulation"}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Asymptotic Convergence of Backpropagation", "Title": "Numerical Experiments", "Abstract": "We  have  calculated, both analytically and in simulations,  the rate  of convergence  at  long  times  in  the  backpropagation learning  al(cid:173) gorithm  for  networks  with  and  without  hidden  units.  Our  basic  finding for units using the standard sigmoid transfer function is  lit  convergence of the  error for  large t,  with  at most logarithmic cor(cid:173) rections  for  networks  with  hidden  units.  Other transfer functions  may lead to a  8lower polynomial rate of convergence.  Our analytic  calculations were presented in (Tesauro, He &  Ahamd, 1989).  Here  we  focus  in more detail on our empirical measurements of the con(cid:173) vergence rate in numerical simulations,  which  confirm our analytic  results."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analog Neural Networks of Limited Precision I", "Title": "Computing with Multilinear Threshold Functions", "Abstract": "703"}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Implementation of Motivated Behavior", "Title": "Feeding in an Artificial Insect", "Abstract": "Most  complex  behaviors  appear  to be governed  by  internal  moti(cid:173) vational  states or  drives  that  modify  an  animal's  responses  to  its  environment.  It is  therefore of considerable  interest to understand  the  neural basis of these  motivational states.  Drawing upon work  on  the  neural  basis  of feeding  in  the  marine  mollusc  Aplysia,  we  have  developed  a  heterogeneous  artificial  neural  network  for  con(cid:173) trolling the feeding behavior of a simulated insect.  We demonstrate  that feeding in this artificial insect shares many characteristics with  the motivated behavior of natural animals."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Cocktail Party Problem", "Title": "Speech/Data Signal Separation Comparison between Backpropagation and SONN", "Abstract": "This  work  introduces  a  new  method  called  Self  Organizing  Neural  Network  (SONN)  algorithm  and  compares  its  performance  with Back  Propagation  in  a  signal  separation  application.  The  problem  is  to  separate  two  signals;  a  modem  data signal  and  a  male  speech  signal,  added and transmitted  through  a  4 khz  channel.  The signals  are sam(cid:173) pled  at  8  khz,  and  using  supervised  learning,  an  attempt  is  made  to  reconstruct  them.  The  SONN  is  an  algorithm  that  constructs  its  own  network  topology  during  training,  which  is  shown  to  be  much  smaller  than  the  BP  network,  faster  to  trained,  and  free  from  the  trial-and(cid:173) error network design that characterize BP."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TRAFFIC", "Title": "Recognizing Objects Using Hierarchical Reference Frame Transformations", "Abstract": "We  describe a model that can recognize  two-dimensional shapes in  an  unsegmented  image,  independent  of their orientation,  position,  and scale.  The model,  called TRAFFIC, efficiently  represents  the  structural  relation  between  an  object  and  each  of its  component  features  by  encoding  the fixed  viewpoint-invariant transformation  from the feature's reference frame to the object's in the weights of a  connectionist  network.  Using  a  hierarchy  of such  transformations,  with increasing complexity of features  at each successive  layer,  the  network  can  recognize  multiple objects  in parallel.  An implemen(cid:173) tation  of TRAFFIC  is  described,  along with  experimental  results  demonstrating  the  network's  ability to  recognize  constellations  of  stars in  a viewpoint-invariant manner."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Closed-Form Inversion of Backpropagation Networks", "Title": "Theory and Optimization Issues", "Abstract": "We describe a closed-form technique for mapping the output of a trained  backpropagation network int.o input activity space. The mapping is an in(cid:173) verse mapping in the sense that, when the image of the mapping in input  activity space is propagat.ed forward through the normal network dynam(cid:173) ics, it reproduces the output used to generate that image. When more  than one such inverse mappings exist, our inverse ma.pping is special in  that it has no projection onto the nullspace of the activation flow opera(cid:173) tor for the entire network. An important by-product of our calculation,  when more than one invel'se mappings exist, is an orthogonal basis set of  a significant portion of the activation flow operator nullspace. This basis  set can be used to obtain an alternate inverse mapping that is optimized  for a particular rea.l-world application."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Comparison of three classification techniques", "Title": "CART, C4.5 and Multi-Layer Perceptrons", "Abstract": "In this paper, after some introductory remarks into the classification prob(cid:173) lem as considered in various research communities, and some discussions  concerning some of the reasons for ascertaining the performances of the  three chosen algorithms, viz., CART (Classification and Regression Tree),  C4.5 (one of the more recent versions of a popular induction tree tech(cid:173) nique known as ID3), and a multi-layer perceptron (MLP), it is proposed  to compare the performances of these algorithms under two criteria: classi(cid:173) fication and generalisation. It is found that, in general, the MLP has better  classification and generalisation accuracies compared with the other two  algorithms."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VLSI Implementations of Learning and Memory Systems", "Title": "A Review", "Abstract": "Today most neural models are already implemented in silicon VLSI, in the form of pro(cid:173) grams running on general purpose digital von Neumann computers. These machines  are available at low cost and are highly flexible. Their flexibility results from the ease  with which their programs can be changed. Maximizing flexibility, however, usually  results in reduced performance. A program will often have to specify several simple op-"}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kohonen Networks and Clustering", "Title": "Comparative Performance in Color Clustering", "Abstract": "The problem of color clustering is defined and shown to be a problem of  assigning a large number (hundreds of thousands) of 3-vectors to a  small number (256) of clusters. Finding those clusters in such a way that  they best represent a full color image using only 256 distinct colors is a  burdensome computational problem. In this paper, the problem is solved  using \"classical\" techniques -- k-means clustering, vector quantization  (which turns out to be the same thing in this application), competitive  learning, and Kohonen self-organizing feature maps. Quality of the  result is judged subjectively by how much the pseudo-color result  resembles the true color image, by RMS quantization error, and by run  time. The Kohonen map provides the best solution."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Extensions of a Theory of Networks for Approximation and Learning", "Title": "Outliers and Negative Examples", "Abstract": "Learning an input-output mapping from a set of examples can be regarded  as synthesizing an approximation of a multi-dimensional function. From  this point of view, this form of learning is closely related to regularization  theory, and we have previously shown (Poggio and Girosi, 1990a, 1990b)  the equivalence between reglilari~at.ioll and a. class of three-layer networks  that we call regularization networks. In this note, we ext.end the theory  by introducing ways of"}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EMPATH", "Title": "Face, Emotion, and Gender Recognition Using Holons", "Abstract": "The  dimens~onali~y of a  set Off  160 1:~ :a:~s ~~·.10 .  female  subjects  IS  reduced  ........ .  network  The extracted features do not correspond to  in previ~us face  recognition systems (KaR· na~e, 19~;)y' ......••.•..  f~tures we  call  holons.  The  hol.ons  are fV~~ t~!  ..... .  ..  ......\\  d'  tances  between  facial  elements."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Second Order Properties of Error Surfaces", "Title": "Learning Time and Generalization", "Abstract": "The learning time of a simple neural network model is obtained through an  analytic computation of the eigenvalue spectrum for the Hessian matrix,  which describes the second order properties of the cost function in the  space of coupling coefficients. The form of the eigenvalue distribution  suggests new techniques for accelerating the learning process, and provides  a theoretical justification for the choice of centered versus biased state  variables."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ALCOVE", "Title": "A Connectionist Model of Human Category Learning", "Abstract": "ALCOVE  is  a  connectionist  model  of human  category  learning  that  fits  a  broad spectrum of human learning data.  Its architecture is  based on well(cid:173) established  psychological  theory,  and  is  related  to  networks  using  radial  basis functions.  From the perspective of cognitive psychology,  ALCOVE can  be construed as a combination of exemplar-based representation and error(cid:173) driven  learning.  From the perspective of connectionism,  it can  be seen  as  incorporating constraints into back-propagation networks  appropriate for  modelling human learning."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spherical Units as Dynamic Consequential Regions", "Title": "Implications for Attention, Competition and Categorization", "Abstract": "• Also a member of Cognitive Science Laboratory, Princeton University, Princeton, NJ 08544"}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Direct memory access using two cues", "Title": "Finding the intersection of sets in a connectionist model", "Abstract": "For lack of alternative models, search and decision processes have provided the  dominant paradigm for human memory access using two or more cues, despite  evidence against search as an access process (Humphreys, Wiles & Bain, 1990).  We present an alternative process to search, based on calculating the intersection  of sets of targets activated by two or more cues. Two methods of computing  the intersection are presented, one using information about the possible targets,  the other constraining the cue-target strengths in the memory matrix. Analysis  using orthogonal vectors to represent the cues and targets demonstrates the  competence of both processes, and simulations using sparse distributed  representations demonstrate the performance of the latter process for tasks  involving 2 and 3 cues."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Flight Control in the Dragonfly", "Title": "A Neurobiological Simulation", "Abstract": "Neural network simulations of the dragonfly flight neurocontrol system  have  been  developed  to  understand  how  this  insect  uses  complex,  unsteady  aerodynamics.  The  simulation  networks  account  for  the  ganglionic  spatial  distribution  of  cells  as  well  as  the  physiologic  operating range and the stochastic cellular fIring history of each neuron.  In  addition  the  motor  neuron  firing  patterns,  \"flight  command  sequences\", were utilized. Simulation training was targeted against both  the  cellular  and  flight  motor  neuron  firing  patterns.  The  trained  networks  accurately  resynthesized  the  intraganglionic  cellular firing  patterns. These in  tum controlled the  motor neuron fIring patterns that  drive  wing  musculature  during  flight.  Such  networks  provide  both  neurobiological analysis tools and fIrst  generation controls for  the  use  of \"unsteady\" aerodynamics."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Evolution and Learning in Neural Networks", "Title": "The Number and Distribution of Learning Trials Affect the Rate of Evolution", "Abstract": "Learning can increase the rate of evolution of a population of  biological organisms (the Baldwin effect). Our simulations  show that in a population of artificial neural networks  solving a pattern recognition problem, no learning or too  much learning leads to slow evolution of the genes whereas  an intermediate amount is optimal. Moreover, for a given  total number of training presentations, fastest evoution  occurs if different individuals within each generation receive  different numbers of presentations, rather than equal  numbers. Because genetic algorithms (GAs) help avoid  local minima in energy functions, our hybrid learning-GA  systems can be applied successfully to complex, high(cid:173) dimensional pattern recognition problems."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SEXNET", "Title": "A Neural Network Identifies Sex From Human Faces", "Abstract": "Sex identification in animals has biological importance. Humans are good  at making this determination visually, but machines have not matched  this ability. A neural network was trained to discriminate sex in human  faces, and performed as well as humans on a set of 90 exemplars. Images  sampled at 30x30 were compressed using a 900x40x900 fully-connected  back-propagation network; activities of hidden units served as input to a  back-propagation \"SexNet\" trained to produce values of 1 for male and  o for female faces. The network's average error rate of 8.1% compared  favorably to humans, who averaged 11.6%. Some SexNet errors mimicked  those of humans."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Speech Recognition to Spoken Language Understanding", "Title": "The Development of the MIT SUMMIT and VOYAGER Systems", "Abstract": "Spoken language is one of the most natural, efficient, flexible, and econom(cid:173) ical means of communication among humans. As computers play an ever  increasing role in our lives, it is important that we address the issue of  providing a graceful human-machine interface through spoken language.  In this paper, we will describe our recent efforts in moving beyond the  scope of speech recognition into the realm of spoken-language understand(cid:173) ing. Specifically, we report on the development of an urban navigation and  exploration system called VOYAGER, an application which we have used as  a basis for performing research in spoken-language understanding."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RecNorm", "Title": "Simultaneous Normalisation and Classification applied to Speech Recognition", "Abstract": "A particular form of neural network is described, which has terminals  for acoustic patterns, class labels and speaker parameters. A method of  training this network to \"tune in\" the speaker parameters to a particular  speaker is outlined, based on a trick for converting a supervised network  to an unsupervised mode. We describe experiments using this approach  in isolated word recognition based on whole-word hidden Markov models.  The results indicate an improvement over speaker-independent perfor(cid:173) mance and, for unlabelled data, a performance close to that achieved on  labelled data."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analog Computation at a Critical Point", "Title": "A Novel Function for Neuronal Oscillations?", "Abstract": "\\Ve show that a simple spin system bia.sed at its critical point can en(cid:173) code spatial characteristics of external signals, sHch as the dimensions of  \"objects\" in the visual field. in the temporal correlation functions of indi(cid:173) vidual spins. Qualit.ative arguments suggest that regularly firing neurons  should be described by a planar spin of unit lengt.h. and such XY models  exhibit critical dynamics over a broad range of parameters. \\Ve show how  to extract these spins from spike trains and then mea'3ure t.he interaction  Hamilt.onian using simulations of small dusters of cells. Static correla(cid:173) tions among spike trains obtained from simulations of large arrays of cells  are in agreement with the predictions from these Hamiltonians, and dy(cid:173) namic correlat.ions display the predicted encoding of spatial information.  \\Ve suggest that this novel representation of object dinwnsions in temporal  correlations may be relevant t.o recent experiment.s on oscillatory neural  firing in the visual cortex."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Devil and the Network", "Title": "What Sparsity Implies to Robustness and Memory", "Abstract": "1 Well, maybe an imp."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Development and Spatial Structure of Cortical Feature Maps", "Title": "A Model Study", "Abstract": "Feature selective cells in  the primary visual cortex of several species are or(cid:173) ganized in hierarchical topographic maps of stimulus features like  \"position  in  visual  space\",  \"orientation\"  and\" ocular  dominance\".  In  order  to  un(cid:173) derstand and describe their spatial structure and their development, we  in(cid:173) vestigate a self-organizing neural network model based on the feature map  algorithm.  The  model  explains  map  formation  as  a  dimension-reducing  mapping  from  a  high-dimensional  feature  space  onto  a  two-dimensional  lattice,  such  that \"similarity\"  between features  (or feature  combinations)  is  translated  into  \"spatial  proximity\"  between  the  corresponding  feature  selective cells.  The model is  able to reproduce several aspects of the spatial  structure of cortical maps  in  the visual  cortex."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimal Sampling of Natural Images", "Title": "A Design Principle for the Visual System", "Abstract": "We formulate the problem of optimizing the sampling of natural images  using an array of linear filters. Optimization of information capacity is  constrained by the noise levels of the individual channels and by a penalty  for the construction of long-range interconnections in the array. At low  signal-to-noise ratios the optimal filter characteristics correspond to bound  states of a Schrodinger equation in which the signal spectrum plays the  role of the potential. The resulting optimal filters are remarkably similar  to those observed in the mammalian visual cortex and the retinal ganglion  cells of lower vertebrates. The observed scale invariance of natural images  plays an essential role in this construction."}
{"Type": "conference", "Year": "1990", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Tempo 2 Algorithm", "Title": "Adjusting Time-Delays By Supervised Learning", "Abstract": "In this work we describe a new method that adjusts time-delays and the widths of  time-windows in artificial neural networks automatically.  The input of the units  are weighted by a gaussian input-window over time which allows the learning  rules for the delays and widths to be derived in the same way as it is used for the  weights.  Our results on a phoneme classification task compare well with results  obtained with the TDNN by Waibel et al., which was manually optimized for the  same task."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Node Splitting", "Title": "A Constructive Algorithm for Feed-Forward Neural Networks", "Abstract": "A constructive algorithm is proposed for feed-forward neural networks,  which uses node-splitting in the hidden layers to build large networks from  smaller ones. The small network forms an approximate model of a set of  training data, and the split creates a larger more powerful network which is  initialised with the approximate solution already found. The insufficiency  of the smaller network in modelling the system which generated the data  leads to oscillation in those hidden nodes whose weight vectors cover re(cid:173) gions in the input space where more detail is required in the model. These  nodes are identified and split in two using principal component analysis,  allowing the new nodes t.o cover the two main modes of each oscillating  vector. Nodes are selected for splitting using principal component analysis  on the oscillating weight vectors, or by examining the Hessian matrix of  second derivatives of the network error with respect to the weight.s. The  second derivat.ive method can also be applied to the input layer, where it  provides a useful indication of t.he relative import.ances of parameters for  the classification t.ask. Node splitting in a standard Multi Layer Percep(cid:173) t.ron is equivalent to introducing a hinge in the decision boundary to allow  more detail to be learned. Initial results were promising, but further eval(cid:173) uation indicates that the long range effects of decision boundaries cause  the new nodes to slip back to the old node position, and nothing is gained.  This problem does not occur in networks of localised receptive fields such  as radial basis functions or gaussian mixtures, where the t.echnique appears  to work well."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Principled Architecture Selection for Neural Networks", "Title": "Application to Corporate Bond Rating Prediction", "Abstract": "684"}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning in the Vestibular System", "Title": "Simulations of Vestibular Compensation Using Recurrent Back-Propagation", "Abstract": "Vestibular compensation is one of the oldest and most well studied paradigms in motor  learning.  Although it is neurophysiologically well described, the adaptive mechanisms  underlying  vestibular  compensation,  and  its  effects  on  the  dynamics  of vestibular  responses,  are still poorly understood.  The purpose of this study  is to gain insight into  the  compensatory  process  by  simulating  it  as  learning  in  a  recurrent  neural  network  model of the vestibulo-ocular reflex (VOR)."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Repeat Until Bored", "Title": "A Pattern Selection Strategy", "Abstract": "An alternative to the typical technique of selecting  training examples  independently from a fixed distribution is fonnulated and analyzed, in  which the current example is presented repeatedly until the error for that  item is reduced to  some criterion value,  ~; then,  another  item  is ran(cid:173) domly selected.  The convergence time can be dramatically increased or  decreased by this heuristic, depending on the task, and is very sensitive  to the value of ~."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Against Edges", "Title": "Function Approximation with Multiple Support Maps", "Abstract": "Networks for reconstructing a sparse or noisy function often use an edge  field to segment the function into homogeneous regions, This approach  assumes that these regions do not overlap or have disjoint parts, which is  often false. For example, images which contain regions split by an occlud(cid:173) ing object can't be properly reconstructed using this type of network. We  have developed a network that overcomes these limitations, using support  maps to represent the segmentation of a signal. In our approach, the sup(cid:173) port of each region in the signal is explicitly represented. Results from  an initial implementation demonstrate that this method can reconstruct  images and motion sequences which contain complicated occlusion."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Locomotion in a Lower Vertebrate", "Title": "Studies of the Cellular Basis of Rhythmogenesis and Oscillator Coupling", "Abstract": "To test  whether  the  known  connectivies  of neurons  in  the lamprey spinal  cord are sufficient to account for locomotor rhythmogenesis, a  CCconnection(cid:173) ist\"  neural network simulation was done using identical cells connected ac(cid:173) cording to experimentally established  patterns.  It was  demonstrated  that  the  network  oscillates  in  a  stable  manner  with  the  same  phase  relation(cid:173) ships among the neurons as observed  in the lamprey.  The model was  then  used  to  explore  coupling  between  identical"}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Single Neuron Model", "Title": "Response to Weak Modulation in the Presence of Noise", "Abstract": "We consider a noisy bist.able single neuron model driven by a periodic  external modulation. The modulation introduces a correlated switching  between st.ates driven by the noise. The information flow through the sys(cid:173) tem from the modulation to the output switching events, leads to a succes(cid:173) sion of strong peaks in the power spectrum. The signal-to-noise ratio (SNR)  obtained from this power spectrum is a measure of the information content  in the neuron response . With increasing noise intensity, the SNR passes  t.hrough a maximum, an effect which has been called stochastic resonance.  We treat t.he problem wit.hin the framework of a recently developed approx(cid:173) imate theory, valid in the limits of weak noise intensity, weak periodic forc(cid:173) ing and low forcing frequency. A comparison of the results of this theory  with those obtained from a linear syst.em FFT is also presented ."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Self-organization in real neurons", "Title": "Anti-Hebb in 'Channel Space'?", "Abstract": "Ion channels are the dynamical systems of the nervous system. Their  distribution within the membrane governs not only communication of in(cid:173) formation between neurons, but also how that information is integrated  within the cell. Here, an argument is presented for an 'anti-Hebbian' rule  for changing the distribution of voltage-dependent ion channels in order  to flatten voltage curvatures in dendrites. Simulations show that this rule  can account for the self-organisation of dynamical receptive field properties  such as resonance and direction selectivity. It also creates the conditions  for the faithful conduction within the cell of signals to which the cell has  been exposed. Various possible cellular implementations of such a learn(cid:173) ing rule are proposed, including activity-dependent migration of channel  proteins in the plane of the membrane."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "JANUS", "Title": "Speech-to-Speech Translation Using Connectionist and Non-Connectionist Techniques", "Abstract": "• Also with University of Karlsruhe, Karlsruhe. Germany.  1N\"ow with Alliant Techsystems Research and Technology Center. Hopkins. Minnesota."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VISIT", "Title": "A Neural Model of Covert Visual Attention", "Abstract": "Visual attention is the ability to dynamically restrict processing to a subset  of the visual field.  Researchers  have long argued that such a  mechanism is  necessary  to efficiently perform many intermediate level visual tasks.  This  paper describes  VISIT,  a  novel  neural  network  model  of visual attention.  The current system models the search for target objects in scenes  contain(cid:173) ing  multiple distractors.  This  is  a  natural  task  for  people,  it  is  studied  extensively by psychologists,  and it requires  attention.  The network's be(cid:173) havior  closely  matches  the  known  psychophysical  data  on  visual  search  and visual  attention.  VISIT also  matches much of the  physiological data  on attention and provides a  novel view  of the functionality of a  number of  visual areas.  This paper concentrates  on  the  biological plausibility of the  model and its relationship to the primary visual cortex, pulvinar, superior  colliculus and posterior  parietal areas."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Operators and curried functions", "Title": "Training and analysis of simple recurrent networks", "Abstract": "We present a framework for programming tbe bidden unit representations of  simple recurrent networks based on the use of hint units (additional targets at  the output layer). We present two ways of analysing a network trained within  this framework: Input patterns act as operators on the information encoded by  the context units; symmetrically, patterns of activation over tbe context units  act as curried functions of the input sequences. Simulations demonstrate that a  network can learn to represent three different functions simultaneously and  canonical discriminant analysis is used to investigate bow operators and curried  functions are represented in the space of bidden unit activations."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Benchmarking Feed-Forward Neural Networks", "Title": "Models and Measures", "Abstract": "Existing metrics for the learning performance of feed-forward neural networks do  not provide a satisfactory basis for comparison because the choice of the training  epoch limit can determine the results of the comparison.  I propose new metrics  which  have  the  desirable property of being  independent of the  training epoch  limit.  The efficiency measures  the yield of correct networks in proportion to the  training effort expended.  The optimal epoch limit provides the greatest efficiency.  The learning performance is modelled statistically, and asymptotic performance  is estimated.  Implementation details may be found in (Harney,  1992)."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Models Wanted", "Title": "Must Fit Dimensions of Sleep and Dreaming", "Abstract": "During waking and sleep, the brain and mind undergo a  tightly linked and  precisely  specified  set  of changes  in state.  At  the  level  of neurons,  this  process  has  been  modeled  by  variations  of Volterra-Lotka  equations  for  cyclic fluctuations of brainstem cell populations.  However, neural network  models based upon rapidly developing knowledge ofthe specific population  connectivities  and  their  differential responses  to drugs  have  not  yet  been  developed.  Furthermore, only  the  most  preliminary  attempts  have  been  made  to model across states.  Some  of our own attempts  to link rapid eye  movement (REM) sleep neurophysiology and dream cognition using neural  network approaches  are summarized in this  paper."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Control for Rolling Mills", "Title": "Incorporating Domain Theories to Overcome Data Deficiency", "Abstract": "In  a  Bayesian  framework,  we  give  a  principled  account  of how  domain(cid:173) specific prior knowledge such  as imperfect analytic domain theories can be  optimally  incorporated  into  networks  of locally-tuned  units:  by  choosing  a  specific  architecture  and  by  applying  a  specific  training  regimen.  Our  method  proved  successful  in  overcoming  the  data  deficiency  problem  in  a  large-scale  application  to  devise  a  neural  control  for  a  hot  line  rolling  mill.  It  achieves  in  this  application  significantly  higher  accuracy  than  optimally-tuned standard  algorithms such  as  sigmoidal backpropagation,  and  outperforms the state-of-the-art solution."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HARMONET", "Title": "A Neural Net for Harmonizing Chorales in the Style of J. S. Bach", "Abstract": "HARMONET, a system employing connectionist networks for music pro(cid:173) cessing, is presented. After being trained on some dozen Bach chorales  using error backpropagation, the system is capable of producing four-part  chorales in the style of J .s.Bach, given a one-part melody. Our system  solves a musical real-world problem on a performance level appropriate  for musical practice. HARMONET's power is based on (a) a new coding  scheme capturing musically relevant information and (b) the integration of  backpropagation and symbolic algorithms in a hierarchical system, com(cid:173) bining the advantages of both."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Network generalization for production", "Title": "Learning and producing styled letterforms", "Abstract": "We designed and trained a connectionist network to generate  letterfonns in a new font given just a few exemplars from  that font. During learning. our network constructed a  distributed internal representation of fonts as well as letters.  despite the fact that each training instance exemplified both a  font and a letter. It was necessary to have separate but  interconnected hidden units for \" letter\" and \"font\"  representations - several alternative architectures were not  successful."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Retinogeniculate Development", "Title": "The Role of Competition and Correlated Retinal Activity", "Abstract": "During visual development, projections from retinal ganglion cells  (RGCs) to the lateral geniculate nucleus (LGN) in cat are refined to  produce ocular dominance layering and precise topographic mapping.  Normal development depends upon activity in RGCs, suggesting a key  role for activity-dependent synaptic plasticity. Recent experiments on  prenatal retina show that during early development, \"waves\" of activity  pass across RGCs (Meister, et aI., 1991). We provide the first  simulations to demonstrate that such retinal waves, in conjunction with  Hebbian synaptic competition and early arrival of contralateral axons,  can account for observed patterns of retinogeniculate projections in  normal and experimentally-treated animals."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Time-Warping Network", "Title": "A Hybrid Framework for Speech Recognition", "Abstract": "recognition  system.  and  we  propose"}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Effective Number of Parameters", "Title": "An Analysis of Generalization and Regularization in Nonlinear Learning Systems", "Abstract": "lCPE and Peff(>\")  were previously  introduced  in  Moody  (1991)."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gradient Descent", "Title": "Second Order Momentum and Saturating Error", "Abstract": "Batch gradient descent, ~w(t) = -7JdE/dw(t) , conver~es to a minimum  of quadratic form with a time constant no better than '4Amax/ Amin where  Amin and Amax are the minimum and maximum eigenvalues of the Hessian  matrix of E with respect to w.  It was recently shown that adding a  momentum term ~w(t) = -7JdE/dw(t) + Q'~w(t - 1) improves this to  ~ VAmax/ Amin, although only in the batch case. Here we show that second(cid:173) order momentum, ~w(t) = -7JdE/dw(t) + Q'~w(t -1) + (3~w(t - 2), can  lower this no further. We then regard gradient descent with momentum  as a dynamic system and explore a non quadratic error surface, showing  that saturation of the error accounts for a variety of effects observed in  simulations and justifies some popular heuristics."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interpretation of Artificial Neural Networks", "Title": "Mapping Knowledge-Based Neural Networks into Rules", "Abstract": "We propose and empirically evaluate a method for the extraction of expert(cid:173) comprehensible rules from trained neural networks. Our method operates in  the context of a three-step process for learning that uses rule-based domain  knowledge in combination with neural networks. Empirical tests using real(cid:173) worlds problems from molecular biology show that the rules our method extracts  from trained neural networks: closely reproduce the accuracy of the network  from which they came, are superior to the rules derived by a learning system that  directly refines symbolic rules, and are expert-comprehensible."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Clusteron", "Title": "Toward a Simple Abstraction for a Complex Neuron", "Abstract": "Are  single  neocortical  neurons  as  powerful as  multi-layered  networks?  A  recent  compartmental modeling study  has shown  that voltage-dependent  membrane  nonlinearities  present  in  a  complex dendritic  tree  can  provide  a  virtual layer of local  nonlinear processing  elements between synaptic in(cid:173) puts  and  the  final  output  at  the  cell  body,  analogous  to  a  hidden  layer  in  a  multi-layer  network.  In  this  paper,  an  abstract  model  neuron  is  in(cid:173) troduced,  called  a  clusteron,  which  incorporates  aspects  of the  dendritic  \"cluster-sensitivity\"  phenomenon seen  in these  detailed  biophysical mod(cid:173) eling  studies.  It is  shown,  using  a  clusteron,  that  a  Hebb-type  learning  rule  can  be  used  to  extract  higher-order  statistics  from  a  set  of  train(cid:173) ing patterns,  by manipulating the spatial ordering of synaptic connections  onto  the  dendritic  tree.  The  potential neurobiological  relevance  of these  higher-order statistics for  nonlinear pattern discrimination is then studied  within a  full  compartmental model  of a  neocortical  pyramidal cell,  using  a  training set  of 1000 high-dimensional sparse random patterns."}
{"Type": "conference", "Year": "1991", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reverse TDNN", "Title": "An Architecture For Trajectory Generation", "Abstract": "The backpropagation algorithm can be used for both recognition and gen(cid:173) eration of time trajectories. When used as a recognizer, it has been shown  that the performance of a network can be greatly improved by adding  structure to the architecture. The same is true in trajectory generation.  In particular a new architecture corresponding to a \"reversed\" TDNN is  proposed. Results show dramatic improvement of performance in the gen(cid:173) eration of hand-written characters. A combination of TDNN and reversed  TDNN for compact encoding is also suggested."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Spatio-Temporal Planning from a Dynamic Programming Teacher", "Title": "Feed-Forward Neurocontrol for Moving Obstacle Avoidance", "Abstract": "e-mail:  gerald@nero.uni-bonn.de"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hidden Markov Models in Molecular Biology", "Title": "New Algorithms and Applications", "Abstract": "*and Division  of Biology,  California  Institute of Technology.  t and Department of Psychology,  Stanford University."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Stimulus Representations", "Title": "A Computational Theory of Hippocampal-Region Function", "Abstract": "We present a theory of cortico-hippocampal interaction in discrimination learning. The  hippocampal region is presumed to form new stimulus representations which facilitate  learning by enhancing the discriminability of predictive stimuli and compressing  stimulus-stimulus redundancies. The cortical and cerebellar regions, which are the sites  of long-term memory. may acquire these new representations but are not assumed to be  capable of forming new representations themselves.  Instantiated as a connectionist  model. this theory accounts for a wide range of trial-level classical conditioning  phenomena in normal (intact) and hippocampal-Iesioned animals. It also makes several  novel predictions which remain to be investigated empirically. The theory implies that  the hippocampal region is involved in even the simplest learning tasks; although  hippocampal-Iesioned animals may be able to use other strategies to learn these tasks. the  theory predicts that they will show consistently different patterns of transfer and  generalization when the task demands change."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Intersecting regions", "Title": "The Key to combinatorial structure in hidden unit space", "Abstract": "In multi-layer networks, regions of hidden unit space can be identified with classes of  equivalent outputs. For example, Elman (1989) showed that the hidden unit patterns for  words in simple grammatical sentences cluster into regions, with similar patterns  representing similar grammatical entities. For example, different tokens of the same word  are clustered tightly, indicating that they are represented within a small region. These  regions can be grouped into larger regions, reflecting a hierarchical structure. The largest"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Planar Hidden Markov Modeling", "Title": "From Speech to Optical Character Recognition", "Abstract": "Tbe  PHMM  approach  was  evaluated  using  a  set  of  isolated  band-written  digits.  An  overall  digit  recognition  accuracy  of  95%  was  acbieved.  An  analysis of the results showed  that even in  the  simple case of recognition  of  isolated  characters,  the  elimination  of  elastic  distortions  enhances  the  performance Significantly. We expect that the advantage of this approach  will  be  even  more  such  as  connected  writing  recognition/spotting,  for  whicb  there  is  no  known  high  accuracy  method  of  recognition."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Perceiving Complex Visual Scenes", "Title": "An Oscillator Neural Network Model that Integrates Selective Attention, Perceptual Organisation, and Invariant Recognition", "Abstract": "the 'where(cid:173)"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Second order derivatives for network pruning", "Title": "Optimal Brain Surgeon", "Abstract": "We investigate the use of information from all second order derivatives of the error  function to perfonn network pruning (i.e., removing unimportant weights from a trained  network) in order to improve generalization, simplify networks, reduce hardware or  storage requirements, increase the speed of further training, and in some cases enable rule  extraction. Our method, Optimal Brain Surgeon (OBS), is Significantly better than  magnitude-based methods and Optimal Brain Damage [Le Cun, Denker and Sol1a, 1990],  which often remove the wrong weights. OBS permits the pruning of more weights than  other methods (for the same error on the training set), and thus yields better  generalization on test data. Crucial to OBS is a recursion relation for calculating the  inverse Hessian matrix H-I from training data and structural information of the net. OBS  permits a 90%, a 76%, and a 62% reduction in weights over backpropagation with weighL  decay on three benchmark MONK's problems [Thrun et aI., 1991]. Of OBS, Optimal  Brain Damage, and magnitude-based methods, only OBS deletes the correct weights from  a trained XOR network in every case. Finally, whereas Sejnowski and Rosenberg [1987J  used 18,000 weights in their NETtalk network, we used OBS to prune a network to just  1560 weights, yielding better generalization."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On-Line Estimation of the Optimal Value Function", "Title": "HJB- Estimators", "Abstract": "The complete effect of a control action Uk at a given time step t/.; is clouded by  the fact that the state history depends on the control actions taken after time  step tk' So the effect of a control action over all future time must be monitored.  Hence, choice of control must inevitably involve knowledge of the future history  of the state trajectory. In other words, the optimal control sequence can not be  determined until after the fact. Of course, standard optimal control theory supplies  an optimal control sequence to this problem for a variety of performance criteria.  Roughly, there are two approaches of interest: solving the two-point boundary value"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Memory-Based Reinforcement Learning", "Title": "Efficient Computation with Prioritized Sweeping", "Abstract": "The paper introduces a memory-based technique, prioritized 6weeping, which is used  both for  stochastic  prediction and  reinforcement  learning.  A fuller  version  of this  paper is in preparation [Moore and Atkeson, 1992].  Consider the  500 state Markov  system depicted in Figure 1.  The system has sixteen absorbing states,  depicted by  white and black circles.  The prediction problem is  to estimate, for  every state, the  long-term  probability  that  it will  terminate  in  a  white,  rather  than  black,  circle.  The data available to the learner is a sequence of observed state transitions.  Let us  consider two existing methods along  with prioritized sweeping."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weight Space Probability Densities in Stochastic Learning", "Title": "I. Dynamics and Equilibria", "Abstract": "where w E 7£m  is  the vector of m  weights,  /-l  is  the learning rate, H[.]  E 7£m  is  the  update function,  and  x(n)  is  the exemplar  (input or  input/target pair)  presented"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Formal Model of the Insect Olfactory Macroglomerulus", "Title": "Simulations and Analytic Results", "Abstract": "It  is  known  from  biological  data  that  the  response  patterns  of  interneurons  in  the olfactory  macroglomerulus  (MGC) of insects are of  central importance for the coding of the olfactory signal. We propose an  analytically  tractable  model  of the  MGC  which allows us  to  relate  the  distribution of response patterns to the architecture of the network."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to See Where and What", "Title": "Training a Net to Make Saccades and Recognize Handwritten Characters", "Abstract": "The Saccade system takes a cue from the ballistic and corrective saccades (eye movements)  of natural vision systems.  Natural saccades make it possible to efficiently move from one  informative area to another by jumping.  The eye  typically  initiates a ballistic saccade to"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Summed Weight Neuron Perturbation", "Title": "An O(N) Improvement Over Weight Perturbation", "Abstract": "The algorithm presented performs gradient descent on the weight space  of an Artificial Neural Network (ANN), using a finite difference to  approximate the gradient The method is novel in that it achieves a com(cid:173) putational complexity similar to that of Node Perturbation, O(N3), but  does not require access to the activity of hidden or internal neurons.  This is possible due to a stochastic relation between perturbations at the  weights and the neurons of an ANN. The algorithm is also similar to  Weight Perturbation in that it is optimal in terms of hardware require(cid:173) ments when used for the training ofVLSI implementations of ANN's."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attractor Neural Networks with Local Inhibition", "Title": "from Statistical Physics to a Digitial Programmable Integrated Circuit", "Abstract": "Networks with local inhibition are shown to have enhanced compu(cid:173) tational performance with respect to the classical Hopfield-like net(cid:173) works. In particular the critical capacity of the network is increased  as well as its capability to store correlated patterns. Chaotic dy(cid:173) namic behaviour (exponentially long transients) of the devices in(cid:173) dicates the overloading of the associative memory. An implementa(cid:173) tion based on a programmable logic device is here presented. A 16  neurons circuit is implemented whit a XILINK 4020 device. The  peculiarity of this solution is the possibility to change parts of the  project (weights, transfer function or the whole architecture) with  a simple software download of the configuration into the XILINK  chip."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Metamorphosis Networks", "Title": "An Alternative to Constructive Models", "Abstract": "Given a set oft raining examples, determining the appropriate num(cid:173) ber  of  free  parameters  is  a  challenging  problem.  Constructive  learning algorithms attempt to solve this problem automatically by  adding  hidden  units,  and  therefore  free  parameters,  during  learn(cid:173) ing.  We  explore  an  alternative  class  of algorithms-called  meta(cid:173) morphosis  algorithms-in  which  the  number  of units  is  fixed,  but  the number of free  parameters gradually increases  during learning.  The architecture we investigate is composed of RBF units on a lat(cid:173) tice,  which  imposes  flexible  constraints  on  the  parameters  of the  network.  Virtues  of this  approach  include  variable  subset  selec(cid:173) tion,  robust  parameter  selection,  multiresolution  processing,  and  interpolation  of sparse training  data."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weight Space Probability Densities in Stochastic Learning", "Title": "II. Transients and Basin Hopping Times", "Abstract": "Despite the recent application of convergence theorems from stochastic approxima(cid:173) tion  theory to  neural  network  learning  (Oja 1982,  White  1989)  there remain  out(cid:173) standing questions about the search dynamics in stochastic learning.  For example,  the convergence theorems do  not  tell  us  to which  of several  optima the algorithm"}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Performance Through Consistency", "Title": "MS-TDNN's for Large Vocabulary Continuous Speech Recognition", "Abstract": "Connectionist Rpeech recognition systems are often handicapped by  an  inconsistency  between  training and  testing  criteria.  This  prob(cid:173) lem  is  addressed  by  the  Multi-State  Time Delay  Neural  Network  (MS-TDNN), a hierarchical phonf'mp and word classifier which uses  DTW  to  modulate  its  connectivit.y  pattern,  and  which  is  directly  trained  on  word-level  targets.  The  consistent  use  of word  accu(cid:173) racy  as  a  criterion  during  bot.h  t.raining  and  testing  leads  to  very  high  system  performance,  even  wif II  limited  training  dat.a.  Until  now,  the  MS-TDN N  has  been  appli('d  primarily  to  small  vocabu(cid:173) lary  recognition  and  word  spotting  tasks.  In  this  papf'f  we  apply  the architecture to large vocabulary continuous speech recognition,  and  demonstrate  that  our  MS-TDNN  outperforms  all  ot,hf'r  sys(cid:173) tems  that  have  been  tested  on  tht'  eMU  Conference  Registration  database."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unsmearing Visual Motion", "Title": "Development of Long-Range Horizontal Intrinsic Connections", "Abstract": "Human VlSlon systems integrate information nonlocally, across long  spatial ranges.  For example, a moving stimulus appears smeared  when viewed briefly (30 ms), yet sharp when viewed for a longer  exposure (100 ms) (Burr, 1980). This suggests that visual systems  combine information along a trajectory that matches the motion of  the stimulus. Our self-organizing neural network model shows how  developmental exposure to moving stimuli can direct the formation of  horizontal trajectory-specific motion integration pathways that unsmear  representations of moving stimuli. These results account for Burr's data  and can potentially also model ot.her phenomena, such as visual inertia."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Power of Approximating", "Title": "a Comparison of Activation Functions", "Abstract": "We compare activation functions in terms of the approximation  power of their feedforward nets. We consider the case of analog as  well as boolean input."}
{"Type": "conference", "Year": "1992", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Transient Signal Detection with Neural Networks", "Title": "The Search for the Desired Signal", "Abstract": "Matched  filtering  has  been  one  of the  most  powerful  techniques  employed for transient detection. Here we will show that a dynamic  neural  network  outperforms  the  conventional  approach.  When  the  artificial neural  network (ANN) is  trained with supervised learning  schemes  there  is  a  need  to  supply  the  desired  signal  for  all  time,  although  we  are  only  interested  in  detecting  the  transient.  In  this  paper  we  also  show  the  effects  on  the  detection  agreement  of  different strategies to construct the desired signal. The extension of  the  Bayes  decision  rule  (011  desired  signal),  optimal  in  static  classification,  performs  worse  than  desired  signals  constructed by  random noise or prediction during the background."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hoeffding Races", "Title": "Accelerating Model Selection Search for Classification and Function Approximation", "Abstract": "Selecting  a good  model of a set  of input points by  cross  validation  is  a  computationally intensive  process,  especially  if the  number of  possible  models  or  the  number  of training  points  is  high.  Tech(cid:173) niques  such  as  gradient  descent  are  helpful  in  searching  through  the space of models,  but problems such  as  local minima, and more  importantly, lack  of a  distance  metric  between  various  models re(cid:173) duce  the applicability of these search  methods.  Hoeffding  Races  is  a  technique  for  finding  a  good  model  for  the  data by  quickly  dis(cid:173) carding bad models, and concentrating the computational effort  at  differentiating between  the better  ones.  This paper focuses  on  the  special  case  of leave-one-out  cross  validation  applied  to  memory(cid:173) based  learning  algorithms,  but  we  also  argue  that  it is  applicable  to any  class  of model selection  problems."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Putting It All Together", "Title": "Methods for Combining Neural Networks", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Curves", "Title": "Asymptotic Values and Rate of Convergence", "Abstract": "1"}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How to Describe Neuronal Activity", "Title": "Spikes, Rates, or Assemblies?", "Abstract": "What  is  the  'correct'  theoretical  description  of neuronal  activity?  The  analysis  of the  dynamics  of a  globally  connected  network  of  spiking neurons  (the Spike Response  Model)  shows  that a  descrip(cid:173) tion  by  mean firing  rates  is  possible  only if active  neurons  fire  in(cid:173) coherently.  If firing  occurs  coherently  or  with spatio-temporal cor(cid:173) relations,  the  spike  structure of the neural  code  becomes  relevant.  Alternatively, neurons can  be gathered into local or distributed en(cid:173) sembles or 'assemblies'.  A description  based on the mean ensemble  activity is,  in principle, possible but the interaction  between  differ(cid:173) ent assemblies becomes highly nonlinear.  A description with spikes  should  therefore  be  preferred."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robot Learning", "Title": "Exploration and Continuous Domains", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Catastrophic interference in connectionist networks", "Title": "Can It Be predicted, can It be prevented?", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Identifying Fault-Prone Software Modules Using Feed-Forward Networks", "Title": "A Case Study", "Abstract": "Functional complexity of a software module can be measured in  terms of static complexity metrics of the program text. Classify(cid:173) ing software modules, based on their static complexity measures,  into different fault-prone categories is a difficult problem in soft(cid:173) ware engineering. This research investigates the applicability of  neural network classifiers for identifying fault-prone software mod(cid:173) ules using a data set from a commercial software system. A pre(cid:173) liminary empirical comparison is performed between a minimum  distance based Gaussian classifier, a perceptron classifier and a  multilayer layer feed-forward network classifier constructed using  a modified Cascade-Correlation algorithm. The modified version  of the Cascade-Correlation algorithm constrains the growth of the  network size by incorporating a cross-validation check during the  output layer training phase. Our preliminary results suggest that  a multilayer feed-forward network can be used as a tool for iden(cid:173) tifying fault-prone software modules early during the development  cycle. Other issues such as representation of software metrics and  selection of a proper training samples are also discussed."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The \"Softmax\" Nonlinearity", "Title": "Derivation Using Statistical Mechanics and Useful Properties as a Multiterminal Analog Circuit Element", "Abstract": "We use mean-field theory methods from Statistical Mechanics to  derive the \"softmax\" nonlinearity from the discontinuous winner(cid:173) take-all (WTA) mapping. We give two simple ways of implementing  \"soft max\" as a multiterminal network element. One of these has a  number of important network-theoretic properties. It is a recipro(cid:173) cal, passive, incrementally passive, nonlinear, resistive multitermi(cid:173) nal element with a content function having the form of information(cid:173) theoretic entropy. These properties should enable one to use this  element in nonlinear RC networks with such other reciprocal el(cid:173) ements as resistive fuses and constraint boxes to implement very  high speed analog optimization algorithms using a minimum of  hardware."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fool's Gold", "Title": "Extracting Finite State Machines from Recurrent Network Dynamics", "Abstract": "Several recurrent networks have been proposed as representations for the  task of formal language learning. After training a recurrent network rec(cid:173) ognize a formal  language or predict the next symbol of a sequence, the  next logical step is to  understand the information processing carried out  by  the  network.  Some researchers have  begun  to  extracting  finite  state  machines from the internal state trajectories of their recurrent networks.  This  paper describes  how  sensitivity  to  initial  conditions  and  discrete  measurements can trick these extraction methods to return illusory finite  state descriptions."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Statistics of Natural Images", "Title": "Scaling in the Woods", "Abstract": "In  order  to  best  understand  a  visual  system  one  should  attempt  to characterize  the natural images it processes.  We  gather  images  from the woods and find that these scenes possess an ensemble scale  invariance.  Further,  they  are  highly  non-Gaussian,  and  this  non(cid:173) Gaussian  character  cannot  be  removed  through local  linear filter(cid:173) ing.  We find  that including a simple  \"gain control\"  nonlinearity in  the filtering  process  makes the filter  output quite Gaussian, mean(cid:173) ing information is maximized at fixed  channel variance.  Finally, we  use  the measured power spectrum to place  an upper bound on the  information conveyed about natural scenes by an array of receptors."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GDS", "Title": "Gradient Descent Generation of Symbolic Classification Rules", "Abstract": "Imagine you have designed a neural network that successfully learns  a complex classification task.  What are the relevant input features  the classifier relies on and how  are these features  combined to pro(cid:173) duce  the  classification  decisions?  There  are  applications  where  a  deeper  insight  into  the  structure  of an  adaptive  system  and  thus  into the underlying classification problem may well be as important  as  the  system's  performance  characteristics,  e.g.  in  economics  or  medicine.  GDSi  is  a  backpropagation-based  training scheme  that  produces networks  transformable into an equivalent and concise  set  of IF-THEN rules.  This is achieved by  imposing penalty terms  on the network parameters that adapt the network to the expressive  power of this class of rules.  Thus during training we simultaneously  minimize classification  and  transformation error.  Some real-world  tasks  demonstrate the viability of our approach."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Packet Routing in Dynamically Changing Networks", "Title": "A Reinforcement Learning Approach", "Abstract": "This  paper  describes  the  Q-routing  algorithm for  packet  routing,  in  which  a  reinforcement  learning  module  is  embedded  into  each  node  of a  switching  network.  Only  local  communication  is  used  by each node to keep  accurate statistics on which routing decisions  lead  to  minimal  delivery  times.  In  simple  experiments  involving  a  36-node,  irregularly  connected  network,  Q-routing  proves  supe(cid:173) rior  to  a  nonadaptive  algorithm  based  on  precomputed  shortest  paths  and  is  able  to route  efficiently  even  when  critical  aspects  of  the  simulation,  such  as  the  network  load,  are  allowed  to  vary  dy(cid:173) namically.  The  paper  concludes  with  a  discussion  of the  tradeoff  between  discovering  shortcuts  and  maintaining stable policies."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayesian Backprop in Action", "Title": "Pruning, Committees, Error Bars and an Application to Spectroscopy", "Abstract": "If several theories  account  for  a phenomenon  we  should  prefer the  simplest  which  describes  the  data  sufficiently  well."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "What Does the Hippocampus Compute?", "Title": "A Precis of the 1993 NIPS Workshop", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Credit Assignment through Time", "Title": "Alternatives to Backpropagation", "Abstract": "Learning  to  recognize  or  predict  sequences  using  long-term  con(cid:173) text  has  many  applications.  However,  practical  and  theoretical  problems  are  found  in  training  recurrent  neural  networks  to  per(cid:173) form tasks in which input/output dependencies span long intervals.  Starting from a mathematical analysis of the  problem, we  consider  and compare alternative algorithms and  architectures  on  tasks for  which the span of the input/output dependencies can be controlled.  Results  on the new  algorithms show  performance qualitatively su(cid:173) perior  to that obtained with backpropagation."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Complex Boolean Functions", "Title": "Algorithms and Applications", "Abstract": "The most commonly used neural network models are not well suited  to direct digital implementations because each node needs to per(cid:173) form a large number of operations between floating point values.  Fortunately, the ability to learn from examples and to generalize is  not restricted to networks ofthis type. Indeed, networks where each  node implements a simple Boolean function (Boolean networks) can  be designed in such a way as to exhibit similar properties. Two  algorithms that generate Boolean networks from examples are pre(cid:173) sented. The results show that these algorithms generalize very  well in a class of problems that accept compact Boolean network  descriptions. The techniques described are general and can be ap(cid:173) plied to tasks that are not known to have that characteristic. Two  examples of applications are presented: image reconstruction and  hand-written character recognition."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Odor Processing in the Bee", "Title": "A Preliminary Study of the Role of Central Input to the Antennal Lobe", "Abstract": "Based  on  precise  anatomical  data  of the  bee's  olfactory  system,  we  propose an investigation of the possible mechanisms of modulation and  control between the two levels of olfactory  information processing:  the  antennallobe glomeruli  and  the  mushroom  bodies.  We use  simplified  neurons,  but realistic  architecture.  As  a  first  conclusion,  we  postulate  that the feature extraction performed by the antennallobe (glomeruli and  interneurons)  necessitates  central  input from  the  mushroom bodies for  fine  tuning. The central input thus  facilitates  the evolution from fuzzy  olfactory images in the glomerular layer towards more focussed  images  upon odor presentation."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Lipreading by neural networks", "Title": "Visual preprocessing, learning, and sensory integration", "Abstract": "We have developed visual preprocessing algorithms for extracting  phonologically relevant features from the grayscale video image of  a speaker, to provide speaker-independent inputs for an automat(cid:173) ic lipreading (\"speechreading\") system. Visual features such as  mouth open/closed, tongue visible/not-visible, teeth visible/not(cid:173) visible, and several shape descriptors of the mouth and its motion  are all rapidly computable in a manner quite insensitive to lighting  conditions. We formed a hybrid speechreading system consisting  of two time delay neural networks (video and acoustic) and inte(cid:173) grated their responses by means of independent opinion pooling  - the Bayesian optimal method given conditional independence,  which seems to hold for our data. This hybrid system had an er(cid:173) ror rate 25% lower than that of the acoustic subsystem alone on a  five-utterance speaker-independent task, indicating that video can  be used to improve speech recognition."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimal Brain Surgeon", "Title": "Extensions and performance comparisons", "Abstract": "We  extend  Optimal  Brain  Surgeon  (OBS)  - to  allow  for  general  error  mea(cid:173) method  for  pruning  networks  - sures, and explore a reduced computational and storage implemen(cid:173) tation  via  a  dominant  eigenspace  decomposition.  Simulations  on  nonlinear,  noisy  pattern  classification  problems  reveal  that  OBS  does  lead  to  improved  generalization,  and  performs  favorably  in  comparison with Optimal Brain Damage (OBD).  We  find  that the  required  retraining  steps  in  OBD  may  lead  to inferior  generaliza(cid:173) tion, a result that can be interpreted as due to injecting noise back  into the system.  A common technique is to stop training of a large  network at the minimum validation error.  We  found  that the test  error  could  be  reduced  even  further  by  means  of  OBS  (but  not  OBD)  pruning.  Our  results justify the t  ~ 0  approximation  used  in  OBS  and  indicate  why  retraining  in  a  highly  pruned  network  may lead to inferior  performance."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "WATTLE", "Title": "A Trainable Gain Analogue VLSI Neural Network", "Abstract": "This paper describes a low power analogue VLSI neural network  called Wattle. Wattle is a 10:6:4 three layer perceptron with multi(cid:173) plying DAC synapses and on chip switched capacitor neurons fabri(cid:173) cated in 1.2um CMOS. The on chip neurons facillitate variable gain  per neuron and lower energy/connection than for previous designs.  The intended application of this chip is Intra Cardiac Electrogram  classification as part of an implantable pacemaker / defibrillator sys(cid:173) tem. Measurements of t.he chip indicate that 10pJ per connection  is achievable as part of an integrated system. Wattle has been suc(cid:173) cessfully trained in loop on parity 4 and ICEG morphology classi(cid:173) fication problems."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tonal Music as a Componential Code", "Title": "Learning Temporal Relationships Between and Within Pitch and Timing Components", "Abstract": "This study explores the extent to which a network that learns the  temporal relationships within and between the component features of  Western tonal music can account for music theoretic and psychological  phenomena such as the tonal hierarchy and rhythmic expectancies.  Predicted and generated sequences were recorded as the representation of  a 153-note waltz melody was learnt by a predictive, recurrent network.  The network learned transitions and relations between and within pitch  and timing components: accent and duration values interacted in the  development of rhythmic and metric structures and, with training, the  network developed chordal expectancies in response to the activation of  individual tones. Analysis of the hidden unit representation revealed  that musical sequences are represented as transitions between states in  hidden unit space."}
{"Type": "conference", "Year": "1993", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning in Compositional Hierarchies", "Title": "Inducing the Structure of Objects from Data", "Abstract": "I  propose a learning algorithm for  learning hierarchical  models  for ob(cid:173) ject recognition.  The  model  architecture  is  a  compositional  hierarchy  that  represents  part-whole relationships:  parts  are  described  in  the lo(cid:173) cal  context of substructures  of the  object.  The  focus  of this  report  is  inducing  the  structure  of  learning  hierarchical  models  from  data,  i.e.  model  prototypes from  observed exemplars of an  object.  At each  node  in the hierarchy, a probability distribution governing its parameters must  be learned.  The connections between  nodes reflects  the structure of the  object.  The  formulation of substructures  is  encouraged  such  that  their  parts  become  conditionally  independent.  The  resulting  model  can  be  interpreted  as  a  Bayesian  Belief Network  and  also  is  in  many  respects  similar to the stochastic visual grammar described by Mjolsness."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning with Preknowledge", "Title": "Clustering with Point and Graph Matching Distance Measures", "Abstract": "Prior constraints are imposed upon a learning problem in the form  of distance measures. Prototypical 2-D point sets and graphs are  learned by clustering with point matching and graph matching dis(cid:173) tance measures. The point matching distance measure is approx.  invariant under affine transformations - translation, rotation, scale  and shear - and permutations. It operates between noisy images  with missing and spurious points. The graph matching distance  measure operates on weighted graphs and is invariant under per(cid:173) mutations. Learning is formulated as an optimization problem .  Large objectives so formulated ('\" million variables) are efficiently  minimized using a combination of optimization techniques - alge(cid:173) braic transformations, iterative projective scaling, clocked objec(cid:173) tives, and deterministic annealing."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Using a Saliency Map for Active Spatial Selective Attention", "Title": "Implementation & Initial Results", "Abstract": "In many vision based tasks, the ability to focus attention on the important  portions of a scene is crucial for good performance on the tasks. In this paper  we present a simple method of achieving spatial selective attention through  the use of a saliency map. The saliency map indicates which regions of the  input retina are important for performing the task. The saliency map is cre(cid:173) ated through predictive auto-encoding. The performance of this method is  demonstrated on two simple tasks which have multiple very strong distract(cid:173) ing features in the input retina. Architectural extensions and application  directions for this model are presented."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Connectionist Technique for Accelerated Textual Input", "Title": "Letting a Network Do the Typing", "Abstract": "Each year people spend a huge amount of time typing. The text people type  typically contains a tremendous amount of redundancy due to predictable  word  usage  patterns  and  the  text's  structure.  This  paper  describes  a  neural network system call AutoTypist that monitors a person's typing and  predicts what will be entered  next.  AutoTypist displays the most likely  subsequent word to the typist, who can accept it with a single keystroke,  instead of typing it in its entirety.  The multi-layer perceptron at the heart  of Auto'JYpist adapts its predictions of likely subsequent text to the user's  word usage pattern,  and to the characteristics of the text currently being  typed.  Increases in typing speed of 2-3% when typing English prose and  10-20% when typing C code have been demonstrated using the system,  suggesting a potential time savings of more than 20 hours per user per year.  In addition to increasing typing speed, AutoTypist reduces the number of  keystrokes a user must type by a similar amount (2-3% for English,  10- 20% for computer programs).  This keystroke savings has the potential to  significantly reduce the frequency  and severity of repeated stress injuries  caused by typing, which are the most common injury suffered in today's  office environment."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Ni1000", "Title": "High Speed Parallel VLSI for Implementing Multilayer Perceptrons", "Abstract": "1"}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "JPMAX", "Title": "Learning to Recognize Moving Objects as a Model-fitting Problem", "Abstract": "934"}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Electrotonic Transformation", "Title": "a Tool for Relating Neuronal Form to Function", "Abstract": "The spatial distribution and time course of electrical signals in neurons  have important theoretical and practical consequences. Because it is  difficult to infer how neuronal form affects electrical signaling, we  have developed a quantitative yet intuitive approach to the analysis of  electrotonus. This approach transforms the architecture of the cell  from anatomical to electrotonic space, using the logarithm of voltage  attenuation as the distance metric. We describe the theory behind this  approach and illustrate its use."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predictive Coding with Neural Nets", "Title": "Application to Text Compression", "Abstract": "To compress text files,  a neural predictor network  P  is used to ap(cid:173) proximate the conditional probability distribution of possible  \"next  characters\",  given  n  previous  characters.  P's outputs are fed  into  standard coding algorithms that generate short codes for characters  with  high  predicted  probability and  long  codes  for  highly  unpre(cid:173) dictable  characters.  Tested  on  short  German  newspaper  articles,  our method outperforms widely used  Lempel-Ziv algorithms (used  in  UNIX  functions such  as  \"compress\"  and  \"gzip\")."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Computational Structure of coordinate transformations", "Title": "A generalization study", "Abstract": "One  of the fundamental properties  that both neural  networks  and  the  central  nervous  system share is  the  ability to learn  and gener(cid:173) alize  from examples.  While this  property  has  been  studied  exten(cid:173) sively  in  the  neural  network  literature  it  has  not  been  thoroughly  explored in human perceptual and motor learning.  We have chosen  a  coordinate  transformation  system-the  visuomotor  map  which  transforms visual coordinates into motor coordinates-to study the  generalization effects  of learning new  input-output  pairs.  Using  a  paradigm of computer  controlled  altered  visual  feedback,  we  have  studied  the  generalization  of the  visuomotor  map  subsequent  to  both local  and context-dependent  remappings.  A  local  remapping  of one  or  two  input-output  pairs  induced  a  significant  global,  yet  decaying,  change  in  the  visuomotor map, suggesting  a  representa(cid:173) tion for  the  map composed of units  with large functional  receptive  fields.  Our study of context-dependent  remappings indicated that  a  single  point  in  visual  space  can  be  mapped to  two different  fin(cid:173) ger  locations  depending  on  a  context  variable-the starting  point  of  the  movement.  Furthermore,  as  the  context  is  varied  there  is  a  gradual  shift  between  the  two  remappings,  consistent  with  two  visuomotor  modules  being  learned  and  gated  smoothly  with  the  context."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Associative Decorrelation Dynamics", "Title": "A Theory of Self-Organization and Optimization in Feedback Networks", "Abstract": "This  paper  outlines  a  dynamic  theory  of  development  and  adap(cid:173) tation  in  neural  networks  with  feedback  connections.  Given  in(cid:173) put ensemble,  the  connections  change in strength according  to  an  associative  learning  rule  and  approach  a  stable  state  where  the  neuronal  outputs  are  decorrelated .  We  apply  this  theory  to  pri(cid:173) mary  visual  cortex and  examine  the implications of the  dynamical  decorrelation  of the  activities  of orientation  selective  cells  by  the  intracortical connections.  The theory gives a  unified  and quantita(cid:173) tive explanation of the  psychophysical experiments on  orientation  contrast and orientation adaptation.  Using only one parameter, we  achieve  good  agreements  between  the  theoretical  predictions  and  the experimental data."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SARDNET", "Title": "A Self-Organizing Feature Map for Sequences", "Abstract": "A  self-organizing  neural  network  for  sequence  classification  called  SARDNET is described  and analyzed experimentally.  SARDNET  extends the Kohonen  Feature Map architecture  with activation re(cid:173) tention  and  decay  in  order  to  create  unique  distributed  response  patterns for different sequences.  SARDNET yields extremely dense  yet descriptive representations of sequential input in very few  train(cid:173) ing  iterations.  The  network  has  proven  successful  on  mapping ar(cid:173) bitrary sequences  of binary and real numbers,  as well  as  phonemic  representations  of  English  words.  Potential  applications  include  isolated  spoken  word  recognition  and  cognitive  science  models  of  sequence  processing."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning direction in global motion", "Title": "two classes of psychophysically-motivated models", "Abstract": "Perceptual learning is  defined  as  fast  improvement  in  performance and  retention  of the  learned  ability  over  a  period  of time.  In a  set  of psy(cid:173) chophysical experiments  we  demonstrated  that  perceptual learning oc(cid:173) curs for the discrimination of direction in stochastic motion stimuli.  Here  we  model  this  learning  using  two  approaches:  a clustering  model  that  learns  to  accommodate  the motion  noise,  and an averaging  model  that  learns to  ignore the noise.  Simulations of the models show  performance  similar to the psychophysical results."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Forward dynamic models in human motor control", "Title": "Psychophysical evidence", "Abstract": "Based  on  computational  principles,  with  as  yet  no  direct  experi(cid:173) mental  validation,  it  has  been  proposed  that  the  central  nervous  system  (CNS)  uses  an internal model to simulate the  dynamic be(cid:173) havior of the motor system in planning, control and learning (Sut(cid:173) ton  and  Barto,  1981;  Ito,  1984;  Kawato  et  aI.,  1987;  Jordan  and  Rumelhart,  1992;  Miall et aI.,  1993).  We  present  experimental re(cid:173) sults  and simulations based on a  novel  approach  that investigates  the temporal propagation of errors  in the sensorimotor integration  process.  Our results  provide  direct  support for  the  existence  of an  internal model."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Patterns of damage in neural networks", "Title": "The effects of lesion area, shape and number", "Abstract": "Eytan  Ruppin,  James A.  Reggia"}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Glove-TalkII", "Title": "Mapping Hand Gestures to Speech Using Neural Networks", "Abstract": "S.  Sidney  Fe Is,  Geoffrey  Hinton"}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "New Algorithms for 2D and 3D Point Matching", "Title": "Pose Estimation and Correspondence", "Abstract": "A  fundamental  open  problem  in  computer  vision-determining  pose  and  correspondence  between  two  sets  of  points  in  space(cid:173) is  solved with a novel, robust  and easily implementable algorithm.  The  technique  works  on  noisy  point sets  that  may be  of unequal  sizes  and  may  differ  by  non-rigid  transformations.  A  2D  varia(cid:173) tion  calculates  the  pose  between  point  sets  related  by  an  affine  transformation-translation, rotation, scale and shear.  A 3D to 3D  variation calculates translation and rotation.  An objective describ(cid:173) ing  the  problem is  derived  from  Mean field  theory.  The objective  is  minimized with clocked  (EM-like)  dynamics.  Experiments with  both  handwritten  and  synthetic  data provide  empirical  evidence  for  the method."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Morphogenesis of the Lateral Geniculate Nucleus", "Title": "How Singularities Affect Global Structure", "Abstract": "The macaque lateral geniculate nucleus (LGN) exhibits an intricate  lamination pattern, which changes midway through the nucleus at a  point coincident with small gaps due to the blind spot in the retina.  We  present a  three-dimensional model of morphogenesis in  which  local cell interactions cause a  wave  of development of neuronal re(cid:173) ceptive fields  to propagate through the nucleus  and establish two  distinct lamination patterns.  We  examine the interactions between  the wave  and the localized singularities due  to the gaps,  and find  that the gaps induce the change in lamination pattern.  We  explore  critical factors which  determine general LGN organization."}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Recurrent Networks", "Title": "Second Order Properties and Pruning", "Abstract": "x(t + 1) = Yo(t + 1) = L WojYj(t)  + Wthres,o"}
{"Type": "conference", "Year": "1994", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization in Reinforcement Learning", "Title": "Safely Approximating the Value Function", "Abstract": "A  straightforward  approach  to  the  curse  of  dimensionality  in  re(cid:173) inforcement  learning  and  dynamic  programming  is  to  replace  the  lookup table with a generalizing function approximator such as a neu(cid:173) ral net.  Although this has been successful in the domain of backgam(cid:173) mon,  there  is  no  guarantee  of convergence.  In  this  paper,  we  show  that the combination of dynamic programming and function approx(cid:173) imation  is  not  robust,  and  in  even  very  benign  cases,  may produce  an  entirely  wrong  policy.  We  then  introduce  Grow-Support,  a  new  algorithm which is safe from divergence yet can still reap the benefits  of successful  generalization ."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beating a Defender in Robotic Soccer", "Title": "Memory-Based Learning of a Continuous Function", "Abstract": "Learning how to adjust to an opponent's position is critical to  the success of having intelligent agents collaborating towards the  achievement of specific tasks in unfriendly environments. This pa(cid:173) per describes our work on a Memory-based technique for to choose  an action based on a continuous-valued state attribute indicating  the position of an opponent. We investigate the question of how an  agent performs in nondeterministic variations of the training situ(cid:173) ations. Our experiments indicate that when the random variations  fall within some bound of the initial training, the agent performs  better with some initial training rather than from a tabula-rasa."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning with ensembles", "Title": "How overfitting can be useful", "Abstract": "We  study  the  characteristics  of learning  with ensembles.  Solving  exactly  the  simple  model  of an  ensemble  of linear  students,  we  find  surprisingly  rich  behaviour.  For  learning  in  large  ensembles,  it  is  advantageous  to  use  under-regularized  students,  which  actu(cid:173) ally  over-fit  the  training data.  Globally optimal performance  can  be  obtained by  choosing  the training set  sizes  of the students ap(cid:173) propriately.  For  smaller ensembles,  optimization of the  ensemble  weights  can yield significant improvements in ensemble generaliza(cid:173) tion  performance,  in particular if the  individual students  are  sub(cid:173) ject to noise in the training process.  Choosing students with a wide  range of regularization parameters makes this improvement robust  against changes in the unknown level of noise  in the training data."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tempering Backpropagation Networks", "Title": "Not All Weights are Created Equal", "Abstract": "Computational Neurobiology Lab  The Salk Institute for BioI. Studies  San Diego, CA 92186-5800, USA"}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SPERT-II", "Title": "A Vector Microprocessor System and its Application to Large Problems in Backpropagation Training", "Abstract": "We  report  on  our  development  of a  high-performance  system  for  neural  network  and other signal  processing  applications.  We  have  designed  and  implemented  a  vector  microprocessor  and  pack(cid:173) aged  it  as  an  attached  processor  for  a  conventional  workstation.  We  present  performance  comparisons  with  commercial  worksta(cid:173) tions on neural  network  backpropagation training.  The SPERT-II  system  demonstrates  significant  speedups  over  extensively  hand(cid:173) optimization code running on  the workstations."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pruning with generalization based weight saliencies", "Title": "λOBD, λOBS", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Using the Future to \"Sort Out\" the Present", "Title": "Rankprop and Multitask Learning for Medical Risk Evaluation", "Abstract": "A patient visits the doctor; the doctor reviews  the patient's history,  asks questions, makes basic measurements (blood pressure,  .. . ), and  prescribes  tests  or  treatment .  The  prescribed  course  of action  is  based  on  an assessment of patient risk-patients at higher risk  are  given  more  and  faster  attention.  It is  also  sequential- it  is  too  expensive  to  immediately order  all  tests  which  might  later  be  of  value.  This  paper  presents  two  methods  that  together  improve  the  accuracy  of  backprop  nets  on  a  pneumonia  risk  assessment  problem  by  10-50%.  Rankprop improves on backpropagation  with  sum of squares error in ranking patients by risk.  Multitask learning  takes advantage of future lab tests  available in the training set,  but  not  available  in  practice  when  predictions  must  be  made.  Both  methods are broadly  applicable."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predictive Q-Routing", "Title": "A Memory-based Reinforcement Learning Approach to Adaptive Traffic Control", "Abstract": "In  this  paper,  we  propose  a  memory-based  Q-Iearning  algorithm  called  predictive  Q-routing  (PQ-routing)  for  adaptive  traffic  con(cid:173) trol.  We attempt to address two problems encountered in Q-routing  (Boyan  &  Littman,  1994),  namely,  the inability to fine-tune  rout(cid:173) ing policies under  low  network  load and  the  inability to learn  new  optimal  policies  under  decreasing  load  conditions.  Unlike  other  memory-based  reinforcement  learning  algorithms  in  which  mem(cid:173) ory  is  used  to  keep  past  experiences  to  increase  learning  speed,  PQ-routing  keeps  the  best  experiences  learned  and  reuses  them  by  predicting  the  traffic  trend.  The  effectiveness  of  PQ-routing  has been  verified  under various network  topologies and traffic con(cid:173) ditions.  Simulation  results  show  that  PQ-routing  is  superior  to  Q-routing in terms of both learning speed and  adaptability."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "REMAP", "Title": "Recursive Estimation and Maximization of A Posteriori Probabilities - Application to Transition-Based Connectionist Speech Recognition", "Abstract": "In  this  paper,  we  introduce  REMAP,  an  approach for  the training  and estimation of posterior probabilities using a recursive algorithm  that is  reminiscent of the EM-based  Forward-Backward  (Liporace  1982)  algorithm  for  the  estimation  of sequence  likelihoods.  Al(cid:173) though  very  general,  the  method  is  developed  in  the  context  of a  statistical  model for  transition-based speech  recognition  using  Ar(cid:173) tificial  Neural  Networks  (ANN)  to  generate  probabilities for  Hid(cid:173) den  Markov  Models  (HMMs).  In  the  new  approach,  we  use  local  conditional posterior probabilities of transitions to estimate global  posterior  probabilities of word  sequences.  Although  we  still  use  ANNs  to  estimate  posterior  probabilities,  the  network  is  trained  with targets that are themselves estimates of local posterior proba(cid:173) bilities.  An  initial experimental result shows a significant decrease  in error-rate in  comparison to a  baseline system."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization in Reinforcement Learning", "Title": "Successful Examples Using Sparse Coarse Coding", "Abstract": "Generalization  in  Reinforcement Learning"}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SEEMORE", "Title": "A View-Based Approach to 3-D Object Recognition Using Multiple Visual Cues", "Abstract": "A  neurally-inspired  visual  object  recognition  system  is  described  called  SEEMORE,  whose  goal  is  to  identify  common objects  from  a  large  known  set-independent  of  3-D  viewiag  angle,  distance,  and  non-rigid  distortion.  SEEMORE's  database  consists  of 100  ob(cid:173) jects  that  are  rigid  (shovel),  non-rigid  (telephone  cord),  articu(cid:173) lated  (book), statistical (shrubbery),  and complex (photographs of  scenes).  Recognition results  were  obtained using a  set of 102 color  and shape feature channels within a simple feedforward network ar(cid:173) chitecture.  In  response  to  a  test  set  of 600  novel  test  views  (6  of  each object)  presented individually in color video images, SEEMORE  identified  the  object correctly  97% of the time (chance is 1%)  using  a  nearest  neighbor  classifier.  Similar levels  of performance  were  obtained for  the  subset  of 15  non-rigid objects.  Generalization be(cid:173) havior reveals emergence  of striking natural category structure  not  explicit in  the  input feature  dimensions."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Unified Learning Scheme", "Title": "Bayesian-Kullback Ying-Yang Machine", "Abstract": "A  Bayesian-Kullback  learning scheme,  called Ying-Yang  Machine,  is  proposed  based on  the  two  complement but equivalent Bayesian  representations  for  joint  density  and  their  Kullback  divergence.  Not  only  the  scheme  unifies  existing  major supervised  and  unsu(cid:173) pervised  learnings,  including  the  classical  maximum likelihood  or  least  square learning,  the  maximum information preservation,  the  EM  & em algorithm and information geometry, the recent  popular  Helmholtz  machine,  as  well  as  other  learning  methods  with  new  variants  and  new  results;  but  also  the  scheme  provides  a  number  of new  learning models."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Temporal coding in the sub-millisecond range", "Title": "Model of barn owl auditory pathway", "Abstract": "Temporal Coding in  the Submillisecond Range:  Model of Bam Owl Auditory Pathway"}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Softassign versus Softmax", "Title": "Benchmarks in Combinatorial Optimization", "Abstract": "A  new  technique,  termed  soft assign,  is  applied  for  the  first  time  to  two  classic  combinatorial  optimization  problems,  the  travel(cid:173) ing  salesman  problem  and  graph  partitioning.  Soft assign ,  which  has emerged from  the recurrent  neural  network/statistical physics  framework, enforces  two-way  (assignment) constraints without the  use  of penalty  terms  in  the  energy  functions.  The  soft assign  can  also  be  generalized  from  two-way  winner-take-all  constraints  to  multiple membership constraints which are required for graph par(cid:173) titioning.  The  soft assign  technique  is  compared  to  the  softmax  (Potts  glass).  Within  the  statistical  physics  framework,  softmax  and a penalty term has been a widely used method for enforcing the  two-way constraints common within many combinatorial optimiza(cid:173) tion  problems.  The  benchmarks  present  evidence  that  soft assign  has clear advantages in accuracy, speed,  parallelizabilityand algo(cid:173) rithmic simplicity over softmax and a penalty term in optimization  problems with two-way constraints."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Isolation to Cooperation", "Title": "An Alternative View of a System of Experts", "Abstract": "We introduce a constructive,  incremental learning system for regression  problems that models data by means of locally linear experts.  In contrast  to  other approaches,  the  experts  are  trained  independently  and  do  not  compete for data during learning.  Only when a prediction for  a query  is  required  do  the  experts  cooperate  by  blending  their  individual  predic(cid:173) tions.  Each expert is trained by  minimizing  a penalized local cross vali(cid:173) dation error using second order methods. In this way, an expert is able to  find a local distance metric by adjusting the size and  shape of the recep(cid:173) tive field in which its predictions are valid, and also to detect relevant in(cid:173) put features  by  adjusting  its bias  on  the  importance of individual input  dimensions. We derive asymptotic results for our method. In a variety of  simulations the properties of the algorithm are demonstrated with respect  to  interference,  learning  speed,  prediction  accuracy,  feature  detection,  and task oriented incremental learning."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Correlated Neuronal Response", "Title": "Time Scales and Mechanisms", "Abstract": "We  have  analyzed the relationship between  correlated spike  count  and the peak in the cross-correlation of spike trains for  pairs of si(cid:173) multaneously recorded neurons  from  a  previous  study of area MT  in  the  macaque  monkey  (Zohary  et  al.,  1994).  We  conclude  that  common  input,  responsible  for  creating peaks  on  the order of ten  milliseconds  wide  in  the  spike  train  cross-correlograms  (CCGs),  is  also  responsible  for  creating  the  correlation  in  spike  count  ob(cid:173) served  at  the  two  second  time  scale  of  the  trial.  We  argue  that  both common excitation and  inhibition  may  play significant  roles  in establishing this  correlation."}
{"Type": "conference", "Year": "1995", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Control of Selective Visual Attention", "Title": "Modeling the \"Where\" Pathway", "Abstract": "We  then  (section  2.3)  address  the  question  of the  integration  of  the  input  in  the  \"saliency map,\"  a  topographically organized map which codes for  the instantaneous  conspicuity  of the  different  parts of the visual field ."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ARTEX", "Title": "A Self-organizing Architecture for Classifying Image Regions", "Abstract": "A self-organizing architecture is  developed for  image region  classi(cid:173) fication.  The system  consists  of a  preprocessor  that utilizes multi(cid:173) scale filtering, competition, cooperation, and diffusion to compute a  vector  of image boundary  and surface  properties,  notably  texture  and  brightness  properties.  This  vector  inputs  to  a  system  that  incrementally  learns  noisy  multidimensional  mappings  and  their  probabilities.  The  architecture  is  applied  to  difficult  real-world  image  classification  problems,  including  classification  of synthet(cid:173) ic  aperture  radar  and  natural  texture  images,  and  outperforms a  recent state-of-the-art system at classifying natural textures."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "3D Object Recognition", "Title": "A Model of View-Tuned Neurons", "Abstract": "In  1990  Poggio and  Edelman proposed  a  view-based  model of ob(cid:173) ject recognition that accounts for several psychophysical properties  of certain  recognition  tasks.  The model predicted  the existence  of  view-tuned  and view-invariant units,  that were  later found  by  Lo(cid:173) gothetis  et  al.  (Logothetis  et  al.,  1995)  in  IT  cortex  of monkeys  trained  with views  of specific  paperclip  objects.  The model,  how(cid:173) ever,  does  not specify  the inputs to the view-tuned  units and their  internal  organization.  In  this  paper  we  propose  a  model of these  view-tuned  units  that  is  consistent  with  physiological  data from  single cell  responses."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Appearance Based Models", "Title": "Mixtures of Second Moment Experts", "Abstract": "This paper describes a new technique for object recognition based on learning  appearance  models.  The  image is  decomposed  into  local  regions  which  are  described  by  a  new  texture  representation  called  \"Generalized  Second  Mo(cid:173) ments\"  that are  derived  from the  output of multiscale,  multiorientation filter  banks.  Class-characteristic local texture features and their global composition  is learned by a hierarchical mixture of experts architecture (Jordan &  Jacobs).  The  technique  is  applied  to  a  vehicle  database  consisting  of 5  general  car  categories  (Sedan,  Van  with back-doors, Van  without back-doors, old Sedan,  and Volkswagen Bug).  This  is  a difficult problem with considerable in-class  variation.  The new  technique has  a 6.5% misclassification rate, compared to  eigen-images which give  17.4% misclassification rate,  and nearest neighbors  which give  15 .7% misclassification rate."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeuroScale", "Title": "Novel Topographic Feature Extraction using RBF Networks", "Abstract": "E  = 2: 2:(d~p - dqp)2,"}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MIMIC", "Title": "Finding Optima by Estimating Probability Densities", "Abstract": "In  many optimization problems,  the structure of solutions reflects  complex relationships between  the different  input parameters.  For  example, experience may tell us  that certain parameters are closely  related  and  should  not  be  explored  independently.  Similarly, ex(cid:173) perience  may establish  that  a  subset  of parameters must  take  on  particular  values.  Any  search  of the  cost  landscape  should  take  advantage of these relationships.  We  present  MIMIC,  a framework  in which  we  analyze the global structure of the optimization land(cid:173) scape.  A  novel  and  efficient  algorithm for  the  estimation of this  structure is  derived.  We  use  knowledge of this structure to guide a  randomized search  through the solution space  and,  in  turn,  to re(cid:173) fine our estimate ofthe structure.  Our technique obtains significant  speed  gains over  other randomized optimization procedures."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GTM", "Title": "A Principled Alternative to the Self-Organizing Map", "Abstract": "The  Self-Organizing Map  (SOM)  algorithm  has  been  extensively  studied and has  been  applied with considerable success to a  wide  variety of problems.  However, the algorithm is derived from heuris(cid:173) tic  ideas  and  this  leads  to a  number of significant  limitations.  In  this  paper,  we  consider  the  problem  of  modelling  the  probabil(cid:173) ity  density  of  data  in  a  space  of several  dimensions  in  terms  of  a  smaller number of latent,  or hidden,  variables.  We  introduce  a  novel form  of latent variable model,  which  we  call the GTM algo(cid:173) rithm (for  Generative  Topographic  Mapping),  which allows general  non-linear  transformations  from  latent  space  to  data  space,  and  which  is  trained  using  the  EM  (expectation-maximization)  algo(cid:173) rithm.  Our approach overcomes the limitations of the SOM, while  introducing no significant disadvantages.  We demonstrate the per(cid:173) formance of the GTM algorithm on simulated data from flow  diag(cid:173) nostics for  a  multi-phase oil pipeline."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bangs, Clicks, Snaps, Thuds and Whacks", "Title": "An Architecture for Acoustic Transient Processing", "Abstract": "We propose  a  neuromorphic  architecture  for  real-time  processing  of \nacoustic transients in analog VLSI.  We show how judicious normalization \nof a time-frequency signal allows an elegant and robust implementation \nof a correlation algorithm. The algorithm uses binary multiplexing instead \nof analog-analog  multiplication.  This  removes  the  need  for  analog \nstorage and analog-multiplication.  Simulations  show that the resulting \nalgorithm has the same out-of-sample classification performance (-93% \ncorrect) as a baseline template-matching algorithm."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Promoting Poor Features to Supervisors", "Title": "Some Inputs Work Better as Outputs", "Abstract": "In supervised  learning there is  usually  a  clear  distinction  between  inputs  and  outputs - inputs are  what  you  will  measure,  outputs  are  what  you  will  predict  from  those  measurements.  This  paper  shows  that the distinction between  inputs  and  outputs is  not this  simple.  Some  features  are  more  useful  as  extra  outputs  than  as  inputs.  By using a feature  as  an output we  get  more than just the  case  values but can. learn a  mapping from  the other inputs to that  feature.  For many features  this mapping may be more useful  than  the  feature  value  itself.  We  present  two  regression  problems  and  one  classification problem  where  performance improves  if features  that  could  have  been  used  as  inputs  are  used  as  extra  outputs  instead.  This result is  surprising since  a feature used  as  an output  is  not  used  during testing."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "An Architectural Mechanism for Direction-tuned Cortical Simple Cells", "Title": "The Role of Mutual Inhibition", "Abstract": "A  linear  architectural  model  of cortical  simple cells  is  presented.  The  model  evidences  how  mutual  inhibition,  occurring  through  synaptic  coupling  functions  asymmetrically  distributed  in  space,  can be a possible basis for  a wide variety of spatio-temporal simple  cell  response properties, including direction selectivity and velocity  tuning.  While  spatial  asymmetries  are  included  explicitly  in  the  structure of the inhibitory interconnections, temporal asymmetries  originate  from  the  specific  mutual  inhibition  scheme  considered.  Extensive simulations supporting the model are reported."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Complex-Cell Responses Derived from Center-Surround Inputs", "Title": "The Surprising Power of Intradendritic Computation", "Abstract": "B.  W.  Mel,  D.  L.  Ruderman and K.  A. Archie"}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dynamic Features for Visual Speechreading", "Title": "A Systematic Comparison", "Abstract": "Humans  use  visual as  well  as  auditory speech signals to recognize  spoken words.  A variety of systems have been investigated for per(cid:173) forming  this  task.  The main  purpose of this  research  was  to sys(cid:173) tematically compare the performance of a range of dynamic visual  features  on  a  speechreading  task.  We  have  found  that  normal(cid:173) ization  of images  to eliminate  variation  due  to  translation,  scale,  and planar rotation  yielded  substantial  improvements  in  general(cid:173) ization performance regardless of the visual representation used.  In  addition,  the dynamic  information  in  the difference  between  suc(cid:173) cessive  frames  yielded  better performance than optical-flow  based  approaches, and compression by local low-pass filtering worked sur(cid:173) prisingly better than global principal components analysis  (PCA).  These results are examined and possible explanations are explored."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Selective Integration", "Title": "A Model for Disparity Estimation", "Abstract": "Selective Integration: A Model for Disparity Estimation"}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Neurothermostat", "Title": "Predictive Optimal Control of Residential Heating Systems", "Abstract": "1  TEMPERATURE REGULATION AS  AN OPTIMAL"}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regression with Input-Dependent Noise", "Title": "A Bayesian Treatment", "Abstract": "In  most  treatments  of the  regression  problem  it  is  assumed  that  the distribution of target data can be described by a  deterministic  function  of the inputs, together with additive Gaussian noise hav(cid:173) ing constant variance.  The use of maximum likelihood to train such  models then  corresponds to the minimization of a  sum-of-squares  error function.  In  many applications a more realistic model would  allow  the  noise  variance  itself to  depend  on  the  input  variables.  However, the use of maximum likelihood to train such models would  give highly biased  results.  In  this paper we  show  how  a  Bayesian  treatment  can  allow  for  an  input-dependent  variance  while  over(cid:173) coming the bias of maximum likelihood."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multilayer Neural Networks", "Title": "One or Two Hidden Layers?", "Abstract": "We study the number of hidden layers required by a multilayer neu(cid:173) ral network with threshold  units to compute a function  f  from n d  to {O, I}.  In dimension d  =  2,  Gibson  characterized  the functions  computable with just one hidden layer, under  the assumption that  there  is no  \"multiple intersection  point\"  and that f  is only defined  on a compact set.  We consider the restriction of f  to the neighbor(cid:173) hood of a  multiple intersection  point or of infinity,  and give  neces(cid:173) sary  and sufficient  conditions for  it  to  be  locally computable with  one  hidden  layer.  We  show  that  adding  these  conditions  to  Gib(cid:173) son's  assumptions  is  not  sufficient  to  ensure  global  computability  with one hidden layer,  by exhibiting a new  non-local configuration,  the  \"critical cycle\",  which  implies  that f  is  not  computable  with  one  hidden  layer."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Learning from Finite Training Sets", "Title": "An Analytical Case Study", "Abstract": "We  analyse  online  learning  from  finite  training  sets  at  non(cid:173) infinitesimal  learning  rates  TJ.  By  an  extension  of statistical  me(cid:173) chanics  methods,  we  obtain  exact  results  for  the  time-dependent  generalization  error  of  a  linear  network  with  a  large  number  of  weights  N.  We  find,  for  example,  that  for  small training  sets  of  size  p  ~ N,  larger  learning rates  can  be  used  without compromis(cid:173) ing  asymptotic  generalization  performance  or  convergence  speed.  Encouragingly,  for  optimal  settings  of  TJ  (and,  less  importantly,  weight decay ,)  at given final  learning time, the generalization per(cid:173) formance of online learning is  essentially  as good as  that of offline  learning."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ARC-LH", "Title": "A New Adaptive Resampling Algorithm for Improving ANN Classifiers", "Abstract": "We introduce arc-Ih,  a new algorithm for improvement of ANN clas(cid:173) sifier  performance,  which  measures  the  importance of patterns  by  aggregated network output errors.  On several  artificial benchmark  problems,  this  algorithm compares favorably  with other  resample  and combine techniques."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Estimating Equivalent Kernels for Neural Networks", "Title": "A Data Perturbation Approach", "Abstract": "We  describe  the  notion  of  \"equivalent  kernels\"  and  suggest  that  this  provides a framework  for comparing different classes of regression models,  including  neural  networks  and  both  parametric  and  non-parametric  statistical techniques.  Unfortunately,  standard techniques break down  when  faced with models, such as neural networks,  in which there is more than one  \"layer\" of adjustable parameters.  We propose an algorithm which overcomes  this limitation,  estimating the equivalent kernels for  neural network models  using  a  data  perturbation approach.  Experimental  results  indicate  that  the  networks do  not  use  the  maximum possible  number of degrees of freedom,  that  these  can  be  controlled  using  regularisation  techniques  and  that  the  equivalent kernels learnt by the network vary both  in \"size\"  and in \"shape\"  in different regions of the input space."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Size of Multilayer Networks for Exact Learning", "Title": "Analytic Approach", "Abstract": "This  article  presents  a  new  result  about  the  size  of a  multilayer  neural network computing real outputs for exact learning of a finite  set of real samples.  The architecture of the network is feedforward,  with  one  hidden  layer  and several  outputs.  Starting from  a  fixed  training set,  we  consider  the  network  as  a  function  of its  weights.  We  derive,  for  a  wide family  of transfer  functions,  a  lower  and  an  upper  bound  on  the  number  of hidden  units  for  exact  learning,  given  the size  of the  dataset  and  the  dimensions of the  input and  output spaces."}
{"Type": "conference", "Year": "1996", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Maximum Likelihood Blind Source Separation", "Title": "A Context-Sensitive Generalization of ICA", "Abstract": "Xi(t) = 2: 2: aji(r)8j(t - r) = 2: aji * 8j"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Revolution", "Title": "Belief Propagation in Graphs with Cycles", "Abstract": "producing  the  real-valued  channel  output  vector  y  =  (Y!, ... ,YN).  The  decoder  must  then use  this  received  vector  to  make  a  guess  U at the  original  information  vector.  The  probability  P\" (e)  of  bit  error  is  minimized  by  choosing  the  Uk  that  maximizes  P(ukly)  for  k  = 1, ... , K.  The  rate  K/N of a  code  is  the  number  of  information  bits  communicated  per  codeword  bit.  We  will  consider  rate  ~ 1/2  systems in this paper,  where  N  ==  2K.  The simplest rate 1/2 encoder duplicates each information hit:  X2k-l  =  X2k  =  Uk,  k  =  1, ... , K.  The optimal decoder for this repetition code  simply averages together  pairs of noisy channel outputs and then applies  a threshold:"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A General Purpose Image Processing Chip", "Title": "Orientation Detection", "Abstract": "The  generalization  ability  of a  neural  network  can  sometimes  be  improved dramatically by regularization.  To  analyze the improve(cid:173) ment  one  needs  more  refined  results  than  the  asymptotic  distri(cid:173) bution  of  the  weight  vector.  Here  we  study  the  simple  case  of  one-dimensional  linear  regression  under  quadratic  regularization,  i.e.,  ridge  regression.  We  study  the  random  design,  misspecified  case, where we derive expansions for  the optimal regularization pa(cid:173) rameter and  the ensuing improvement.  It is  possible  to construct  examples  where it  is  best to use no regularization."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Serial Order in Reading Aloud", "Title": "Connectionist Models and Neighborhood Structure", "Abstract": "If globally high dimensional data has locally only low dimensional distribu(cid:173) tions,  it is  advantageous to perform a local dimensionality reduction before  further processing the data.  In this paper we examine several techniques for  local  dimensionality reduction  in the  context of locally weighted linear re(cid:173) gression.  As possible candidates, we derive local versions of factor analysis  regression, principle component regression, principle component regression  on joint distributions, and partial least squares regression. After outlining the  statistical bases of these  methods,  we perform Monte Carlo  simulations to  evaluate  their  robustness  with  respect  to  violations  of their  statistical  as(cid:173) sumptions.  One  surprising  outcome  is  that  locally  weighted  partial  least  squares  regression offers the best average results,  thus outperforming even  factor analysis, the theoretically most appealing of our candidate techniques."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Automated Aircraft Recovery via Reinforcement Learning", "Title": "Initial Experiments", "Abstract": "Automated Aircraft Recovery via Reinforcement Learning"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Receptive Field Formation in Natural Scene Environments", "Title": "Comparison of Single Cell Learning Rules", "Abstract": "B.  S.  Blais, N.  Intrator, H.  Shouval and L  N.  Cooper"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization in Decision Trees and DNF", "Title": "Does Size Matter?", "Abstract": "M.  Golea,  P Bartlett,  W.  S. Lee and L  Mason"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Asymptotic Theory for Regularization", "Title": "One-Dimensional Linear Case", "Abstract": "The  generalization  ability  of a  neural  network  can  sometimes  be  improved dramatically by regularization.  To  analyze the improve(cid:173) ment  one  needs  more  refined  results  than  the  asymptotic  distri(cid:173) bution  of  the  weight  vector.  Here  we  study  the  simple  case  of  one-dimensional  linear  regression  under  quadratic  regularization,  i.e.,  ridge  regression.  We  study  the  random  design,  misspecified  case, where we derive expansions for  the optimal regularization pa(cid:173) rameter and  the ensuing improvement.  It is  possible  to construct  examples  where it  is  best to use no regularization."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Instabilities in Eye Movement Control", "Title": "A Model of Periodic Alternating Nystagmus", "Abstract": "Nystagmus is  a pattern of eye movement characterized by  smooth rota(cid:173) tions  of the eye in one direction  and  rapid  rotations  in  the opposite di(cid:173) rection that reset eye position.  Periodic alternating nystagmus (PAN) is  a form  of uncontrollable  nystagmus  that  has  been  described  as  an  un(cid:173) stable but amplitude-limited oscillation.  PAN has been observed previ(cid:173) ously  only  in  subjects  with  vestibulo-cerebellar damage.  We describe  results in  which  PAN can be produced  in normal  subjects by prolonged  rotation in darkness.  We propose a new model  in  which the neural  cir(cid:173) cuits  that control eye movement are  inherently  unstable,  but  this  insta(cid:173) bility  is  kept  in  check  under  normal  circumstances  by  the  cerebellum.  Circumstances  which  alter  this  cerebellar  restraint,  such  as  vestibulo(cid:173) cerebellar damage or plasticity  due  to  rotation  in  darkness,  can  lead  to  PAN."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Radial Basis Functions", "Title": "A Bayesian Treatment", "Abstract": "Bayesian methods have been successfully applied to regression and  classification  problems  in  multi-layer  perceptrons.  We  present  a  novel  application of Bayesian  techniques to Radial Basis Function  networks  by  developing a  Gaussian approximation to the posterior  distribution  which,  for  fixed  basis  function  widths,  is  analytic  in  the  parameters.  The setting of regularization  constants  by  cross(cid:173) validation is  wasteful  as  only  a  single optimal  parameter estimate  is  retained.  We  treat this  issue  by  assigning  prior distributions to  these constants, which are then adapted in light of the data under  a  simple re-estimation formula."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Synaptic Transmission", "Title": "An Information-Theoretic Perspective", "Abstract": "Here  we  analyze  synaptic  transmission  from  an  infonnation-theoretic  perspective. We derive c1osed-fonn expressions for the lower-bounds on  the capacity of a simple model of a cortical synapse under two explicit  coding paradigms.  Under the \"signal estimation\" paradigm, we assume  the signal to be encoded in the mean firing rate of a Poisson neuron.  The  perfonnance of an optimal linear estimator of the  signal  then  provides  a lower bound on the  capacity for signal estimation.  Under the  \"signal  detection\" paradigm, the presence or absence of the signal has to be de(cid:173) tected.  Perfonnance of the optimal spike detector allows us to compute  a lower bound on the capacity for signal detection.  We  find  that single  synapses (for empirically measured parameter values) transmit infonna(cid:173) tion poorly but  significant  improvement can be  achieved  with  a  small  amount of redundancy."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Just One View", "Title": "Invariances in Inferotemporal Cell Tuning", "Abstract": "216"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Using Expectation to Guide Processing", "Title": "A Study of Three Real-World Applications", "Abstract": "In many real world tasks, only a small fraction of the available inputs are important  at any  particular time. This paper presents a method for ascertaining the relevance  of inputs  by  exploiting  temporal  coherence  and  predictability.  The  method  pro(cid:173) posed in this paper dynamically allocates relevance to inputs by using expectations  of their  future  values.  As  a  model  of the  task  is  learned,  the  model  is  simulta(cid:173) neously extended to create task-specific predictions of the future values of inputs.  Inputs which are either not relevant, and therefore not accounted for in the model,  or those which contain noise, will not be predicted accurately. These inputs can be  de-emphasized, and, in turn, a new, improved, model of the task created. The tech(cid:173) niques  presented  in  this  paper  have  yielded  significant  improvements  for  the  vision-based  autonomous control of a land vehicle,  vision-based hand tracking in  cluttered scenes, and the detection of faults in the etching of semiconductor wafers."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Parallel versus Serial Processing", "Title": "A Computational Study of Visual Search", "Abstract": "On Parallel versus Serial Processing: A  Computational Study a/Visual Search"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "S-Map", "Title": "A Network with a Simple Self-Organization Algorithm for Generative Topographic Mappings", "Abstract": "The S-Map is a network with a simple learning algorithm that com(cid:173) bines  the  self-organization  capability  of the  Self-Organizing  Map  (SOM)  and the probabilistic interpretability of the Generative To(cid:173) pographic  Mapping  (GTM).  The  simulations  suggest  that  the  S(cid:173) Map algorithm has a  stronger tendency  to self-organize from  ran(cid:173) dom  initial  configuration  than  the  GTM.  The  S-Map  algorithm  can  be  further  simplified  to employ  pure  Hebbian  learning,  with(cid:173) out changing the qualitative behaviour of the network."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Linear Concepts and Hidden Variables", "Title": "An Empirical Study", "Abstract": "We  learn  CIA  with  two  techniques:  the  standard  EM  algorithm,  and  a  new  algorithm we develop based on covariances.  We  compare these, in a controlled  fashion, against an algorithm (a version of Winnow) that attempts to find a good  linear classifier directly.  Our conclusions help delimit the fragility  of using the  CIA model for classification: once the data departs from this model, performance  quickly degrades and drops below that of the directly-learned linear classifier."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regression with Input-dependent Noise", "Title": "A Gaussian Process Treatment", "Abstract": "Cy(x(i),xU» =vyexp (-~ tWYl(x~i) _x~j»2) + Jy 8(i,j)"}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Human-like Knowledge by Singular Value Decomposition", "Title": "A Progress Report", "Abstract": "Singular value decomposition  (SVD)  can  be  viewed  as  a  method  for  unsupervised training of a network that associates two  classes  of events  reciprocally by linear connections  through  a single  hidden  layer.  SVD  was used to learn and represent relations among  very large numbers  of  words  (20k-60k)  and  very  large numbers  of natural  text  passages  (lk- 70k)  in  which  they  occurred.  The  result  was  100-350  dimensional  \"semantic spaces\" in which any trained or newly aibl word or passage  could be represented as  a vector,  and  similarities  were measured by  the  cosine  of  the  contained  angle  between  vectors.  Good  accmacy  in  simulating  human judgments and behaviors has  been  demonstrated  by  performance  on  multiple-choice  vocabulary  and  domain  knowledge  tests, emulation of expert essay evaluations,  and  in  several other ways.  Examples are also given of how the kind of knowledge extracted by  this  method can be applied."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Toward a Single-Cell Account for Binocular Disparity Tuning", "Title": "An Energy Model May Be Hiding in Your Dendrites", "Abstract": "Converging  evidence  has  shown  that  human  object  recognition  depends  on  familiarity  with  the  images  of  an  object.  Further,  the  greater  the  similarity  between  objects,  the  stronger  is  the  dependence  on  object  appearance,  and  the  more  important  two(cid:173) dimensional (2D) image information becomes.  These findings,  how(cid:173) ever, do not rule out the use of 3D structural information in recog(cid:173) nition,  and  the  degree  to  which  3D  information  is  used  in  visual  memory is an important issue.  Liu, Knill, & Kersten (1995) showed  that  any model  that  is  restricted  to  rotations  in  the  image  plane  of independent  2D  templates  could not  account for  human perfor(cid:173) mance in discriminating novel object views.  We now present results  from models of generalized radial basis functions  (GRBF), 2D near(cid:173) est  neighbor  matching that  allows  2D  affine  transformations,  and  a Bayesian statistical estimator that integrates over all possible 2D  affine  transformations.  The  performance  of the  human  observers  relative  to  each  of  the  models  is  better for  the  novel  views  than  for  the familiar  template views,  suggesting that humans generalize  better to novel  views  from  template views.  The  Bayesian estima(cid:173) tor yields the optimal performance with  2D  affine  transformations  and  independent  2D  templates.  Therefore,  models  of  2D  affine  matching  operations  with  independent  2D  templates  are unlikely  to account for  human recognition performance."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MELONET I", "Title": "Neural Nets for Inventing Baroque-Style Chorale Variations", "Abstract": "MELONET I is a multi-scale neural network system producing  baroque-style melodic variations. Given a melody, the system in(cid:173) vents a four-part chorale harmonization and a variation of any  chorale voice, after being trained on music pieces of composers like  J. S. Bach and J . Pachelbel. Unlike earlier approaches to the learn(cid:173) ing of melodic structure, the system is able to learn and reproduce  high-order structure like harmonic, motif and phrase structure in  melodic sequences. This is achieved by using mutually interacting  feedforward networks operating at different time scales, in combi(cid:173) nation with Kohonen networks to classify and recognize musical  structure. The results are chorale partitas in the style of J. Pachel(cid:173) bel. Their quality has been judged by experts to be comparable to  improvisations invented by an experienced human organist."}
{"Type": "conference", "Year": "1997", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ensemble and Modular Approaches for Face Detection", "Title": "A Comparison", "Abstract": "threshold  used  to adjust the sensitivity of the model."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probabilistic Modeling for Face Orientation Discrimination", "Title": "Learning from Labeled and Unlabeled Data", "Abstract": "This paper presents probabilistic modeling methods to solve the problem of dis(cid:173) criminating between five facial  orientations with  very  little labeled data.  Three  models are explored. The first model maintains no inter-pixel dependencies, the  second model is capable of modeling a set of arbitrary pair-wise dependencies,  and the last model allows  dependencies  only  between  neighboring pixels. We  show that for all three of these models, the accuracy of the learned models can  be greatly improved by  augmenting a small number of labeled training images  with  a  large  set of unlabeled  images using  Expectation-Maximization.  This  is  important because it is often difficult to obtain image labels, while many unla(cid:173) beled images  are  readily  available.  Through  a  large  set  of empirical  tests,  we  examine the benefits  of unlabeled data  for  each  of the  models.  By  using only  two randomly selected labeled examples per class, we can discriminate between  the five  facial orientations with an accuracy of 94%; with six labeled examples,  we achieve an accuracy of 98%."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Boxlets", "Title": "A Fast Convolution Algorithm for Signal Processing and Neural Networks", "Abstract": "Signal  processing  and  pattern  recognition  algorithms make  exten(cid:173) sive  use  of convolution.  In  many cases, computational accuracy  is  not  as  important  as  computational  speed.  In  feature  extraction,  for  instance,  the  features  of interest  in  a  signal  are  usually  quite  distorted.  This form of noise justifies some level of quantization in  order  to  achieve  faster  feature  extraction .  Our  approach  consists  of approximating regions  of the  signal  with  low  degree  polynomi(cid:173) als,  and then differentiating the resulting signals in order to obtain  impulse functions  (or derivatives of impulse functions).  With this  representation,  convolution  becomes  extremely  simple and  can  be  implemented quite effectively.  The true  convolution can  be  recov(cid:173) ered  by  integrating  the  result  of  the  convolution.  This  method  yields  substantial speed  up  in feature  extraction  and is  applicable  to convolutional neural  networks."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Convergence Rates of Algorithms for Visual Search", "Title": "Detecting Visual Contours", "Abstract": "This  paper  formulates  the  problem  of  visual  search  as  Bayesian  inference  and  defines  a  Bayesian  ensemble  of  problem  instances .  In  particular,  we  address  the  problem  of  the  detection  of  visual  contours  in  noise/clutter  by  optimizing  a  global  criterion  which  combines  local  intensity  and  geometry  information.  We  analyze  the  convergence  rates  of  A * search  algorithms  using  results  from  information theory to bound  the  probability of rare  events  within  the Bayesian ensemble.  This analysis determines characteristics of  the  domain ,  which  we  call  order  parameters,  that  determine  the  convergence  rates.  In  particular,  we  present  a  specific  admissible  A * algorithm with pruning which converges, with high probability,  with  expected  time  O(N)  in  the  size  of  the  problem.  In  addi(cid:173) tion,  we  briefly  summarize  extensions  of this  work  which  address  fundamental  limits  of target  contour  detectability  (Le.  algorithm  independent results)  and the use  of non-admissible heuristics."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On-Line Learning with Restricted Training Sets", "Title": "Exact Solution as Benchmark for General Theories", "Abstract": "O(ws(s log d+log(dqh/ s))) and O(ws((h/ s) log q) +log(dqh/ s)) are  upper bounds for  the VC-dimension of a  set of neural networks of  units  with  piecewise  polynomial  activation  functions,  where  s  is  the  depth  of  the  network,  h  is  the  number  of  hidden  units,  w  is  the  number  of  adjustable  parameters,  q  is  the  maximum  of  the  number of polynomial segments of the activation function, and d is  the  maximum degree  of  the polynomials;  also  n(wslog(dqh/s))  is  a  lower  bound  for  the VC-dimension  of such  a  network set,  which  are tight for  the cases  s =  8(h)  and  s is  constant.  For the special  case q =  1,  the VC-dimension is  8(ws log d)."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shrinking the Tube", "Title": "A New Support Vector Regression Algorithm", "Abstract": "A new algorithm for Support Vector regression is  described.  For a priori  chosen 1/,  it automatically adjusts a flexible tube of minimal radius to the  data such that  at most a fraction  1/  of the data points lie outside.  More(cid:173) over,  it  is  shown  how  to  use  parametric  tube  shapes  with  non-constant  radius. The algorithm is analysed theoretically and experimentally."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse Code Shrinkage", "Title": "Denoising by Nonlinear Maximum Likelihood Estimation", "Abstract": "Sparse  coding  is  a  method  for  finding  a  representation  of data in  which  each  of the  components of the representation is  only  rarely  significantly  active.  Such  a  representation is  closely  related  to re(cid:173) dundancy reduction and independent component analysis,  and has  some  neurophysiological  plausibility.  In  this  paper,  we  show  how  sparse coding can be used for denoising.  Using maximum likelihood  estimation of nongaussian variables corrupted by gaussian noise, we  show  how  to  apply a  shrinkage nonlinearity on  the components  of  sparse coding so  as  to reduce noise.  Furthermore,  we  show  how  to  choose the optimal sparse coding basis for  denoising.  Our method  is  closely  related  to  the  method  of wavelet  shrinkage,  but  has  the  important benefit over wavelet methods that both the features and  the shrinkage parameters are estimated directly from  the data."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Maximum-Likelihood Continuity Mapping (MALCOM)", "Title": "An Alternative to HMMs", "Abstract": "We describe Maximum-Likelihood Continuity Mapping (MALCOM), an  alternative to  hidden Markov models (HMMs) for processing sequence  data such as speech.  While HMMs have a discrete \"hidden\" space con(cid:173) strained by  a fixed  finite-automaton architecture, MALCOM has a con(cid:173) tinuous hidden space-a continuity map-that is  constrained only  by  a  smoothness requirement on paths through the space.  MALCOM fits  into  the same probabilistic framework for speech recognition as  HMMs, but  it represents  a  more  realistic  model  of the  speech  production  process.  To  evaluate the extent to which MALCOM captures speech production  information, we  generated continuous speech continuity maps  for three  speakers  and  used  the  paths  through  them  to  predict measured  speech  articulator data.  The median  correlation  between  the MALCOM paths  obtained from  only the  speech  acoustics  and  articulator measurements  was 0.77 on an  independent test set not used  to train MALCOM or the  predictor.  This  unsupervised  model  achieved  correlations  over speak(cid:173) ers and articulators only 0.02 to 0.15 lower than those obtained using an  analogous supervised method which used articulatory measurements as  well as acoustics .."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DTs", "Title": "Dynamic Trees", "Abstract": "In  this  paper we  introduce a new  class of image models,  which  we  call  dynamic trees or  DTs.  A dynamic tree model specifies  a prior  over a  large number of trees, each one of which is  a tree-structured  belief  net  (TSBN).  Experiments  show  that  DTs  are  capable  of  generating images that are less blocky, and the models have better  translation  invariance properties  than  a  fixed,  \"balanced\"  TSBN.  We  also show that Simulated Annealing is effective at finding trees  which  have high  posterior probability."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unsupervised and Supervised Clustering", "Title": "The Mutual Information between Parameters and Observations", "Abstract": "Recent  works  in  parameter  estimation  and  neural  coding  have  demonstrated that optimal performance are related to the  mutual  information between parameters and data.  We  consider the mutual  information in  the case where  the dependency in the parameter (a  vector  8)  of  the  conditional  p.d.f.  of each  observation  (a  vector  0, is  through  the  scalar  product  8.~ only.  We  derive  bounds  and  asymptotic behaviour for  the mutual information and compare with  results  obtained on  the same model with the\" replica technique\" ."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Perceiving without Learning", "Title": "From Spirals to Inside/Outside Relations", "Abstract": "As  a benchmark task,  the  spiral  problem  is  well  known  in  neural  net(cid:173) works.  Unlike  previous  work  that  emphasizes  learning,  we  approach  the  problem from  a generic perspective that does  not involve learning.  We  point out that the spiral problem is intrinsically connected to the in(cid:173) side/outside problem.  A  generic  solution  to  both problems is proposed  based on  oscillatory correlation using a time delay network.  Our simu(cid:173) lation results are qualitatively  consistent with  human performance,  and  we  interpret human limitations in  terms  of synchrony and  time  delays,  both biologically plausible.  As a special case, our network without time  delays can always distinguish these figures regardless of shape, position,  size, and orientation."}
{"Type": "conference", "Year": "1998", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Utilizing lime", "Title": "Asynchronous Binding", "Abstract": "Historically,  connectionist  systems  have  not excelled  at  represent(cid:173) ing and manipulating complex structures.  How  can a  system com(cid:173) posed  of simple  neuron-like  computing  elements  encode  complex  relations?  Recently,  researchers have begun to appreciate that rep(cid:173) resentations can extend in  both time and space.  Many researchers  have proposed that the synchronous firing of units can encode com(cid:173) plex  representations.  I  identify  the  limitations  of  this  approach  and present an  asynchronous model of binding that effectively rep(cid:173) resents  complex  structures.  The  asynchronous model  extends  the  synchronous approach.  I argue that our cognitive architecture uti(cid:173) lizes  a similar mechanism."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "v-Arc", "Title": "Ensemble Learning in the Presence of Outliers", "Abstract": "AdaBoost and other ensemble methods have successfully  been ap(cid:173) plied  to a  number  of classification  tasks,  seemingly  defying  prob(cid:173) lems of overfitting.  AdaBoost performs gradient descent in an error  function  with  respect  to the margin,  asymptotically concentrating  on  the  patterns which  are  hardest to learn.  For  very  noisy  prob(cid:173) lems,  however,  this  can  be  disadvantageous.  Indeed,  theoretical  analysis has shown that the margin distribution,  as opposed to just  the minimal margin, plays a crucial role in understanding this phe(cid:173) nomenon.  Loosely  speaking,  some  outliers  should  be  tolerated  if  this  has  the  benefit  of substantially  increasing  the  margin  on  the  remaining points.  We  propose a  new  boosting algorithm which  al(cid:173) lows for  the possibility of a  pre-specified fraction of points to lie  in  the margin area Or even on the wrong side of the decision boundary."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Image Recognition in Context", "Title": "Application to Microscopic Urinalysis", "Abstract": "i  =  1, ... N.  With  each  object  we  associate  a  Consider  a  set  of  N  objects  Ti ,  class  label  Ci  that  is  a  member  of  a  label  set  n  =  {1 , ... , D} .  Each  object  Ti  is  characterized  by  a  set  of  measurements  Xi  E  R P,  which  we  call  a  feature  vec(cid:173) tor.  Many  techniques  [1][2][4J[6}  incorporate  context  by  conditioning  the  posterior  probability  of objects'  identities  on  the joint features  of all  accompanying objects.  i.e .•  P(Cl, C2,··· , cNlxl , . . . , XN). and then maximizing it with respectto Cl, C2, . .. , CN . It can  be  shown  thatp(cl,c2, . . . ,cNlxl, . . . ,xN)  ex  p(cllxl) ... p(CNlxN)  (~ci\"\"'(N\\ given  certain reasonable assumptions."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Better Generative Models for Sequential Data Problems", "Title": "Bidirectional Recurrent Mixture Density Networks", "Abstract": "This  paper  describes  bidirectional  recurrent  mixture  density  net(cid:173) works,  which  can  model  multi-modal  distributions  of  the  type  P(Xt Iyf)  and  P(Xt lXI, X2 , ... ,Xt-l, yf) without  any  explicit  as(cid:173) sumptions  about  the  use  of context .  These  expressions  occur  fre(cid:173) quently  in  pattern  recognition  problems  with  sequential  data,  for  example  in  speech  recognition.  Experiments  show  that  the  pro(cid:173) posed generative models give  a higher likelihood on test data com(cid:173) pared to a  traditional modeling approach, indicating that they can  summarize  the statistical  properties of the data better."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Understanding Stepwise Generalization of Support Vector Machines", "Title": "a Toy Model", "Abstract": "In this  article  we  study the effects  of introducing structure in the  input distribution of the data to be learnt by a  simple perceptron.  We  determine the learning curves within the framework of Statis(cid:173) tical  Mechanics.  Stepwise  generalization  occurs  as  a  function  of  the number of examples when the distribution of patterns is highly  anisotropic.  Although  extremely simple,  the model  seems  to cap(cid:173) ture  the  relevant  features  of  a  class  of  Support  Vector  Machines  which was  recently shown to present this behavior."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Recurrent Cortical Competition", "Title": "Strengthen or Weaken?", "Abstract": "We investigate the short term .dynamics of the recurrent competition and  neural  activity in the primary visual cortex in terms of information pro(cid:173) cessing and in the context of orientation selectivity.  We propose that af(cid:173) ter stimulus onset, the strength of the recurrent excitation decreases due  to  fast  synaptic depression.  As  a consequence,  the network shifts from  an  initially highly  nonlinear to a  more  linear operating  regime.  Sharp  orientation tuning is established in the first highly competitive phase.  In  the second and less competitive phase, precise signaling of multiple ori(cid:173) entations and long range modulation, e.g.,  by intra- and inter-areal con(cid:173) nections becomes possible (surround effects).  Thus the network first ex(cid:173) tracts  the  salient  features  from  the  stimulus,  and  then  starts  to  process  the details.  We  show  that  this  signal  processing  strategy  is  optimal  if  the neurons have limited bandwidth and their objective is to transmit the  maximum amount of information in any time interval beginning with the  stimulus onset."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Informative Statistics", "Title": "A Nonparametnic Approach", "Abstract": "We discuss an information theoretic approach for categorizing and mod(cid:173) eling dynamic processes. The approach can learn a compact and informa(cid:173) tive statistic which summarizes past states to predict future observations.  Furthermore, the  uncertainty of the prediction is characterized nonpara(cid:173) metrically by a joint density over the learned statistic and present obser(cid:173) vation.  We  discuss the  application of the technique to both noise driven  dynamical systems and random processes sampled from a density which  is conditioned on the past. In the first case we show results in which both  the  dynamics of random walk and the  statistics of the  driving noise  are  captured.  In the second case we  present results in  which a summarizing  statistic  is  learned  on  noisy  random telegraph  waves  with  differing de(cid:173) pendencies on past states.  In both cases the algorithm yields a principled  approach for discriminating processes with differing dynamics and/or de(cid:173) pendencies.  The method is  grounded in  ideas  from  information theory  and nonparametric statistics."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Coexpression to Coregulation", "Title": "An Approach to Inferring Transcriptional Regulation among Gene Classes from Large-Scale Expression Data", "Abstract": "the  circuit  parameter  sets"}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Data Visualization and Feature Selection", "Title": "New Algorithms for Nongaussian Data", "Abstract": "Data  visualization  and  feature  selection  methods  are  proposed  based on the )oint mutual information and ICA.  The visualization  methods can find  many good 2-D  projections for  high dimensional  data interpretation,  which  cannot be easily found by  the other ex(cid:173) isting methods.  The new  variable selection  method is found  to be  better in eliminating redundancy in the inputs than other methods  based  on  simple mutual information.  The efficacy  of the  methods  is illustrated on a radar signal analysis problem to find  2-D viewing  coordinates for  data visualization and to select  inputs for  a  neural  network  classifier.  Keywords:  feature  selection,  joint mutual information,  ICA,  vi(cid:173) sualization, classification."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning the Similarity of Documents", "Title": "An Information-Geometric Approach to Document Retrieval and Categorization", "Abstract": "The  project  pursued  in  this  paper  is  to  develop  from  first  information-geometric  principles  a  general  method  for  learning  the  similarity  between  text  documents.  Each  individual  docu(cid:173) ment  is  modeled  as  a  memoryless  information source.  Based  on  a  latent  class  decomposition of the  term-document  matrix, a  low(cid:173) dimensional  (curved)  multinomial subfamily is  learned.  From this  model a  canonical similarity function - known as the Fisher  kernel  - is  derived.  Our  approach  can  be  applied  for  unsupervised  and  supervised  learning problems alike.  This in  particular covers inter(cid:173) esting  cases  where  both,  labeled and  unlabeled  data are  available.  Experiments in  automated indexing and text categorization verify  the advantages of the proposed  method."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Constructing Heterogeneous Committees Using Input Feature Grouping", "Title": "Application to Economic Forecasting", "Abstract": "The  committee  approach  has  been  proposed  for  reducing  model  uncertainty  and  improving  generalization  performance.  The  ad(cid:173) vantage of committees depends  on  (1)  the performance of individ(cid:173) ual members  and  (2)  the correlational structure of errors between  members.  This paper presents an input grouping technique for  de(cid:173) signing a  heterogeneous  committee.  With  this  technique,  all input  variables are first grouped based on their mutual information.  Sta(cid:173) tistically  similar  variables  are  assigned  to  the  same  group.  Each  member's  input  set  is  then  formed  by  input  variables  extracted  from different groups.  Our designed  committees have less error cor(cid:173) relation between its members, since each member observes different  input variable combinations.  The individual member's feature sets  contain less redundant information, because highly correlated vari(cid:173) ables will not be combined together.  The member feature sets con(cid:173) tain almost complete information, since each set contains a feature  from  each  information group.  An  empirical study for  a  noisy  and  nonstationary  economic  forecasting  problem  shows  that  commit(cid:173) tees constructed by our proposed technique outperform committees  formed using several existing techniques."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Audio Vision", "Title": "Using Audio-Visual Synchrony to Locate Sounds", "Abstract": "Psychophysical and physiological evidence shows that sound local(cid:173) ization of acoustic signals is strongly influenced by  their synchrony  with visual signals.  This effect,  known as ventriloquism, is at work  when  sound  coming  from  the  side  of a  TV  set  feels  as  if it  were  coming  from  the  mouth  of the  actors.  The  ventriloquism  effect  suggests that there is  important information about sound location  encoded in  the synchrony between the audio and video signals.  In  spite  of  this  evidence,  audiovisual  synchrony  is  rarely  used  as  a  source of information  in  computer  vision  tasks.  In  this  paper  we  explore the use  of audio  visual  synchrony to locate sound sources.  We developed a system that searches for regions of the visual land(cid:173) scape that correlate highly with the acoustic signals and tags them  as  likely  to contain an acoustic  source.  We  discuss  our experience  implementing the system,  present results on a  speaker localization  task and discuss potential applications of the approach."}
{"Type": "conference", "Year": "1999", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Parallel Problems Server", "Title": "an Interactive Tool for Large Scale Machine Learning", "Abstract": "Imagine that you wish to classify data consisting of tens of thousands of ex(cid:173) amples residing in a twenty thousand dimensional space.  How can one ap(cid:173) ply standard machine learning algorithms? We describe the Parallel Prob(cid:173) lems Server (PPServer) and MATLAB*P.  In tandem they  allow users  of  networked computers to work transparently on large data sets from within  Matlab.  This  work is motivated by the desire to  bring the many  benefits  of scientific computing algorithms and computational power to  machine  learning researchers.  We  demonstrate the usefulness  of the system on  a number of tasks.  For  example,  we perform independent components analysis on very large text  corpora consisting  of tens  of thousands of documents,  making  minimal  changes  to  the original Bell  and  Sejnowski Matlab source  (Bell  and  Se(cid:173) jnowski,  1995).  Applying ML techniques to data previously beyond their  reach leads to interesting analyses of both data and algorithms."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Overfitting in Neural Nets", "Title": "Backpropagation, Conjugate Gradient, and Early Stopping", "Abstract": "The conventional wisdom is that backprop nets with excess hidden units  generalize  poorly.  We  show  that  nets  with  excess  capacity  generalize  well when  trained with backprop and early  stopping.  Experiments  sug(cid:173) gest two reasons for this:  1) Overfitting can vary significantly in different  regions of the model.  Excess capacity allows better fit to regions of high  non-linearity,  and  backprop often  avoids  overfitting  the  regions  of low  non-linearity.  2)  Regardless  of size,  nets  learn  task  subcomponents  in  similar sequence.  Big nets pass  through stages  similar to those learned  by  smaller nets.  Early  stopping can  stop training the large net  when  it  generalizes  comparably  to  a  smaller net.  We  also  show  that conjugate  gradient can yield worse generalization because it overfits regions of low  non-linearity when learning to fit regions of high non-linearity."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A PAC-Bayesian Margin Bound for Linear Classifiers", "Title": "Why SVMs work", "Abstract": "to a  vanishing com(cid:173)"}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "APRICODD", "Title": "Approximate Policy Construction Using Decision Diagrams", "Abstract": "We propose a method of approximate dynamic programming for Markov  decision processes (MDPs) using algebraic decision diagrams  (ADDs).  We produce near-optimal value functions and policies with much lower  time  and  space  requirements  than  exact  dynamic  programming.  Our  method reduces  the  sizes  of the  intermediate value functions  generated  during value iteration by replacing the values at the terminals of the ADD  with  ranges  of values.  Our method is  demonstrated on  a class  of large  MDPs (with up to 34 billion states), and we compare the results with the  optimal value functions."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accumulator Networks", "Title": "Suitors of Local Probability Propagation", "Abstract": "One  way  to  approximate  inference  in  richly-connected  graphical  models  is  to  apply  the  sum-product  algorithm  (a.k.a.  probabil(cid:173) ity propagation algorithm), while  ignoring the fact  that the graph  has cycles.  The sum-product  algorithm can  be directly applied in  Gaussian networks  and in  graphs for  coding,  but for  many condi(cid:173) tional probability functions  - including the sigmoid function  - di(cid:173) rect  application of the sum-product  algorithm is  not possible.  We  introduce  \"accumulator networks\"  that  have low  local  complexity  (but exponential global complexity) so  the sum-product algorithm  can be directly applied.  In an accumulator network, the probability  of a child given its parents is  computed by accumulating the inputs  from the parents in a Markov chain or more generally a tree.  After  giving  expressions  for  inference  and  learning  in  accumulator  net(cid:173) works,  we  give  results  on the  \"bars problem\"  and on the problem  of extracting translated, overlapping faces  from  an image."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Maximum Likelihood and Density Estimation", "Title": "A Sample-Based Criterion for Unsupervised Learning of Complex Models", "Abstract": "The goal of many unsupervised learning procedures is to bring two  probability  distributions  into  alignment.  Generative  models  such  as  Gaussian mixtures and Boltzmann machines can be cast in this  light,  as  can recoding models  such  as ICA  and projection pursuit.  We propose a novel sample-based error measure for these classes of  models, which applies even in situations where maximum likelihood  (ML)  and  probability  density  estimation-based  formulations  can(cid:173) not be applied,  e.g.,  models that are nonlinear  or have intractable  posteriors.  Furthermore,  our  sample-based  error  measure  avoids  the difficulties of approximating a  density function.  We  prove that  with  an unconstrained  model,  (1)  our approach  converges  on  the  correct solution as the number of samples goes to infinity,  and  (2)  the expected solution of our approach in the generative framework  is  the  ML  solution.  Finally,  we  evaluate our approach via simula(cid:173) tions of linear and nonlinear models  on  mixture of Gaussians and  ICA problems.  The experiments show the broad applicability and  generality of our approach."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Manhattan World Assumption", "Title": "Regularities in Scene Statistics which Enable Bayesian Inference", "Abstract": "Preliminary work by the authors made use of the so-called  \"Man(cid:173) hattan  world\"  assumption  about  the  scene  statistics  of  city  and  indoor scenes.  This assumption stated that such  scenes were built  on a  cartesian grid which led to regularities in the image edge gra(cid:173) dient  statistics.  In this paper we  explore the general applicability  of this  assumption  and show  that,  surprisingly,  it holds  in a  large  variety of less structured environments including rural scenes.  This  enables us, from  a single image, to determine the orientation of the  viewer relative to the scene structure and also to detect target ob(cid:173) jects  which  are  not  aligned  with  the  grid.  These  inferences  are  performed  using  a  Bayesian  model  with  probability  distributions  (e.g.  on the image gradient statistics)  learnt from  real data."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Discovering Hidden Variables", "Title": "A Structure-Based Approach", "Abstract": "A serious problem in learning probabilistic models is the presence of hid(cid:173) den variables. These variables are not observed, yet interact with several  of the observed variables.  As  such,  they induce seemingly complex de(cid:173) pendencies  among  the  latter.  In  recent years,  much  attention  has  been  devoted to  the  development of algorithms for  learning parameters,  and  in  some cases  structure, in  the presence of hidden variables.  In this  pa(cid:173) per,  we  address  the  related  problem of detecting  hidden  variables  that  interact with the observed variables.  This problem is of interest both for  improving our understanding of the domain and as a preliminary step that  guides the learning procedure towards promising models.  A very natural  approach is  to  search for \"structural  signatures\" of hidden variables - substructures in the learned network that tend to  suggest the presence of  a hidden variable.  We  make this  basic  idea concrete, and  show  how  to  integrate it with structure-search algorithms.  We evaluate this method on  several synthetic and real-life datasets, and show that it performs surpris(cid:173) ingly well."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FaceSync", "Title": "A Linear Operator for Measuring Synchronization of Video Facial Images and Audio Tracks", "Abstract": "This paper describes an algorithm, FaceSync, that measures the degree of synchronization  between the video image of a face and the associated audio signal. We can do this task by  synthesizing the talking face,  using techniques  such  as Video  Rewrite  [1], and then com(cid:173) paring the synthesized video with the test video. That process, however, is expensive. Our  solution finds  a linear operator that, when applied to the audio and video signals, generates  an  audio-video-synchronization-error  signal.  The  linear  operator  gathers  information  from throughout the image and thus allows us to do the computation inexpensively.  Hershey and Movellan  [2]  describe an approach based on measuring the mutual informa(cid:173) tion between the audio signal and individual pixels in the  video. The correlation between  the audio signal, x, and one pixel in the image y,  is  given by Pearson's correlation,  r.  The  mutual information between these two  variables is  given by f(x,y)  = -1/2  log(l-?). They  create movies that show the regions of the video that have high correlation with the audio;"}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayes Networks on Ice", "Title": "Robotic Search for Antarctic Meteorites", "Abstract": "A  Bayes  network  based  classifier  for  distinguishing  terrestrial  rocks  from  meteorites  is  implemented  onboard  the  Nomad  robot.  Equipped with a camera,  spectrometer and eddy current sensor, this  robot searched the  ice  sheets of Antarctica and autonomously made  the first robotic identification of a meteorite, in January 2000 at the  Elephant Moraine.  This paper discusses  rock classification from  a  robotic platform, and describes the system onboard Nomad."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shape Context", "Title": "A New Descriptor for Shape Matching and Object Recognition", "Abstract": "We  develop  an  approach  to  object  recognition  based  on  match(cid:173) ing shapes and using a resulting measure of similarity in a  nearest  neighbor  classifier.  The  key  algorithmic  problem  here  is  that  of  finding  pointwise  correspondences  between  an  image shape  and  a  stored  prototype  shape.  We  introduce  a  new  shape  descriptor,  the  shape  context,  which  makes  this  possible,  using  a  simple  and  robust algorithm.  The shape context at a point captures the distri(cid:173) bution over relative positions of other shape points and thus sum(cid:173) marizes  global  shape in  a  rich,  local  descriptor.  We  demonstrate  that  shape  contexts  greatly  simplify  recovery  of correspondences  between points of two given shapes.  Once shapes are aligned, shape  contexts are used to define a robust score for measuring shape sim(cid:173) ilarity.  We  have  used  this  score  in  a  nearest-neighbor  classifier  for  recognition of hand written  digits  as  well  as  3D  objects,  using  exactly  the  same  distance  function.  On  the  benchmark  MNIST  dataset  of handwritten  digits,  this  yields  an  error  rate  of 0.63%,  outperforming other published techniques."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel-Based Reinforcement Learning in Average-Cost Problems", "Title": "An Application to Optimal Portfolio Choice", "Abstract": "Many  approaches  to  reinforcement  learning  combine  neural  net(cid:173) works  or other  parametric function  approximators with  a  form  of  temporal-difference  learning  to  estimate  the  value  function  of  a  Markov  Decision  Process.  A  significant disadvantage of those  pro(cid:173) cedures  is that the resulting learning algorithms are frequently un(cid:173) stable.  In  this  work,  we  present  a  new,  kernel-based  approach  to  reinforcement learning which overcomes this difficulty and provably  converges  to a  unique solution.  By contrast to existing algorithms,  our  method  can  also  be  shown  to  be  consistent  in  the  sense  that  its  costs  converge  to  the  optimal costs  asymptotically.  Our  focus  is  on learning in  an average-cost  framework  and on a  practical  ap(cid:173) plication to  the optimal portfolio choice problem."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interactive Parts Model", "Title": "An Application to Recognition of On-line Cursive Script", "Abstract": "In  this  work,  we  introduce  an  Interactive  Parts  (IP)  model as  an  alternative  to  Hidden  Markov  Models  (HMMs).  We  tested  both  models  on  a  database of on-line  cursive  script.  We  show  that  im(cid:173) plementations of HMMs  and the IP model, in which  all letters  are  assumed  to have  the same average width, give  comparable results.  However , in contrast to  HMMs,  the  IP model can handle duration  modeling without  an increase  in  computational complexity."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Feature Correspondence", "Title": "A Markov Chain Monte Carlo Approach", "Abstract": "When  trying  to  recover  3D  structure  from  a  set  of  images,  the  most difficult  problem is  establishing  the correspondence  between  the measurements.  Most existing  approaches  assume that features  can be tracked across frames,  whereas methods that exploit rigidity  constraints to facilitate matching do so only under restricted  cam(cid:173) era  motion.  In  this  paper  we  propose  a  Bayesian  approach  that  avoids  the  brittleness  associated  with  singling out  one  \"best\"  cor(cid:173) respondence,  and instead consider the distribution over all possible  correspondences.  We  treat  both  a  fully  Bayesian  approach  that  yields  a  posterior  distribution,  and  a  MAP  approach  that  makes  use of EM  to maximize this posterior.  We show how  Markov chain  Monte  Carlo methods can  be  used  to implement these  techniques  in practice,  and present  experimental results on real  data."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Temporally Dependent Plasticity", "Title": "An Information Theoretic Account", "Abstract": "The paradigm of Hebbian learning has recently received a novel in(cid:173) terpretation with the discovery of synaptic plasticity that depends  on the relative timing of pre and post  synaptic spikes.  This paper  derives a temporally dependent learning rule from the basic princi(cid:173) ple of mutual information maximization and studies its relation to  the experimentally observed  plasticity.  We  find  that  a  supervised  spike-dependent learning rule sharing similar structure with the ex(cid:173) perimentally observed plasticity increases mutual information to a  stable near  optimal  level.  Moreover,  the  analysis  reveals  how  the  temporal structure of time-dependent learning rules is  determined  by the temporal filter  applied by neurons over their inputs.  These  results suggest experimental prediction as to the dependency of the  learning rule on neuronal biophysical parameters"}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Curves for Gaussian Processes Regression", "Title": "A Framework for Good Approximations", "Abstract": "Based  on  a  statistical mechanics  approach,  we  develop  a  method  for approximately computing average case learning curves for Gaus(cid:173) sian  process  regression  models.  The  approximation  works  well  in  the large  sample size  limit  and for  arbitrary dimensionality  of the  input space.  We explain how the approximation can be systemati(cid:173) cally improved and argue that similar techniques can be applied to  general likelihood models."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Periodic Component Analysis", "Title": "An Eigenvalue Method for Representing Periodic Structure in Speech", "Abstract": "An  eigenvalue  method  is  developed  for  analyzing  periodic  structure in  speech.  Signals are analyzed by  a matrix diagonalization reminiscent of  methods  for principal component analysis  (PCA)  and  independent com(cid:173) ponent analysis (ICA).  Our method-called periodic component analysis  (1l\"CA)-uses  constructive interference to  enhance periodic  components  of the frequency  spectrum and  destructive interference  to  cancel  noise.  The front end emulates important aspects of auditory processing, such as  cochlear filtering, nonlinear compression, and insensitivity to phase, with  the  aim  of approaching the robustness of human  listeners.  The  method  avoids the inefficiencies of autocorrelation at the pitch period:  it does not  require  long  delay  lines,  and  it correlates  signals  at  a clock rate  on  the  order  of the  actual pitch,  as  opposed  to  the  original  sampling rate.  We  derive its cost function and present some experimental results."}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Continuous Distributions", "Title": "Simulations With Field Theoretic Priors", "Abstract": "that a particular density Q(x) gave rise to these data is given by  P[Q(x)] rr~1 Q(Xi)"}
{"Type": "conference", "Year": "2000", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Divisive and Subtractive Mask Effects", "Title": "Linking Psychophysics and Biophysics", "Abstract": "We describe an analogy between psychophysically measured effects  in  contrast  masking,  and  the  behavior  of a  simple  integrate-and(cid:173) fire  neuron  that  receives  time-modulated  inhibition.  In  the  psy(cid:173) chophysical experiments, we tested observers ability to discriminate  contrasts of peripheral  Gabor patches  in  the  presence  of collinear  Gabor flankers.  The data reveal a complex interaction pattern that  we  account  for  by  assuming  that  flankers  provide  divisive  inhibi(cid:173) tion  to  the  target  unit  for  low  target  contrasts,  but  provide  sub(cid:173) tractive  inhibition  to  the  target  unit  for  higher  target  contrasts.  A similar switch from divisive to subtractive inhibition is  observed  in  an integrate-and-fire unit that receives  inhibition  modulated in  time such that the cell spends part of the time in  a high-inhibition  state  and  part  of  the  time  in  a  low-inhibition  state.  The  simi(cid:173) larity  between  the effects  suggests  that  one  may  cause  the  other.  The biophysical model makes testable predictions for  physiological  single-cell  recordings."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Playing is believing", "Title": "The role of beliefs in multi-agent learning", "Abstract": "We propose a new classiﬁcation for multi-agent learning algorithms, with each league of players characterized by both their possible strategies and possible beliefs. Using this classiﬁcation, we review the optimality of ex- isting algorithms, including the case of interleague play. We propose an incremental improvement to the existing algorithms that seems to achieve average payoffs that are at least the Nash equilibrium payoffs in the long- run against fair opponents."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probabilistic principles in unsupervised learning of visual structure", "Title": "human data and a model", "Abstract": "To ﬁnd out how the representations of structured visual objects depend on the co-occurrence statistics of their constituents, we exposed subjects to a set of composite images with tight control exerted over (1) the condi- tional probabilities of the constituent fragments, and (2) the value of Bar- low’s criterion of “suspicious coincidence” (the ratio of joint probability to the product of marginals). We then compared the part veriﬁcation re- sponse times for various probe/target combinations before and after the exposure. For composite probes, the speedup was much larger for tar- gets that contained pairs of fragments perfectly predictive of each other, compared to those that did not. This effect was modulated by the sig- niﬁcance of their co-occurrence as estimated by Barlow’s criterion. For lone-fragment probes, the speedup in all conditions was generally lower than for composites. These results shed light on the brain’s strategies for unsupervised acquisition of structural information in vision."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Prodding the ROC Curve", "Title": "Constrained Optimization of Classifier Performance", "Abstract": "An ROC curve (Green & Swets, 1966) can be used to visualize the discriminative performance of a two-alternative classiﬁer that outputs class posteriors. To explain the ROC curve, a classiﬁer can be thought of as making a positive/negative judgement as to whether an input is a member of some class. Two different accuracy measures can be obtained from the classiﬁer: the accuracy of correctly identifying an input as a member of the class (a correct acceptance or CA), and the accuracy of correctly identifying an input as a nonmember of the class (a correct rejection or CR). To evaluate the CA and CR rates, it is necessary to pick a threshold above which the classiﬁer’s probability estimate is inter- preted as an “accept,” and below which is interpreted as a “reject”—call this the criterion. The ROC curve plots CA against CR rates for various criteria (Figure 1a). Note that as the threshold is lowered, the CA rate increases and the CR rate decreases. For a criterion of 1, the CA rate approaches 0 and the CR rate 1; for a criterion of 0, the CA rate approaches 1"}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Estimating Car Insurance Premia", "Title": "a Case Study in High-Dimensional Data Inference", "Abstract": "Estimating insurance premia from data is a difficult regression problem for several reasons: the large number of variables, many of which are .discrete, and the very peculiar shape of the noise distri(cid:173) bution, asymmetric with fat tails, with a large majority zeros and a few unreliable and very large values. We compare several machine learning methods for estimating insurance premia, and test them on a large data base of car insurance policies. We find that func(cid:173) tion approximation methods that do not optimize a squared loss, like Support Vector Machines regression, do not work well in this context. Compared methods include decision trees and generalized linear models. The best results are obtained with a mixture of experts, which better identifies the least and most risky contracts, and allows to reduce the median premium by charging more to the most risky customers."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Classifying Single Trial EEG", "Title": "Towards Brain Computer Interfacing", "Abstract": "Driven by the progress in the ﬁeld of single-trial analysis of EEG, there is a growing interest in brain computer interfaces (BCIs), i.e., systems that enable human subjects to control a computer only by means of their brain signals. In a pseudo-online simulation our BCI detects upcoming ﬁnger movements in a natural keyboard typing condition and predicts their lat- erality. This can be done on average 100–230 ms before the respective key is actually pressed, i.e., long before the onset of EMG. Our approach is appealing for its short response time and high classiﬁcation accuracy (>96%) in a binary decision where no human training is involved. We compare discriminative classiﬁers like Support Vector Machines (SVMs) and different variants of Fisher Discriminant that possess favorable reg- ularization properties for dealing with high noise cases (inter-trial vari- ablity)."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Model of the Phonological Loop", "Title": "Generalization and Binding", "Abstract": "We present a  neural network model that shows how the prefrontal  cortex, interacting with the basal ganglia, can maintain a sequence  of  phonological  information  in  activation-based  working  memory  (i.e.,  the  phonological  loop).  The  primary function  of this  phono(cid:173) logical  loop  may  be  to  transiently  encode  arbitrary  bindings  of  information  necessary  for  tasks  - the  combinatorial  expressive  power  of language  enables  very  flexible  binding  of essentially  ar(cid:173) bitrary  pieces  of information.  Our  model  takes  advantage  of the  closed-class nature of phonemes, which allows  different  neural rep(cid:173) resentations of all possible phonemes at each sequential position to  be encoded.  To  make this work,  we  suggest that the basal ganglia  provide a  region-specific update signal that allocates phonemes to  the appropriate sequential coding slot.  To  demonstrate that flexi(cid:173) ble,  arbitrary binding of novel  sequences can be supported by this  mechanism,  we  show  that  the  model  can  generalize  to  novel  se(cid:173) quences after  moderate amounts of training."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Linking Motor Learning to Function Approximation", "Title": "Learning in an Unlearnable Force Field", "Abstract": "velocity-dependent force field (such as the fields we use), the IM must be able to encode velocity in order to anticipate the upcoming force. We hoped that the e#ect of errors in one direction on subsequent movements in other directions would give information about the width of the elements which the IM used in encoding velocity. For example, if the basis elements were narrow, then movements in a given direction would result in little or no change in performance in neighboring directions. Wide basis elements would mean appropriately larger e#ects. We hypothesized that an estimate of the width of the basis elements could be cal- culated by fitting the time sequence of errors to a set of equations representing a dynamical system. The dynamical system assumed that error in a movement resulted from a di#erence between the IM's approximation and the actual environ- ment, an assumption that has recently been corroborated [3]. The error in turn changed the IM, a#ecting subsequent movements:"}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Modularity in the motor system", "Title": "decomposition of muscle patterns as combinations of time-varying synergies", "Abstract": "The question of whether the nervous system produces movement through the combination of a few discrete elements has long been central to the study of motor control. Muscle synergies, i.e. coordinated patterns of muscle activity, have been proposed as possible building blocks. Here we propose a model based on combinations of muscle synergies with a spe- ciﬁc amplitude and temporal structure. Time-varying synergies provide a realistic basis for the decomposition of the complex patterns observed in natural behaviors. To extract time-varying synergies from simultane- ous recording of EMG activity we developed an algorithm which extends existing non-negative matrix factorization techniques."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Discriminative vs. Generative Classifiers", "Title": "A comparison of logistic regression and naive Bayes", "Abstract": "We  compare discriminative  and  generative learning as  typified  by  logistic regression and naive Bayes.  We show,  contrary to a widely(cid:173) held  belief  that  discriminative  classifiers  are  almost  always  to  be  preferred,  that  there  can  often  be  two  distinct  regimes  of  per(cid:173) formance  as  the  training  set  size  is  increased,  one  in  which  each  algorithm  does  better.  This  stems  from  the  observation- which  is  borne  out  in  repeated  experiments- that  while  discriminative  learning has lower asymptotic error, a generative classifier may also  approach its  (higher)  asymptotic error  much faster."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Spectral Clustering", "Title": "Analysis and an algorithm", "Abstract": "Despite many empirical successes of spectral  clustering  methods(cid:173) algorithms  that  cluster  points  using  eigenvectors  of  matrices  de(cid:173) rived  from  the  data- there  are  several  unresolved  issues.  First,  there  are  a  wide  variety  of  algorithms  that  use  the  eigenvectors  in  slightly  different  ways.  Second,  many of these  algorithms  have  no  proof that  they  will  actually  compute  a  reasonable  clustering.  In  this  paper,  we  present  a  simple  spectral  clustering  algorithm  that can be implemented using a  few  lines  of Matlab.  Using  tools  from  matrix  perturbation  theory,  we  analyze  the  algorithm,  and  give  conditions  under  which  it  can  be  expected  to  do  well.  We  also  show  surprisingly  good  experimental  results  on  a  number  of  challenging clustering problems."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cobot", "Title": "A Social Reinforcement Learning Agent", "Abstract": "We report on the use of reinforcement learning with Cobot, a software agent residing in the well-known online community LambdaMOO. Our initial work on Cobot (Isbell et al.2000) provided him with the ability to collect social statistics and report them to users. Here we describe an application of RL allowing Cobot to take proactive actions in this complex social environment, and adapt behavior from multiple sources of human reward. After 5 months of training, and 3171 reward and punishment events from 254 different LambdaMOO users, Cobot learned nontrivial preferences for a number of users, modiﬁng his behavior based on his current state. Here we describe LambdaMOO and the state and action spaces of Cobot, and report the statistical results of the learning experiment."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Relative Density Nets", "Title": "A New Way to Combine Backpropagation with HMM's", "Abstract": "Logistic units in the first  hidden layer of a  feedforward neural net(cid:173) work  compute  the  relative  probability  of a  data point  under  two  Gaussians.  This  leads  us  to  consider  substituting  other  density  models.  We  present  an architecture for  performing discriminative  learning of Hidden Markov Models using a  network of many small  HMM's.  Experiments on speech  data show it  to be superior to the  standard method of discriminatively training HMM's."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Intelligent surfer", "Title": "Probabilistic Combination of Link and Content Information in PageRank", "Abstract": "The PageRank algorithm, used in the Google search engine, greatly  improves the results of Web search by taking into account the link  structure  of  the  Web.  PageRank  assigns  to  a  page  a  score  propor- tional to the number of times a random surfer would visit that page,  if  it  surfed  indefinitely  from  page  to  page,  following  all  outlinks  from  a  page  with  equal  probability.  We  propose  to  improve  Page- Rank  by  using  a  more  intelligent  surfer,  one  that  is  guided  by  a  probabilistic model of the relevance of a page to a query. Efficient  execution  of  our  algorithm  at  query  time  is  made  possible  by  pre- computing  at  crawl  time  (and  thus  once  for  all  queries)  the  neces- sary  terms.  Experiments  on  two  large  subsets  of  the  Web  indicate  that  our  algorithm  significantly  outperforms  PageRank  in  the  (hu- man-rated)  quality  of the pages returned, while remaining efficient  enough to be used in today’s large search engines."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KLD-Sampling", "Title": "Adaptive Particle Filters", "Abstract": "Over the last years, particle ﬁlters have been applied with great success to a variety of state estimation problems. We present a statistical approach to increasing the efﬁciency of particle ﬁlters by adapting the size of sample sets on-the-ﬂy. The key idea of the KLD-sampling method is to bound the approximation error introduced by the sample-based representation of the particle ﬁlter. The name KLD-sampling is due to the fact that we measure the approximation error by the Kullback-Leibler distance. Our adaptation approach chooses a small number of samples if the density is focused on a small part of the state space, and it chooses a large number of samples if the state uncertainty is high. Both the implementation and computation overhead of this approach are small. Extensive experiments using mobile robot localization as a test application show that our approach yields drastic improvements over particle ﬁlters with ﬁxed sample set sizes and over a previously introduced adaptation technique."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Product Analysis", "Title": "Learning to Model Observations as Products of Hidden Variables", "Abstract": "Factor analysis  and principal  components  analysis  can be  used  to  model linear relationships between observed variables  and linearly  map  high-dimensional  data to  a  lower-dimensional  hidden  space.  In  factor  analysis,  the  observations  are  modeled  as  a  linear  com(cid:173) bination  of normally  distributed  hidden  variables.  We  describe  a  nonlinear  generalization of factor  analysis,  called  \"product analy(cid:173) sis\",  that  models  the  observed  variables  as  a  linear  combination  of products  of normally  distributed  hidden  variables.  Just  as  fac(cid:173) tor  analysis  can  be  viewed  as  unsupervised  linear  regression  on  unobserved,  normally  distributed  hidden  variables,  product  anal(cid:173) ysis  can  be  viewed  as  unsupervised  linear  regression  on  products  of unobserved,  normally  distributed  hidden  variables.  The  map(cid:173) ping  between  the  data  and  the  hidden  space  is  nonlinear,  so  we  use  an  approximate variational  technique  for  inference  and learn(cid:173) ing.  Since  product  analysis  is  a  generalization  of factor  analysis,  product  analysis  always  finds  a  higher  data likelihood than factor  analysis.  We  give results on pattern recognition  and illumination(cid:173) invariant image clustering."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EM-DD", "Title": "An Improved Multiple-Instance Learning Technique", "Abstract": "We  present  a  new  multiple-instance  (MI)  learning technique  (EM(cid:173) DD)  that  combines  EM  with  the  diverse  density  (DD)  algorithm.  EM-DD is a general-purpose MI algorithm that can be applied with  boolean  or  real-value  labels  and  makes  real-value  predictions.  On  the boolean Musk benchmarks, the EM-DD algorithm without any  tuning  significantly  outperforms  all  previous  algorithms.  EM-DD  is  relatively  insensitive to the number of relevant  attributes  in  the  data set  and  scales  up  well  to  large  bag  sizes.  Furthermore,  EM(cid:173) DD  provides  a  new  framework  for  MI  learning,  in  which  the  MI  problem  is  converted  to  a  single-instance  setting  by  using  EM  to  estimate the instance  responsible  for  the  label of the bag."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MIME", "Title": "Mutual Information Minimization and Entropy Maximization for Bayesian Belief Propagation", "Abstract": "Bayesian belief propagation in graphical models has been recently shown to have very close ties to inference methods based in statis- tical physics. After Yedidia et al. demonstrated that belief prop- agation (cid:12)xed points correspond to extrema of the so-called Bethe free energy, Yuille derived a double loop algorithm that is guar- anteed to converge to a local minimum of the Bethe free energy. Yuille’s algorithm is based on a certain decomposition of the Bethe free energy and he mentions that other decompositions are possi- ble and may even be fruitful. In the present work, we begin with the Bethe free energy and show that it has a principled interpre- tation as pairwise mutual information minimization and marginal entropy maximization (MIME). Next, we construct a family of free energy functions from a spectrum of decompositions of the original Bethe free energy. For each free energy in this family, we develop a new algorithm that is guaranteed to converge to a local min- imum. Preliminary computer simulations are in agreement with this theoretical development."}
{"Type": "conference", "Year": "2001", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The g Factor", "Title": "Relating Distributions on Features to Distributions on Images", "Abstract": "We  describe  the  g-factor,  which  relates  probability  distributions  on image features  to  distributions on the  images  themselves.  The  g-factor  depends  only  on  our choice  of features  and  lattice  quanti(cid:173) zation and is  independent of the training image data.  We  illustrate  the importance  of the g-factor by analyzing how the parameters of  Markov Random Field (i.e.  Gibbs or log-linear) probability models  of images are learned from data by maximum likelihood estimation.  In particular, we study homogeneous MRF models which learn im(cid:173) age distributions in terms of clique potentials corresponding to fea(cid:173) ture  histogram  statistics  (d.  Minimax  Entropy  Learning  (MEL)  by  Zhu,  Wu  and  Mumford  1997  [11]) .  We  first  use  our  analysis  of the  g-factor  to  determine  when  the  clique  potentials  decouple  for  different  features .  Second,  we  show  that  clique  potentials  can  be  computed  analytically  by  approximating  the  g-factor.  Third,  we  demonstrate a  connection between this  approximation and the  Generalized Iterative Scaling algorithm (GIS),  due to Darroch and  Ratcliff  1972  [2],  for  calculating  potentials.  This  connection  en(cid:173) ables  us  to  use  GIS  to  improve  our  multinomial  approximation,  using  Bethe-Kikuchi[8]  approximations to simplify  the  GIS  proce(cid:173) dure.  We  support our analysis by computer simulations."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Nonparametric Representation of Policies and Value Functions", "Title": "A Trajectory-Based Approach", "Abstract": "A longstanding goal of reinforcement learning is to develop non- parametric representations of policies and value functions that support rapid learning without suffering from interference or the curse of di- mensionality. We have developed a trajectory-based approach, in which policies and value functions are represented nonparametrically along tra- jectories. These trajectories, policies, and value functions are updated as the value function becomes more accurate or as a model of the task is up- dated. We have applied this approach to periodic tasks such as hopping and walking, which required handling discount factors and discontinu- ities in the task dynamics, and using function approximation to represent value functions at discontinuities. We also describe extensions of the ap- proach to make the policies more robust to modeling error and sensor noise."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Automatic Derivation of Statistical Algorithms", "Title": "The EM Family and Beyond", "Abstract": "14 max pr(x| phi,mu,sigma\u0001 ) wrt  phi,mu,sigma\u0001 ; \u0005\u0007\u0006 inference task: maximize the conditional probability pr\u0002\u0004\u0003 rameters \u0003"}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Going Metric", "Title": "Denoising Pairwise Data", "Abstract": "Pairwise  data in  empirical  sciences  typically  violate  metricity,  ei(cid:173) ther  due  to  noise  or  due  to  fallible  estimates,  and  therefore  are  hard  to  analyze  by  conventional  machine  learning  technology.  In  this  paper  we  therefore  study  ways  to  work  around  this  problem.  First,  we  present  an  alternative  embedding  to  multi-dimensional  scaling  (MDS)  that  allows  us  to  apply  a  variety  of classical  ma(cid:173) chine learning and signal processing algorithms.  The class of pair(cid:173) wise grouping algorithms which share the shift-invariance property  is  statistically  invariant  under  this  embedding  procedure,  leading  to  identical assignments  of objects to clusters.  Based on this  new  vectorial  representation,  denoising  methods  are  applied  in  a  sec(cid:173) ond  step.  Both steps  provide a  theoretically  well  controlled setup  to  translate  from  pairwise  data  to  the  respective  denoised  met(cid:173) ric  representation.  We  demonstrate the practical usefulness of our  theoretical  reasoning by  discovering structure in  protein sequence  data bases, visibly improving performance upon existing automatic  methods."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spikernels", "Title": "Embedding Spiking Neurons in Inner-Product Spaces", "Abstract": "Inner-product operators, often referred to as kernels in statistical learning, de- ﬁne a mapping from some input space into a feature space. The focus of this paper is the construction of biologically-motivated kernels for cortical ac- tivities. The kernels we derive, termed Spikernels, map spike count sequences into an abstract vector space in which we can perform various prediction tasks. We discuss in detail the derivation of Spikernels and describe an efﬁcient al- gorithm for computing their value on any two sequences of neural population spike counts. We demonstrate the merits of our modeling approach using the Spikernel and various standard kernels for the task of predicting hand move- ment velocities from cortical recordings. In all of our experiments all the ker- nels we tested outperform the standard scalar product used in regression with the Spikernel consistently achieving the best performance."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The RA Scanner", "Title": "Prediction of Rheumatoid Joint Inflammation Based on Laser Imaging", "Abstract": "We describe the RA scanner, a novel system for the examination of pa- tients suffering from rheumatoid arthritis. The RA scanner is based on a novel laser-based imaging technique which is sensitive to the optical characteristics of ﬁnger joint tissue. Based on the laser images, ﬁnger joints are classiﬁed according to whether the inﬂammatory status has improved or worsened. To perform the classiﬁcation task, various lin- ear and kernel-based systems were implemented and their performances were compared. Special emphasis was put on measures to reliably per- form parameter tuning and evaluation, since only a very small data set was available. Based on the results presented in this paper, it was con- cluded that the RA scanner permits a reliable classiﬁcation of patholog- ical ﬁnger joints, thus paving the way for a further development from prototype to product stage."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shape Recipes", "Title": "Scene Representations that Refer to the Image", "Abstract": "The goal of low-level vision is to estimate an underlying scene, given an observed image. Real-world scenes (eg, albedos or shapes) can be very complex, conventionally requiring high dimensional representations which are hard to estimate and store. We propose a low-dimensional rep- resentation, called a scene recipe, that relies on the image itself to de- scribe the complex scene conﬁgurations. Shape recipes are an example: these are the regression coefﬁcients that predict the bandpassed shape from image data. We describe the beneﬁts of this representation, and show two uses illustrating their properties: (1) we improve stereo shape estimates by learning shape recipes at low resolution and applying them at full resolution; (2) Shape recipes implicitly contain information about lighting and materials and we use them for material segmentation."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hidden Markov Model of Cortical Synaptic Plasticity", "Title": "Derivation of the Learning Rule", "Abstract": "Cortical synaptic plasticity depends on the relative timing of pre- and postsynaptic spikes and also on the temporal pattern of presynaptic spikes and of postsynaptic spikes. We study the hypothesis that cortical synap- tic plasticity does not associate individual spikes, but rather whole ﬁr- ing episodes, and depends only on when these episodes start and how long they last, but as little as possible on the timing of individual spikes. Here we present the mathematical background for such a study. Stan- dard methods from hidden Markov models are used to deﬁne what “ﬁr- ing episodes” are. Estimating the probability of being in such an episode requires not only the knowledge of past spikes, but also of future spikes. We show how to construct a causal learning rule, which depends only on past spikes, but associates pre- and postsynaptic ﬁring episodes as if it also knew future spikes. We also show that this learning rule agrees with some features of synaptic plasticity in superﬁcial layers of rat visual cortex (Froemke and Dan, Nature 416:433, 2002)."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rate Distortion Function in the Spin Glass State", "Title": "A Toy Model", "Abstract": "We applied statistical mechanics to an inverse problem of linear mapping to investigate the physics of optimal lossy compressions. We used the replica symmetry breaking technique with a toy model to demonstrate Shannon’s result. The rate distortion function, which is widely known as the theoretical limit of the compression with a ﬁdelity criterion, is derived. Numerical study shows that sparse constructions of the model provide suboptimal compressions."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Real Time Voice Processing with Audiovisual Feedback", "Title": "Toward Autonomous Agents with Perfect Pitch", "Abstract": "We have implemented a real time front end for detecting voiced speech and estimating its fundamental frequency. The front end performs the signal processing for voice-driven agents that attend to the pitch contours of human speech and provide continuous audiovisual feedback. The al- gorithm we use for pitch tracking has several distinguishing features: it makes no use of FFTs or autocorrelation at the pitch period; it updates the pitch incrementally on a sample-by-sample basis; it avoids peak picking and does not require interpolation in time or frequency to obtain high res- olution estimates; and it works reliably over a four octave range, in real time, without the need for postprocessing to produce smooth contours. The algorithm is based on two simple ideas in neural computation: the introduction of a purposeful nonlinearity, and the error signal of a least squares ﬁt. The pitch tracker is used in two real time multimedia applica- tions: a voice-to-MIDI player that synthesizes electronic music from vo- calized melodies, and an audiovisual Karaoke machine with multimodal feedback. Both applications run on a laptop and display the user’s pitch scrolling across the screen as he or she sings into the computer."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ranking with Large Margin Principle", "Title": "Two Approaches", "Abstract": "We discuss the problem of ranking k instances with the use of a \"large  margin\" principle. We introduce two main approaches: the first is the  \"fixed margin\" policy in which the margin of the closest neighboring  classes is being maximized - which turns out to be a direct generaliza(cid:173) tion of SVM to ranking learning. The second approach allows for k - 1  different margins where the sum of margins is maximized. This approach  is shown to reduce to lI-SVM when the number of classes k = 2. Both  approaches are optimal in size of 21 where I is the total number of training  examples. Experiments performed on visual classification and \"collab(cid:173) orative filtering\" show that both approaches outperform existing ordinal  regression algorithms applied for ranking and multi-class SVM applied  to general multi-class classification."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Categorization Under Complexity", "Title": "A Unified MDL Account of Human Learning of Regular and Irregular Categories", "Abstract": "A number of different principles have been advanced to explain the manner in which hu(cid:173) mans learn to categorize objects. It has been variously suggested that the underlying prin(cid:173) ciple might be the similarity structure of objects [1], the manipulability of decision bound~ aries [2], or Bayesian inference [3][4]. While many of these theories are mathematically well-grounded and have been successful in explaining a range of experimental findings, they have commonly only been tested on a narrow collection of concept types similar to the simple unimodal categories of Figure 1(a-e)."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Maximally Informative Dimensions", "Title": "Analyzing Neural Responses to Natural Signals", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Expected and Unexpected Uncertainty", "Title": "ACh and NE in the Neocortex", "Abstract": "Inference and adaptation in noisy and changing, rich sensory environ- ments are rife with a variety of speciﬁc sorts of variability. Experimental and theoretical studies suggest that these different forms of variability play different behavioral, neural and computational roles, and may be reported by different (notably neuromodulatory) systems. Here, we re- ﬁne our previous theory of acetylcholine’s role in cortical inference in the (oxymoronic) terms of expected uncertainty, and advocate a theory for norepinephrine in terms of unexpected uncertainty. We suggest that norepinephrine reports the radical divergence of bottom-up inputs from prevailing top-down interpretations, to inﬂuence inference and plasticity. We illustrate this proposal using an adaptive factor analysis model."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Feature Selection and Classification on Matrix Data", "Title": "From Large Margins to Small Covering Numbers", "Abstract": "We investigate the problem of learning a classiﬂcation task for datasets which are described by matrices. Rows and columns of these matrices correspond to objects, where row and column ob- jects may belong to diﬁerent sets, and the entries in the matrix express the relationships between them. We interpret the matrix el- ements as being produced by an unknown kernel which operates on object pairs and we show that - under mild assumptions - these ker- nels correspond to dot products in some (unknown) feature space. Minimizing a bound for the generalization error of a linear classi- ﬂer which has been obtained using covering numbers we derive an objective function for model selection according to the principle of structural risk minimization. The new objective function has the advantage that it allows the analysis of matrices which are not pos- itive deﬂnite, and not even symmetric or square. We then consider the case that row objects are interpreted as features. We suggest an additional constraint, which imposes sparseness on the row objects and show, that the method can then be used for feature selection. Finally, we apply this method to data obtained from DNA microar- rays, where \\column\" objects correspond to samples, \\row\" objects correspond to genes and matrix elements correspond to expression levels. Benchmarks are conducted using standard one-gene classiﬂ- cation and support vector machines and K-nearest neighbors after standard feature selection. Our new method extracts a sparse set of genes and provides superior classiﬂcation results."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Digital Antennal Lobe for Pattern Equalization", "Title": "Analysis and Design", "Abstract": "Re-mapping  patterns  in  order  to  equalize  their  distribution  may  greatly  simplify  both the  structure  and  the  training of classifiers.  Here,  the  properties  of one  such  map  obtained  by  running  a  few  steps of discrete-time dynamical system are explored.  The system  is  called  'Digital  Antennal  Lobe'  (DAL)  because  it  is  inspired  by  recent studies of the antennallobe, a structure in the olfactory sys(cid:173) tem  of the  grasshopper.  The  pattern-spreading  properties  of the  DAL  as  well  as  its  average behavior  as  a  function  of its  (few)  de(cid:173) sign  parameters are analyzed by extending previous results of Van  Vreeswijk and Sompolinsky.  Furthermore, a technique for  adapting  the  parameters of the  initial  design  in  order  to  obtain  opportune  noise-rejection behavior is suggested.  Our results are demonstrated  with a  number of simulations."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VIBES", "Title": "A Variational Inference Engine for Bayesian Networks", "Abstract": "In recent years variational methods have become a popular tool for approximate inference and learning in a wide variety of proba- bilistic models. For each new application, however, it is currently necessary (cid:12)rst to derive the variational update equations, and then to implement them in application-speci(cid:12)c code. Each of these steps is both time consuming and error prone. In this paper we describe a general purpose inference engine called VIBES (‘Variational Infer- ence for Bayesian Networks’) which allows a wide variety of proba- bilistic models to be implemented and solved variationally without recourse to coding. New models are speci(cid:12)ed either through a simple script or via a graphical interface analogous to a drawing package. VIBES then automatically generates and solves the vari- ational equations. We illustrate the power and (cid:13)exibility of VIBES using examples from Bayesian mixture modelling."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How to Combine Color and Shape Information for 3D Object Recognition", "Title": "Kernels do the Trick", "Abstract": "This paper presents a  kernel method that allows to combine  color  and shape information for  appearance-based object recognition.  It  doesn't require to define a new common representation, but use the  power of kernels to combine different representations together in an  effective manner.  These results are achieved using results of statis(cid:173) tical mechanics of spin glasses combined with Markov random fields  via kernel functions.  Experiments show  an increase in recognition  rate up  to 5.92%  with respect to conventional strategies."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning About Multiple Objects in Images", "Title": "Factorial Learning without Factorial Search", "Abstract": "We consider data which are images containing views of multiple objects. Our task is to learn about each of the objects present in the images. This task can be approached as a factorial learning problem, where each image must be explained by instantiating a model for each of the objects present with the correct instantiation parameters. A major problem with learning a factorial model is that as the number of objects increases, there is a combinatorial explosion of the number of conﬁgurations that need to be considered. We develop a method to extract object models sequentially from the data by making use of a robust statistical method, thus avoid- ing the combinatorial explosion, and present results showing successful extraction of objects from real images."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast Sparse Gaussian Process Methods", "Title": "The Informative Vector Machine", "Abstract": "We present a framework for sparse Gaussian process (GP) methods which uses forward selection with criteria based on information- theoretic principles, previously suggested for active learning. Our goal is not only to learn d{sparse predictors (which can be evalu- ated in O(d) rather than O(n), d (cid:28) n, n the number of training points), but also to perform training under strong restrictions on time and memory requirements. The scaling of our method is at most O(n (cid:1) d2), and in large real-world classi(cid:12)cation experiments we show that it can match prediction performance of the popular support vector machine (SVM), yet can be signi(cid:12)cantly faster in training. In contrast to the SVM, our approximation produces esti- mates of predictive probabilities (‘error bars’), allows for Bayesian model selection and is less complex in implementation."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel-Based Extraction of Slow Features", "Title": "Complex Cells Learn Disparity and Translation Invariance from Natural Images", "Abstract": "F  _  V  _  L.i Yi 2  L.i Yi"}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Coulomb Classifiers", "Title": "Generalizing Support Vector Machines via an Analogy to Electrostatic Systems", "Abstract": "We introduce a family of classiﬂers based on a physical analogy to an electrostatic system of charged conductors. The family, called Coulomb classiﬂers, includes the two best-known support-vector machines (SVMs), the ”{SVM and the C{SVM. In the electrostat- ics analogy, a training example corresponds to a charged conductor at a given location in space, the classiﬂcation function corresponds to the electrostatic potential function, and the training objective function corresponds to the Coulomb energy. The electrostatic framework provides not only a novel interpretation of existing algo- rithms and their interrelationships, but it suggests a variety of new methods for SVMs including kernels that bridge the gap between polynomial and radial-basis functions, objective functions that do not require positive-deﬂnite kernels, regularization techniques that allow for the construction of an optimal classiﬂer in Minkowski space. Based on the framework, we propose novel SVMs and per- form simulation studies to show that they are comparable or su- perior to standard SVMs. The experiments include classiﬂcation tasks on data which are represented in terms of their pairwise prox- imities, where a Coulomb Classiﬂer outperformed standard SVMs."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Minimax Differential Dynamic Programming", "Title": "An Application to Robust Biped Walking", "Abstract": "We developed a robust control policy design method in high-dimensional state space by using differential dynamic programming with a minimax criterion. As an example, we applied our method to a simulated ﬁve link biped robot. The results show lower joint torques from the optimal con- trol policy compared to a hand-tuned PD servo controller. Results also show that the simulated biped robot can successfully walk with unknown disturbances that cause controllers generated by standard differential dy- namic programming and the hand-tuned PD servo to fail. Learning to compensate for modeling error and previously unknown disturbances in conjunction with robust control design is also demonstrated."}
{"Type": "conference", "Year": "2002", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Improving Transfer Rates in Brain Computer Interfacing", "Title": "A Case Study", "Abstract": "In this paper we present results of a study on brain computer interfacing. We adopted an approach of Farwell & Donchin [4], which we tried to improve in several aspects. The main objective was to improve the trans- fer rates based on ofﬂine analysis of EEG-data but within a more realistic setup closer to an online realization than in the original studies. The ob- jective was achieved along two different tracks: on the one hand we used state-of-the-art machine learning techniques for signal classiﬁcation and on the other hand we augmented the data space by using more electrodes for the interface. For the classiﬁcation task we utilized SVMs and, as mo- tivated by recent ﬁndings on the learning of discriminative densities, we accumulated the values of the classiﬁcation function in order to combine several classiﬁcations, which ﬁnally lead to signiﬁcantly improved rates as compared with techniques applied in the original work. In combina- tion with the data space augmentation, we achieved competitive transfer rates at an average of 50.5 bits/min and with a maximum of 84.7 bits/min."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Holistic Approach to Compositional Semantics", "Title": "a connectionist model and robot experiments", "Abstract": "We present a novel connectionist model for acquiring the semantics of a simple language through the behavioral experiences of a real robot. We focus on the “compositionality” of semantics, a fundamental character- istic of human language, which is the ability to understand the meaning of a sentence as a combination of the meanings of words. We also pay much attention to the “embodiment” of a robot, which means that the robot should acquire semantics which matches its body, or sensory-motor system. The essential claim is that an embodied compositional semantic representation can be self-organized from generalized correspondences between sentences and behavioral patterns. This claim is examined and conﬁrmed through simple experiments in which a robot generates corre- sponding behaviors from unlearned sentences by analogy with the corre- spondences between learned sentences and behaviors."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Simplicial Mixtures of Markov Chains", "Title": "Distributed Modelling of Dynamic User Profiles", "Abstract": "To provide a compact generative representation of the sequential activ- ity of a number of individuals within a group there is a tradeoff between the deﬁnition of individual speciﬁc and global models. This paper pro- poses a linear-time distributed model for ﬁnite state symbolic sequences representing traces of individual user activity by making the assump- tion that heterogeneous user behavior may be ‘explained’ by a relatively small number of common structurally simple behavioral patterns which may interleave randomly in a user-speciﬁc proportion. The results of an empirical study on three different sources of user traces indicates that this modelling approach provides an efﬁcient representation scheme, re- ﬂected by improved prediction performance as well as providing low- complexity and intuitively interpretable representations."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Towards Social Robots", "Title": "Automatic Evaluation of Human-Robot Interaction by Facial Expression Classification", "Abstract": "Computer animated agents and robots bring a social dimension to hu- man computer interaction and force us to think in new ways about how computers could be used in daily life. Face to face communication is a real-time process operating at a time scale of less than a second. In this paper we present progress on a perceptual primitive to automatically detect frontal faces in the video stream and code them with respect to 7 dimensions in real time: neutral, anger, disgust, fear, joy, sadness, sur- prise. The face ﬁnder employs a cascade of feature detectors trained with boosting techniques [13, 2]. The expression recognizer employs a novel combination of Adaboost and SVM’s. The generalization performance to new subjects for a 7-way forced choice was 93.3% and 97% correct on two publicly available datasets. The outputs of the classiﬁer change smoothly as a function of time, providing a potentially valuable repre- sentation to code facial expression dynamics in a fully automatic and unobtrusive manner. The system was deployed and evaluated for mea- suring spontaneous facial expressions in the ﬁeld in an application for automatic assessment of human-robot interaction."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Large Margin Classifiers", "Title": "Convex Loss, Low Noise, and Convergence Rates", "Abstract": "Many classiﬁcation algorithms, including the support vector machine, boosting and logistic regression, can be viewed as minimum contrast methods that minimize a convex surrogate of the 0-1 loss function. We characterize the statistical consequences of using such a surrogate by pro- viding a general quantitative relationship between the risk as assessed us- ing the 0-1 loss and the risk as assessed using any nonnegative surrogate loss function. We show that this relationship gives nontrivial bounds un- der the weakest possible condition on the loss function—that it satisfy a pointwise form of Fisher consistency for classiﬁcation. The relationship is based on a variational transformation of the loss function that is easy to compute in many applications. We also present a reﬁned version of this result in the case of low noise. Finally, we present applications of our results to the estimation of convergence rates in the general setting of function classes that are scaled hulls of a ﬁnite-dimensional base class."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Doubly Balanced Network of Spiking Neurons", "Title": "A Memory Model with High Capacity", "Abstract": "A balanced network leads to contradictory constraints on memory  models, as exemplified in previous work on accommodation of  synfire chains. Here we show that these constraints can be  overcome by introducing a 'shadow' inhibitory pattern for each  excitatory pattern of the model. This is interpreted as a double- balance principle, whereby there exists both global balance  between average excitatory and inhibitory currents and local  balance between the currents carrying coherent activity at any  given time frame. This principle can be applied to networks with  Hebbian cell assemblies, leading to a high capacity of the  associative memory. The number of possible patterns is limited by  a combinatorial constraint that turns out to be P=0.06N within the  specific model that we employ. This limit is reached by the  Hebbian cell assembly network. To the best of our knowledge this  is the first time that such high memory capacities are demonstrated  in the asynchronous state of models of spiking neurons."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Factorization with Uncertainty and Missing Data", "Title": "Exploiting Temporal Coherence", "Abstract": "The problem of \\Structure From Motion\" is a central problem in vision: given the 2D locations of certain points we wish to recover the camera motion and the 3D coordinates of the points. Un- der simpliﬂed camera models, the problem reduces to factorizing a measurement matrix into the product of two low rank matrices. Each element of the measurement matrix contains the position of a point in a particular image. When all elements are observed, the problem can be solved trivially using SVD, but in any realistic sit- uation many elements of the matrix are missing and the ones that are observed have a diﬁerent directional uncertainty. Under these conditions, most existing factorization algorithms fail while human perception is relatively unchanged. In this paper we use the well known EM algorithm for factor analy- sis to perform factorization. This allows us to easily handle missing data and measurement uncertainty and more importantly allows us to place a prior on the temporal trajectory of the latent variables (the camera position). We show that incorporating this prior gives a signiﬂcant improvement in performance in challenging image se- quences."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Using the Forest to See the Trees", "Title": "A Graphical Model Relating Features, Objects, and Scenes", "Abstract": "Standard approaches to object detection focus on local patches of the image, and try to classify them as background or not. We propose to use the scene context (image as a whole) as an extra source of (global) information, to help resolve local ambiguities. We present a conditional random ﬁeld for jointly solving the tasks of object detection and scene classiﬁcation."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Information Maximization in Noisy Channels ", "Title": "A Variational Approach", "Abstract": "The maximisation of information transmission over noisy channels is a common, albeit generally computationally diﬃcult problem. We approach the diﬃculty of computing the mutual information for noisy channels by using a variational approximation. The re- sulting IM algorithm is analagous to the EM algorithm, yet max- imises mutual information, as opposed to likelihood. We apply the method to several practical examples, including linear compression, population encoding and CDMA."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mechanism of Neural Interference by Transcranial Magnetic Stimulation", "Title": "Network or Single Neuron?", "Abstract": "This paper proposes neural mechanisms of transcranial magnetic stim- ulation (TMS). TMS can stimulate the brain non-invasively through a brief magnetic pulse delivered by a coil placed on the scalp, interfering with speciﬁc cortical functions with a high temporal resolution. Due to these advantages, TMS has been a popular experimental tool in various neuroscience ﬁelds. However, the neural mechanisms underlying TMS- induced interference are still unknown; a theoretical basis for TMS has not been developed. This paper provides computational evidence that in- hibitory interactions in a neural population, not an isolated single neuron, play a critical role in yielding the neural interference induced by TMS."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimal Manifold Representation of Data", "Title": "An Information Theoretic Approach", "Abstract": "Suppose that we have a data set X in a high dimensional state space RD described by a density function ρ(x). We would like to ﬁnd a “simpliﬁed” description of this data set. One may do so by visualizing a lower dimensional manifold M that “almost” describes the data. If we have a manifold M and a stochastic map PM : x → PM(µ|x) to points µ on the manifold, we will say that they provide a manifold description of the data set X. Note that the stochastic map here is well justiﬁed: if a data point does not lie exactly on the manifold then we should expect some uncertainty in the estimation of the value of its latent variables. Also note that we do not need to specify the inverse (generative) map: M → RD; it can be obtained by Bayes’ rule. The manifold description (M, PM) is a less than faithful representation of the data. To formalize this notion we will introduce the distortion measure D(M, PM, ρ):"}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "All learning is Local", "Title": "Multi-agent Learning in Global Reward Games", "Abstract": "In large multiagent games, partial observability, coordination, and credit assignment persistently plague attempts to design good learning algo- rithms. We provide a simple and efﬁcient algorithm that in part uses a linear system to model the world from a single agent’s limited per- spective, and takes advantage of Kalman ﬁltering to allow an agent to construct a good training signal and learn an effective policy."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attractive People", "Title": "Assembling Loose-Limbed Models using Non-parametric Belief Propagation", "Abstract": "The detection and pose estimation of people in images and video is made challenging by the variability of human appearance, the complexity of natural scenes, and the high dimensionality of articulated body mod- els. To cope with these problems we represent the 3D human body as a graphical model in which the relationships between the body parts are represented by conditional probability distributions. We formulate the pose estimation problem as one of probabilistic inference over a graphi- cal model where the random variables correspond to the individual limb parameters (position and orientation). Because the limbs are described by 6-dimensional vectors encoding pose in 3-space, discretization is im- practical and the random variables in our model must be continuous- valued. To approximate belief propagation in such a graph we exploit a recently introduced generalization of the particle ﬁlter. This framework facilitates the automatic initialization of the body-model from low level cues and is robust to occlusion of body parts and scene clutter."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GPPS", "Title": "A Gaussian Process Positioning System for Cellular Networks", "Abstract": "In this article, we present a novel approach to solving the localization problem in cellular networks. The goal is to estimate a mobile user’s position, based on measurements of the signal strengths received from network base stations. Our solution works by building Gaussian process models for the distribution of signal strengths, as obtained in a series of calibration measurements. In the localization stage, the user’s posi- tion can be estimated by maximizing the likelihood of received signal strengths with respect to the position. We investigate the accuracy of the proposed approach on data obtained within a large indoor cellular network."}
{"Type": "conference", "Year": "2003", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ARA*", "Title": "Anytime A* with Provable Bounds on Sub-Optimality", "Abstract": "In real world planning problems, time for deliberation is often limited. Anytime planners are well suited for these problems: they ﬁnd a feasi- ble solution quickly and then continually work on improving it until time runs out. In this paper we propose an anytime heuristic search, ARA, which tunes its performance bound based on available search time. It starts by ﬁnding a suboptimal solution quickly using a loose bound, then tightens the bound progressively as time allows. Given enough time it ﬁnds a provably optimal solution. While improving its bound, ARA reuses previous search efforts and, as a result, is signiﬁcantly more efﬁ- cient than other anytime search methods. In addition to our theoretical analysis, we demonstrate the practical utility of ARA* with experiments on a simulated robot kinematic arm and a dynamic path planning prob- lem for an outdoor rover."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The power of feature clustering", "Title": "An application to object detection", "Abstract": "We give a fast rejection scheme that is based on image segments and          demonstrate it on the canonical example of face detection. However, in-          stead of focusing on the detection step we focus on the rejection step and          show that our method is simple and fast to be learned, thus making it          an excellent pre-processing step to accelerate standard machine learning          classifiers, such as neural-networks, Bayes classifiers or SVM. We de-          compose a collection of face images into regions of pixels with similar          behavior over the image set. The relationships between the mean and          variance of image segments are used to form a cascade of rejectors that          can reject over 99.8% of image patches, thus only a small fraction of the          image patches must be passed to a full-scale classifier. Moreover, the          training time for our method is much less than an hour, on a standard PC.          The shape of the features (i.e. image segments) we use is data-driven,          they are very cheap to compute and they form a very low dimensional          feature space in which exhaustive search for the best features is tractable."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel Projection Machine", "Title": "a New Tool for Pattern Recognition", "Abstract": "for every f  L2([0, 1]). Given a Mercer kernel k on [0, 1][0, 1], the regularization least square procedure proposes"}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Schema Learning", "Title": "Experience-Based Construction of Predictive Action Models", "Abstract": "Schema learning is a way to discover probabilistic, constructivist, pre- dictive action models (schemas) from experience. It includes meth- ods for ﬁnding and using hidden state to make predictions more accu- rate. We extend the original schema mechanism [1] to handle arbitrary discrete-valued sensors, improve the original learning criteria to handle POMDP domains, and better maintain hidden state by using schema pre- dictions. These extensions show large improvement over the original schema mechanism in several rewardless POMDPs, and achieve very low prediction error in a difﬁcult speech modeling task. Further, we compare extended schema learning to the recently introduced predictive state rep- resentations [2], and ﬁnd their predictions of next-step action effects to be approximately equal in accuracy. This work lays the foundation for a schema-based system of integrated learning and planning."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Machine Learning Applied to Perception", "Title": "Decision Images for Gender Classification", "Abstract": "We study gender discrimination of human faces using a combination of psychophysical classiﬁcation and discrimination experiments together with methods from machine learning. We reduce the dimensionality of a set of face images using principal component analysis, and then train a set of linear classiﬁers on this reduced representation (linear support vec- tor machines (SVMs), relevance vector machines (RVMs), Fisher linear discriminant (FLD), and prototype (prot) classiﬁers) using human clas- siﬁcation data. Because we combine a linear preprocessor with linear classiﬁers, the entire system acts as a linear classiﬁer, allowing us to visu- alise the decision-image corresponding to the normal vector of the separ- ating hyperplanes (SH) of each classiﬁer. We predict that the female-to- maleness transition along the normal vector for classiﬁers closely mim- icking human classiﬁcation (SVM and RVM [1]) should be faster than the transition along any other direction. A psychophysical discrimina- tion experiment using the decision images as stimuli is consistent with this prediction."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Topographic Support Vector Machine", "Title": "Classification Using Local Label Configurations", "Abstract": "The standard approach to the classification of objects is to consider the          examples as independent and identically distributed (iid). In many real          world settings, however, this assumption is not valid, because a topo-          graphical relationship exists between the objects. In this contribution we          consider the special case of image segmentation, where the objects are          pixels and where the underlying topography is a 2D regular rectangular          grid. We introduce a classification method which not only uses measured          vectorial feature information but also the label configuration within a to-          pographic neighborhood. Due to the resulting dependence between the          labels of neighboring pixels, a collective classification of a set of pixels          becomes necessary. We propose a new method called 'Topographic Sup-          port Vector Machine' (TSVM), which is based on a topographic kernel          and a self-consistent solution to the label assignment shown to be equiv-          alent to a recurrent neural network. The performance of the algorithm is          compared to a conventional SVM on a cell image segmentation task."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Cerebellum Chip", "Title": "an Analog VLSI Implementation of a Cerebellar Model of Classical Conditioning", "Abstract": "We  present  a  biophysically  constrained  cerebellar  model  of                classical  conditioning,  implemented  using  a  neuromorphic  analog                VLSI (aVLSI) chip.  Like its biological counterpart, our cerebellar                model  is  able  to  control  adaptive  behavior  by  predicting  the                precise timing of events.  Here we describe the functionality of the                chip  and  present  its  learning  performance,  as  evaluated  in                simulated  conditioning  experiments  at  the  circuit  level  and  in                behavioral  experiments  using  a  mobile  robot.    We  show  that  this                aVLSI model supports the acquisition and extinction of adaptively                timed  conditioned  responses  under  real-world  conditions  with                ultra-low power consumption."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pictorial Structures for Molecular Modeling", "Title": "Interpreting Density Maps", "Abstract": "X-ray crystallography is currently the most common way protein  structures are elucidated. One of the most time-consuming steps in  the crystallographic process is interpretation of the electron density  map, a task that involves finding patterns in a three-dimensional  picture of a protein. This paper describes DEFT (DEFormable  Template), an algorithm using pictorial structures to build a  flexible protein model from the protein's amino-acid sequence.  Matching this pictorial structure into the density map is a way of  automating density-map interpretation. Also described are several  extensions to the pictorial structure matching algorithm necessary  for this automated interpretation. DEFT is tested on a set of  density maps ranging from 2 to 4Å resolution, producing root- mean-squared errors ranging from 1.38 to 1.84Å."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Laplacian PDF Distance", "Title": "A Cost Function for Clustering in a Kernel Feature Space", "Abstract": "Acknowledgments.               This work was partially supported by NSF grant ECS- 0300340."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Solitaire", "Title": "Man Versus Machine", "Abstract": "In this paper, we apply the rollout method to a version of solitaire, modeled as a deter- ministic Markov decision problem with over 52! states. Determinism drastically reduces computational requirements, making it possible to consider iterated rollouts1. With five iterations, a game, implemented in Java, takes about one hour and forty-five minutes on average on a SUN Blade 2000 machine with two 900MHz CPUs, and the probability of winning exceeds that of a human expert by about a factor of two. Our study represents an important contribution both to the study of the rollout method and to the study of solitaire."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Similarity and Discrimination in Classical Conditioning", "Title": "A Latent Variable Account", "Abstract": "We propose a probabilistic, generative account of configural learning          phenomena in classical conditioning. Configural learning experiments          probe how animals discriminate and generalize between patterns of si-          multaneously presented stimuli (such as tones and lights) that are dif-          ferentially predictive of reinforcement. Previous models of these issues          have been successful more on a phenomenological than an explanatory          level: they reproduce experimental findings but, lacking formal founda-          tions, provide scant basis for understanding why animals behave as they          do. We present a theory that clarifies seemingly arbitrary aspects of pre-          vious models while also capturing a broader set of data. Key patterns          of data, e.g. concerning animals' readiness to distinguish patterns with          varying degrees of overlap, are shown to follow from statistical inference."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Boosting on Manifolds", "Title": "Adaptive Regularization of Base Classifiers", "Abstract": "to determine the base errors. Figure 3(f) indicates that REGBOOST has a clear advantage here. REGBOOST is also far better than the semi-supervised algorithm proposed in [12] (their best test error using the same settings is 18%)."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reducing Spike Train Variability", "Title": "A Computational Theory Of Spike-Timing Dependent Plasticity", "Abstract": "We model in detail the experiment of Zhang et al. [12] (Figure 2a). In this exper- iment, a post neuron is identified that has two neurons projecting to it, call them the pre and the driver. The pre is subthreshold: it produces depolarization but no spike. The driver is suprathreshold: it induces a spike in the post. Plasticity of the pre-post synapse is measured as a function of the timing between pre and post spikes (tpre-post) by varying the timing between induced spikes in the pre and the driver (tpre-driver). This measurement yields the well-known STDP curve (Figure 1b).1 The experiment imposes several constraints on a simulation: The driver alone causes spiking > 70% of the time, the pre alone causes spiking < 10% of the time, synchronous firing of driver and pre cause LTP if and only if the post fires, and the time constants of the EPSPs--s and m in the sSRM--are in the range of 13ms and 1015ms respectively. These constraints remove many free parameters from our simulation. We do not explicitly model the two input cells; instead, we model the EPSPs they produce. The magnitude of these EPSPs are picked to satisfy the experimental constraints: the driver EPSP alone causes a spike in the post on 77.4% of trials, and the pre EPSP alone causes a spike on fewer than 0.1% of trials. Free parameters of the simulation are  and  in the spike-probability function ( can be folded into ), and the magnitude (us, u                                          ,  f ,                                        r     abs) and reset time constants ( s                                                                             r       r     abs). The dependent variable of the simulation is tpre-driver, and we measure the time of the post spike to determine tpre-post. We estimate the weight update for a given tpre-driver using Equation 8, approximating the integral by a summation over all time-discretized output responses consisting of 0, 1, or 2 spikes. Three or more spikes have a probability that is vanishingly small."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Chemosensory Processing in a Spiking Model of the Olfactory Bulb", "Title": "Chemotopic Convergence and Center Surround Inhibition", "Abstract": "This paper presents a neuromorphic model of two olfactory signal-          processing primitives: chemotopic convergence of olfactory           receptor neurons, and center on-off surround lateral inhibition in           the olfactory bulb. A self-organizing model of receptor           convergence onto glomeruli is used to generate a spatially           organized map, an olfactory image. This map serves as input to a           lattice of spiking neurons with lateral connections. The dynamics           of this recurrent network transforms the initial olfactory image into           a spatio-temporal pattern that evolves and stabilizes into odor- and           intensity-coding attractors. The model is validated using           experimental data from an array of temperature-modulated gas           sensors.  Our results are consistent with recent neurobiological           findings on the antennal lobe of the honeybee and the locust."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VDCBPI", "Title": "an Approximate Scalable Algorithm for Large POMDPs", "Abstract": "The above tips work well when VDC is integrated with BPI. We believe they are sufficient to ensure proper integration of VDC with other POMDP algorithms, though we haven't verified this empirically."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Generalized Bradley-Terry Model", "Title": "From Group Competition to Individual Skill", "Abstract": "The Bradley-Terry model for paired comparison has been popular in many areas. We propose a generalized version in which paired individual comparisons are extended to paired team comparisons. We introduce a simple algorithm with convergence proofs to solve the model and obtain individual skill. A useful application to multi-class probability estimates using error-correcting codes is demonstrated."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Co-Validation", "Title": "Using Model Disagreement on Unlabeled Data to Validate Classification Algorithms", "Abstract": "In the context of binary classification, we define disagreement as a mea-          sure of how often two independently-trained models differ in their clas-          sification of unlabeled data. We explore the use of disagreement for error          estimation and model selection. We call the procedure co-validation,          since the two models effectively (in)validate one another by comparing          results on unlabeled data, which we assume is relatively cheap and plen-          tiful compared to labeled data. We show that per-instance disagreement          is an unbiased estimate of the variance of error for that instance. We also          show that disagreement provides a lower bound on the prediction (gen-          eralization) error, and a tight upper bound on the \"variance of prediction          error\", or the variance of the average error across instances, where vari-          ance is measured across training sets. We present experimental results on          several data sets exploring co-validation for error estimation and model          selection. The procedure is especially effective in active learning set-          tings, where training sets are not drawn at random and cross validation          overestimates error."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Co-Training and Expansion", "Title": "Towards Bridging Theory and Practice", "Abstract": "Computer Science Dept. Carnegie Mellon Univ. Pittsburgh, PA 15213"}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Theory of localized synfire chain", "Title": "characteristic propagation speed of stable spike pattern", "Abstract": "Repeated spike patterns have often been taken as evidence for the synfire          chain, a phenomenon that a stable spike synchrony propagates through          a feedforward network. Inter-spike intervals which represent a repeated          spike pattern are influenced by the propagation speed of a spike packet.          However, the relation between the propagation speed and network struc-          ture is not well understood. While it is apparent that the propagation          speed depends on the excitatory synapse strength, it might also be related          to spike patterns. We analyze a feedforward network with Mexican-Hat-          type connectivity (FMH) using the Fokker-Planck equation. We show          that both a uniform and a localized spike packet are stable in the FMH          in a certain parameter region. We also demonstrate that the propagation          speed depends on the distinct firing patterns in the same network."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Power of Selective Memory", "Title": "Self-Bounded Learning of Prediction Suffix Trees", "Abstract": "Prediction suffix trees (PST) provide a popular and effective tool for tasks          such as compression, classification, and language modeling. In this pa-          per we take a decision theoretic view of PSTs for the task of sequence          prediction. Generalizing the notion of margin to PSTs, we present an on-          line PST learning algorithm and derive a loss bound for it. The depth of          the PST generated by this algorithm scales linearly with the length of the          input. We then describe a self-bounded enhancement of our learning al-          gorithm which automatically grows a bounded-depth PST. We also prove          an analogous mistake-bound for the self-bounded algorithm. The result          is an efficient algorithm that neither relies on a-priori assumptions on the          shape or maximal depth of the target PST nor does it require any param-          eters. To our knowledge, this is the first provably-correct PST learning          algorithm which generates a bounded-depth PST while being competi-          tive with any fixed PST determined in hindsight."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spike Sorting", "Title": "Bayesian Clustering of Non-Stationary Data", "Abstract": "In some cases, validity of the automatic clustering can be assessed by checking functional properties associated with the underlying neurons. In Figure 3B we present such a valida- tion for a successfully tracked cluster."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Blind One-microphone Speech Separation", "Title": "A Spectral Learning Approach", "Abstract": "We present an algorithm to perform blind, one-microphone speech sep-          aration. Our algorithm separates mixtures of speech without modeling          individual speakers. Instead, we formulate the problem of speech sep-          aration as a problem in segmenting the spectrogram of the signal into          two or more disjoint sets. We build feature sets for our segmenter using          classical cues from speech psychophysics. We then combine these fea-          tures into parameterized affinity matrices. We also take advantage of the          fact that we can generate training examples for segmentation by artifi-          cially superposing separately-recorded signals. Thus the parameters of          the affinity matrices can be tuned using recent work on learning spectral          clustering [1]. This yields an adaptive, speech-specific segmentation al-          gorithm that can successfully separate one-microphone speech mixtures."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Parallel Support Vector Machines", "Title": "The Cascade SVM", "Abstract": "We describe an algorithm for support vector machines (SVM) that  can be parallelized efficiently and scales to very large problems with  hundreds of thousands of training vectors. Instead of analyzing the  whole training set in one optimization step, the data are split into  subsets and optimized separately with multiple SVMs. The partial  results are combined and filtered again in a ‘Cascade’ of SVMs, until  the global optimum is reached. The Cascade SVM can be spread over  multiple processors with minimal communication overhead and  requires far less memory, since the kernel matrices are much smaller  than for a regular SVM. Convergence to the global optimum is  guaranteed with multiple passes through the Cascade, but already a  single pass provides good generalization. A single pass is 5x – 10x  faster than a regular SVM for problems of 100,000 vectors when  implemented on a single processor. Parallel implementations on a  cluster of 16 processors were tested with over 1 million vectors  (2-class problems), converging in a day or two, while a regular SVM  never converged in over a week."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "At the Edge of Chaos", "Title": "Real-time Computations and Self-Organized Criticality in Recurrent Neural Networks", "Abstract": "Acknowledgement                        This work was supported in part by the PASCAL project #IST-2002-506778 of the European Community."}
{"Type": "conference", "Year": "2004", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sharing Clusters among Related Groups", "Title": "Hierarchical Dirichlet Processes", "Abstract": "We propose the hierarchical Dirichlet process (HDP), a nonparametric Bayesian model for clustering problems involving multiple groups of data. Each group of data is modeled with a mixture, with the number of components being open-ended and inferred automatically by the model. Further, components can be shared across groups, allowing dependencies across groups to be modeled effectively as well as conferring generaliza- tion to new groups. Such grouped clustering problems occur often in practice, e.g. in the problem of topic discovery in document corpora. We report experimental results on three text corpora showing the effective and superior performance of the HDP over previous models."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Inference with Minimal Communication", "Title": "a Decision-Theoretic Variational Approach", "Abstract": "Given a directed graphical model with binary-valued hidden nodes and real-valued noisy observations, consider deciding upon the maximum a-posteriori (MAP) or the maximum posterior-marginal (MPM) assignment under the restriction that each node broadcasts only to its children exactly one single-bit message. We present a variational formulation, viewing the processing rules local to all nodes as degrees-of-freedom, that minimizes the loss in expected (MAP or MPM) performance subject to such online communication constraints. The approach leads to a novel message-passing algorithm to be executed offline, or before observations are realized, which mitigates the performance loss by iteratively coupling all rules in a manner implicitly driven by global statistics. We also provide (i) illustrative examples, (ii) assumptions that guarantee convergence and efficiency and (iii) connections to active research areas."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Non-Gaussian Component Analysis", "Title": "a Semi-parametric Framework for Linear Dimension Reduction", "Abstract": "We propose a new linear method for dimension reduction to identify nonGaussian components in high dimensional data. Our method, NGCA (non-Gaussian component analysis), uses a very general semi-parametric framework. In contrast to existing projection methods we define what is uninteresting (Gaussian): by projecting out uninterestingness, we can estimate the relevant non-Gaussian subspace. We show that the estimation error of finding the non-Gaussian components tends to zero at a parametric rate. Once NGCA components are identified and extracted, various tasks can be applied in the data analysis process, like data visualization, clustering, denoising or classification. A numerical study demonstrates the usefulness of our method."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How fast to work", "Title": "Response vigor, motivation and tonic dopamine", "Abstract": "Reinforcement learning models have long promised to unify computa- tional, psychological and neural accounts of appetitively conditioned be- havior. However, the bulk of data on animal conditioning comes from free-operant experiments measuring how fast animals will work for rein- forcement. Existing reinforcement learning (RL) models are silent about these tasks, because they lack any notion of vigor. They thus fail to ad- dress the simple observation that hungrier animals will work harder for food, as well as stranger facts such as their sometimes greater produc- tivity even when working for irrelevant outcomes such as water. Here, we develop an RL framework for free-operant behavior, suggesting that subjects choose how vigorously to perform selected actions by optimally balancing the costs and beneﬁts of quick responding. Motivational states such as hunger shift these factors, skewing the tradeoff. This accounts normatively for the effects of motivation on response rates, as well as many other classic ﬁndings. Finally, we suggest that tonic levels of dopamine may be involved in the computation linking motivational state to optimal responding, thereby explaining the complex vigor-related ef- fects of pharmacological manipulation of dopamine."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Accuracy of Bounded Rationality", "Title": "How Far from Optimal Is Fast and Frugal?", "Abstract": "Fast and frugal heuristics are well studied models of bounded rationality. Psychological research has proposed the take-the-best heuristic as a successful strategy in decision making with limited resources. Take-thebest searches for a sufficiently good ordering of cues (features) in a task where objects are to be compared lexicographically. We investigate the complexity of the problem of approximating optimal cue permutations for lexicographic strategies. We show that no efficient algorithm can approximate the optimum to within any constant factor, if P = NP. We further consider a greedy approach for building lexicographic strategies and derive tight bounds for the performance ratio of a new and simple algorithm. This algorithm is proven to perform better than take-the-best."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Two view learning", "Title": "SVM-2K, Theory and Practice", "Abstract": "Kernel methods make it relatively easy to define complex highdimensional feature spaces. This raises the question of how we can identify the relevant subspaces for a particular learning task. When two views of the same phenomenon are available kernel Canonical Correlation Analysis (KCCA) has been shown to be an effective preprocessing step that can improve the performance of classification algorithms such as the Support Vector Machine (SVM). This paper takes this observation to its logical conclusion and proposes a method that combines this two stage learning (KCCA followed by SVM) into a single optimisation termed SVM-2K. We present both experimental and theoretical analysis of the approach showing encouraging results and insights."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Top-Down Control of Visual Attention", "Title": "A Rational Account", "Abstract": "Theories of visual attention commonly posit that early parallel processes extract con- spicuous features such as color contrast and motion from the visual field. These features are then combined into a saliency map, and attention is directed to the most salient regions first. Top-down attentional control is achieved by modulating the contribution of different feature types to the saliency map. A key source of data concerning attentional control comes from behavioral studies in which the effect of recent experience is exam- ined as individuals repeatedly perform a perceptual discrimination task (e.g., “what shape is the odd-colored object?”). The robust finding is that repetition of features of recent trials (e.g., target color) facilitates performance. We view this facilitation as an adaptation to the statistical structure of the environment. We propose a probabilistic model of the environment that is updated after each trial. Under the assumption that attentional control operates so as to make performance more efficient for more likely environmental states, we obtain parsimonious explanations for data from four different experiments. Further, our model provides a rational explanation for why the influence of past experience on attentional control is short lived."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Using ``epitomes'' to model genetic diversity", "Title": "Rational design of HIV vaccine cocktails", "Abstract": "We introduce a new model of genetic diversity which summarizes a large input dataset into an epitome, a short sequence or a small set of short sequences of probability distributions capturing many overlapping subsequences from the dataset. The epitome as a representation has already been used in modeling real-valued signals, such as images and audio. The discrete sequence model we introduce in this paper targets applications in genetics, from multiple alignment to recombination and mutation inference. In our experiments, we concentrate on modeling the diversity of HIV where the epitome emerges as a natural model for producing relatively small vaccines covering a large number of immune system targets known as epitopes. Our experiments show that the epitome includes more epitopes than other vaccine designs of similar length, including cocktails of consensus strains, phylogenetic tree centers, and observed strains. We also discuss epitome designs that take into account uncertainty about Tcell cross reactivity and epitope presentation. In our experiments, we find that vaccine optimization is fairly robust to these uncertainties."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ideal Observers for Detecting Motion", "Title": "Correspondence Noise", "Abstract": "We derive a Bayesian Ideal Observer (BIO) for detecting motion and solving the correspondence problem. We obtain Barlow and Tripathy’s classic model as an approximation. Our psychophysical experiments show that the trends of human performance are similar to the Bayesian Ideal, but overall human performance is far worse. We investigate ways to degrade the Bayesian Ideal but show that even extreme degradations do not approach human performance. Instead we propose that humans perform motion tasks using generic, general purpose, models of motion. We perform more psychophysical experiments which are consistent with humans using a Slow-and-Smooth model and which rule out an alterna- tive model using Slowness."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning in Silicon", "Title": "Timing is Everything", "Abstract": "We hypothesize that the hippocampus achieves its precise spike timing (about 10ms) through plasticity enhanced phase-coding (PEP). The source of hippocampal timing preci- sion in the presence of variability (and noise) remains unexplained. Synaptic plasticity can compensate for variability in excitability if it increases excitatory synaptic input to neurons in inverse proportion to their excitabilities. Recasting this in a phase-coding framework, we desire a learning rule that increases excitatory synaptic input to neurons directly related to their phases. Neurons that lag require additional synaptic input, whereas neurons that lead"}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rate Distortion Codes in Sensor Networks", "Title": "A System-level Analysis", "Abstract": "This paper provides a system-level analysis of a scalable distributed sens- ing model for networked sensors. In our system model, a data center ac- quires data from a bunch of L sensors which each independently encode their noisy observations of an original binary sequence, and transmit their encoded data sequences to the data center at a combined rate R, which is limited. Supposing that the sensors use independent LDGM rate dis- tortion codes, we show that the system performance can be evaluated for any given ﬁnite R when the number of sensors L goes to inﬁnity. The analysis shows how the optimal strategy for the distributed sensing prob- lem changes at critical values of the data rate R or the noise level."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Pair-Based STDP", "Title": "a Phenomenological Rule for Spike Triplet and Frequency Effects", "Abstract": "While classical experiments on spike-timing dependent plasticity analyzed synaptic changes as a function of the timing of pairs of pre- and postsynaptic spikes, more recent experiments also point to the effect of spike triplets. Here we develop a mathematical framework that allows us to characterize timing based learning rules. Moreover, we identify a candidate learning rule with five variables (and 5 free parameters) that captures a variety of experimental data, including the dependence of potentiation and depression upon pre- and postsynaptic firing frequencies. The relation to the Bienenstock-Cooper-Munro rule as well as to some timing-based rules is discussed."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Estimating the wrong Markov random field", "Title": "Benefits in the computation-limited setting", "Abstract": "Consider the problem of joint parameter estimation and prediction in a Markov random field: i.e., the model parameters are estimated on the basis of an initial set of data, and then the fitted model is used to perform prediction (e.g., smoothing, denoising, interpolation) on a new noisy observation. Working in the computation-limited setting, we analyze a joint method in which the same convex variational relaxation is used to construct an M-estimator for fitting parameters, and to perform approximate marginalization for the prediction step. The key result of this paper is that in the computation-limited setting, using an inconsistent parameter estimator (i.e., an estimator that returns the \"wrong\" model even in the infinite data limit) is provably beneficial, since the resulting errors can partially compensate for errors made by using an approximate prediction technique. En route to this result, we analyze the asymptotic properties of M-estimators based on convex variational relaxations, and establish a Lipschitz stability property that holds for a broad class of variational methods. We show that joint estimation/prediction based on the reweighted sum-product algorithm substantially outperforms a commonly used heuristic based on ordinary sum-product. 1 Keywords: Markov random fields; variational method; message-passing algorithms; sum-product; belief propagation; parameter estimation; learning."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analyzing Coupled Brain Sources", "Title": "Distinguishing True from Spurious Interaction", "Abstract": "When trying to understand the brain, it is of fundamental importance to analyse (e.g. from EEG/MEG measurements) what parts of the cortex interact with each other in order to infer more accurate models of brain activity. Common techniques like Blind Source Separation (BSS) can estimate brain sources and single out artifacts by using the underlying assumption of source signal independence. However, physiologically interesting brain sources typically interact, so BSS will--by construction-- fail to characterize them properly. Noting that there are truly interacting sources and signals that only seemingly interact due to effects of volume conduction, this work aims to contribute by distinguishing these effects. For this a new BSS technique is proposed that uses anti-symmetrized cross-correlation matrices and subsequent diagonalization. The resulting decomposition consists of the truly interacting brain sources and suppresses any spurious interaction stemming from volume conduction. Our new concept of interacting source analysis (ISA) is successfully demonstrated on MEG data."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CMOL CrossNets", "Title": "Possible Neuromorphic Nanoelectronic Circuits", "Abstract": "Recent  results  [1,  2]  indicate  that  the  current  VLSI  paradigm  based  on  CMOS  technology  can  be  hardly  extended  beyond  the  10-nm  frontier:  in  this  range  the  sensitivity  of  parameters  (most  importantly,  the  gate  voltage  threshold)  of  silicon  field-effect  transistors  to  inevitable  fabrication  spreads  grows  exponentially.  This  sensitivity will probably send the fabrication facilities costs skyrocketing, and may  lead to the end of Moore’s Law some time during the next decade.   There  is  a  growing  consensus  that  the  impending  Moore’s  Law  crisis  may  be  preempted by a radical paradigm shift from the purely CMOS technology to hybrid  CMOS/nanodevice circuits, e.g., those of “CMOL” variety (Fig. 1). Such circuits (see,  e.g., Ref. 3 for their recent review) would combine a level of advanced CMOS devices  fabricated by the lithographic patterning, and two-layer nanowire crossbar formed,  e.g.,  by  nanoimprint,  with  nanowires  connected  by  simple,  similar,  two-terminal  nanodevices at each crosspoint. For such devices, molecular single-electron latching  switches [4] are presently the leading candidates, in particular because they may be  fabricated using the self-assembled monolayer (SAM) technique which already gave  reproducible results for simpler molecular devices [5]."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Forgetron", "Title": "A Kernel-Based Perceptron on a Fixed Budget", "Abstract": "The Perceptron algorithm, despite its simplicity, often performs well on online classification tasks. The Perceptron becomes especially effective when it is used in conjunction with kernels. However, a common difficulty encountered when implementing kernel-based online algorithms is the amount of memory required to store the online hypothesis, which may grow unboundedly. In this paper we present and analyze the Forgetron algorithm for kernel-based online learning on a fixed memory budget. To our knowledge, this is the first online learning algorithm which, on one hand, maintains a strict limit on the number of examples it stores while, on the other hand, entertains a relative mistake bound. In addition to the formal results, we also present experiments with real datasets which underscore the merits of our approach."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rodeo", "Title": "Sparse Nonparametric Regression in High Dimensions", "Abstract": "We present a method for nonparametric regression that performs bandwidth selection and variable selection simultaneously. The approach is based on the technique of incrementally decreasing the bandwidth in directions where the gradient of the estimator with respect to bandwidth is large. When the unknown function satisfies a sparsity condition, our approach avoids the curse of dimensionality, achieving the optimal minimax rate of convergence, up to logarithmic factors, as if the relevant variables were known in advance. The method--called rodeo (regularization of derivative expectation operator)--conducts a sequence of hypothesis tests, and is easy to implement. A modified version that replaces hard with soft thresholding effectively solves a sequence of lasso problems."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hot Coupling", "Title": "A Particle Approach to Inference and Normalization on Pairwise Undirected Graphs", "Abstract": "This paper presents a new sampling algorithm for approximating func- tions of variables representable as undirected graphical models of arbi- trary connectivity with pairwise potentials, as well as for estimating the notoriously dif(cid:2)cult partition function of the graph. The algorithm (cid:2)ts into the framework of sequential Monte Carlo methods rather than the more widely used MCMC, and relies on constructing a sequence of in- termediate distributions which get closer to the desired one. While the idea of using (cid:147)tempered(cid:148) proposals is known, we construct a novel se- quence of target distributions where, rather than dropping a global tem- perature parameter, we sequentially couple individual pairs of variables that are, initially, sampled exactly from a spanning tree of the variables. We present experimental results on inference and estimation of the parti- tion function for sparse and densely-connected graphs."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spectral Bounds for Sparse PCA", "Title": "Exact and Greedy Algorithms", "Abstract": "Sparse PCA seeks approximate sparse \"eigenvectors\" whose projections capture the maximal variance of data. As a cardinality-constrained and non-convex optimization problem, it is NP-hard and is encountered in a wide range of applied fields, from bio-informatics to finance. Recent progress has focused mainly on continuous approximation and convex relaxation of the hard cardinality constraint. In contrast, we consider an alternative discrete spectral formulation based on variational eigenvalue bounds and provide an effective greedy strategy as well as provably optimal solutions using branch-and-bound search. Moreover, the exact methodology used reveals a simple renormalization step that improves approximate solutions obtained by any continuous method. The resulting performance gain of discrete algorithms is demonstrated on real-world benchmark data and in extensive Monte Carlo evaluation trials."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Gaussian Processes", "Title": "On the Distributions of Infinite Networks", "Abstract": "A general analysis of the limiting distribution of neural network functions is performed, with emphasis on non-Gaussian limits. We show that with i.i.d. symmetric stable output weights, and more generally with weights distributed from the normal domain of attraction of a stable variable, that the neural functions converge in distribution to stable processes. Conditions are also investigated under which Gaussian limits do occur when the weights are independent but not identically distributed. Some particularly tractable classes of stable distributions are examined, and the possibility of learning with such processes."}
{"Type": "conference", "Year": "2005", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Oblivious Equilibrium", "Title": "A Mean Field Approximation for Large-Scale Dynamic Games", "Abstract": "We propose a mean-ﬁeld approximation that dramatically reduces the computational complexity of solving stochastic dynamic games. We pro- vide conditions that guarantee our method approximates an equilibrium as the number of agents grow. We then derive a performance bound to assess how well the approximation performs for any given number of agents. We apply our method to an important class of problems in ap- plied microeconomics. We show with numerical experiments that we are able to greatly expand the set of economic problems that can be analyzed computationally."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hidden Markov Dirichlet Process", "Title": "Modeling Genetic Recombination in Open Ancestral Space", "Abstract": "We present a new statistical framework called hidden Markov Dirichlet process (HMDP) to jointly model the genetic recombinations among possibly infinite number of founders and the coalescence-with-mutation events in the resulting genealogies. The HMDP posits that a haplotype of genetic markers is generated by a sequence of recombination events that select an ancestor for each locus from an unbounded set of founders according to a 1st-order Markov transition process. Conjoining this process with a mutation model, our method accommodates both between-lineage recombination and within-lineage sequence variations, and leads to a compact and natural interpretation of the population structure and inheritance process underlying haplotype data. We have developed an efficient sampling algo rithm for HMDP based on a two-level nested Polya urn scheme. On both simulated and real SNP haplotype data, our method performs competitively or significantly better than extant methods in uncovering the recombination hotspots along chromosomal loci; and in addition it also infers the ancestral genetic patterns and offers a highly accurate map of ancestral compositions of modern populations."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reducing Calibration Time For Brain-Computer Interfaces", "Title": "A Clustering Approach", "Abstract": "Up to now even subjects that are experts in the use of machine learning based BCI systems still have to undergo a calibration session of about 20-30 min. From this data their (movement) intentions are so far infered. We now propose a new paradigm that allows to completely omit such calibration and instead transfer knowledge from prior sessions. To achieve this goal we first define normalized CSP features and distances in-between. Second, we derive prototypical features across sessions: (a) by clustering or (b) by feature concatenation methods. Finally, we construct a classifier based on these individualized prototypes and show that, indeed, classifiers can be successfully transferred to a new session for a number of subjects."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Aggregating Classification Accuracy across Time", "Title": "Application to Single Trial EEG", "Abstract": "We present a method for binary on-line classification of triggered but temporally blurred events that are embedded in noisy time series in the context of on-line discrimination between left and right imaginary hand-movement. In particular the goal of the binary classification problem is to obtain the decision, as fast and as reliably as possible from the recorded EEG single trials. To provide a probabilistic decision at every time-point t the presented method gathers information from two distinct sequences of features across time. In order to incorporate decisions from prior time-points we suggest an appropriate weighting scheme, that emphasizes time instances, providing a higher discriminatory power between the instantaneous class distributions of each feature, where the discriminatory power is quantified in terms of the Bayes error of misclassification. The effectiveness of this procedure is verified by its successful application in the 3rd BCI competition. Disclosure of the data after the competition revealed this approach to be superior with single trial error rates as low as 10.7, 11.5 and 16.7% for the three different sub jects under study."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Non-rigid point set registration", "Title": "Coherent Point Drift", "Abstract": "We introduce Coherent Point Drift (CPD), a novel probabilistic method for nonrigid registration of point sets. The registration is treated as a Maximum Likelihood (ML) estimation problem with motion coherence constraint over the velocity field such that one point set moves coherently to align with the second set. We formulate the motion coherence constraint and derive a solution of regularized ML estimation through the variational approach, which leads to an elegant kernel form. We also derive the EM algorithm for the penalized ML optimization with deterministic annealing. The CPD method simultaneously finds both the non-rigid transformation and the correspondence between two point sets without making any prior assumption of the transformation model except that of motion coherence. This method can estimate complex non-linear non-rigid transformations, and is shown to be accurate on 2D and 3D examples and robust in the presence of outliers and missing points."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stratification Learning", "Title": "Detecting Mixed Density and Dimensionality in High Dimensional Point Clouds", "Abstract": "The study of point cloud data sampled from a stratification, a collection of manifolds with possible different dimensions, is pursued in this paper. We present a technique for simultaneously soft clustering and estimating the mixed dimensionality and density of such structures. The framework is based on a maximum likelihood estimation of a Poisson mixture model. The presentation of the approach is completed with artificial and real examples demonstrating the importance of extending manifold learning to stratification learning."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptor Grammars", "Title": "A Framework for Specifying Compositional Nonparametric Bayesian Models", "Abstract": "This paper introduces adaptor grammars, a class of probabilistic models of lan- guage that generalize probabilistic context-free grammars (PCFGs). Adaptor grammars augment the probabilistic rules of PCFGs with “adaptors” that can in- duce dependencies among successive uses. With a particular choice of adaptor, based on the Pitman-Yor process, nonparametric Bayesian models of language using Dirichlet processes and hierarchical Dirichlet processes can be written as simple grammars. We present a general-purpose inference algorithm for adaptor grammars, making it easy to deﬁne and use such models, and illustrate how several existing nonparametric Bayesian models can be expressed within this framework."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "iLSTD", "Title": "Eligibility Traces and Convergence Analysis", "Abstract": "We present new theoretical and empirical results with the iLSTD algorithm for policy evaluation in reinforcement learning with linear function approximation. iLSTD is an incremental method for achieving results similar to LSTD, the dataefficient, least-squares version of temporal difference learning, without incurring the full cost of the LSTD computation. LSTD is O(n2 ), where n is the number of parameters in the linear function approximator, while iLSTD is O(n). In this paper, we generalize the previous iLSTD algorithm and present three new results: (1) the first convergence proof for an iLSTD algorithm; (2) an extension to incorporate eligibility traces without changing the asymptotic computational complexity; and (3) the first empirical results with an iLSTD algorithm for a problem (mountain car) with feature vectors large enough (n = 10, 000) to show substantial computational advantages over LSTD."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Context Effects in Category Learning", "Title": "An Investigation of Four Probabilistic Models", "Abstract": "Figure 1: Schematic depiction of sequential effects in categorization"}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Model Spatial Dependency", "Title": "Semi-Supervised Discriminative Random Fields", "Abstract": "We present a novel, semi-supervised approach to training discriminative random fields (DRFs) that efficiently exploits labeled and unlabeled training data to achieve improved accuracy in a variety of image processing tasks. We formulate DRF training as a form of MAP estimation that combines conditional loglikelihood on labeled data, given a data-dependent prior, with a conditional entropy regularizer defined on unlabeled data. Although the training objective is no longer concave, we develop an efficient local optimization procedure that produces classifiers that are more accurate than ones based on standard supervised DRF training. We then apply our semi-supervised approach to train DRFs to segment both synthetic and real data sets, and demonstrate significant improvements over supervised DRFs in each case."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PG-means", "Title": "learning the number of clusters in data", "Abstract": "We present a novel algorithm called PG-means which is able to learn the number of clusters in a classical Gaussian mixture model. Our method is robust and efficient; it uses statistical hypothesis tests on one-dimensional projections of the data and model to determine if the examples are well represented by the model. In so doing, we are applying a statistical test for the entire model at once, not just on a per-cluster basis. We show that our method works well in difficult cases such as non-Gaussian data, overlapping clusters, eccentric clusters, high dimension, and many true clusters. Further, our new method provides a much more stable estimate of the number of clusters than existing methods."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Conditional Random Sampling", "Title": "A Sketch-based Sampling Technique for Sparse Data", "Abstract": "We1 develop Conditional Random Sampling (CRS), a technique particularly suit- able for sparse data. In large-scale applications, the data are often highly sparse. CRS combines sketching and sampling in that it converts sketches of the data into conditional random samples online in the estimation stage, with the sample size determined retrospectively. This paper focuses on approximating pairwise l2 and l1 distances and comparing CRS with random projections. For boolean (0/1) data, CRS is provably better than random projections. We show using real-world data that CRS often outperforms random projections. This technique can be applied in learning, data mining, information retrieval, and database query optimizations."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-Robot Negotiation", "Title": "Approximating the Set of Subgame Perfect Equilibria in General-Sum Stochastic Games", "Abstract": "In real-world planning problems, we must reason not only about our own goals, but about the goals of other agents with which we may interact. Often these agents' goals are neither completely aligned with our own nor directly opposed to them. Instead there are opportunities for cooperation: by joining forces, the agents can all achieve higher utility than they could separately. But, in order to cooperate, the agents must negotiate a mutually acceptable plan from among the many possible ones, and each agent must trust that the others will follow their parts of the deal. Research in multi-agent planning has often avoided the problem of making sure that all agents have an incentive to follow a proposed joint plan. On the other hand, while game theoretic algorithms handle incentives correctly, they often don't scale to large planning problems. In this paper we attempt to bridge the gap between these two lines of research: we present an efficient game-theoretic approximate planning algorithm, along with a negotiation protocol which encourages agents to compute and agree on joint plans that are fair and optimal in a sense defined below. We demonstrate our algorithm and protocol on two simple robotic planning problems.1"}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning with Hypergraphs", "Title": "Clustering, Classification, and Embedding", "Abstract": "We usually endow the investigated objects with pairwise relationships, which can be illustrated as graphs. In many real-world problems, however, relationships among the objects of our interest are more complex than pair- wise. Naively squeezing the complex relationships into pairwise ones will inevitably lead to loss of information which can be expected valuable for our learning tasks however. Therefore we consider using hypergraphs in- stead to completely represent complex relationships among the objects of our interest, and thus the problem of learning with hypergraphs arises. Our main contribution in this paper is to generalize the powerful methodology of spectral clustering which originally operates on undirected graphs to hy- pergraphs, and further develop algorithms for hypergraph embedding and transductive classiﬁcation on the basis of the spectral hypergraph cluster- ing approach. Our experiments on a number of benchmarks showed the advantages of hypergraphs over usual graphs."}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TrueSkill™", "Title": "A Bayesian Skill Rating System", "Abstract": "Abstract Unavailable"}
{"Type": "conference", "Year": "2006", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MLLE", "Title": "Modified Locally Linear Embedding Using Multiple Weights", "Abstract": "The locally linear embedding (LLE) is improved by introducing multiple linearly independent local weight vectors for each neighborhood. We characterize the reconstruction weights and show the existence of the linearly independent weight vectors at each neighborhood. The modiﬁed locally linear embedding (MLLE) proposed in this paper is much stable. It can retrieve the ideal embedding if MLLE is applied on data points sampled from an isometric manifold. MLLE is also compared with the local tangent space alignment (LTSA). Numerical examples are given that show the improvement and efﬁciency of MLLE."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Simulated Annealing", "Title": "Rigorous finite-time guarantees for optimization on continuous domains", "Abstract": "We point out that Boltzmann distributions are not the only distributions which can be adopted as equilibrium distributions in simulated annealing [7]. In this paper it is convenient for us to adopt a different type of equilibrium distribution in place of Boltzmann distributions."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FilterBoost", "Title": "Regression and Classification on Large Datasets", "Abstract": "We study boosting in the ﬁltering setting, where the booster draws examples from an oracle instead of using a ﬁxed training set and so may train efﬁciently on very large datasets. Our algorithm, which is based on a logistic regression technique proposed by Collins, Schapire, & Singer, requires fewer assumptions to achieve bounds equivalent to or better than previous work. Moreover, we give the ﬁrst proof that the algorithm of Collins et al. is a strong PAC learner, albeit within the ﬁltering setting. Our proofs demonstrate the algorithm’s strong theoretical proper- ties for both classiﬁcation and conditional probability estimation, and we validate these results through extensive experiments. Empirically, our algorithm proves more robust to noise and overﬁtting than batch boosters in conditional probability estimation and proves competitive in classiﬁcation."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hippocampal Contributions to Control", "Title": "The Third Way", "Abstract": "Recent experimental studies have focused on the specialization of different neural structures for different types of instrumental behavior. Recent theoretical work has provided normative accounts for why there should be more than one control system, and how the output of different controllers can be integrated. Two par- ticlar controllers have been identiﬁed, one associated with a forward model and the prefrontal cortex and a second associated with computationally simpler, habit- ual, actor-critic methods and part of the striatum. We argue here for the normative appropriateness of an additional, but so far marginalized control system, associ- ated with episodic memory, and involving the hippocampus and medial temporal cortices. We analyze in depth a class of simple environments to show that episodic control should be useful in a range of cases characterized by complexity and in- ferential noise, and most particularly at the very early stages of learning, long before habitization has set in. We interpret data on the transfer of control from the hippocampus to the striatum in the light of this hypothesis."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DIFFRAC", "Title": "a discriminative and flexible framework for clustering", "Abstract": "We present a novel linear clustering framework (Diffrac) which relies on a linear discriminative cost function and a convex relaxation of a combinatorial optimization problem. The large convex optimization problem is solved through a sequence of lower dimensional singular value decompositions. This framework has several attractive properties: (1) although apparently similar to K-means, it exhibits superior clustering performance than K-means, in particular in terms of robustness to noise. (2) It can be readily extended to non linear clustering if the discriminative cost function is based on positive definite kernels, and can then be seen as an alternative to spectral clustering. (3) Prior information on the partition is easily incorporated, leading to state-of-the-art performance for semi-supervised learning, for clustering or classification. We present empirical evaluations of our algorithms on synthetic and real medium-scale datasets."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Better than least squares", "Title": "comparison of objective functions for estimating linear-nonlinear models", "Abstract": "This paper compares a family of methods for characterizing neural feature selec- tivity with natural stimuli in the framework of the linear-nonlinear model. In this model, the neural ﬁring rate is a nonlinear function of a small number of relevant stimulus components. The relevant stimulus dimensions can be found by max- imizing one of the family of objective functions, R´enyi divergences of different orders [1, 2]. We show that maximizing one of them, R´enyi divergence of or- der 2, is equivalent to least-square ﬁtting of the linear-nonlinear model to neural data. Next, we derive reconstruction errors in relevant dimensions found by max- imizing R´enyi divergences of arbitrary order in the asymptotic limit of large spike numbers. We ﬁnd that the smallest errors are obtained with R´enyi divergence of order 1, also known as Kullback-Leibler divergence. This corresponds to ﬁnding relevant dimensions by maximizing mutual information [2]. We numerically test how these optimization schemes perform in the regime of low signal-to-noise ra- tio (small number of spikes and increasing neural noise) for model visual neurons. We ﬁnd that optimization schemes based on either least square ﬁtting or informa- tion maximization perform well even when number of spikes is small. Information maximization provides slightly, but signiﬁcantly, better reconstructions than least square ﬁtting. This makes the problem of ﬁnding relevant dimensions, together with the problem of lossy compression [3], one of examples where information- theoretic measures are no more data limited than those derived from least squares."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Ranking in Survival Analysis", "Title": "Bounds on the Concordance Index", "Abstract": "In this paper, we show that classical survival analysis involving censored data can naturally be cast as a ranking problem. The concordance index (CI), which quantifies the quality of rankings, is the standard performance measure for model \\emph{assessment} in survival analysis. In contrast, the standard approach to \\emph{learning} the popular proportional hazard (PH) model is based on Cox's partial likelihood. In this paper we devise two bounds on CI--one of which emerges directly from the properties of PH models--and optimize them \\emph{directly}. Our experimental results suggest that both methods perform about equally well, with our new approach giving slightly better results than the Cox's method. We also explain why a method designed to maximize the Cox's partial likelihood also ends up (approximately) maximizing the CI."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regulator Discovery from Gene Expression Time Series of Malaria Parasites", "Title": "a Hierachical Approach", "Abstract": "We introduce a hierarchical Bayesian model for the discovery of putative regulators from gene expression data only. The hierarchy incorporates the knowledge that there are just a few regulators that by themselves only regulate a handful of genes. This is implemented through a so-called spike-and-slab prior, a mixture of Gaussians with different widths, with mixing weights from a hierarchical Bernoulli model. For efficient inference we implemented expectation propagation. Running the model on a malaria parasite data set, we found four genes with significant homology to transcription factors in an amoebe, one RNA regulator and three genes of unknown function (out of the top ten genes considered)."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SpAM", "Title": "Sparse Additive Models", "Abstract": "We present a new class of models for high-dimensional nonparametric regression and classiﬁcation called sparse additive models (SpAM). Our methods combine ideas from sparse linear modeling and additive nonparametric regression. We de- rive a method for ﬁtting the models that is effective even when the number of covariates is larger than the sample size. A statistical analysis of the properties of SpAM is given together with empirical results on synthetic and real data, show- ing that SpAM can be effective in ﬁtting sparse nonparametric models in high dimensional data."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EEG-Based Brain-Computer Interaction", "Title": "Improved Accuracy by Automatic Single-Trial Error Detection", "Abstract": "Brain-computer interfaces (BCIs), as any other interaction modality based on physiological signals and body channels (e.g., muscular activity, speech and gestures), are prone to errors in the recognition of subject's intent. An elegant approach to improve the accuracy of BCIs consists in a verification procedure directly based on the presence of error-related potentials (ErrP) in the EEG recorded right after the occurrence of an error. Six healthy volunteer subjects with no prior BCI experience participated in a new human-robot interaction experiment where they were asked to mentally move a cursor towards a target that can be reached within a few steps using motor imagination. This experiment confirms the previously reported presence of a new kind of ErrP. These Interaction ErrP\" exhibit a first sharp negative peak followed by a positive peak and a second broader negative peak (~290, ~350 and ~470 ms after the feedback, respectively). But in order to exploit these ErrP we need to detect them in each single trial using a short window following the feedback associated to the response of the classifier embedded in the BCI. We have achieved an average recognition rate of correct and erroneous single trials of 81.8% and 76.2%, respectively. Furthermore, we have achieved an average recognition rate of the subject's intent while trying to mentally drive the cursor of 73.1%. These results show that it's possible to simultaneously extract useful information for mental control to operate a brain-actuated device as well as cognitive states such as error potentials to improve the quality of the brain-computer interaction. Finally, using a well-known inverse model (sLORETA), we show that the main focus of activity at the occurrence of the ErrP are, as expected, in the pre-supplementary motor area and in the anterior cingulate cortex.\""}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Invariant Common Spatial Patterns", "Title": "Alleviating Nonstationarities in Brain-Computer Interfacing", "Abstract": "Brain-Computer Interfaces can suffer from a large variance of the subject condi- tions within and across sessions. For example vigilance ﬂuctuations in the indi- vidual, variable task involvement, workload etc. alter the characteristics of EEG signals and thus challenge a stable BCI operation. In the present work we aim to deﬁne features based on a variant of the common spatial patterns (CSP) algorithm that are constructed invariant with respect to such nonstationarities. We enforce invariance properties by adding terms to the denominator of a Rayleigh coefﬁcient representation of CSP such as disturbance covariance matrices from ﬂuctuations in visual processing. In this manner physiological prior knowledge can be used to shape the classiﬁcation engine for BCI. As a proof of concept we present a BCI classiﬁer that is robust to changes in the level of parietal a -activity. In other words, the EEG decoding still works when there are lapses in vigilance."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fixing Max-Product", "Title": "Convergent Message Passing Algorithms for MAP LP-Relaxations", "Abstract": "We present a novel message passing algorithm for approximating the MAP problem in graphical models. The algorithm is similar in structure to max-product but unlike max-product it always converges, and can be proven to find the exact MAP solution in various settings. The algorithm is derived via block coordinate descent in a dual of the LP relaxation of MAP, but does not require any tunable parameters such as step size or tree weights. We also describe a generalization of the method to cluster based potentials. The new method is tested on synthetic and real-world problems, and compares favorably with previous approaches."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GRIFT", "Title": "A graphical model for inferring visual classification features from human data", "Abstract": "This paper describes a new model for human visual classification that enables the recovery of image features that explain human subjects' performance on different visual classification tasks. Unlike previous methods, this algorithm does not model their performance with a single linear classifier operating on raw image pixels. Instead, it models classification as the combination of multiple feature detectors. This approach extracts more information about human visual classification than has been previously possible with other methods and provides a foundation for further exploration."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CPR for CSPs", "Title": "A Probabilistic Relaxation of Constraint Propagation", "Abstract": "This paper proposes constraint propagation relaxation (CPR), a probabilistic approach to classical constraint propagation that provides another view on the whole parametric family of survey propagation algorithms SP(ρ), ranging from belief propagation (ρ = 0) to (pure) survey propagation(ρ = 1). More importantly, the approach elucidates the implicit, but fundamental assumptions underlying SP(ρ), thus shedding some light on its effectiveness and leading to applications beyond k-SAT."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HM-BiTAM", "Title": "Bilingual Topic Exploration, Word Alignment, and Translation", "Abstract": "We present a novel paradigm for statistical machine translation (SMT), based on joint modeling of word alignment and the topical aspects underlying bilingual document pairs via a hidden Markov Bilingual Topic AdMixture (HM-BiTAM). In this new paradigm, parallel sentence-pairs from a parallel document-pair are coupled via a certain semantic-flow, to ensure coherence of topical context in the alignment of matching words between languages, during likelihood-based training of topic-dependent translational lexicons, as well as topic representations in each language. The resulting trained HM-BiTAM can not only display topic patterns like other methods such as LDA, but now for bilingual corpora; it also offers a principled way of inferring optimal translation in a context-dependent way. Our method integrates the conventional IBM Models based on HMM --- a key component for most of the state-of-the-art SMT systems, with the recently proposed BiTAM model, and we report an extensive empirical analysis (in many way complementary to the description-oriented of our method in three aspects: word alignment, bilingual topic representation, and translation."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TrueSkill Through Time", "Title": "Revisiting the History of Chess", "Abstract": "We extend the Bayesian skill rating system TrueSkill to infer entire time series of skills of players by smoothing through time instead of (cid:12)ltering. The skill of each participating player, say, every year is represented by a latent skill variable which is a(cid:11)ected by the relevant game outcomes that year, and coupled with the skill variables of the previous and subsequent year. Inference in the resulting factor graph is carried out by approximate message passing (EP) along the time series of skills. As before the system tracks the uncertainty about player skills, explicitly models draws, can deal with any number of competing entities and can infer individual skills from team results. We extend the system to estimate player-speci(cid:12)c draw mar- gins. Based on these models we present an analysis of the skill curves of important players in the history of chess over the past 150 years. Results include plots of players’ lifetime skill development as well as the ability to compare the skills of di(cid:11)erent players across time. Our results indicate that a) the overall playing strength has increased over the past 150 years, and b) that modelling a player’s ability to force a draw provides signi(cid:12)cantly better predictive power."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayesian binning beats approximate alternatives", "Title": "estimating peri-stimulus time histograms", "Abstract": "The peristimulus time historgram (PSTH) and its more continuous cousin, the spike density function (SDF) are staples in the analytic toolkit of neurophysiologists. The former is usually obtained by binning spiketrains, whereas the standard method for the latter is smoothing with a Gaussian kernel. Selection of a bin with or a kernel size is often done in an relatively arbitrary fashion, even though there have been recent attempts to remedy this situation \\cite{ShimazakiBinningNIPS2006,ShimazakiBinningNECO2007}. We develop an exact Bayesian, generative model approach to estimating PSHTs and demonstate its superiority to competing methods. Further advantages of our scheme include automatic complexity control and error bars on its predictions."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Transfer Learning using Kolmogorov Complexity", "Title": "Basic Theory and Empirical Evaluations", "Abstract": "In transfer learning we aim to solve new problems using fewer examples using information gained from solving related problems. Transfer learning has been successful in practice, and extensive PAC analysis of these methods has been de- veloped. However it is not yet clear how to deﬁne relatedness between tasks. This is considered as a major problem as it is conceptually troubling and it makes it unclear how much information to transfer and when and how to transfer it. In this paper we propose to measure the amount of information one task contains about another using conditional Kolmogorov complexity between the tasks. We show how existing theory neatly solves the problem of measuring relatedness and transferring the ‘right’ amount of information in sequential transfer learning in a Bayesian setting. The theory also suggests that, in a very formal and precise sense, no other reasonable transfer method can do much better than our Kolmogorov Complexity theoretic transfer method, and that sequential transfer is always justi- ﬁed. We also develop a practical approximation to the method and use it to transfer information between 8 arbitrarily chosen databases from the UCI ML repository."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "McRank", "Title": "Learning to Rank Using Multiple Classification and Gradient Boosting", "Abstract": "We cast the ranking problem as (1) multiple classiﬁcation (“Mc”) (2) multiple or- dinal classiﬁcation, which lead to computationally tractable learning algorithms for relevance ranking in Web search. We consider the DCG criterion (discounted cumulative gain), a standard quality measure in information retrieval. Our ap- proach is motivated by the fact that perfect classiﬁcations result in perfect DCG scores and the DCG errors are bounded by classiﬁcation errors. We propose us- ing the Expected Relevance to convert class probabilities into ranking scores. The class probabilities are learned using a gradient boosting tree algorithm. Evalua- tions on large-scale datasets show that our approach can improve LambdaRank [5] and the regressions-based ranker [6], in terms of the (normalized) DCG scores. An efﬁcient implementation of the boosting tree algorithm is also presented."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predicting Brain States from fMRI Data", "Title": "Incremental Functional Principal Component Regression", "Abstract": "We propose a method for reconstruction of human brain states directly from functional neuroimaging data. The method extends the traditional multivariate regression analysis of discretized fMRI data to the domain of stochastic functional measurements, facilitating evaluation of brain responses to naturalistic stimuli and boosting the power of functional imaging. The method searches for sets of voxel timecourses that optimize a multivariate functional linear model in terms of Rsquare-statistic. Population based incremental learning is used to search for spatially distributed voxel clusters, taking into account the variation in Haemodynamic lag across brain areas and among subjects by voxel-wise non-linear registration of stimuli to fMRI data. The method captures spatially distributed brain responses to naturalistic stimuli without attempting to localize function. Application of the method for prediction of naturalistic stimuli from new and unknown fMRI data shows that the approach is capable of identifying distributed clusters of brain locations that are highly predictive of a specific stimuli."}
{"Type": "conference", "Year": "2007", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Experience-Guided Search", "Title": "A Theory of Attentional Control", "Abstract": "People perform a remarkable range of tasks that require search of the visual en- vironment for a target item among distractors. The Guided Search model (Wolfe, 1994, 2007), or GS, is perhaps the best developed psychological account of hu- man visual search. To prioritize search, GS assigns saliency to locations in the visual ﬁeld. Saliency is a linear combination of activations from retinotopic maps representing primitive visual features. GS includes heuristics for setting the gain coefﬁcient associated with each map. Variants of GS have formalized the notion of optimization as a principle of attentional control (e.g., Baldwin & Mozer, 2006; Cave, 1999; Navalpakkam & Itti, 2006; Rao et al., 2002), but every GS-like model must be ’dumbed down’ to match human data, e.g., by corrupting the saliency map with noise and by imposing arbitrary restrictions on gain modulation. We propose a principled probabilistic formulation of GS, called Experience-Guided Search (EGS), based on a generative model of the environment that makes three claims: (1) Feature detectors produce Poisson spike trains whose rates are conditioned on feature type and whether the feature belongs to a target or distractor; (2) the en- vironment and/or task is nonstationary and can change over a sequence of trials; and (3) a prior speciﬁes that features are more likely to be present for target than for distractors. Through experience, EGS infers latent environment variables that determine the gains for guiding search. Control is thus cast as probabilistic infer- ence, not optimization. We show that EGS can replicate a range of human data from visual search, including data that GS does not address."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Translated Learning", "Title": "Transfer Learning across Different Feature Spaces", "Abstract": "This paper investigates a new machine learning strategy called translated learning. Unlike many previous learning tasks, we focus on how to use labeled data from one feature space to enhance the classification of other entirely different learning spaces. For example, we might wish to use labeled text data to help learn a model for classifying image data, when the labeled images are difficult to obtain. An important aspect of translated learning is to build a \"bridge\" to link one feature space (known as the \"source space\") to another space (known as the \"target space\") through a translator in order to migrate the knowledge from source to target. The translated learning solution uses a language model to link the class labels to the features in the source spaces, which in turn is translated to the features in the target spaces. Finally, this chain of linkages is completed by tracing back to the instances in the target spaces. We show that this path of linkage can be modeled using a Markov chain and risk minimization. Through experiments on the text-aided image classification and cross-language classification tasks, we demonstrate that our translated learning framework can greatly outperform many state-of-the-art baseline methods."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cascaded Classification Models", "Title": "Combining Models for Holistic Scene Understanding", "Abstract": "One of the original goals of computer vision was to fully understand a natural scene. This requires solving several problems simultaneously, including object detection, labeling of meaningful regions, and 3d reconstruction. While great progress has been made in tackling each of these problems in isolation, only recently have researchers again been considering the difficult task of assembling various methods to the mutual benefit of all. We consider learning a set of such classification models in such a way that they both solve their own problem and help each other. We develop a framework known as Cascaded Classification Models (CCM), where repeated instantiations of these classifiers are coupled by their input/output variables in a cascade that improves performance at each level. Our method requires only a limited âblack boxâ interface with the models, allowing us to use very sophisticated, state-of-the-art classifiers without having to look under the hood. We demonstrate the effectiveness of our method on a large set of natural images by combining the subtasks of scene categorization, object detection, multiclass image segmentation, and 3d scene reconstruction."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unlabeled data", "Title": "Now it helps, now it doesn't", "Abstract": "Empirical evidence shows that in favorable situations semi-supervised learning (SSL) algorithms can capitalize on the abundancy of unlabeled training data to improve the performance of a learning task, in the sense that fewer labeled training data are needed to achieve a target error bound. However, in other situations unlabeled data do not seem to help. Recent attempts at theoretically characterizing the situations in which unlabeled data can help have met with little success, and sometimes appear to conflict with each other and intuition. In this paper, we attempt to bridge the gap between practice and theory of semi-supervised learning. We develop a rigorous framework for analyzing the situations in which unlabeled data can help and quantify the improvement possible using finite sample error bounds. We show that there are large classes of problems for which SSL can significantly outperform supervised learning, in finite sample regimes and sometimes also in terms of error convergence rates."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Semi-supervised Learning with Weakly-Related Unlabeled Data ", "Title": "Towards Better Text Categorization", "Abstract": "The cluster assumption is exploited by most semi-supervised learning (SSL) methods. However, if the unlabeled data is merely weakly related to the target classes, it becomes questionable whether driving the decision boundary to the low density regions of the unlabeled data will help the classification. In such case, the cluster assumption may not be valid; and consequently how to leverage this type of unlabeled data to enhance the classification accuracy becomes a challenge. We introduce Semi-supervised Learning with Weakly-Related Unlabeled Data\" (SSLW), an inductive method that builds upon the maximum-margin approach, towards a better usage of weakly-related unlabeled information. Although the SSLW could improve a wide range of classification tasks, in this paper, we focus on text categorization with a small training pool. The key assumption behind this work is that, even with different topics, the word usage patterns across different corpora tends to be consistent. To this end, SSLW estimates the optimal word-correlation matrix that is consistent with both the co-occurrence information derived from the weakly-related unlabeled documents and the labeled documents. For empirical evaluation, we present a direct comparison with a number of state-of-the-art methods for inductive semi-supervised learning and text categorization; and we show that SSLW results in a significant improvement in categorization accuracy, equipped with a small training set and an unlabeled resource that is weakly related to the test beds.\""}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weighted Sums of Random Kitchen Sinks", "Title": "Replacing minimization with randomization in learning", "Abstract": "Randomized neural networks are immortalized in this AI Koan: In the days when Sussman was a novice, Minsky once came to him as he sat hacking at the PDP-6. What are you doing?'' asked Minsky.I am training a randomly wired neural net to play tic-tac-toe,'' Sussman replied. Why is the net wired randomly?'' asked Minsky. Sussman replied,I do not want it to have any preconceptions of how to play.'' Minsky then shut his eyes. Why do you close your eyes?'' Sussman asked his teacher.So that the room will be empty,'' replied Minsky. At that moment, Sussman was enlightened. We analyze shallow random networks with the help of concentration of measure inequalities. Specifically, we consider architectures that compute a weighted sum of their inputs after passing them through a bank of arbitrary randomized nonlinearities. We identify conditions under which these networks exhibit good classification performance, and bound their test error in terms of the size of the dataset and the number of random nonlinearities."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "QUIC-SVD", "Title": "Fast SVD Using Cosine Trees", "Abstract": "The Singular Value Decomposition is a key operation in many machine learning methods. Its computational cost, however, makes it unscalable and impractical for the massive-sized datasets becoming common in applications. We present a new method, QUIC-SVD, for fast approximation of the full SVD with automatic sample size minimization and empirical relative error control. Previous Monte Carlo approaches have not addressed the full SVD nor benefited from the efficiency of automatic, empirically-driven sample sizing. Our empirical tests show speedups of several orders of magnitude over exact SVD. Such scalability should enable QUIC-SVD to meet the needs of a wide array of methods and applications."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MAS", "Title": "a multiplicative approximation scheme for probabilistic inference", "Abstract": "We propose a multiplicative approximation scheme (MAS) for inference problems in graphical models, which can be applied to various inference algorithms. The method uses $\\epsilon$-decompositions which decompose functions used throughout the inference procedure into functions over smaller sets of variables with a known error $\\epsilon$. MAS translates these local approximations into bounds on the accuracy of the results. We show how to optimize $\\epsilon$-decompositions and provide a fast closed-form solution for an $L_2$ approximation. Applying MAS to the Variable Elimination inference algorithm, we introduce an algorithm we call DynaDecomp which is extremely fast in practice and provides guaranteed error bounds on the result. The superior accuracy and efficiency of DynaDecomp is demonstrated."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Complexity of Linear Prediction", "Title": "Risk Bounds, Margin Bounds, and Regularization", "Abstract": "We provide sharp bounds for Rademacher and Gaussian complexities of (constrained) linear classes. These bounds make short work of providing a number of corollaries including: risk bounds for linear prediction (including settings where the weight vectors are constrained by either $L_2$ or $L_1$ constraints), margin bounds (including both $L_2$ and $L_1$ margins, along with more general notions based on relative entropy), a proof of the PAC-Bayes theorem, and $L_2$ covering numbers (with $L_p$ norm constraints and relative entropy constraints). In addition to providing a unified analysis, the results herein provide some of the sharpest risk and margin bounds (improving upon a number of previous results). Interestingly, our results show that the uniform convergence rates of empirical risk minimization algorithms tightly match the regret bounds of online learning algorithms for linear prediction (up to a constant factor of 2)."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sequential effects", "Title": "Superstition or rational behavior?", "Abstract": "In a variety of behavioral tasks, subjects exhibit an automatic and apparently sub-optimal sequential effect: they respond more rapidly and accurately to a stimulus if it reinforces a local pattern in stimulus history, such as a string of repetitions or alternations, compared to when it violates such a pattern. This is often the case even if the local trends arise by chance in the context of a randomized design, such that stimulus history has no predictive power. In this work, we use a normative Bayesian framework to examine the hypothesis that such idiosyncrasies may reflect the inadvertent engagement of fundamental mechanisms critical for adapting to changing statistics in the natural environment. We show that prior belief in non-stationarity can induce experimentally observed sequential effects in an otherwise Bayes-optimal algorithm. The Bayesian algorithm is shown to be well approximated by linear-exponential filtering of past observations, a feature also apparent in the behavioral data. We derive an explicit relationship between the parameters and computations of the exact Bayesian algorithm and those of the approximate linear-exponential filter. Since the latter is equivalent to a leaky-integration process, a commonly used model of neuronal dynamics underlying perceptual decision-making and trial-to-trial dependencies, our model provides a principled account of why such dynamics are useful. We also show that near-optimal tuning of the leaky-integration process is possible, using stochastic gradient descent based only on the noisy binary inputs. This is a proof of concept that not only can neurons implement near-optimal prediction based on standard neuronal dynamics, but that they can also learn to tune the processing parameters without explicitly representing probabilities."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PSDBoost", "Title": "Matrix-Generation Linear Programming for Positive Semidefinite Matrices Learning", "Abstract": "In this work, we consider the problem of learning a positive semidefinite matrix. The critical issue is how to preserve positive semidefiniteness during the course of learning. Our algorithm is mainly inspired by LPBoost [1] and the general greedy convex optimization framework of Zhang [2]. We demonstrate the essence of the algorithm, termed PSDBoost (positive semidefinite Boosting), by focusing on a few different applications in machine learning. The proposed PSDBoost algorithm extends traditional Boosting algorithms in that its parameter is a positive semidefinite matrix with trace being one instead of a classifier. PSDBoost is based on the observation that any trace-one positive semidefinitematrix can be decomposed into linear convex combinations of trace-one rank-one matrices, which serve as base learners of PSDBoost. Numerical experiments are presented."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Model Selection in Gaussian Graphical Models", "Title": "High-Dimensional Consistency of \\boldmath$\\ell_1$-regularized MLE", "Abstract": "We consider the problem of estimating the graph structure associated with a Gaussian Markov random field (GMRF) from i.i.d. samples. We study the performance of study the performance of the 1 -regularized maximum likelihood estimator in the high-dimensional setting, where the number of nodes in the graph p, the number of edges in the graph s and the maximum node degree d, are allowed to grow as a function of the number of samples n. Our main result provides sufficient conditions on (n, p, d) for the 1 -regularized MLE estimator to recover all the edges of the graph with high probability. Under some conditions on the model covariance, we show that model selection can be achieved for sample sizes n = (d2 log(p)), with the error decaying as O(exp(-c log(p))) for some constant c. We illustrate our theoretical results via simulations and show good correspondences between the theoretical predictions and behavior in simulations."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How memory biases affect information transmission", "Title": "A rational analysis of serial reproduction", "Abstract": "Many human interactions involve pieces of information being passed from one person to another, raising the question of how this process of information transmission is affected by the capacities of the agents involved. In the 1930s, Sir Frederic Bartlett explored the influence of memory biases in âserial reproductionâ of information, in which one personâs reconstruction of a stimulus from memory becomes the stimulus seen by the next person. These experiments were done using relatively uncontrolled stimuli such as pictures and stories, but suggested that serial reproduction would transform information in a way that reflected the biases inherent in memory. We formally analyze serial reproduction using a Bayesian model of reconstruction from memory, giving a general result characterizing the effect of memory biases on information transmission. We then test the predictions of this account in two experiments using simple one-dimensional stimuli. Our results provide theoretical and empirical justification for the idea that serial reproduction reflects memory biases."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Novelty Detection", "Title": "Incongruent Events, when General and Specific Classifiers Disagree", "Abstract": "Unexpected stimuli are a challenge to any machine learning algorithm. Here we identify distinct types of unexpected events, focusing on 'incongruent events' - when 'general level' and 'specific level' classifiers give conflicting predictions. We define a formal framework for the representation and processing of incongruent events: starting from the notion of label hierarchy, we show how partial order on labels can be deduced from such hierarchies. For each event, we compute its probability in different ways, based on adjacent levels (according to the partial order) in the label hierarchy . An incongruent event is an event where the probability computed based on some more specific level (in accordance with the partial order) is much smaller than the probability computed based on some more general level, leading to conflicting predictions. We derive algorithms to detect incongruent events from different types of hierarchies, corresponding to class membership or part membership. Respectively, we show promising results with real data on two specific problems: Out Of Vocabulary words in speech recognition, and the identification of a new sub-class (e.g., the face of a new individual) in audio-visual facial object recognition."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Look Ma, No Hands", "Title": "Analyzing the Monotonic Feature Abstraction for Text Classification", "Abstract": "Is accurate classification possible in the absence of hand-labeled data? This paper introduces the Monotonic Feature (MF) abstraction--where the probability of class membership increases monotonically with the MF's value. The paper proves that when an MF is given, PAC learning is possible with no hand-labeled data under certain assumptions. We argue that MFs arise naturally in a broad range of textual classification applications. On the classic \"20 Newsgroups\" data set, a learner given an MF and unlabeled data achieves classification accuracy equal to that of a state-of-the-art semi-supervised learner relying on 160 hand-labeled examples. Even when MFs are not given as input, their presence or absence can be determined from a small amount of hand-labeled data, which yields a new semi-supervised learning method that reduces error by 15% on the 20 Newsgroups data."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reconciling Real Scores with Binary Comparisons", "Title": "A New Logistic Based Model for Ranking", "Abstract": "The problem of ranking arises ubiquitously in almost every aspect of life, and in particular in Machine Learning/Information Retrieval. A statistical model for ranking predicts how humans rank subsets V of some universe U . In this work we define a statistical model for ranking that satisfies certain desirable properties. The model automatically gives rise to a logistic regression based approach to learning how to rank, for which the score and comparison based approaches are dual views. This offers a new generative approach to ranking which can be used for IR. There are two main contexts for this work. The first is the theory of econometrics and study of statistical models explaining human choice of alternatives. In this context, we will compare our model with other well known models. The second context is the problem of ranking in machine learning, usually arising in the context of information retrieval. Here, much work has been done in the discriminative setting, where different heuristics are used to define ranking risk functions. Our model is built rigorously and axiomatically based on very simple desirable properties defined locally for comparisons, and automatically implies the existence of a global score function serving as a natural model parameter which can be efficiently fitted to pairwise comparison judgment data by solving a convex optimization problem."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adapting to a Market Shock", "Title": "Optimal Sequential Market-Making", "Abstract": "We study the profit-maximization problem of a monopolistic market-maker who sets two-sided prices in an asset market. The sequential decision problem is hard to solve because the state space is a function. We demonstrate that the belief state is well approximated by a Gaussian distribution. We prove a key monotonicity property of the Gaussian state update which makes the problem tractable, yielding the first optimal sequential market-making algorithm in an established model. The algorithm leads to a surprising insight: an optimal monopolist can provide more liquidity than perfectly competitive market-makers in periods of extreme uncertainty, because a monopolist is willing to absorb initial losses in order to learn a new valuation rapidly so she can extract higher profits later."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DiscLDA", "Title": "Discriminative Learning for Dimensionality Reduction and Classification", "Abstract": "Probabilistic topic models (and their extensions) have become popular as models of latent structures in collections of text documents or images. These models are usually treated as generative models and trained using maximum likelihood estimation, an approach which may be suboptimal in the context of an overall classification problem. In this paper, we describe DiscLDA, a discriminative learning framework for such models as Latent Dirichlet Allocation (LDA) in the setting of dimensionality reduction with supervised side information. In DiscLDA, a class-dependent linear transformation is introduced on the topic mixture proportions. This parameter is estimated by maximizing the conditional likelihood using Monte Carlo EM. By using the transformed topic mixture proportions as a new representation of documents, we obtain a supervised dimensionality reduction algorithm that uncovers the latent structure in a document collection while preserving predictive power for the task of classification. We compare the predictive power of the latent structure of DiscLDA with unsupervised LDA on the 20 Newsgroup ocument classification task."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimization on a Budget", "Title": "A Reinforcement Learning Approach", "Abstract": "Many popular optimization algorithms, like the Levenberg-Marquardt algorithm (LMA), use heuristic-based controllers'' that modulate the behavior of the optimizer during the optimization process. For example, in the LMA a damping parameter is dynamically modified based on a set rules that were developed using various heuristic arguments. Reinforcement learning (RL) is a machine learning approach to learn optimal controllers by examples and thus is an obvious candidate to improve the heuristic-based controllers implicit in the most popular and heavily used optimization algorithms. Improving the performance of off-the-shelf optimizers is particularly important for time-constrained optimization problems. For example the LMA algorithm has become popular for many real-time computer vision problems, including object tracking from video, where only a small amount of time can be allocated to the optimizer on each incoming video frame. Here we show that a popular modern reinforcement learning technique using a very simply state space can dramatically improve the performance of general purpose optimizers, like the LMA. Most surprisingly the controllers learned for a particular domain appear to work very well also on very different optimization domains. For example we used RL methods to train a new controller for the damping parameter of the LMA. This controller was trained on a collection of classic, relatively small, non-linear regression problems. The modified LMA performed better than the standard LMA on these problems. Most surprisingly, it also dramatically outperformed the standard LMA on a difficult large scale computer vision problem for which it had not been trained before. Thus the controller appeared to have extracted control rules that were not just domain specific but generalized across a wide range of optimization domains.\""}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MCBoost", "Title": "Multiple Classifier Boosting for Perceptual Co-clustering of Images and Visual Features", "Abstract": "We present a new co-clustering problem of images and visual features. The problem involves a set of non-object images in addition to a set of object images and features to be co-clustered. Co-clustering is performed in a way of maximising discrimination of object images from non-object images, thus emphasizing discriminative features. This provides a way of obtaining perceptual joint-clusters of object images and features. We tackle the problem by simultaneously boosting multiple strong classifiers which compete for images by their expertise. Each boosting classifier is an aggregation of weak-learners, i.e. simple visual features. The obtained classifiers are useful for multi-category and multi-view object detection tasks. Experiments on a set of pedestrian images and a face data set demonstrate that the method yields intuitive image clusters with associated features and is much superior to conventional boosting classifiers in object detection tasks."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dynamic visual attention", "Title": "searching for coding length increments", "Abstract": "A visual attention system should respond placidly when common stimuli are presented, while at the same time keep alert to anomalous visual inputs. In this paper, a dynamic visual attention model based on the rarity of features is proposed. We introduce the Incremental Coding Length (ICL) to measure the perspective entropy gain of each feature. The objective of our model is to maximize the entropy of the sampled visual features. In order to optimize energy consumption, the limit amount of energy of the system is re-distributed amongst features according to their Incremental Coding Length. By selecting features with large coding length increments, the computational system can achieve attention selectivity in both static and dynamic scenes. We demonstrate that the proposed model achieves superior accuracy in comparison to mainstream approaches in static saliency map generation. Moreover, we also show that our model captures several less-reported dynamic visual search behaviors, such as attentional swing and inhibition of return."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mind the Duality Gap", "Title": "Logarithmic regret algorithms for online optimization", "Abstract": "We describe a primal-dual framework for the design and analysis of online strongly convex optimization algorithms. Our framework yields the tightest known logarithmic regret bounds for Follow-The-Leader and for the gradient descent algorithm proposed in HazanKaKaAg06. We then show that one can interpolate between these two extreme cases. In particular, we derive a new algorithm that shares the computational simplicity of gradient descent but achieves lower regret in many practical situations. Finally, we further extend our framework for generalized strongly convex functions."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Measures of Clustering Quality", "Title": "A Working Set of Axioms for Clustering", "Abstract": "Aiming towards the development of a general clustering theory, we discuss abstract axiomatization for clustering. In this respect, we follow up on the work of Kelinberg, (Kleinberg) that showed an impossibility result for such axiomatization. We argue that an impossibility result is not an inherent feature of clustering, but rather, to a large extent, it is an artifact of the specific formalism used in Kleinberg. As opposed to previous work focusing on clustering functions, we propose to address clustering quality measures as the primitive object to be axiomatized. We show that principles like those formulated in Kleinberg's axioms can be readily expressed in the latter framework without leading to inconsistency. A clustering-quality measure is a function that, given a data set and its partition into clusters, returns a non-negative real number representing how strong' orconclusive' the clustering is. We analyze what clustering-quality measures should look like and introduce a set of requirements (`axioms') that express these requirement and extend the translation of Kleinberg's axioms to our framework. We propose several natural clustering quality measures, all satisfying the proposed axioms. In addition, we show that the proposed clustering quality can be computed in polynomial time."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimal Response Initiation", "Title": "Why Recent Experience Matters", "Abstract": "In most cognitive and motor tasks, speed-accuracy tradeoffs are observed: Individuals can respond slowly and accurately, or quickly yet be prone to errors. Control mechanisms governing the initiation of behavioral responses are sensitive not only to task instructions and the stimulus being processed, but also to the recent stimulus history. When stimuli can be characterized on an easy-hard dimension (e.g., word frequency in a naming task), items preceded by easy trials are responded to more quickly, and with more errors, than items preceded by hard trials. We propose a rationally motivated mathematical model of this sequential adaptation of control, based on a diffusion model of the decision process in which difficulty corresponds to the drift rate for the correct response. The model assumes that responding is based on the posterior distribution over which response is correct, conditioned on the accumulated evidence. We derive this posterior as a function of the drift rate, and show that higher estimates of the drift rate lead to (normatively) faster responding. Trial-by-trial tracking of difficulty thus leads to sequential effects in speed and accuracy. Simulations show the model explains a variety of phenomena in human speeded decision making. We argue this passive statistical mechanism provides a more elegant and parsimonious account than extant theories based on elaborate control structures."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Overlaying classifiers", "Title": "a practical approach for optimal ranking", "Abstract": "ROC curves are one of the most widely used displays to evaluate performance of scoring functions. In the paper, we propose a statistical method for directly optimizing the ROC curve. The target is known to be the regression function up to an increasing transformation and this boils down to recovering the level sets of the latter. We propose to use classifiers obtained by empirical risk minimization of a weighted classification error and then to construct a scoring rule by overlaying these classifiers. We show the consistency and rate of convergence to the optimal ROC curve of this procedure in terms of supremum norm and also, as a byproduct of the analysis, we derive an empirical estimate of the optimal ROC curve."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Psychiatry", "Title": "Insights into depression through normative decision-making models", "Abstract": "∗qhuys@cantab.net, joshuav@jhu.edu, dayan@gatsby.ucl.ac.uk; www.gatsby.ucl.ac.uk/∼qhuys/pub.html"}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Finding Latent Causes in Causal Networks", "Title": "an Efficient Approach Based on Markov Blankets", "Abstract": "Causal structure-discovery techniques usually assume that all causes of more than one variable are observed. This is the so-called causal sufficiency assumption. In practice, it is untestable, and often violated. In this paper, we present an efficient causal structure-learning algorithm, suited for causally insufficient data. Similar to algorithms such as IC* and FCI, the proposed approach drops the causal sufficiency assumption and learns a structure that indicates (potential) latent causes for pairs of observed variables. Assuming a constant local density of the data-generating graph, our algorithm makes a quadratic number of conditional-independence tests w.r.t. the number of variables. We show with experiments that our algorithm is comparable to the state-of-the-art FCI algorithm in accuracy, while being several orders of magnitude faster on large problems. We conclude that MBCS* makes a new range of causally insufficient problems computationally tractable."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Goal-directed decision making in prefrontal cortex", "Title": "a computational framework", "Abstract": "Research in animal learning and behavioral neuroscience has distinguished between two forms of action control: a habit-based form, which relies on stored action values, and a goal-directed form, which forecasts and compares action outcomes based on a model of the environment. While habit-based control has been the subject of extensive computational research, the computational principles underlying goal-directed control in animals have so far received less attention. In the present paper, we advance a computational framework for goal-directed control in animals and humans. We take three empirically motivated points as founding premises: (1) Neurons in dorsolateral prefrontal cortex represent action policies, (2) Neurons in orbitofrontal cortex represent rewards, and (3) Neural computation, across domains, can be appropriately understood as performing structured probabilistic inference. On a purely computational level, the resulting account relates closely to previous work using Bayesian inference to solve Markov decision problems, but extends this work by introducing a new algorithm, which provably converges on optimal plans. On a cognitive and neuroscientific level, the theory provides a unifying framework for several different forms of goal-directed action selection, placing emphasis on a novel form, within which orbitofrontal reward representations directly drive policy selection."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning the Semantic Correlation", "Title": "An Alternative Way to Gain from Unlabeled Text", "Abstract": "In this paper, we address the question of what kind of knowledge is generally transferable from unlabeled text. We suggest and analyze the semantic correlation of words as a generally transferable structure of the language and propose a new method to learn this structure using an appropriately chosen latent variable model. This semantic correlation contains structural information of the language space and can be used to control the joint shrinkage of model parameters for any specific task in the same space through regularization. In an empirical study, we construct 190 different text classification tasks from a real-world benchmark, and the unlabeled documents are a mixture from all these tasks. We test the ability of various algorithms to use the mixed unlabeled text to enhance all classification tasks. Empirical results show that the proposed approach is a reliable and scalable method for semi-supervised learning, regardless of the source of unlabeled data, the specific task to be enhanced, and the prediction model used."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Design of Loss Functions for Classification", "Title": "theory, robustness to outliers, and SavageBoost", "Abstract": "The machine learning problem of classifier design is studied from the perspective of probability elicitation, in statistics. This shows that the standard approach of proceeding from the specification of a loss, to the minimization of conditional risk is overly restrictive. It is shown that a better alternative is to start from the specification of a functional form for the minimum conditional risk, and derive the loss function. This has various consequences of practical interest, such as showing that 1) the widely adopted practice of relying on convex loss functions is unnecessary, and 2) many new losses can be derived for classification problems. These points are illustrated by the derivation of a new loss which is not convex, but does not compromise the computational tractability of classifier design, and is robust to the contamination of data with outliers. A new boosting algorithm, SavageBoost, is derived for the minimization of this loss. Experimental results show that it is indeed less sensitive to outliers than conventional methods, such as Ada, Real, or LogitBoost, and converges in fewer iterations."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Clustered Multi-Task Learning", "Title": "A Convex Formulation", "Abstract": "In multi-task learning several related tasks are considered simultaneously, with the hope that by an appropriate sharing of information across tasks, each task may benefit from the others. In the context of learning linear functions for supervised classification or regression, this can be achieved by including a priori information about the weight vectors associated with the tasks, and how they are expected to be related to each other. In this paper, we assume that tasks are clustered into groups, which are unknown beforehand, and that tasks within a group have similar weight vectors. We design a new spectral norm that encodes this a priori assumption, without the prior knowledge of the partition of tasks into groups, resulting in a new convex optimization formulation for multi-task learning. We show in simulations on synthetic examples and on the iedb MHC-I binding dataset, that our approach outperforms well-known convex methods for multi-task learning, as well as related non convex methods dedicated to the same problem."}
{"Type": "conference", "Year": "2008", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One sketch for all", "Title": "Theory and Application of Conditional Random Sampling", "Abstract": "Conditional Random Sampling (CRS) was originally proposed for efficiently computing pairwise ($l_2$, $l_1$) distances, in static, large-scale, and sparse data sets such as text and Web data. It was previously presented using a heuristic argument. This study extends CRS to handle dynamic or streaming data, which much better reflect the real-world situation than assuming static data. Compared with other known sketching algorithms for dimension reductions such as stable random projections, CRS exhibits a significant advantage in that it is ``one-sketch-for-all.'' In particular, we demonstrate that CRS can be applied to efficiently compute the $l_p$ distance and the Hilbertian metrics, both are popular in machine learning. Although a fully rigorous analysis of CRS is difficult, we prove that, with a simple modification, CRS is rigorous at least for an important application of computing Hamming norms. A generic estimator and an approximate variance formula are provided and tested on various applications, for computing Hamming norms, Hamming distances, and $\\chi^2$ distances."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DUOL", "Title": "A Double Updating Approach for Online Learning", "Abstract": "In most online learning algorithms, the weights assigned to the misclassified examples (or support vectors) remain unchanged during the entire learning process. This is clearly insufficient since when a new misclassified example is added to the pool of support vectors, we generally expect it to affect the weights for the existing support vectors. In this paper, we propose a new online learning method, termed Double Updating Online Learning\", or \"DUOL\" for short. Instead of only assigning a fixed weight to the misclassified example received in current trial, the proposed online learning algorithm also tries to update the weight for one of the existing support vectors. We show that the mistake bound can be significantly improved by the proposed online learning method. Encouraging experimental results show that the proposed technique is in general considerably more effective than the state-of-the-art online learning algorithms.\""}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking LDA", "Title": "Why Priors Matter", "Abstract": "Implementations of topic models typically use symmetric Dirichlet priors with fixed concentration parameters, with the implicit assumption that such smoothing parameters\" have little practical effect. In this paper, we explore several classes of structured priors for topic models. We find that an asymmetric Dirichlet prior over the document-topic distributions has substantial advantages over a symmetric prior, while an asymmetric prior over the topic-word distributions provides no real benefit. Approximation of this prior structure through simple, efficient hyperparameter optimization steps is sufficient to achieve these performance gains. The prior structure we advocate substantially increases the robustness of topic models to variations in the number of topics and to the highly skewed word frequency distributions common in natural language. Since this prior structure can be implemented using efficient algorithms that add negligible cost beyond standard inference techniques, we recommend it as a new standard for topic modeling.\""}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Augmenting Feature-driven fMRI Analyses", "Title": "Semi-supervised learning and resting state activity", "Abstract": "Resting state activity is brain activation that arises in the absence of any task, and is usually measured in awake subjects during prolonged fMRI scanning sessions where the only instruction given is to close the eyes and do nothing.  It has been recognized in recent years that resting state activity is implicated in a wide variety of brain function.  While certain networks of brain areas have different levels of activation at rest and during a task, there is nevertheless significant similarity between activations in the two cases.  This suggests that recordings of resting state activity can be used as a source of unlabeled data to augment discriminative regression techniques in a semi-supervised setting.  We evaluate this setting empirically yielding three main results: (i) regression tends to be improved by the use of Laplacian regularization even when no additional unlabeled data are available, (ii) resting state data may have a similar marginal distribution to that recorded during the execution of a visual processing task reinforcing the hypothesis that these conditions have similar types of activation, and (iii) this source of information can be broadly exploited to improve the robustness of empirical inference in fMRI studies, an inherently data poor domain."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Who’s Doing What", "Title": "Joint Modeling of Names and Verbs for Simultaneous Face and Pose Annotation", "Abstract": "Given a corpus of news items consisting of images accompanied by text captions, we want to find out `whos doing what, i.e. associate names and action verbs in the captions to the face and body pose of the persons in the images. We present a joint model for simultaneously solving the image-caption correspondences and learning visual appearance models for the face and pose classes occurring in the corpus. These models can then be used to recognize people and actions in novel images without captions. We demonstrate experimentally that our jointface and pose model solves the correspondence problem better than earlier models covering only the face, and that it can perform recognition of new uncaptioned images."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Large Scale Nonparametric Bayesian Inference", "Title": "Data Parallelisation in the Indian Buffet Process", "Abstract": "Nonparametric Bayesian models provide a framework for flexible probabilistic modelling of complex datasets. Unfortunately, Bayesian inference methods often require high-dimensional averages and can be slow to compute, especially with the potentially unbounded representations associated with nonparametric models. We address the challenge of scaling nonparametric Bayesian inference to the increasingly large datasets found in real-world applications, focusing on the case of parallelising inference in the Indian Buffet Process (IBP).  Our approach divides a large data set between multiple processors.  The processors use message passing to compute likelihoods in an asynchronous, distributed fashion and to propagate statistics about the global Bayesian posterior.  This novel MCMC sampler is the first parallel inference scheme for IBP-based models, scaling to datasets orders of magnitude larger than had previously been possible."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Replicated Softmax", "Title": "an Undirected Topic Model", "Abstract": "We show how to model documents as bags of words using family of two-layer, undirected graphical models. Each member of the family has the same number of binary hidden units but a different number of ``softmax visible units. All of the softmax units in all of the models in the family share the same weights to the binary hidden units. We describe efficient inference and learning procedures for such a family. Each member of the family models the probability distribution of documents of a specific length as a product of topic-specific distributions rather than as a mixture and this gives much better generalization than Latent Dirichlet Allocation for modeling the log probabilities of held-out documents. The low-dimensional topic vectors learned by the undirected family are also much better than LDA topic vectors for retrieving documents that are similar to a query document. The learned topics are more general than those found by LDA because precision is achieved by intersecting many general topics rather than by selecting a single precise topic to generate each word."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Help or Hinder", "Title": "Bayesian Models of Social Goal Inference", "Abstract": "Everyday social interactions are heavily influenced by our snap judgments about others goals.  Even young infants can infer the goals of intentional agents from observing how they interact with objects and other agents in their environment: e.g., that one agent is helping orhindering anothers attempt to get up a hill or open a box. We propose a model for how people can infer these social goals from actions, based on inverse planning in multiagent Markov decision problems (MDPs).  The model infers the goal most likely to be driving an agents behavior by assuming the agent acts approximately rationally given environmental constraints and its model of other agents present.  We also present behavioral evidence in support of this model over a simpler, perceptual cue-based alternative."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Statistical Analysis of Semi-Supervised Learning", "Title": "The Limit of Infinite Unlabelled Data", "Abstract": "We study the behavior of the popular Laplacian Regularization method for Semi-Supervised Learning at the regime of a fixed number of labeled points but a large number of unlabeled points.  We show that in $\\R^d$, $d \\geq 2$, the method is actually not well-posed, and as the number of unlabeled points increases the solution degenerates to a noninformative function.  We also contrast the method with the Laplacian Eigenvector method, and discuss the ``smoothness assumptions associated with this alternate method."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predicting the Optimal Spacing of Study", "Title": "A Multiscale Context Model of Memory", "Abstract": "When individuals learn facts (e.g., foreign language vocabulary) over multiple study sessions, the temporal spacing of study has a significant impact on memory retention.  Behavioral experiments have shown a nonmonotonic relationship between spacing and retention:  short or long intervals between study sessions yield lower cued-recall accuracy than intermediate intervals.  Appropriate spacing of study can double retention on educationally relevant time scales.  We introduce a Multiscale Context Model (MCM) that is able to predict the influence of a particular study schedule on retention for specific material.  MCMs prediction is based on empirical data characterizing forgetting of the material following a single study session.  MCM is a synthesis of two existing memory models (Staddon, Chelaru, & Higa, 2002; Raaijmakers, 2003).  On the surface, these  models are unrelated and incompatible, but we show they share a core feature  that allows them to be integrated.  MCM can determine study schedules that  maximize the durability of learning, and has implications for education  and training.  MCM can be cast either as a neural network with inputs that  fluctuate over time, or as a cascade of leaky integrators.  MCM is  intriguingly similar to a Bayesian multiscale model of memory (Kording, Tenenbaum, Shadmehr, 2007), yet MCM is better able to account for human  declarative memory."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dirichlet-Bernoulli Alignment", "Title": "A Generative Model for Multi-Class Multi-Label Multi-Instance Corpora", "Abstract": "We propose Dirichlet-Bernoulli Alignment (DBA), a generative model for corpora in which each pattern (e.g., a document) contains a set of instances (e.g., paragraphs in the document) and belongs to multiple classes. By casting predefined classes as latent Dirichlet variables (i.e., instance level labels), and modeling the multi-label of each pattern as Bernoulli variables conditioned on the weighted empirical average of topic assignments, DBA automatically aligns the latent topics discovered from data to human-defined classes. DBA is useful for both pattern classification and instance disambiguation, which are tested on text classification and named entity disambiguation for web search queries respectively."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FACTORIE", "Title": "Probabilistic Programming via Imperatively Defined Factor Graphs", "Abstract": "Discriminatively trained undirected graphical models have had wide empirical success, and there has been increasing interest in toolkits that ease their application to complex relational data.  The power in relational models is in their repeated structure and tied parameters; at issue is how to define these structures in a powerful and flexible way. Rather than using a declarative language, such as SQL or first-order logic, we advocate using an imperative language to express various aspects of model structure, inference, and learning.  By combining the traditional, declarative, statistical semantics of factor graphs with imperative definitions of their construction and operation, we allow the user to mix declarative and procedural domain knowledge, and also gain significant efficiencies.  We have implemented such imperatively defined factor graphs in a system we call Factorie, a software library for an object-oriented, strongly-typed, functional language.  In experimental comparisons to Markov Logic Networks on joint segmentation and coreference, we find our approach to be 3-15 times faster while reducing error by 20-25%-achieving a new state of the art."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Orthogonal Matching Pursuit From Noisy Random Measurements", "Title": "A New Analysis", "Abstract": "Orthogonal matching pursuit (OMP) is a widely used greedy algorithm for recovering sparse vectors from linear measurements.  A well-known analysis of Tropp and Gilbert shows that OMP can recover a k-sparse n-dimensional real vector from m = 4k log(n) noise-free random linear measurements with a probability that goes to one as n goes to infinity. This work shows strengthens this result by showing that a lower number of measurements, m = 2k log(n-k), is in fact sufficient for asymptotic recovery. Moreover, this number of measurements is also sufficient for detection of the sparsity pattern (support) of the vector with measurement errors provided the signal-to-noise ratio (SNR) scales to infinity. The scaling m = 2k log(n-k) exactly matches the number of measurements required by the more complex lasso for signal recovery."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Categories", "Title": "The Visual Memex Model for Reasoning About Object Relationships", "Abstract": "The use of context is critical for scene understanding in computer vision, where the recognition of an object is driven by both local appearance and the objects relationship to other elements of the scene (context).  Most current approaches rely on modeling the relationships between object categories as a source of context. In this paper we seek to move beyond categories to provide a richer appearance-based model of context.  We present an exemplar-based model of objects and their relationships, the Visual Memex, that encodes both local appearance and 2D spatial context between object instances. We evaluate our model on Torralbas proposed Context Challenge against a baseline category-based system. Our experiments suggest that moving beyond categories for context modeling appears to be quite beneficial, and may be the critical missing ingredient in scene understanding systems."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularized Distance Metric Learning", "Title": "Theory and Algorithm", "Abstract": "In this paper, we examine the generalization error of regularized distance metric learning. We show that with appropriate constraints, the generalization error of regularized distance metric learning could be independent from the dimensionality, making it suitable for handling high dimensional data. In addition, we present an efficient online learning algorithm for regularized distance metric learning. Our empirical studies with data classification and face recognition show that the proposed algorithm is (i) effective for distance metric learning when compared to the state-of-the-art methods, and (ii) efficient and robust for high dimensional data."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust Principal Component Analysis", "Title": "Exact Recovery of Corrupted Low-Rank Matrices via Convex Optimization", "Abstract": "Principal component analysis is a fundamental operation in computational data analysis, with myriad applications ranging from web search to bioinformatics to computer vision and image analysis. However, its performance and applicability in real scenarios are limited by a lack of robustness to outlying or corrupted observations. This paper considers the idealized “robust principal component analysis” problem of recovering a low rank matrix A from corrupted observations D = A + E. Here, the error entries E can be arbitrarily large (modeling grossly corrupted observations common in visual and bioinformatic data), but are assumed to be sparse. We prove that most matrices A can be efficiently and exactly recovered from most error sign-and-support patterns, by solving a simple convex program. Our result holds even when the rank of A grows nearly proportionally (up to a logarithmic factor) to the dimensionality of the observation space and the number of errors E grows in proportion to the total number of entries in the matrix. A by-product of our analysis is the first proportional growth results for the related problem of completing a low-rank matrix from a small fraction of its entries. Simulations and real-data examples corroborate the theoretical results, and suggest potential applications in computer vision."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from Neighboring Strokes", "Title": "Combining Appearance and Context for Multi-Domain Sketch Recognition", "Abstract": "We propose a new sketch recognition framework that combines a rich representation of low level visual appearance with a graphical model for capturing high level relationships between symbols. This joint model of appearance and context allows our framework to be less sensitive to noise and drawing variations, improving accuracy and robustness. The result is a recognizer that is better able to handle the wide range of drawing styles found in messy freehand sketches. We evaluate our work on two real-world domains, molecular diagrams and electrical circuit diagrams, and show that our combined approach significantly improves recognition performance."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rank-Approximate Nearest Neighbor Search", "Title": "Retaining Meaning and Speed in High Dimensions", "Abstract": "The long-standing problem of efficient nearest-neighbor (NN) search has ubiquitous applications ranging from astrophysics to MP3 fingerprinting to bioinformatics to movie recommendations.  As the dimensionality of the dataset increases, exact NN search becomes computationally prohibitive; (1+eps)-distance-approximate NN search can provide large speedups but risks losing the meaning of NN search present in the ranks (ordering) of the distances. This paper presents a simple, practical algorithm allowing the user to, for the first time, directly control the true accuracy of NN search (in terms of ranks) while still achieving the large speedups over exact NN.  Experiments with high-dimensional datasets show that it often achieves faster and more accurate results than the best-known distance-approximate method, with much more stable behavior."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Know Thy Neighbour", "Title": "A Normative Theory of Synaptic Depression", "Abstract": "Synapses exhibit an extraordinary degree of short-term malleability, with release probabilities and effective synaptic strengths changing markedly over multiple timescales. From the perspective of a fixed computational operation in a network, this seems like a most unacceptable degree of added noise. We suggest an alternative theory according to which short term synaptic plasticity plays a normatively-justifiable role. This theory starts from the commonplace observation that the spiking of a neuron is an incomplete, digital, report of the analog quantity that contains all the critical information, namely its membrane potential. We suggest that one key task for a synapse is to solve the inverse problem of estimating the pre-synaptic membrane potential from the spikes it receives and prior  expectations, as in a recursive filter. We show that short-term synaptic depression has canonical dynamics which closely resemble those required for optimal estimation, and that it indeed supports high quality estimation. Under this account, the local postsynaptic potential and the level of synaptic resources track the (scaled) mean and variance of the estimated presynaptic membrane potential. We make  experimentally testable predictions for how the statistics of subthreshold membrane potential fluctuations and the form of spiking non-linearity should be related to the properties of short-term plasticity in any particular cell type."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Randomized Pruning", "Title": "Efficiently Calculating Expectations in Large Dynamic Programs", "Abstract": "Pruning can massively accelerate the computation of feature expectations in large models.  However, any single pruning mask will introduce bias.  We present a novel approach which employs a randomized sequence of pruning masks. Formally, we apply auxiliary variable MCMC sampling to generate this sequence of masks, thereby gaining theoretical guarantees about convergence. Because each mask is generally able to skip large portions of an underlying dynamic program, our approach is particularly compelling for high-degree algorithms.  Empirically, we demonstrate our method on bilingual parsing, showing decreasing bias as more masks are incorporated, and outperforming fixed tic-tac-toe pruning."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Local Rules for Global MAP", "Title": "When Do They Work ?", "Abstract": "We consider the question of computing Maximum A Posteriori (MAP) assignment in an arbitrary pair-wise Markov Random Field (MRF). We present a randomized iterative algorithm based on simple local updates. The algorithm, starting with an arbitrary initial assignment, updates it in each iteration by first, picking a random node, then selecting an (appropriately chosen) random local neighborhood and optimizing over this local neighborhood. Somewhat surprisingly, we show that this algorithm finds a near optimal assignment within $2n\\ln n$ iterations on average and with high probability for {\\em any} $n$ node pair-wise MRF with {\\em geometry} (i.e. MRF graph with polynomial growth) with the approximation error depending on (in a reasonable manner) the geometric growth rate of the graph and the average radius of the local neighborhood -- this allows for a graceful tradeoff between the complexity of the algorithm and the approximation error. Through extensive simulations, we show that our algorithm finds extremely good approximate solutions for various kinds of MRFs with geometry."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Convexity", "Title": "Online Submodular Minimization", "Abstract": "We consider an online decision problem over a discrete space in which the loss function is submodular. We give algorithms which are computationally efficient and are Hannan-consistent in both the full information and bandit settings."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Whose Vote Should Count More", "Title": "Optimal Integration of Labels from Labelers of Unknown Expertise", "Abstract": "Modern machine learning-based approaches to computer vision require very large databases of labeled images. Some contemporary vision systems already require on the order of millions of images for training (e.g., Omron face detector). While the collection of these large databases is becoming a bottleneck, new Internet-based services that allow labelers from around the world to be easily hired and managed provide a promising solution.  However, using these services to label large databases brings with it new theoretical and practical challenges: (1) The labelers may have wide ranging levels of expertise which are unknown a priori, and in some cases may be adversarial; (2) images may vary in their level of difficulty; and (3) multiple labels for the same image must be combined to provide an estimate of the actual label of the image. Probabilistic approaches provide a principled way to approach these problems. In this paper we present a probabilistic model and use it to simultaneously infer the label of each image, the expertise of each labeler, and the difficulty of each image. On both simulated and real data, we demonstrate that the model outperforms the commonly used ``Majority Vote heuristic for inferring image labels, and is robust to both adversarial and noisy labelers."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reading Tea Leaves", "Title": "How Humans Interpret Topic Models", "Abstract": "Probabilistic topic models are a popular tool for the unsupervised analysis of text, providing both a predictive model of future text and a latent topic representation of the corpus. Practitioners typically assume that the latent space is semantically meaningful. It is used to check models, summarize the corpus, and guide exploration of its contents. However, whether the latent space is interpretable is in need of quantitative evaluation. In this paper, we present new quantitative methods for measuring semantic meaning in inferred topics. We back these measures with large-scale user studies, showing that they capture aspects of the model that are undetected by previous measures of model quality based on held-out likelihood. Surprisingly, topic models which perform better on held-out likelihood may infer less semantically meaningful topics."}
{"Type": "conference", "Year": "2009", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Complexity of Decentralized Control", "Title": "Special Cases", "Abstract": "The worst-case complexity of general decentralized POMDPs, which are equivalent to partially observable stochastic games (POSGs) is very high, both for the cooperative and competitive cases.  Some reductions in complexity have been achieved by exploiting independence relations in some models.  We show that these results are somewhat limited:  when these independence assumptions are relaxed in very small ways, complexity returns to that of the general case."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Relaxed Clipping", "Title": "A Global Training Method for Robust Regression and Classification", "Abstract": "Robust regression and classification are often thought to require non-convex loss functions that prevent scalable, global training. However, such a view neglects the possibility of reformulated training methods that can yield practically solvable alternatives. A natural way to make a loss function more robust to outliers is to truncate loss values that exceed a maximum threshold. We demonstrate that a relaxation of this form of ``loss clipping'' can be made globally solvable and applicable to any standard loss while guaranteeing robustness against outliers. We present a generic procedure that can be applied to standard loss functions and demonstrate improved robustness in regression and classification problems."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Transduction with Matrix Completion", "Title": "Three Birds with One Stone", "Abstract": "We pose transductive classification as a matrix completion problem. By assuming the underlying matrix has a low rank, our formulation is able to handle three problems simultaneously: i) multi-label learning, where each item has more than one label, ii) transduction, where most of these labels are unspecified, and iii) missing data, where a large number of features are missing. We obtained satisfactory results on several real-world tasks, suggesting that the low rank assumption may not be as restrictive as it seems. Our method allows for different loss functions to apply on the feature and label entries of the matrix. The resulting nuclear norm minimization problem is solved with a modified fixed-point continuation method that is guaranteed to find the global optimum."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Getting lost in space", "Title": "Large sample analysis of the resistance distance", "Abstract": "The commute distance between two vertices in a graph is the expected   time it takes a random walk to travel from the first to the second   vertex and back. We study the behavior of the commute distance as the size of the underlying graph   increases. We prove that the commute distance converges to an   expression that does not take into account the structure of the   graph at all and that is completely meaningless as a distance   function on the graph. Consequently, the use of the raw commute   distance for machine learning purposes is strongly discouraged for   large graphs and in high dimensions. As an alternative we introduce   the amplified commute distance that corrects for   the undesired large sample effects."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Object Bank", "Title": "A High-Level Image Representation for Scene Classification & Semantic Feature Sparsification", "Abstract": "Robust low-level image features have been proven to be effective representations for a variety of visual recognition tasks such as object recognition and scene classification; but pixels, or even local image patches, carry little semantic meanings. For high level visual tasks, such low-level image representations are potentially not enough. In this paper, we propose a high-level image representation, called the Object Bank, where an image is represented as a scale invariant response map of a large number of pre-trained generic object detectors, blind to the testing dataset or visual task. Leveraging on the Object Bank representation, superior performances on high level visual recognition tasks can be achieved with simple off-the-shelf classifiers such as logistic regression and linear SVM. Sparsity algorithms make our representation more efficient and scalable for large scene datasets, and reveal semantically meaningful feature patterns."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Size Matters", "Title": "Metric Visual Search Constraints from Monocular Metadata", "Abstract": "Metric constraints are known to be highly discriminative for many objects, but if training is limited to data captured from a particular 3-D sensor the quantity of training data may be severly limited. In this paper, we show how a crucial aspect of 3-D information–object and feature absolute size–can be added to models learned from commonly available online imagery, without use of any 3-D sensing or re- construction at training time. Such models can be utilized at test time together with explicit 3-D sensing to perform robust search. Our model uses a “2.1D” local feature, which combines traditional appearance gradient statistics with an estimate of average absolute depth within the local window. We show how category size information can be obtained from online images by exploiting relatively unbiquitous metadata fields specifying camera intrinstics. We develop an efficient metric branch-and-bound algorithm for our search task, imposing 3-D size constraints as part of an optimal search for a set of features which indicate the presence of a category. Experiments on test scenes captured with a traditional stereo rig are shown, exploiting training data from from purely monocular sources with associated EXIF metadata."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Feature Transitions with Saccadic Search", "Title": "Size, Color, and Orientation Are Not Alike", "Abstract": "Size, color, and orientation have long been considered elementary features whose attributes are extracted in parallel and available to guide the deployment of attention. If each is processed in the same fashion with simply a different set of local detectors, one would expect similar search behaviours on localizing an equivalent flickering change among identically laid out disks. We analyze feature transitions associated with saccadic search and find out that size, color, and orientation are not alike in dynamic attribute processing over time. The Markovian feature transition is attractive for size, repulsive for color, and largely reversible for orientation."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Actions", "Title": "Discriminative Models for Contextual Group Activities", "Abstract": "We propose a discriminative model for recognizing group activities. Our model jointly captures the group activity, the individual person actions, and the interactions among them. Two new types of contextual information, group-person interaction and person-person interaction, are explored in a latent variable framework. Different from most of the previous latent structured models which assume a predefined structure for the hidden layer, e.g. a tree structure, we treat the structure of the hidden layer as a latent variable and implicitly infer it during learning and inference. Our experimental results demonstrate that by inferring this contextual information together with adaptive structures, the proposed model can significantly improve activity recognition performance."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "More data means less inference", "Title": "A pseudo-max approach to structured learning", "Abstract": "The problem of learning to predict structured labels is of key importance in many applications. However, for general graph structure both learning and inference in this setting are intractable. Here we show that it is possible to circumvent this difficulty when the input distribution is rich enough via a method similar in spirit to pseudo-likelihood. We show how our new method achieves consistency, and illustrate empirically that it indeed performs as well as exact methods when sufficiently large training sets are used."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Lifted Inference Seen from the Other Side ", "Title": "The Tractable Features", "Abstract": "Lifted inference algorithms for representations that combine first-order logic and probabilistic graphical models have been the focus of much recent research. All lifted algorithms developed to date are based on the same underlying idea: take a standard probabilistic inference algorithm (e.g., variable elimination, belief propagation etc.) and improve its efficiency by exploiting repeated structure in the first-order model. In this paper, we propose an approach from the other side in that we use techniques from logic for probabilistic inference. In particular, we define a set of rules that look only at the logical representation to identify models for which exact efficient inference is possible. We show that our rules yield several new tractable classes that cannot be solved efficiently by any of the existing techniques."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Epitome driven 3-D Diffusion Tensor image segmentation", "Title": "on extracting specific structures", "Abstract": "We study the problem of segmenting specific white matter structures of interest from Diffusion Tensor (DT-MR) images of the human brain. This is an important requirement in many Neuroimaging studies: for instance, to evaluate whether a brain structure exhibits group level differences as a function of disease in a set of images. Typically, interactive expert guided segmentation has been the method of choice for such applications, but this is tedious for large datasets common today. To address this problem, we endow an image segmentation algorithm with 'advice' encoding some global characteristics of the region(s) we want to extract. This is accomplished by constructing (using expert-segmented images) an epitome of a specific region - as a histogram over a bag of 'words' (e.g.,suitable feature descriptors). Now, given such a representation, the problem reduces to segmenting new brain image with additional constraints that enforce consistency between the segmented foreground and the pre-specified histogram over features. We present combinatorial approximation algorithms to incorporate such domain specific constraints for Markov Random Field (MRF) segmentation. Making use of recent results on image co-segmentation, we derive effective solution strategies for our problem. We provide an analysis of solution quality, and present promising experimental evidence showing that many structures of interest in Neuroscience can be extracted reliably from 3-D brain image volumes using our algorithm."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Multi-Task Lasso", "Title": "with Application to eQTL Detection", "Abstract": "To understand the relationship between genomic variations among population and complex diseases, it is essential to detect eQTLs which are associated with phenotypic effects. However, detecting eQTLs remains a challenge due to complex underlying mechanisms and the very large number of genetic loci involved compared to the number of samples. Thus, to address the problem, it is desirable to take advantage of the structure of the data and prior information about genomic locations such as conservation scores and transcription factor binding sites.  In this paper, we propose a novel regularized regression approach for detecting eQTLs which takes into account related traits simultaneously while incorporating many regulatory features. We first present a Bayesian network for a multi-task learning problem that includes priors on SNPs, making it possible to estimate the significance of each covariate adaptively. Then we find the maximum a posteriori (MAP) estimation of regression coefficients and estimate weights of covariates jointly. This optimization procedure is efficient since it can be achieved by using convex optimization and a coordinate descent procedure iteratively. Experimental results on simulated and real yeast datasets confirm that our model outperforms previous methods for finding eQTLs."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Categories and Functional Units", "Title": "An Infinite Hierarchical Model for Brain Activations", "Abstract": "We present a model that describes the structure in the responses of different brain areas to a set of stimuli in terms of stimulus categories\" (clusters of stimuli) and \"functional units\" (clusters of voxels). We assume that voxels within a unit respond similarly to all stimuli from the same category, and design a nonparametric hierarchical model to capture inter-subject variability among the units. The model explicitly captures the relationship between brain activations and fMRI time courses. A variational inference algorithm derived based on the model can learn categories, units, and a set of unit-category activation probabilities from data. When applied to data from an fMRI study of object recognition, the method finds meaningful and consistent clusterings of stimuli into categories and voxels into units.\""}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Collaborative Filtering in a Non-Uniform World", "Title": "Learning with the Weighted Trace Norm", "Abstract": "We show that matrix completion with trace-norm regularization can be significantly hurt when entries of the matrix are sampled non-uniformly, but that a properly weighted version of the trace-norm regularizer works well with non-uniform sampling. We show that the weighted trace-norm regularization indeed yields significant gains on the highly non-uniformly sampled Netflix dataset."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sodium entry efficiency during action potentials", "Title": "A novel single-parameter family of Hodgkin-Huxley models", "Abstract": "Sodium entry during an action potential determines the energy efficiency of a neuron. The classic Hodgkin-Huxley model of action potential generation is notoriously inefficient in that regard with about 4 times more charges flowing through the membrane than the theoretical minimum required to achieve the observed depolarization. Yet, recent experimental results show that mammalian neurons are close to the optimal metabolic efficiency and that the dynamics of their voltage-gated channels is significantly different than the one exhibited by the classic Hodgkin-Huxley model during the action potential. Nevertheless, the original Hodgkin-Huxley model is still widely used and rarely to model the squid giant axon from which it was extracted. Here, we introduce a novel family of Hodgkin-Huxley models that correctly account for sodium entry, action potential width and whose voltage-gated channels display a dynamics very similar to the most recent experimental observations in mammalian neurons. We speak here about a family of models because the model is parameterized by a unique parameter the variations of which allow to reproduce the entire range of experimental observations from cortical pyramidal neurons to Purkinje cells, yielding a very economical framework to model a wide range of different central neurons. The present paper demonstrates the performances and discuss the properties of this new family of models."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predictive Subspace Learning for Multi-view Data", "Title": "a Large Margin Approach", "Abstract": "Learning from multi-view data is important in many applications, such as image classification and annotation. In this paper, we present a large-margin learning framework to discover a predictive latent subspace representation shared by multiple views. Our approach is based on an undirected latent space Markov network that fulfills a weak conditional independence assumption that multi-view observations and response variables are independent given a set of latent variables. We provide efficient inference and parameter estimation methods for the latent subspace model. Finally, we demonstrate the advantages of large-margin learning on real video and web image data for discovering predictive latent representations and improving the performance on image classification, annotation and retrieval."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Exploiting weakly-labeled Web images to improve object classification", "Title": "a domain adaptation approach", "Abstract": "Most current image categorization methods require large collections of manually annotated training examples to learn accurate visual recognition models. The time-consuming human labeling effort effectively limits these approaches to recognition problems involving a small number of different object classes. In order to address this shortcoming, in recent years several authors have proposed to learn object classifiers from weakly-labeled Internet images, such as photos retrieved by keyword-based image search engines. While this strategy eliminates the need for human supervision, the recognition accuracies of these methods are considerably lower than those obtained with fully-supervised approaches, because of the noisy nature of the labels associated to Web data.  In this paper we investigate and compare methods that learn image classifiers by combining very few manually annotated examples (e.g., 1-10 images per class) and a large number of weakly-labeled Web photos retrieved using keyword-based image search. We cast this as a domain adaptation problem: given a few strongly-labeled examples in a target domain (the manually annotated examples) and many source domain examples (the weakly-labeled Web photos), learn classifiers yielding small generalization error on the target domain. Our experiments demonstrate that, for the same number of strongly-labeled examples, our domain adaptation approach produces significant recognition rate improvements over the best published results (e.g., 65% better when using 5 labeled training examples per class) and that our classifiers are one order of magnitude faster to learn and to evaluate than the best competing method, despite our use of large weakly-labeled data sets."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sphere Embedding", "Title": "An Application to Part-of-Speech Induction", "Abstract": "Motivated by an application to unsupervised part-of-speech tagging, we present an algorithm for the Euclidean embedding of large sets of categorical data based on co-occurrence statistics. We use the CODE model of Globerson et al. but constrain the embedding to lie on a high-dimensional unit sphere. This constraint allows for efficient optimization, even in the case of large datasets and high embedding dimensionality. Using k-means clustering of the embedded data, our approach efficiently produces state-of-the-art results. We analyze the reasons why the sphere constraint is beneficial in this application, and conjecture that these reasons might apply quite generally to other large-scale tasks."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deciphering subsampled data", "Title": "adaptive compressive sampling as a principle of brain communication", "Abstract": "A new algorithm is proposed for a) unsupervised learning of sparse representations from subsampled measurements and b) estimating the parameters required for linearly reconstructing signals from the sparse codes. We verify that the new algorithm performs efficient data compression on par with the recent method of compressive sampling. Further, we demonstrate that the algorithm performs robustly when stacked in several stages or when applied in undercomplete or overcomplete situations. The new algorithm can explain how neural populations in the brain that receive subsampled input through fiber bottlenecks are able to form coherent response properties."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structural epitome", "Title": "a way to summarize one’s visual experience", "Abstract": "In order to study the properties of total visual input in humans, a single subject wore a camera for two weeks capturing, on average, an image every 20 seconds (www.research.microsoft.com/~jojic/aihs). The resulting new dataset contains a mix of indoor and outdoor scenes as well as numerous foreground objects. Our first analysis goal is to create a visual summary of the subject’s two weeks of life using unsupervised algorithms that would automatically discover recurrent scenes, familiar faces or common actions. Direct application of existing algorithms, such as panoramic stitching (e.g.  Photosynth) or appearance-based clustering models (e.g. the epitome), is impractical due to either the large dataset size or the dramatic variation in the lighting conditions.    As a remedy to these problems, we introduce a novel image representation, the “stel epitome,” and an associated efficient learning algorithm. In our model, each image or image patch is characterized by a hidden mapping T, which, as in previous epitome models, defines a mapping between the image-coordinates and the coordinates in the large all-I-have-seen\" epitome matrix. The limited epitome real-estate forces the mappings of different images to overlap, with this overlap indicating image similarity. However, in our model the image similarity does not depend on direct pixel-to-pixel intensity/color/feature comparisons as in previous epitome models, but on spatial configuration of scene or object parts, as the model is based on the palette-invariant stel models. As a result, stel epitomes capture structure that is invariant to non-structural changes, such as illumination, that tend to uniformly affect pixels belonging to a single scene or object part.\""}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Parametric Bandits", "Title": "The Generalized Linear Case", "Abstract": "We consider structured multi-armed bandit tasks in which the agent is guided by prior structural knowledge that can be exploited to efficiently select the optimal arm(s) in situations where the number of arms is large, or even infinite. We pro- pose a new optimistic, UCB-like, algorithm for non-linearly parameterized bandit problems using the Generalized Linear Model (GLM) framework. We analyze the regret of the proposed algorithm, termed GLM-UCB, obtaining results similar to those recently proved in the literature for the linear regression case. The analysis also highlights a key difficulty of the non-linear case which is solved in GLM-UCB by focusing on the reward space rather than on the parameter space. Moreover, as the actual efficiency of current parameterized bandit algorithms is often deceiving in practice, we provide an asymptotic argument leading to significantly faster convergence. Simulation studies on real data sets illustrate the performance and the robustness of the proposed GLM-UCB approach."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hallucinations in Charles Bonnet Syndrome Induced by Homeostasis", "Title": "a Deep Boltzmann Machine Model", "Abstract": "The Charles Bonnet Syndrome (CBS) is characterized by complex vivid visual hallucinations in people with, primarily, eye diseases and no other neurological pathology. We present a Deep Boltzmann Machine model of CBS, exploring two core hypotheses: First, that the visual cortex learns a generative or predictive model of sensory input, thus explaining its capability to generate internal imagery. And second, that homeostatic mechanisms stabilize neuronal activity levels, leading to hallucinations being formed when input is lacking. We reproduce a variety of qualitative findings in CBS. We also introduce a modification to the DBM that allows us to model a possible role of acetylcholine in CBS as mediating the balance of feed-forward and feed-back processing. Our model might provide new insights into CBS and also demonstrates that generative frameworks are promising as hypothetical models of cortical learning and perception."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Brain covariance selection", "Title": "better individual functional connectivity models using population prior", "Abstract": "Spontaneous brain activity, as observed in functional neuroimaging, has been shown to display reproducible structure that expresses brain architecture and carries markers of brain pathologies. An important view of modern neuroscience is that such large-scale structure of coherent activity reflects modularity properties of brain connectivity graphs. However, to date, there has been no demonstration that the limited and noisy data available in spontaneous activity observations could be used to learn full-brain probabilistic models that generalize to new data.  Learning such models entails two main challenges:  i) modeling full brain connectivity is a difficult estimation problem that faces the curse of dimensionality and  ii) variability between subjects, coupled with the variability of functional signals between experimental runs, makes the use of multiple datasets challenging.  We describe subject-level brain functional connectivity structure as a multivariate Gaussian process and introduce a new strategy to estimate it from group data, by imposing a common structure on the graphical model in the population. We show that individual models learned from functional Magnetic Resonance Imaging (fMRI) data using this population prior generalize better to unseen data than models based on alternative regularization schemes. To our knowledge, this is the first report of a cross-validated model of spontaneous brain activity. Finally, we use the estimated graphical model to explore the large-scale characteristics of functional architecture and show for the first time that known cognitive networks appear as the integrated communities of functional connectivity graph."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Learning", "Title": "Random Averages, Combinatorial Parameters, and Learnability", "Abstract": "We develop a theory of online learning by defining several complexity measures. Among them are analogues of Rademacher complexity, covering numbers and fat-shattering dimension from statistical learning theory. Relationship among these complexity measures, their connection to online learning, and tools for bounding them are provided. We apply these results to various learning problems. We provide a complete characterization of online learnability in the supervised setting."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Towards Holistic Scene Understanding", "Title": "Feedback Enabled Cascaded Classification Models", "Abstract": "In many machine learning domains (such as scene understanding), several related sub-tasks (such as scene categorization, depth estimation, object detection) operate on the same raw data and provide correlated outputs. Each of these tasks is often notoriously hard, and state-of-the-art classifiers already exist for many sub-tasks. It is desirable to have an algorithm that can capture such correlation without requiring to make any changes to the inner workings of any classifier.  We propose Feedback Enabled Cascaded Classification Models (FE-CCM), that maximizes the joint likelihood of the sub-tasks, while requiring only a ‘black-box’ interface to the original classifier for each sub-task. We use a two-layer cascade of classifiers, which are repeated instantiations of the original ones, with the output of the first layer fed into the second layer as input. Our training method involves a feedback step that allows later classifiers to provide earlier classifiers information about what error modes to focus on. We show that our method significantly improves performance in all the sub-tasks in two different domains: (i) scene understanding, where we consider depth estimation, scene categorization, event categorization, object detection, geometric labeling and saliency detection, and (ii) robotic grasping, where we consider grasp point detection and object classification."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Divisive Normalization", "Title": "Justification and Effectiveness as Efficient Coding Transform", "Abstract": "Divisive normalization (DN) has been advocated as an effective nonlinear {\\em efficient coding} transform for natural sensory signals with applications in biology and engineering. In this work, we aim to establish a connection between the DN transform and the statistical properties of natural sensory signals. Our analysis is based on the use of multivariate {\\em t} model to capture some important statistical properties of natural sensory signals. The multivariate {\\em t} model justifies DN as an approximation to the transform that completely eliminates its statistical dependency. Furthermore, using the multivariate {\\em t} model and measuring statistical dependency with multi-information, we can precisely quantify the statistical dependency that is reduced by the DN transform. We compare this with the actual performance of the DN transform in reducing statistical dependencies of natural sensory signals. Our theoretical analysis and quantitative evaluations confirm DN as an effective efficient coding transform for natural sensory signals. On the other hand, we also observe a previously unreported phenomenon that DN may increase statistical dependencies when the size of pooling is small."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The LASSO risk", "Title": "asymptotic results and real world examples", "Abstract": "We consider the problem of learning a coefficient vector x0 from noisy linear observation y=Ax0+w. In many contexts (ranging from model selection to image processing) it is desirable to construct a sparse estimator. In this case, a popular approach consists in solving an l1-penalized least squares problem known as the LASSO or BPDN.  For sequences of matrices A of increasing dimensions, with iid gaussian entries, we prove that the normalized risk of the LASSO converges to a limit, and we obtain an explicit expression for this limit. Our result is the first rigorous derivation of an explicit formula for the asymptotic risk of the LASSO for random instances. The proof technique is based on the analysis of AMP, a recently developed efficient algorithm, that is inspired from graphical models ideas.   Through simulations on real data matrices (gene expression data and hospital medical records) we observe that these results can be relevant in a broad array of practical applications."}
{"Type": "conference", "Year": "2010", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-label Multiple Kernel Learning by Stochastic Approximation", "Title": "Application to Visual Object Recognition", "Abstract": "Recent studies have shown that multiple kernel learning is very effective for object recognition, leading to the popularity  of kernel learning in computer vision problems. In this work, we develop an efficient algorithm for multi-label multiple kernel learning (ML-MKL). We assume that all the classes under  consideration  share the same combination of kernel functions, and the objective is to find the optimal kernel combination that benefits all the classes. Although several algorithms have been developed for ML-MKL, their computational cost is linear in the number of classes, making them unscalable when the number of classes is large, a challenge  frequently  encountered in visual object recognition. We address this computational challenge by developing a framework for ML-MKL that combines the worst-case analysis with stochastic approximation. Our analysis shows that the complexity of our algorithm is $O(m^{1/3}\\sqrt{ln m})$, where $m$ is the number of classes. Empirical studies with object recognition show that while achieving similar classification accuracy, the proposed method is significantly more efficient than the state-of-the-art algorithms for ML-MKL."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Emergence of Multiplication in a Biophysical Model of a Wide-Field Visual Neuron for Computing Object Approaches", "Title": "Dynamics, Peaks, & Fits", "Abstract": "Many species show avoidance reactions in response to looming object approaches.  In locusts, the corresponding escape behavior correlates with the activity  of the lobula giant movement detector (LGMD) neuron.  During an object approach,  its firing rate was reported to gradually increase until a peak is reached,  and then it declines quickly.  The $\\eta$-function predicts that the LGMD activity  is a product between an exponential function of angular size $\\exp(-\\Theta)$ and  angular velocity $\\dot{\\Theta}$, and that peak activity is reached before time-to-contact  (ttc).  The $\\eta$-function has become the prevailing LGMD model because it  reproduces many experimental observations, and even experimental evidence for  the multiplicative operation was reported.  Several inconsistencies remain  unresolved, though.  Here we address these issues with a new model ($\\psi$-model),  which explicitly connects $\\Theta$ and $\\dot{\\Theta}$ to biophysical quantities.  The $\\psi$-model avoids biophysical problems associated with implementing  $\\exp(\\cdot)$, implements the multiplicative operation of $\\eta$ via divisive  inhibition, and explains why activity peaks could occur after ttc.  It consistently  predicts response features of the LGMD, and provides excellent fits to published  experimental data, with goodness of fit measures comparable to corresponding  fits with the $\\eta$-function."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SpaRCS", "Title": "Recovering low-rank and sparse matrices from compressive measurements", "Abstract": "We consider the problem of recovering a matrix $\\mathbf{M}$ that is the sum of a low-rank matrix $\\mathbf{L}$ and a sparse matrix $\\mathbf{S}$ from a small set of linear measurements of the form $\\mathbf{y} = \\mathcal{A}(\\mathbf{M}) = \\mathcal{A}({\\bf L}+{\\bf S})$.  This model subsumes three important classes of signal recovery problems:  compressive sensing, affine rank minimization, and robust principal component analysis.  We propose a natural optimization problem for signal recovery under this model and develop a new greedy algorithm called SpaRCS to solve it.  SpaRCS inherits a number of desirable properties from the state-of-the-art CoSaMP and ADMiRA algorithms, including exponential convergence and efficient implementation.  Simulation results with video compressive sensing, hyperspectral imaging, and robust matrix completion data sets demonstrate both the accuracy and efficacy of the algorithm."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multilinear Subspace Regression", "Title": "An Orthogonal Tensor Decomposition Approach", "Abstract": "A multilinear subspace regression model based on so called latent variable decomposition is introduced. Unlike standard regression methods which typically employ matrix (2D) data representations followed by vector subspace transformations, the proposed approach uses tensor subspace transformations to model common latent variables across both the independent and dependent data. The proposed approach aims to maximize the correlation between the so derived latent variables and is shown to be suitable for the prediction of multidimensional dependent data from multidimensional independent data, where for the estimation of the latent variables we introduce an algorithm based on Multilinear Singular Value Decomposition (MSVD) on a specially defined cross-covariance tensor. It is next shown that in this way we are also able to unify the existing Partial Least Squares (PLS) and N-way PLS regression algorithms within the same framework. Simulations on benchmark synthetic data confirm the advantages of the proposed approach, in terms of its predictive ability and robustness, especially for small sample sizes. The potential of the proposed technique is further illustrated on a real world task of the decoding of human intracranial electrocorticogram (ECoG) from a simultaneously recorded scalp electroencephalograph (EEG)."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PiCoDes", "Title": "Learning a Compact Code for Novel-Category Recognition", "Abstract": "We introduce PiCoDes: a very compact image descriptor which nevertheless allows high performance on object category recognition. In particular, we address novel-category recognition: the task of defining indexing structures and image representations which enable a large collection of images to be searched for an object category that was not known when the index was built. Instead, the training images defining the category are supplied at query time. We explicitly learn descriptors of a given length (from as small as 16 bytes per image) which have good object-recognition performance. In contrast to previous work in the domain of object recognition, we do not choose an arbitrary intermediate representation, but explicitly learn short codes. In contrast to previous approaches to learn compact codes, we optimize explicitly for (an upper bound on) classification performance. Optimization directly for binary features is difficult and nonconvex, but we present an alternation scheme and convex upper bound which demonstrate excellent performance in practice. PiCoDes of 256 bytes match the accuracy of the current best known classifier for the Caltech256 benchmark, but they decrease the database storage size by a factor of 100 and speed-up the training and testing of novel classes by orders of magnitude."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hogwild!", "Title": "A Lock-Free Approach to Parallelizing Stochastic Gradient Descent", "Abstract": "Stochastic Gradient Descent (SGD) is a popular algorithm that can achieve state-of-the-art performance on a variety of machine  learning tasks.  Several researchers have recently proposed schemes  to parallelize SGD, but all require  performance-destroying memory locking and synchronization. This work aims to show using novel theoretical analysis, algorithms,  and implementation that SGD can be implemented without any locking. We present an update scheme called Hogwild which allows processors access to shared memory with the possibility of overwriting each other's work. We show that when the associated optimization problem is sparse, meaning most gradient updates only modify small parts of the decision variable, then Hogwild achieves a nearly optimal rate of convergence.  We demonstrate experimentally that Hogwild outperforms alternative schemes that use locking by an order of magnitude."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Two is better than one", "Title": "distinct roles for familiarity and recollection in retrieving palimpsest memories", "Abstract": "Storing a new pattern in a palimpsest memory system comes at the cost of interfering with the memory traces of previously stored items. Knowing the age of a pattern thus becomes critical for recalling it faithfully. This implies that there should be a tight coupling between estimates of age, as a form of familiarity, and the neural dynamics of recollection, something which current theories omit. Using a normative model of autoassociative memory, we show that a dual memory system, consisting of two interacting modules for familiarity and recollection, has best performance for both recollection and recognition. This finding provides a new window onto actively contentious psychological and neural aspects of recognition memory."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multiclass Boosting", "Title": "Theory and Algorithms", "Abstract": "The problem of  multiclass boosting is considered. A new framework,based on multi-dimensional codewords and predictors is introduced. The optimal set of codewords is derived, and a margin enforcing loss proposed. The resulting risk is minimized by gradient descent on a multidimensional functional space. Two algorithms are proposed: 1) CD-MCBoost, based on coordinate descent, updates one predictor component at a time, 2) GD-MCBoost, based on gradient descent, updates all components jointly. The algorithms differ in the weak learners that they support but are both shown to be 1) Bayes consistent, 2) margin enforcing, and 3) convergent to the global minimum of the risk. They also reduce to AdaBoost when there are only two classes. Experiments show that both methods outperform previous multiclass boosting approaches on a number of datasets."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Trace Lasso", "Title": "a trace norm regularization for correlated designs", "Abstract": "Using the $\\ell_1$-norm to regularize the estimation of  the parameter vector of a linear model leads to an unstable estimator when covariates are highly correlated. In this paper, we introduce a new penalty function which takes into account the correlation of the design matrix to stabilize the estimation. This norm, called the trace Lasso, uses the trace norm of the selected covariates, which is a convex surrogate of their rank, as the criterion of model complexity. We analyze the properties of our norm, describe an optimization algorithm based on reweighted least-squares, and illustrate the behavior of this norm on synthetic data, showing that it is more adapted to strong correlations than competing methods such as the elastic net."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RTRMC", "Title": "A Riemannian trust-region method for low-rank matrix completion", "Abstract": "We consider large matrices of low rank. We address the problem of recovering such matrices when most of the entries are unknown. Matrix completion finds applications in recommender systems. In this setting, the rows of the matrix may correspond to items and the columns may correspond to users. The known entries are the ratings given by users to some items. The aim is to predict the unobserved ratings. This problem is commonly stated in a constrained optimization framework. We follow an approach that exploits the geometry of the low-rank constraint to recast the problem as an unconstrained optimization problem on the Grassmann manifold. We then apply first- and second-order Riemannian trust-region methods to solve it. The cost of each iteration is linear in the number of known entries. Our methods, RTRMC 1 and 2, outperform state-of-the-art algorithms on a wide range of problem instances."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "High-Dimensional Graphical Model Selection", "Title": "Tractable Graph Families and Necessary Conditions", "Abstract": "We consider the problem of Ising and Gaussian graphical model selection given n i.i.d. samples from the model. We propose an efficient threshold-based algorithm   for structure estimation based known as  conditional mutual information test. This simple local algorithm    requires only low-order statistics of the data and decides    whether  two nodes   are neighbors in the unknown graph. Under some transparent assumptions, we establish that the proposed algorithm is structurally consistent (or sparsistent)  when the number of samples scales as n= Omega(J{min}^{-4} log p), where p is the number of nodes and J{min} is the minimum edge potential.  We also prove novel non-asymptotic necessary conditions for graphical model selection."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ShareBoost", "Title": "Efficient multiclass learning with feature sharing", "Abstract": "Multiclass prediction is the problem of classifying an object into a    relevant target class.  We consider the problem of learning a    multiclass predictor that uses only few features, and in particular,    the number of used features should increase sub-linearly with the    number of possible classes. This implies that features should be    shared by several classes. We describe and analyze the ShareBoost    algorithm for learning a multiclass predictor that uses few shared    features. We prove that ShareBoost efficiently finds a predictor    that uses few shared features (if such a predictor exists) and that    it has a small generalization error. We also describe how to use    ShareBoost for learning a non-linear predictor that has a fast    evaluation time. In a series of experiments with natural data sets    we demonstrate the benefits of ShareBoost and evaluate its success    relatively to other state-of-the-art approaches."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast and Balanced", "Title": "Efficient Label Tree Learning for Large Scale Object Recognition", "Abstract": "We present a novel approach to efficiently learn a label tree for large scale classification with many classes. The key contribution of the approach is a technique to simultaneously determine the structure of the tree and learn the classifiers for each node in the tree. This approach also allows fine grained control over the efficiency vs accuracy trade-off in designing a label tree, leading to more balanced trees. Experiments are performed on large scale image classification with 10184 classes and 9 million images. We demonstrate significant improvements in test accuracy and efficiency with less training time and more balanced trees compared to the previous state of the art by Bengio et al."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Im2Text", "Title": "Describing Images Using 1 Million Captioned Photographs", "Abstract": "We develop and demonstrate automatic image description methods using a large captioned photo collection.  One contribution is our technique for the automatic collection of this new dataset -- performing a huge number of Flickr queries and then filtering the noisy results down to 1 million images with associated visually relevant captions.  Such a collection allows us to approach the extremely challenging problem of description generation using relatively simple non-parametric methods and produces surprisingly effective results. We also develop methods incorporating many state of the art, but fairly noisy, estimates of image content to produce even more pleasing results. Finally we introduce a new objective performance measure for image captioning."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beating SGD", "Title": "Learning SVMs in Sublinear Time", "Abstract": "We present an optimization approach for linear SVMs based on a stochastic primal-dual approach, where the primal step is akin to an importance-weighted SGD, and the dual step is a stochastic update on the importance weights.  This yields an optimization method with a sublinear dependence on the training set size, and the first method for learning linear SVMs with runtime less then the size of the training set required for learning!"}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Learning", "Title": "Stochastic, Constrained, and Smoothed Adversaries", "Abstract": "Learning theory has largely focused on two main learning scenarios: the classical statistical setting where instances are drawn i.i.d. from a fixed distribution, and the adversarial scenario whereby at every time step the worst instance is revealed to the player. It can be argued that in the real world neither of these assumptions is reasonable. We define the minimax value of a game where the adversary is restricted in his moves, capturing stochastic and non-stochastic assumptions on data. Building on the sequential symmetrization approach, we define a notion of distribution-dependent Rademacher complexity for the spectrum of problems ranging from i.i.d. to worst-case. The bounds let us immediately deduce variation-type bounds. We study a smoothed online learning scenario and show that exponentially small amount of noise can make function classes with infinite Littlestone dimension learnable."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning in Hilbert vs. Banach Spaces", "Title": "A Measure Embedding Viewpoint", "Abstract": "The goal of this paper is to investigate the advantages and disadvantages of learning in Banach spaces over Hilbert spaces. While many works have been carried out in generalizing Hilbert methods to Banach spaces, in this paper, we consider the simple problem of learning a Parzen window classifier in a reproducing kernel Banach space (RKBS)---which is closely related to the notion of embedding probability measures into an RKBS---in order to carefully understand its pros and cons over the Hilbert space classifier. We show that while this generalization yields richer distance measures on probabilities compared to its Hilbert space counterpart, it however suffers from serious computational drawback limiting its practical applicability, which therefore demonstrates the need for developing efficient learning algorithms in Banach spaces."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "See the Tree Through the Lines", "Title": "The Shazoo Algorithm", "Abstract": "Predicting the nodes of a given graph is a fascinating   theoretical problem with applications in several domains.   Since graph sparsification via spanning trees   retains enough information while making the task much easier,   trees are an important special case of this problem.   Although it is known how to predict the nodes of an unweighted tree   in a nearly optimal way, in the weighted case a fully satisfactory   algorithm is not available yet. We fill this hole and introduce an efficient node predictor,   Shazoo, which is nearly optimal on any weighted tree. Moreover, we show that Shazoo can   be viewed as a common nontrivial generalization of both previous approaches for   unweighted trees and weighted lines.   Experiments on real-world datasets confirm that Shazoo performs well in that   it fully exploits the structure of the input tree,   and gets very close to (and sometimes better than)   less scalable energy minimization methods."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Directed Graph Embedding", "Title": "an Algorithm based on Continuous Limits of Laplacian-type Operators", "Abstract": "This paper considers the problem of embedding directed graphs in Euclidean space while retaining directional information. We model the observed graph as a sample from a manifold endowed with a vector field, and we design an algo- rithm that separates and recovers the features of this process: the geometry of the manifold, the data density and the vector field. The algorithm is motivated by our analysis of Laplacian-type operators and their continuous limit as generators of diffusions on a manifold. We illustrate the recovery algorithm on both artificially constructed and real data."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "High-dimensional regression with noisy and missing data", "Title": "Provable guarantees with non-convexity", "Abstract": "Although the standard formulations of prediction problems involve fully-observed and noiseless data drawn in an i.i.d. manner, many  applications involve noisy and/or missing data, possibly involving dependencies. We study these issues in the context of high-dimensional  sparse linear regression, and propose novel estimators for the cases of noisy, missing, and/or dependent data. Many standard approaches to noisy or missing data, such as those using the EM algorithm, lead to optimization problems that are inherently non-convex, and it is difficult to establish theoretical guarantees on practical algorithms. While our approach also involves optimizing non-convex programs, we are able to both analyze the statistical error associated with any global optimum, and prove that a simple projected gradient descent algorithm will converge in polynomial time to a small neighborhood of the set of global minimizers. On the statistical side, we provide non-asymptotic bounds that hold with high probability for the cases of noisy, missing, and/or dependent data. On the computational side, we prove that under the same types of conditions required for statistical consistency, the projected gradient descent algorithm will converge at geometric rates to a near-global minimizer. We illustrate these theoretical predictions with simulations, showing agreement with the predicted scalings."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Active dendrites", "Title": "adaptation to spike-based communication", "Abstract": "Computational analyses of dendritic computations often assume stationary inputs to neurons, ignoring the pulsatile nature of spike-based communication between neurons and the moment-to-moment fluctuations caused by such spiking inputs. Conversely, circuit computations with spiking neurons are usually formalized without regard to the rich nonlinear nature of dendritic processing. Here we address the computational challenge faced by neurons that compute and represent analogue quantities but communicate with digital spikes, and show that reliable computation of even purely linear functions of inputs can require the interplay of strongly nonlinear subunits within the postsynaptic dendritic tree. Our theory predicts a matching of dendritic nonlinearities and synaptic weight distributions to the joint statistics of presynaptic inputs. This approach suggests normative roles for some puzzling forms of nonlinear dendritic dynamics and plasticity."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EigenNet", "Title": "A Bayesian hybrid of generative and conditional models for sparse learning", "Abstract": "For many real-world applications, we often need to select correlated variables---such as genetic variations and imaging features associated with Alzheimer's disease---in a high dimensional space. The correlation between variables presents a challenge to classical variable selection methods. To address this challenge, the elastic net has been developed and successfully applied to many applications. Despite its great success, the elastic net does not exploit the correlation information embedded in the data to select correlated variables. To overcome this limitation, we present a novel hybrid model, EigenNet, that uses the eigenstructures of data to guide variable selection. Specifically, it integrates a sparse conditional classification model with a generative model capturing variable correlations in a principled Bayesian framework. We develop an efficient active-set algorithm to estimate the model via evidence maximization. Experiments on synthetic data and imaging genetics data demonstrated the superior predictive performance of the EigenNet over the lasso, the elastic net, and the automatic relevance determination."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Manifold Precis", "Title": "An Annealing Technique for Diverse Sampling of Manifolds", "Abstract": "In this paper, we consider the 'Precis' problem of sampling K representative yet diverse data points from a large dataset. This problem arises frequently in applications such as video and document summarization, exploratory data analysis, and pre-filtering. We formulate a general theory which encompasses not just traditional techniques devised for vector spaces, but also non-Euclidean manifolds, thereby enabling these techniques to shapes, human activities, textures and many other image and video based datasets. We propose intrinsic manifold measures for measuring the quality of a selection of points with respect to their representative power, and their diversity. We then propose efficient algorithms to optimize the cost function using a novel annealing-based iterative alternation algorithm. The proposed formulation is applicable to manifolds of known geometry as well as to manifolds whose geometry needs to be estimated from samples. Experimental results show the strength and generality of the proposed approach."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "$\\theta$-MRF", "Title": "Capturing Spatial and Semantic Structure in the Parameters for Scene Understanding", "Abstract": "For most scene understanding tasks (such as object detection or depth estimation), the classifiers need to consider contextual information in addition to the local features. We can capture such contextual information by taking as input the features/attributes from all the regions in the image. However, this contextual dependence also varies with the spatial location of the region of interest, and we therefore need a different set of parameters for each spatial location. This results in a very large number of parameters. In this work, we model the independence properties between the parameters for each location and for each task, by defining a Markov Random Field (MRF) over the parameters. In particular, two sets of parameters are encouraged to have similar values if they are spatially close or semantically close. Our method is, in principle, complementary to other ways of capturing context such as the ones that use a graphical model over the labels instead. In extensive evaluation over two different settings, of multi-class object detection and of multiple scene understanding tasks (scene categorization, depth estimation, geometric labeling), our method beats the state-of-the-art methods in all the four tasks."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Maximum Covariance Unfolding ", "Title": "Manifold Learning for Bimodal Data", "Abstract": "We propose maximum covariance unfolding (MCU), a manifold learning algorithm for simultaneous dimensionality reduction of data from different input modalities.   Given high dimensional inputs from two different but naturally aligned sources, MCU computes a common low dimensional embedding that maximizes the cross-modal (inter-source) correlations while preserving the local (intra-source) distances.  In this paper, we explore two applications of MCU.  First we use MCU to analyze EEG-fMRI data, where an important goal is to visualize the fMRI voxels that are most strongly correlated with changes in EEG traces.  To perform this visualization, we augment MCU with an additional step for metric learning in the high dimensional voxel space.  Second, we use MCU to perform cross-modal retrieval of matched image and text samples from Wikipedia.  To manage large applications of MCU, we develop a fast implementation based on ideas from spectral graph theory.  These ideas transform the original problem for MCU, one of semidefinite programming, into a simpler problem in semidefinite quadratic linear programming."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Bandits to Experts", "Title": "On the Value of Side-Observations", "Abstract": "We consider an adversarial online learning setting where a decision maker can choose an action in every stage of the game. In addition to observing the reward of the chosen action, the decision maker gets side observations on the reward he would have obtained had he chosen some of the other actions. The observation structure is encoded as a graph, where node i is linked to  node j if sampling i provides information on the reward of j. This setting naturally interpolates between the well-known ``experts'' setting, where the decision maker can view all rewards, and the multi-armed bandits setting, where the decision maker can only view the reward of the chosen action. We develop practical algorithms with provable regret guarantees, which depend on non-trivial graph-theoretic properties of the information feedback structure. We also provide partially-matching lower bounds."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hierarchical Matching Pursuit for Image Classification", "Title": "Architecture and Fast Algorithms", "Abstract": "Extracting good representations from images is essential for many computer vision tasks. In this paper, we propose hierarchical matching pursuit (HMP), which builds a feature hierarchy layer-by-layer using an efficient matching pursuit encoder. It includes three modules: batch (tree) orthogonal matching pursuit, spatial pyramid max pooling, and contrast normalization. We investigate the architecture of HMP, and show that all three components are critical for good performance. To speed up the orthogonal matching pursuit, we propose a batch tree orthogonal matching pursuit that is particularly suitable to encode a large number of observations that share the same large dictionary. HMP is scalable and can efficiently handle full-size images. In addition, HMP enables linear support vector machines (SVM) to match the performance of nonlinear SVM while being scalable to large datasets. We compare HMP with many state-of-the-art algorithms including convolutional deep belief networks, SIFT based single layer sparse coding, and kernel based feature learning. HMP consistently yields superior accuracy on three types of image classification problems: object recognition (Caltech-101), scene recognition (MIT-Scene), and static event recognition (UIUC-Sports)."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How Do Humans Teach", "Title": "On Curriculum Learning and Teaching Dimension", "Abstract": "We study the empirical strategies that humans follow as they teach a target concept with a simple 1D threshold to a robot.  Previous studies of computational teaching, particularly the teaching dimension model and the curriculum learning principle, offer contradictory predictions on what optimal strategy the teacher should follow in this teaching task. We show through behavioral studies that humans employ three distinct teaching strategies, one of which is consistent with the curriculum learning principle, and propose a novel theoretical framework as a potential explanation for this strategy. This framework, which assumes a teaching goal of minimizing the learner's expected generalization error at each iteration, extends the standard teaching dimension model and offers a theoretical justification for curriculum learning."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TD_gamma", "Title": "Re-evaluating Complex Backups in Temporal Difference Learning", "Abstract": "We show that the lambda-return target used in the TD(lambda) family of algorithms is the maximum likelihood estimator for a specific model of how the variance of an n-step return estimate increases with n. We introduce the gamma-return estimator, an alternative target based on a more accurate model of variance, which defines the TDgamma family of complex-backup temporal difference learning algorithms. We derive TDgamma, the gamma-return equivalent of the original TD(lambda) algorithm, which eliminates the lambda parameter but can only perform updates at the end of an episode and requires time and space proportional to the episode length. We then derive a second algorithm, TDgamma(C), with a capacity parameter C. TDgamma(C) requires C times more time and memory than TD(lambda) and is incremental and online. We show that TDgamma outperforms TD(lambda) for any setting of lambda on 4 out of 5 benchmark domains, and that TDgamma(C) performs as well as or better than TD_gamma for intermediate settings of C."}
{"Type": "conference", "Year": "2011", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Newtron", "Title": "an Efficient Bandit algorithm for Online Multiclass Prediction", "Abstract": "We present an efficient algorithm for the problem of online multiclass prediction with bandit feedback in the fully adversarial setting. We measure its regret with respect to the log-loss defined in \\cite{AbernethyR09}, which is parameterized by a scalar (\\alpha). We prove that the regret of \\newtron is (O(\\log T)) when (\\alpha) is a constant that does not vary with horizon (T), and at most (O(T^{2/3})) if (\\alpha) is allowed to increase to infinity with (T). For (\\alpha) = (O(\\log T)), the regret is bounded by (O(\\sqrt{T})), thus solving the open problem of \\cite{KST08, AbernethyR09}. Our algorithm is based on a novel application of the online Newton method \\cite{HAK07}. We test our algorithm and show it to perform well in experiments, even when (\\alpha) is a small constant."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FastEx", "Title": "Hash Clustering with Exponential Families", "Abstract": "Clustering is a key component in data analysis toolbox. Despite its   importance, scalable algorithms often eschew rich statistical models   in favor of simpler descriptions such as $k$-means clustering. In   this paper we present a sampler, capable of estimating   mixtures of exponential families. At its heart lies a novel proposal distribution using random   projections to achieve high throughput in generating proposals, which is crucial   for clustering models with large numbers of clusters."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimal Neural Tuning Curves for Arbitrary Stimulus Distributions", "Title": "Discrimax, Infomax and Minimum $L_p$ Loss", "Abstract": "In this work we study how the stimulus distribution influences the optimal coding of an individual neuron. Closed-form solutions to the optimal sigmoidal tuning curve are provided for a neuron obeying Poisson statistics under a given stimulus distribution. We consider a variety of optimality criteria, including maximizing discriminability, maximizing mutual information and minimizing estimation error under a general $L_p$ norm.  We generalize the Cramer-Rao lower bound and show how the $L_p$ loss can be written as a functional of the Fisher Information in the asymptotic limit, by proving the moment convergence of certain functions of Poisson random variables.  In this manner, we show how the optimal tuning curve depends upon the loss function, and the equivalence of maximizing mutual information with minimizing $L_p$ loss in the limit as $p$ goes to zero."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How They Vote", "Title": "Issue-Adjusted Models of Legislative Behavior", "Abstract": "We develop a probabilistic model of legislative data that uses the text of the bills to uncover lawmakers' positions on specific political issues.  Our model can be used to explore how a lawmaker's voting patterns deviate from what is expected and how that deviation depends on what is being voted on. We derive approximate posterior inference algorithms based on variational methods. Across 12 years of legislative data, we demonstrate both improvement in heldout predictive performance and the model's utility in interpreting an inherently multi-dimensional space."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multiclass Learning Approaches", "Title": "A Theoretical Comparison with Implications", "Abstract": "We theoretically analyze and compare the following five popular multiclass classification methods: One vs. All, All Pairs, Tree-based classifiers, Error Correcting Output Codes (ECOC) with randomly generated code matrices, and Multiclass SVM. In the first four methods, the classification is based on a reduction to binary classification. We consider the case where the binary classifier comes from a class of VC dimension $d$, and in particular from the class of halfspaces over $\\reals^d$. We analyze both the estimation error and the approximation error of these methods. Our analysis reveals interesting conclusions of practical relevance, regarding the success of the different approaches under various conditions. Our proof technique employs tools from VC theory to analyze the \\emph{approximation error} of hypothesis classes. This is in sharp contrast to most, if not all, previous uses of VC theory, which only deal with estimation error."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Augmented-SVM", "Title": "Automatic space partitioning for combining multiple non-linear dynamics", "Abstract": "Non-linear dynamical systems (DS) have been used extensively for building generative models of human behavior. Its applications range from modeling brain dynamics  to encoding motor commands. Many schemes have been proposed for encoding robot motions using dynamical systems with a single attractor placed at a predefined target in state space. Although these enable the robots to react against sudden perturbations without any re-planning, the motions are always directed towards a single target. In this work, we focus on combining several such DS with distinct attractors, resulting in a multi-stable DS. We show its applicability in reach-to-grasp tasks where the attractors represent several grasping points on the target object. While exploiting multiple attractors provides more flexibility in recovering from unseen perturbations, it also increases the complexity of the underlying learning problem. Here we present the Augmented-SVM (A-SVM) model which inherits region partitioning ability of the well known SVM classifier and is augmented with novel constraints derived from the individual DS. The new constraints modify the original SVM dual whose optimal solution then results in a new class of support vectors (SV). These new SV ensure that the resulting multi-stable DS incurs minimum deviation from the original dynamics and is stable at each of the attractors within a finite region of attraction. We show, via implementations on a simulated 10 degrees of freedom mobile robotic platform, that the model is capable of real-time motion generation and is able to adapt on-the-fly to perturbations."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accelerated Training for Matrix-norm Regularization", "Title": "A Boosting Approach", "Abstract": "Sparse learning models typically combine a smooth loss with a nonsmooth penalty, such as trace norm. Although recent developments in sparse approximation have offered promising solution methods, current approaches either apply only to matrix-norm constrained problems or provide suboptimal convergence rates. In this paper, we propose a boosting method for regularized learning that guarantees $\\epsilon$ accuracy within $O(1/\\epsilon)$ iterations. Performance is further accelerated by interlacing boosting with fixed-rank local optimization---exploiting a simpler local objective than previous work. The proposed method yields state-of-the-art performance on large-scale problems. We also demonstrate an application to latent multiview learning for which we provide the first efficient weak-oracle."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shifting Weights", "Title": "Adapting Object Detectors from Image to Video", "Abstract": "Typical object detectors trained on images perform poorly on video, as there is a clear distinction in domain between the two types of data. In this paper, we tackle the problem of adapting object detectors learned from images to work well on videos. We treat the problem as one of unsupervised domain adaptation, in which we are given labeled data from the source domain (image), but only unlabeled data from the target domain (video). Our approach, self-paced domain adaptation, seeks to iteratively adapt the detector by re-training the detector with automatically discovered target domain examples, starting with the easiest first. At each iteration, the algorithm adapts by considering an increased number of target domain examples, and a decreased number of source domain examples. To discover target domain examples from the vast amount of video data, we introduce a simple, robust approach that scores trajectory tracks instead of bounding boxes. We also show how rich and expressive features specific to the target domain can be incorporated under the same framework. We show promising results on the 2011 TRECVID Multimedia Event Detection and LabelMe Video datasets that illustrate the benefit of our approach to adapt object detectors to video."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Minimization of Continuous Bethe Approximations", "Title": "A Positive Variation", "Abstract": "We develop convergent minimization algorithms for Bethe variational approximations which explicitly constrain marginal estimates to families of valid distributions.  While existing message passing algorithms define fixed point iterations corresponding to stationary points of the Bethe free energy, their greedy dynamics do not distinguish between local minima and maxima, and can fail to converge. For continuous estimation problems, this instability is linked to the creation of invalid marginal estimates, such as Gaussians with negative variance. Conversely, our approach leverages multiplier methods with well-understood convergence properties, and uses bound projection methods to ensure that marginal approximations are valid at all iterations. We derive general algorithms for discrete and Gaussian pairwise Markov random fields, showing improvements over standard loopy belief propagation. We also apply our method to a hybrid model with both discrete and continuous variables, showing improvements over expectation propagation."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Latent Graphical Model Selection", "Title": "Efficient Methods for Locally Tree-like Graphs", "Abstract": "Graphical model selection refers to the problem of estimating the unknown graph structure given observations at the nodes in the model. We consider a challenging instance of this problem when some of the nodes are latent or hidden.  We  characterize  conditions for tractable graph estimation and develop efficient methods with provable guarantees. We consider the class of Ising models Markov on  locally tree-like graphs, which are in the regime of correlation decay. We  propose an efficient method for graph estimation, and establish its structural consistency when the number of samples $n$ scales as $n = \\Omega(\\theta_{\\min}^{-\\delta \\eta(\\eta+1)-2}\\log p)$, where $\\theta_{\\min}$ is the minimum edge potential, $\\delta$ is the depth (i.e., distance from a hidden node to the nearest  observed nodes), and $\\eta$ is a parameter which depends on the minimum and maximum node and edge potentials in the Ising model. The proposed method is practical to implement and provides  flexibility to control  the number of latent variables and the cycle lengths in the output graph.  We also present necessary conditions for graph estimation by any method and show that our method nearly matches the lower bound  on sample requirements."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Scalable CUR Matrix Decomposition Algorithm", "Title": "Lower Time Complexity and Tighter Bound", "Abstract": "The CUR matrix decomposition is an important extension of Nyström approximation to a general matrix. It approximates any data matrix in terms of a small number of its columns and rows. In this paper we propose a novel randomized CUR algorithm with an expected relative-error bound. The proposed algorithm has the advantages over the existing relative-error CUR algorithms that it possesses tighter theoretical bound and lower time complexity, and that it can avoid maintaining the whole data matrix in main memory. Finally, experiments on several real-world datasets demonstrate significant improvement over the existing relative-error algorithms."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interpreting prediction markets", "Title": "a stochastic approach", "Abstract": "We strengthen recent connections between prediction markets and learning by showing that a natural class of market makers can be understood as performing stochastic mirror descent when trader demands are sequentially drawn from a fixed distribution. This provides new insights into how market prices (and price paths) may be interpreted as a summary of the market's belief distribution by relating them to the optimization problem being solved. In particular, we show that the stationary point of the stochastic process of prices generated by the market is equal to the market's Walrasian equilibrium of classic market analysis. Together, these results suggest how traditional market making mechanisms might be replaced with general purpose learning algorithms while still retaining guarantees about their behaviour."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Relax and Randomize ", "Title": "From Value to Algorithms", "Abstract": "We show a principled way of deriving online learning algorithms from a minimax analysis. Various upper bounds on the minimax value, previously thought to be non-constructive, are shown to yield algorithms. This allows us to seamlessly recover known methods and to derive new ones, also capturing such ''unorthodox'' methods as Follow the Perturbed Leader and the R^2 forecaster. Understanding the inherent complexity of the learning problem thus leads to the development of algorithms. To illustrate our approach, we present several new algorithms, including a family of randomized methods that use the idea of a ''random play out''. New versions of the Follow-the-Perturbed-Leader algorithms are presented, as well as methods based on the Littlestone's dimension, efficient methods for matrix completion with trace norm, and algorithms for the problems of transductive learning and prediction with static experts."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic optimization and sparse statistical recovery", "Title": "Optimal algorithms for high dimensions", "Abstract": "We develop and analyze stochastic optimization algorithms for problems in which the expected loss is strongly convex, and the optimum is (approximately) sparse. Previous approaches are able to exploit only one of these two structures, yielding a $\\order(\\pdim/T)$ convergence rate for strongly convex objectives in $\\pdim$ dimensions and $\\order(\\sqrt{\\spindex( \\log\\pdim)/T})$ convergence rate when the optimum is $\\spindex$-sparse. Our algorithm is based on successively solving a series of $\\ell_1$-regularized optimization problems using Nesterov's dual averaging algorithm. We establish that the error of our solution after $T$ iterations is at most $\\order(\\spindex(\\log\\pdim)/T)$, with natural extensions to approximate sparsity. Our results apply to locally Lipschitz losses including the logistic, exponential, hinge and least-squares losses. By recourse to statistical minimax results, we show that our convergence rates are optimal up to constants. The effectiveness of our approach is also confirmed in numerical simulations where we compare to several baselines on a least-squares regression problem."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How Prior Probability Influences Decision Making", "Title": "A Unifying Probabilistic Model", "Abstract": "How does the brain combine prior knowledge with sensory evidence when making decisions under uncertainty? Two competing descriptive models have been proposed based on experimental data.  The first posits an additive offset to a decision variable, implying a static effect of the prior. However, this model is inconsistent with recent data from a motion discrimination task involving temporal integration of uncertain sensory evidence. To explain this data, a second model has been proposed which assumes a time-varying influence of the prior. Here we present a normative model of decision making that incorporates prior knowledge in a principled way.  We show that the additive offset model and the time-varying prior model emerge naturally when decision making is viewed within the framework of partially observable Markov decision processes (POMDPs).  Decision making in the model reduces to (1) computing beliefs given observations and prior information in a Bayesian manner, and (2) selecting actions based on these beliefs to maximize the  expected sum of future rewards. We show that the model can explain both  data previously explained using the additive offset model as well as more  recent data on the time-varying influence of prior knowledge on decision making."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Nyström Method vs Random Fourier Features", "Title": "A Theoretical and Empirical Comparison", "Abstract": "Both random Fourier features and the Nyström method have been successfully applied to efficient kernel learning. In this work, we investigate the fundamental difference between these two approaches, and how the difference could affect their generalization performances. Unlike approaches based on random Fourier features  where the basis functions (i.e., cosine and sine functions) are sampled from a distribution  {\\it independent} from the training data, basis functions used by the Nyström method are randomly sampled from the training examples and are therefore {\\it data dependent}. By exploring this difference, we show that when there is a large gap in the eigen-spectrum of the kernel matrix, approaches based the Nyström method can yield  impressively  better generalization error bound than random Fourier features based approach. We empirically verify our theoretical findings on a wide range of large data sets."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Halfspaces with the Zero-One Loss", "Title": "Time-Accuracy Tradeoffs", "Abstract": "Given $\\alpha,\\epsilon$, we study the time complexity   required to improperly learn a halfspace with misclassification   error rate of at most $(1+\\alpha)\\,L^*_\\gamma + \\epsilon$, where   $L^*_\\gamma$ is the optimal $\\gamma$-margin error rate. For $\\alpha   = 1/\\gamma$, polynomial time and sample complexity is achievable   using the hinge-loss. For $\\alpha = 0$, \\cite{ShalevShSr11} showed   that $\\poly(1/\\gamma)$ time is impossible, while learning is   possible in time $\\exp(\\tilde{O}(1/\\gamma))$.  An immediate   question, which this paper tackles, is what is achievable if $\\alpha   \\in (0,1/\\gamma)$.  We derive positive results interpolating between   the polynomial time for $\\alpha = 1/\\gamma$ and the exponential   time for $\\alpha=0$. In particular, we show that there are cases in   which $\\alpha = o(1/\\gamma)$ but the problem is still solvable in   polynomial time. Our results naturally extend to the adversarial   online learning model and to the PAC learning with malicious noise   model."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Factorial LDA", "Title": "Sparse Multi-Dimensional Text Models", "Abstract": "Multi-dimensional latent variable models can capture the many latent factors in a text corpus, such as topic, author perspective and sentiment. We introduce factorial LDA, a multi-dimensional latent variable model in which a document is influenced by K different factors, and each word token depends on a K-dimensional vector of latent variables. Our model incorporates structured word priors and learns a sparse product of factors. Experiments on research abstracts show that our model can learn latent factors such as research topic, scientific discipline, and focus (e.g. methods vs. applications.) Our modeling improvements reduce test perplexity and improve human interpretability of the discovered factors."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structure estimation for discrete graphical models", "Title": "Generalized covariance matrices and their inverses", "Abstract": "We investigate a curious relationship between the structure of a discrete graphical model and the support of the inverse of a generalized covariance matrix. We show that for certain graph structures, the support of the inverse covariance matrix of indicator variables on the vertices of a graph reﬂects the conditional independence structure of the graph. Our work extends results that have previously been es- tablished only in the context of multivariate Gaussian graphical models, thereby addressing an open question about the signiﬁcance of the inverse covariance ma- trix of a non-Gaussian distribution. Based on our population-level results, we show how the graphical Lasso may be used to recover the edge structure of cer- tain classes of discrete graphical models, and present simulations to verify our theoretical results."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GenDeR", "Title": "A Generic Diversified Ranking Algorithm", "Abstract": "Diversified ranking is a fundamental task in machine learning. It is broadly applicable in many real world problems, e.g., information retrieval, team assembling, product search, etc. In this paper, we consider a generic setting where we aim to diversify the top-k ranking list based on an arbitrary relevance function and an arbitrary similarity function among all the examples. We formulate it as an optimization problem and show that in general it is NP-hard. Then, we show that for a large volume of the parameter space, the proposed objective function enjoys the diminishing returns property, which enables us to design a scalable, greedy algorithm to find the near-optimal solution. Experimental results on real data sets demonstrate the effectiveness of the proposed algorithm."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Best Arm Identification", "Title": "A Unified Approach to Fixed Budget and Fixed Confidence", "Abstract": "We study the problem of identifying the best arm(s) in the stochastic multi-armed bandit setting. This problem has been studied in the literature from two different perspectives: fixed budget and fixed confidence. We propose a unifying approach that leads to a meta-algorithm called unified gap-based exploration (UGapE), with a common structure and similar theoretical analysis for these two settings. We prove a performance bound for the two versions of the algorithm showing that the two problems are characterized by the same notion of complexity. We also show how the UGapE algorithm as well as its theoretical analysis can be extended to take into account the variance of the arms and to multiple bandits. Finally, we evaluate the performance of UGapE and compare it with a number of existing fixed budget and fixed confidence algorithms."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Deformations to Parts", "Title": "Motion-based Segmentation of 3D Objects", "Abstract": "We develop a method for discovering the parts of an articulated object from aligned meshes capturing various three-dimensional (3D) poses.  We adapt the distance dependent Chinese restaurant process (ddCRP) to allow nonparametric discovery of a potentially unbounded number of parts, while simultaneously guaranteeing a spatially connected segmentation.  To allow analysis of datasets in which object instances have varying shapes, we model part variability across poses via affine transformations.  By placing a matrix normal-inverse-Wishart prior on these affine transformations, we develop a ddCRP Gibbs sampler which tractably marginalizes over transformation uncertainty.  Analyzing a dataset of humans captured in dozens of poses, we infer parts which provide quantitatively better motion predictions than conventional clustering methods."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Forging The Graphs", "Title": "A Low Rank and Positive Semidefinite Graph Learning Approach", "Abstract": "In many graph-based machine learning and data mining approaches, the quality of the graph is critical. However, in real-world applications, especially in semi-supervised learning and unsupervised learning, the evaluation of the quality of a graph is often expensive and sometimes even impossible, due the cost or the unavailability of ground truth. In this paper, we proposed a robust approach with convex optimization to ``forge'' a graph: with an input of a graph, to learn a graph with higher quality. Our major concern is that an ideal graph shall satisfy all the following constraints: non-negative, symmetric, low rank, and positive semidefinite. We develop a graph learning algorithm by solving a convex optimization problem and further develop an efficient optimization to obtain global optimal solutions with theoretical guarantees. With only one non-sensitive parameter, our method is shown by experimental results to be robust and achieve higher accuracy in semi-supervised learning and clustering under various settings. As a preprocessing of graphs, our method has a wide range of potential applications machine learning and data mining."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dip-means", "Title": "an incremental clustering method for estimating the number of clusters", "Abstract": "Learning the number of clusters is a key problem in data clustering. We present dip-means, a novel robust incremental method to learn the number of data clusters that may be used as a wrapper around any iterative clustering algorithm of the k-means family. In contrast to many popular methods which make assumptions about the underlying cluster distributions, dip-means only assumes a fundamental cluster property: each cluster to admit a unimodal distribution. The proposed algorithm considers each cluster member as a ''viewer'' and applies a univariate statistic hypothesis test for unimodality (dip-test) on the distribution of the distances between the viewer and the cluster members. Two important advantages are: i) the unimodality test is applied on univariate distance vectors, ii) it can be directly applied with kernel-based methods, since only the pairwise distances are involved in the computations. Experimental results on artificial and real datasets indicate the effectiveness of our method and its superiority over analogous approaches."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Latent Coincidence Analysis", "Title": "A Hidden Variable Model for Distance Metric Learning", "Abstract": "We describe a latent variable model for supervised dimensionality reduction and distance metric learning. The model discovers linear projections of high dimensional data that shrink the distance between similarly labeled inputs and expand the distance between differently labeled ones. The model’s continuous latent variables locate pairs of examples in a latent space of lower dimensionality. The model differs significantly from classical factor analysis in that the posterior distribution over these latent variables is not always multivariate Gaussian. Nevertheless we show that inference is completely tractable and derive an Expectation-Maximization (EM) algorithm for parameter estimation. We also compare the model to other approaches in distance metric learning. The model’s main advantage is its simplicity: at each iteration of the EM algorithm, the distance metric is re-estimated by solving an unconstrained least-squares problem. Experiments show that these simple updates are highly effective."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Learning of Smoothing Functions", "Title": "Application to Electricity Load Forecasting", "Abstract": "This paper proposes an efficient online learning algorithm to track the smoothing functions of Additive Models. The key idea is to combine the linear representation of Additive Models with a Recursive Least Squares (RLS) filter. In order to quickly track changes in the model and put more weight on recent data, the RLS filter uses a forgetting factor which exponentially weights down observations by the order of their arrival. The tracking behaviour is further enhanced by using an adaptive forgetting factor which is updated based on the gradient of the a priori errors. Using results from Lyapunov stability theory, upper bounds for the learning rate are analyzed. The proposed algorithm is applied to 5 years of electricity load data provided by the French utility company Electricite de France (EDF). Compared to state-of-the-art methods, it achieves a superior performance in terms of model tracking and prediction accuracy."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A P300 BCI for the Masses", "Title": "Prior Information Enables Instant Unsupervised Spelling", "Abstract": "The usability of Brain Computer Interfaces (BCI) based on the P300 speller is severely hindered by the need for long training times and many repetitions of the same stimulus. In this contribution we introduce a set of unsupervised hierarchical probabilistic models that tackle both problems simultaneously by incorporating prior knowledge from two sources: information from other training subjects (through transfer learning) and information about the words being spelled (through language models). We show, that due to this prior knowledge, the performance of the unsupervised models parallels and in some cases even surpasses that of supervised models, while eliminating the tedious training session."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multiple Choice Learning", "Title": "Learning to Produce Multiple Structured Outputs", "Abstract": "The paper addresses the problem of generating multiple hypotheses for prediction tasks that involve interaction with users or successive components in a cascade. Given a set of multiple hypotheses, such components/users have the ability to automatically rank the results and thus retrieve the best one. The standard approach for handling this scenario is to learn a single model and then produce M-best Maximum a Posteriori (MAP) hypotheses from this model. In contrast, we formulate this multiple {\\em choice} learning task as a multiple-output structured-output prediction problem with a loss function that captures the natural setup of the problem. We present a max-margin formulation  that minimizes an upper-bound on this loss-function. Experimental results on the problems of image co-segmentation and protein side-chain prediction show that our method outperforms conventional approaches used for this  scenario and leads to substantial improvements in prediction accuracy."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fiedler Random Fields", "Title": "A Large-Scale Spectral Approach to Statistical Network Modeling", "Abstract": "Statistical models for networks have been typically committed to strong prior assumptions concerning the form of the modeled distributions. Moreover, the vast majority of currently available models are explicitly designed for capturing some specific graph properties (such as power-law degree distributions), which makes them unsuitable for application to domains where the behavior of the target quantities is not known a priori. The key contribution of this paper is twofold. First, we introduce the Fiedler delta statistic, based on the Laplacian spectrum of graphs, which allows to dispense with any parametric assumption concerning the modeled network properties. Second, we use the defined statistic to develop the Fiedler random field model, which allows for efficient estimation of edge distributions over large-scale random networks. After analyzing the dependence structure involved in Fiedler random fields, we estimate them over several real-world networks, showing that they achieve a much higher modeling accuracy than other well-known statistical approaches."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Semi-Crowdsourced Clustering", "Title": "Generalizing Crowd Labeling by Robust Distance Metric Learning", "Abstract": "One of the main challenges in data clustering is to define an appropriate similarity measure between two objects. Crowdclustering addresses this challenge by defining the pairwise similarity based on the manual annotations obtained through crowdsourcing. Despite its encouraging results, a key limitation of crowdclustering is that it can only cluster objects when their manual annotations are available. To address this limitation, we propose a new approach for clustering, called \\textit{semi-crowdsourced clustering} that effectively combines the low-level features of objects with the manual annotations of a subset of the objects obtained via crowdsourcing. The key idea is to learn an appropriate similarity measure, based on the low-level features of objects, from the manual annotations of only a small portion of the data to be clustered. One difficulty in learning the pairwise similarity measure is that there is a significant amount of noise and inter-worker variations in the manual annotations obtained via crowdsourcing. We address this difficulty by developing a metric learning algorithm based on the matrix completion method. Our empirical study with two real-world image data sets shows that the proposed algorithm outperforms state-of-the-art distance metric learning algorithms in both clustering accuracy and computational efficiency."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Waveform Driven Plasticity in BiFeO3 Memristive Devices", "Title": "Model and Implementation", "Abstract": "Memristive devices have recently been proposed as efficient implementations of plastic synapses in neuromorphic systems. The plasticity in these memristive devices, i.e. their resistance change, is defined by the applied waveforms. This behavior resembles biological synapses, whose plasticity is also triggered by mechanisms that are determined by local waveforms. However, learning in memristive devices has so far been approached mostly on a pragmatic technological level. The focus seems to be on finding any waveform that achieves spike-timing-dependent plasticity (STDP), without regard to the biological veracity of said waveforms or to further important forms of plasticity. Bridging this gap, we make use of a plasticity model driven by neuron waveforms that explains a large number of experimental observations and adapt it to the characteristics of the recently introduced BiFeO$_3$ memristive material. Based on this approach, we show STDP for the first time for this material, with learning window replication superior to previous memristor-based STDP implementations. We also demonstrate in measurements that it is possible to overlay short and long term plasticity at a memristive device in the form of the well-known triplet plasticity. To the best of our knowledge, this is the first implementations of triplet plasticity on any physical memristive device."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The representer theorem for Hilbert spaces", "Title": "a necessary and sufficient condition", "Abstract": "The representer theorem is a property that lies at the foundation of regularization theory and kernel methods. A class of regularization functionals is said to admit a linear representer theorem if every member of the class admits minimizers that lie in the finite dimensional subspace spanned by the representers of the data. A recent characterization states that certain classes of regularization functionals with differentiable regularization term admit a linear representer theorem for any choice of the data if and only if the regularization term is a radial nondecreasing function. In this paper, we extend such result by weakening the assumptions on the regularization term. In particular, the main result of this paper implies that, for a sufficiently large family of regularization functionals, radial nondecreasing functions are the only lower semicontinuous regularization terms that guarantee existence of a representer theorem for any choice of the data."}
{"Type": "conference", "Year": "2012", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Q-MKL", "Title": "Matrix-induced Regularization in Multi-Kernel Learning with Applications to Neuroimaging", "Abstract": "Multiple Kernel Learning (MKL) generalizes SVMs to the setting where one simultaneously trains a linear classifier and chooses an optimal combination of given base kernels. Model complexity is typically controlled using various norm regularizations on the vector of base kernel mixing coefficients. Existing methods, however, neither regularize nor exploit potentially useful information pertaining to how kernels in the input set 'interact'; that is, higher order kernel-pair relationships that can be easily obtained via unsupervised (similarity, geodesics), supervised (correlation in errors), or domain knowledge driven mechanisms (which features were used to construct the kernel?). We show that by substituting the norm penalty with an arbitrary quadratic function Q \\succeq 0, one can impose a desired covariance structure on mixing coefficient selection, and use this as an inductive bias when learning the concept. This formulation significantly generalizes the widely used 1- and 2-norm MKL objectives. We explore the model’s utility via experiments on a challenging Neuroimaging problem, where the goal is to predict a subject’s conversion to Alzheimer’s Disease (AD) by exploiting aggregate information from several distinct imaging modalities. Here, our new model outperforms the state of the art (p-values << 10−3 ). We briefly discuss ramifications in terms of learning bounds (Rademacher complexity)."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Third-Order Edge Statistics", "Title": "Contour Continuation, Curvature, and Cortical Connections", "Abstract": "Association field models have been used to explain human contour grouping performance and to explain the mean frequency of long-range horizontal connections across cortical columns in V1. However, association fields essentially depend on pairwise statistics of edges in natural scenes. We develop a spectral test of the sufficiency of pairwise statistics and show that there is significant higher-order structure.  An analysis using a probabilistic spectral embedding reveals curvature-dependent components to the association field, and reveals a challenge for biological learning algorithms."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On model selection consistency of penalized M-estimators", "Title": "a geometric theory", "Abstract": "Penalized M-estimators are used in diverse areas of science and engineering to fit high-dimensional models with some low-dimensional structure. Often, the penalties are \\emph{geometrically decomposable}, \\ie\\ can be expressed as a sum of (convex) support functions. We generalize the notion of irrepresentable to geometrically decomposable penalties and develop a general framework for establishing consistency and model selection consistency of M-estimators with such penalties. We then use this framework to derive results for some special cases of interest in bioinformatics and statistical learning."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Graphical Transformation for Belief Propagation", "Title": "Maximum Weight Matchings and Odd-Sized Cycles", "Abstract": "Max-product ‘belief propagation’ (BP) is a popular distributed heuristic for finding the Maximum A Posteriori (MAP) assignment in a joint probability distribution represented by a Graphical Model (GM). It was recently shown that BP converges to the correct MAP assignment for a class of loopy GMs with the following common feature: the Linear Programming (LP) relaxation to the MAP problem is tight (has no integrality gap). Unfortunately, tightness of the LP relaxation does not, in general, guarantee convergence and correctness of the BP algorithm. The failure of BP in such cases motivates reverse engineering a solution – namely, given a tight LP, can we design a ‘good’ BP algorithm.  In this paper, we design a BP algorithm for the Maximum Weight Matching (MWM) problem over general graphs. We prove that the algorithm converges to the correct optimum if the respective LP relaxation, which may include inequalities associated with non-intersecting odd-sized cycles, is tight. The most significant part of our approach is the introduction of a novel graph transformation designed to force convergence of BP. Our theoretical result suggests an efficient BP-based heuristic for the MWM problem, which consists of making sequential, “cutting plane”, modifications to the underlying GM. Our experiments show that this heuristic performs as well as traditional cutting-plane algorithms using LP solvers on MWM problems."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Action is in the Eye of the Beholder", "Title": "Eye-gaze Driven Model for Spatio-Temporal Action Localization", "Abstract": "We propose a new weakly-supervised structured learning approach for recognition and spatio-temporal localization of actions in video. As part of the proposed approach we develop a generalization of the Max-Path search algorithm, which allows us to efficiently search over a structured space of multiple spatio-temporal paths, while also allowing to incorporate context information into the model. Instead of using spatial annotations, in the form of bounding boxes, to guide the latent model during training, we utilize human gaze data in the form of a weak supervisory signal. This is achieved by incorporating gaze, along with the classification, into the structured loss within the latent SVM learning framework. Experiments on a challenging benchmark dataset, UCF-Sports, show that our model is more accurate, in terms of classification, and achieves state-of-the-art results in localization. In addition, we show how our model can produce top-down saliency maps conditioned on the classification label and localized latent paths."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BIG & QUIC", "Title": "Sparse Inverse Covariance Estimation for a Million Variables", "Abstract": "The l1-regularized Gaussian maximum likelihood estimator (MLE) has been shown to have strong statistical guarantees in recovering a sparse inverse covariance matrix even under high-dimensional settings. However, it requires solving a difficult non-smooth log-determinant program with number of parameters scaling quadratically with the number of Gaussian variables. State-of-the-art methods thus do not scale to problems with more than 20,000 variables. In this paper, we develop an algorithm BigQUIC, which can solve 1 million dimensional l1-regularized Gaussian MLE problems (which would thus have 1000 billion parameters) using a single machine, with bounded memory. In order to do so, we carefully exploit the underlying structure of the problem. Our innovations include a novel block-coordinate descent method with the blocks chosen via a clustering scheme to minimize repeated computations; and allowing for inexact computation of specific components. In spite of these modifications,  we are able to theoretically analyze our procedure and show that BigQUIC can achieve super-linear or even quadratic convergence rates."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust Multimodal Graph Matching", "Title": "Sparse Coding Meets Graph Matching", "Abstract": "Graph matching is a challenging problem with very important applications in a wide range of fields, from image and video analysis to biological and biomedical problems. We propose a robust graph matching algorithm inspired in sparsity-related techniques. We cast the problem, resembling group or collaborative sparsity formulations, as a non-smooth convex optimization problem that can be efficiently solved using augmented Lagrangian techniques. The method can deal with weighted or unweighted graphs, as well as multimodal data, where different graphs represent different types of data. The proposed approach is also naturally integrated with collaborative graph inference techniques, solving general network inference problems where the observed variables, possibly coming from different modalities, are not in correspondence. The algorithm is tested and compared with state-of-the-art graph matching techniques in both synthetic and real graphs. We also present results on multimodal graphs and applications to collaborative inference of brain connectivity from alignment-free functional magnetic resonance imaging (fMRI) data."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimistic policy iteration and natural actor-critic", "Title": "A unifying view and a non-optimality result", "Abstract": "Approximate dynamic programming approaches to the reinforcement learning problem are often categorized into greedy value function methods and value-based policy gradient methods. As our first main result, we show that an important subset of the latter methodology is, in fact, a limiting special case of a general formulation of the former methodology; optimistic policy iteration encompasses not only most of the greedy value function methods but also natural actor-critic methods, and permits one to directly interpolate between them. The resulting continuum adjusts the strength of the Markov assumption in policy improvement and, as such, can be seen as dual in spirit to the continuum in TD($\\lambda$)-style algorithms in policy evaluation. As our second main result, we show for a substantial subset of soft-greedy value function approaches that, while having the potential to avoid policy oscillation and policy chattering, this subset can never converge toward any optimal policy, except in a certain pathological case. Consequently, in the context of approximations, the majority of greedy value function methods seem to be deemed to suffer either from the risk of oscillation/chattering or from the presence of systematic sub-optimality."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Auditing", "Title": "Active Learning with Outcome-Dependent Query Costs", "Abstract": "We propose a learning setting in which unlabeled data is free, and the cost of a label depends on its value, which is not known in advance. We study binary classification in an extreme case, where the algorithm only pays for negative labels. Our motivation are applications such as fraud detection, in which investigating an honest transaction should be avoided if possible. We term the setting auditing, and consider the auditing complexity of an algorithm: The number of negative points it labels to learn a hypothesis with low relative error. We design auditing algorithms for thresholds on the line and axis-aligned rectangles, and show that with these algorithms, the auditing complexity can be significantly lower than the active label complexity. We discuss a general approach for auditing for a general hypothesis class, and describe several interesting directions for future work."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Variational Approximations to non-Exponential Family Change Point Models", "Title": "With Application to Radar Tracking", "Abstract": "The Bayesian online change point detection (BOCPD) algorithm provides an efficient way to do exact inference when the parameters of an underlying model may suddenly change over time. BOCPD requires computation of the underlying model's posterior predictives, which can only be computed online in $O(1)$ time and memory for exponential family models. We develop variational approximations to the posterior on change point times (formulated as run lengths) for efficient inference when the underlying model is not in the exponential family, and does not have tractable posterior predictive distributions. In doing so, we develop improvements to online variational inference. We apply our methodology to a tracking problem using radar data with a signal-to-noise feature that is Rice distributed. We also develop a variational method for inferring the parameters of the (non-exponential family) Rice distribution."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RNADE", "Title": "The real-valued neural autoregressive density-estimator", "Abstract": "We introduce RNADE, a new model for joint density estimation of real-valued vectors. Our model calculates the density of a datapoint as the product of one-dimensional conditionals modeled using mixture density networks with shared parameters. RNADE learns a distributed representation of the data, while having a tractable expression for the calculation of densities. A tractable likelihood allows direct comparison with other methods and training by standard gradient-based optimizers. We compare the performance of RNADE on several datasets of heterogeneous and perceptual data, finding it outperforms mixture models in all but one case."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Estimating the Unseen", "Title": "Improved Estimators for Entropy and other Properties", "Abstract": "Recently, [Valiant and Valiant] showed that a class of distributional properties, which includes such practically relevant properties as entropy, the number of distinct elements, and distance metrics between pairs of distributions, can be estimated given a SUBLINEAR sized sample.  Specifically, given a sample consisting of independent draws from any distribution over at most n distinct elements, these properties can be estimated accurately using a sample of size O(n / log n).  We propose a novel modification of this approach and show: 1) theoretically, our estimator is optimal (to constant factors, over worst-case instances), and 2) in practice, it performs exceptionally well for a variety of estimation tasks, on a variety of natural distributions, for a wide range of parameters.  Perhaps unsurprisingly, the key step in this approach is to first use the sample to characterize the unseen\" portion of the distribution.  This goes beyond such tools as the Good-Turing frequency estimation scheme, which estimates the total probability mass of the unobserved portion of the distribution: we seek to estimate the \"shape\"of the unobserved portion of the distribution.  This approach is robust, general, and theoretically principled;  we expect that it may be fruitfully used as a component within larger machine learning and data analysis systems. \""}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Local Privacy and Minimax Bounds", "Title": "Sharp Rates for Probability Estimation", "Abstract": "We provide a detailed study of the estimation of probability distributions---discrete and continuous---in a stringent setting in which data is kept private even from the statistician.  We give sharp minimax rates of convergence for estimation in these locally private settings, exhibiting fundamental tradeoffs between privacy and convergence rate, as well as providing tools to allow movement along the privacy-statistical efficiency continuum. One of the consequences of our results is that Warner's classical work on randomized response is an optimal way to perform survey sampling while maintaining privacy of the respondents."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "It is all in the noise", "Title": "Efficient multi-task Gaussian process inference with structured residuals", "Abstract": "Multi-task prediction models are widely being used to couple regressors or classification models by sharing information across related tasks. A common pitfall of these models is that they assume that the output tasks are independent conditioned on the inputs. Here, we propose a multi-task Gaussian process approach to model both the relatedness between regressors as well as the task correlations in the residuals, in order to more accurately identify true sharing between regressors. The resulting Gaussian model has a covariance term that is the sum of Kronecker products, for which efficient parameter inference and out of sample prediction are feasible. On both synthetic examples and applications to phenotype prediction in genetics, we find substantial benefits of modeling structured noise compared to established alternatives."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Inverse Density as an Inverse Problem", "Title": "the Fredholm Equation Approach", "Abstract": "We address the problem of estimating the ratio $\\frac{q}{p}$ where $p$ is a density function and $q$ is another density, or, more generally an arbitrary function.  Knowing or approximating this ratio is needed in various problems of inference and integration, in particular, when one needs to average a function with respect to one probability distribution, given a sample from another. It is often referred as {\\it importance sampling} in statistical inference and is  also closely related to the problem of {\\it covariate shift} in transfer learning as well as to various MCMC methods. Our approach is based on reformulating the problem of estimating the ratio as an inverse problem in terms of an integral operator corresponding to a kernel, and thus reducing it to an integral equation, known as the Fredholm problem of the first kind.   This formulation, combined with the techniques of regularization and kernel methods, leads to a principled kernel-based framework for constructing algorithms and for analyzing them theoretically.  The resulting family of algorithms (FIRE, for Fredholm Inverse Regularized Estimator) is flexible,  simple and  easy to implement. We provide detailed theoretical analysis including concentration bounds and convergence rates for the Gaussian kernel for densities defined on $\\R^d$ and smooth $d$-dimensional sub-manifolds of the Euclidean space. Model selection for unsupervised or semi-supervised inference is generally a difficult problem. Interestingly, it turns out that in the density ratio estimation setting, when samples from both distributions are available, there are simple completely unsupervised methods for choosing parameters. We  call this model selection mechanism CD-CV for Cross-Density Cross-Validation. Finally, we show encouraging experimental results including applications to classification  within the covariate shift framework."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse nonnegative deconvolution for compressive calcium imaging", "Title": "algorithms and phase transitions", "Abstract": "We propose a compressed sensing (CS) calcium imaging framework for monitoring large neuronal populations, where we image randomized projections of the spatial calcium concentration at each timestep, instead of measuring the concentration at individual locations. We develop scalable nonnegative deconvolution methods for extracting the neuronal spike time series from such observations. We also address the problem of demixing the spatial locations of the neurons using rank-penalized matrix factorization methods. By exploiting the sparsity of neural spiking we demonstrate that the number of measurements needed per timestep is significantly smaller than the total number of neurons, a result that can potentially enable imaging of larger populations at considerably faster rates compared to traditional raster-scanning techniques. Unlike traditional CS setups, our problem involves a block-diagonal sensing matrix and a non-orthogonal sparse basis that spans multiple timesteps. We study the effect of these distinctive features in a noiseless setup using recent results relating conic geometry to CS. We provide tight approximations to the number of measurements needed for perfect deconvolution for certain classes of spiking processes, and show that this number displays a phase transition,\" similar to phenomena observed in more standard CS settings; however, in this case the required measurement rate depends not just on the mean sparsity level but also on other details of the underlying spiking process.\""}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reservoir Boosting ", "Title": "Between Online and Offline Ensemble Learning", "Abstract": "We propose to train an ensemble with the help of a reservoir in which the learning algorithm can store a limited number of samples. This novel approach lies in the area between offline and online ensemble approaches and can be seen either as a restriction of the former or an enhancement of the latter.  We identify some basic strategies that can be used to populate this reservoir and present our main contribution, dubbed Greedy Edge Expectation Maximization (GEEM), that maintains the reservoir content in the case of Boosting by viewing the samples through their projections into the weak classifier response space.  We propose an efficient algorithmic implementation which makes it tractable in practice, and demonstrate its efficiency experimentally on several compute-vision data-sets, on which it outperforms both online and offline methods in a memory constrained setting."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Decision Jungles", "Title": "Compact and Rich Models for Classification", "Abstract": "Randomized decision trees and forests have a rich history in machine learning and have seen considerable success in application, perhaps particularly so for computer vision. However, they face a fundamental limitation: given enough data, the number of nodes in decision trees will grow exponentially with depth. For certain applications, for example on mobile or embedded processors, memory is a limited resource, and so the exponential growth of trees limits their depth, and thus their potential accuracy. This paper proposes decision jungles, revisiting the idea of ensembles of rooted decision directed acyclic graphs (DAGs), and shows these to be compact and powerful discriminative models for classification. Unlike conventional decision trees that only allow one path to every node, a DAG in a decision jungle allows multiple paths from the root to each leaf. We present and compare two new node merging algorithms that jointly optimize both the features and the structure of the DAGs efficiently. During training, node splitting and node merging are driven by the minimization of exactly the same objective function, here the weighted sum of entropies at the leaves. Results on varied datasets show that, compared to decision forests and several other baselines, decision jungles require dramatically less memory while considerably improving generalization."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Forgetful Bayes and myopic planning", "Title": "Human learning and decision-making in a bandit setting", "Abstract": "How humans achieve long-term goals in an uncertain environment, via repeated trials and noisy observations, is an important problem in cognitive science. We investigate this behavior in the context of a multi-armed bandit task. We compare human behavior to a variety of models that vary in their representational and computational complexity. Our result shows that subjects' choices, on a trial-to-trial basis, are best captured by a forgetful\" Bayesian iterative learning model in combination with a partially myopic decision policy known as Knowledge Gradient. This model accounts for subjects' trial-by-trial choice better than a number of other previously proposed models, including optimal Bayesian learning and risk minimization, epsilon-greedy and win-stay-lose-shift. It has the added benefit of being closest in performance to the optimal Bayesian model than all the other heuristic models that have the same computational complexity (all are significantly less complex than the optimal model). These results constitute an advancement in the theoretical understanding of how humans negotiate the tension between exploration and exploitation in a noisy, imperfectly known environment.\""}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Embed and Project", "Title": "Discrete Sampling with Universal Hashing", "Abstract": "We consider the problem of sampling from a probability distribution defined over a high-dimensional discrete set, specified for instance by a graphical model. We propose a sampling algorithm, called PAWS, based on embedding the set into a higher-dimensional space which is then randomly projected using universal hash functions to a lower-dimensional subspace and explored using combinatorial search methods. Our scheme can leverage fast combinatorial optimization tools as a blackbox and, unlike MCMC methods, samples produced are guaranteed to be within an (arbitrarily small) constant factor of the true probability distribution. We demonstrate that by using state-of-the-art combinatorial search tools, PAWS can efficiently sample from Ising grids with strong interactions and from software verification instances, while MCMC and variational methods fail in both cases."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Correlations strike back (again)", "Title": "the case of associative memory retrieval", "Abstract": "It has long been recognised that statistical dependencies in neuronal activity need to be taken into account when decoding stimuli encoded in a neural population. Less studied, though equally pernicious, is the need to take account of dependencies between synaptic weights when decoding patterns previously encoded in an auto-associative memory. We show that activity-dependent learning generically produces such correlations, and failing to take them into account in the dynamics of memory retrieval leads to catastrophically poor recall. We derive optimal network dynamics for recall in the face of synaptic correlations caused by a range of synaptic plasticity rules. These dynamics involve well-studied circuit motifs, such as forms of feedback inhibition and experimentally observed dendritic nonlinearities. We therefore show how addressing the problem of synaptic correlations leads to a novel functional account of key biophysical features of the neural substrate."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeViSE", "Title": "A Deep Visual-Semantic Embedding Model", "Abstract": "Modern visual recognition systems are often limited in their ability to scale to large numbers of object categories. This limitation is in part due to the increasing difficulty of acquiring sufficient training data in the form of labeled images as the number of object categories grows. One remedy is to leverage data from other sources -- such as text data -- both to train visual models and to constrain their predictions. In this paper we present a new deep visual-semantic embedding model trained to identify visual objects using both labeled image data as well as semantic information gleaned from unannotated text. We demonstrate that this model matches state-of-the-art performance on the 1000-class ImageNet object recognition challenge while making more semantically reasonable errors, and also show that the semantic information can be exploited to make predictions about tens of thousands of image labels not observed during training. Semantic knowledge improves such zero-shot predictions by up to 65%, achieving hit rates of up to 10% across thousands of novel labels never seen by the visual model."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "q-OCSVM", "Title": "A q-Quantile Estimator for High-Dimensional Distributions", "Abstract": "In this paper we introduce a novel method that can efficiently estimate a family of hierarchical dense sets in high-dimensional distributions. Our method can be regarded as a natural extension of the one-class SVM (OCSVM) algorithm that finds multiple parallel separating hyperplanes in a reproducing kernel Hilbert space. We call our method q-OCSVM, as it can be used to estimate $q$ quantiles of a high-dimensional distribution. For this purpose, we introduce a new global convex optimization program that finds all estimated sets at once and show that it can be solved efficiently. We prove the correctness of our method and present empirical results that demonstrate its superiority over existing methods."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fantope Projection and Selection", "Title": "A near-optimal convex relaxation of sparse PCA", "Abstract": "We propose a novel convex relaxation of sparse principal subspace estimation based on the convex hull of rank-$d$ projection matrices (the Fantope). The convex problem can be solved efficiently using alternating direction method of multipliers (ADMM). We establish a near-optimal convergence rate, in terms of the sparsity, ambient dimension, and sample size, for estimation of the principal subspace of a general covariance matrix without assuming the spiked covariance model. In the special case of $d=1$, our result implies the near- optimality of DSPCA even when the solution is not rank 1. We also provide a general theoretical framework for analyzing the statistical  properties of the method for arbitrary input matrices that extends the  applicability and provable guarantees to a wide array of settings.  We  demonstrate this with an application to Kendall's tau correlation matrices  and transelliptical component analysis."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Submodular Maximization", "Title": "Identifying Representative Elements in Massive Data", "Abstract": "Many large-scale machine learning problems (such as clustering, non-parametric learning, kernel machines, etc.) require selecting, out of a massive data set, a manageable, representative subset. Such problems can often be reduced to maximizing a submodular set function subject to cardinality constraints. Classical approaches require centralized access to the full data set; but for truly large-scale problems, rendering the data centrally is often impractical.  In this paper, we consider the problem of submodular function maximization in a distributed fashion. We develop a simple, two-stage protocol GreeDI, that is easily implemented using MapReduce style computations. We theoretically analyze our approach, and show, that under certain natural conditions, performance close to the (impractical) centralized approach can be achieved. In our extensive experiments, we demonstrate the effectiveness of our approach on several applications, including sparse Gaussian process inference on tens of millions of examples using Hadoop."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Bandits to Experts", "Title": "A Tale of Domination and Independence", "Abstract": "We consider the partial observability model for multi-armed bandits, introduced by Mannor and Shamir (2011). Our main result is a characterization of regret in the directed observability model in terms of the dominating and independence numbers of the observability graph. We also show that in the undirected case, the learner can achieve optimal regret without even accessing the observability graph before selecting an action. Both results are shown using variants of the Exp3 algorithm operating on the observability graph in a time-efficient manner."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "B-test", "Title": "A Non-parametric, Low Variance Kernel Two-sample Test", "Abstract": "We propose a family of maximum mean discrepancy (MMD) kernel two-sample tests that have low sample complexity and are consistent. The test has a hyperparameter that allows one to control the tradeoff between sample complexity and computational time. Our family of tests, which we denote as B-tests, is both computationally and statistically efficient, combining favorable properties of previously proposed MMD two-sample tests.  It does so by better leveraging samples to produce low variance estimates in the finite sample case, while avoiding a quadratic number of kernel evaluations and complex null-hypothesis approximation as would be required by tests relying on one sample U-statistics. The B-test uses a smaller than quadratic number of kernel evaluations and avoids completely the computational burden of complex null-hypothesis approximation while maintaining consistency and probabilistically conservative thresholds on Type I error. Finally, recent results of combining multiple kernels transfer seamlessly to our hypothesis test, allowing a further increase in discriminative power and decrease in sample complexity."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sinkhorn Distances", "Title": "Lightspeed Computation of Optimal Transport", "Abstract": "Optimal transportation distances are a fundamental family of parameterized distances for histograms in the probability simplex. Despite their appealing theoretical properties, excellent performance and intuitive formulation, their computation involves the resolution of a linear program whose cost is prohibitive whenever the histograms' dimension exceeds a few hundreds. We propose in this work a new family of optimal transportation distances that look at transportation problems from a maximum-entropy perspective. We smooth the classical optimal transportation problem with an entropic regularization term, and show that the resulting optimum is also a distance which can be computed through Sinkhorn's matrix scaling algorithm at a speed that is several orders of magnitude faster than that of transportation solvers. We also report improved performance on the MNIST benchmark problem over competing distances."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic blockmodel approximation of a graphon", "Title": "Theory and consistent estimation", "Abstract": "Given a convergent sequence of graphs, there exists a limit object called the graphon from which random graphs are generated. This nonparametric perspective of random graphs opens the door to study graphs beyond the traditional parametric models, but at the same time also poses the challenging question of how to estimate the graphon underlying observed graphs. In this paper, we propose a computationally efficient algorithm to estimate a graphon from a set of observed graphs generated from it. We show that, by approximating the graphon with stochastic block models, the graphon can be consistently estimated, that is, the estimation error vanishes as the size of the graph approaches infinity."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DESPOT", "Title": "Online POMDP Planning with Regularization", "Abstract": "POMDPs provide a principled framework for planning under uncertainty, but are computationally intractable, due to the “curse of dimensionality” and the “curse of history”. This paper presents an online lookahead search algorithm that alleviates these difficulties by limiting the search to a set of sampled scenarios. The execution of all policies on the sampled scenarios is summarized using a Determinized Sparse Partially Observable Tree (DESPOT), which is a sparsely sampled belief tree. Our algorithm, named Regularized DESPOT (R-DESPOT), searches the DESPOT for a policy that optimally balances the size of the policy and the accuracy on its value estimate obtained through sampling. We give an output-sensitive performance bound for all policies derived from the DESPOT, and show that R-DESPOT works well if a small optimal policy exists. We also give an anytime approximation to R-DESPOT. Experiments show strong results, compared with two of the fastest online POMDP algorithms."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural representation of action sequences", "Title": "how far can a simple snippet-matching model take us?", "Abstract": "The macaque Superior Temporal Sulcus (STS) is a brain area that receives and integrates inputs from both the ventral and dorsal visual processing streams (thought to specialize in form and motion processing respectively). For the processing of articulated actions, prior work has shown that even a small population of STS neurons contains sufficient information for the decoding of actor invariant to action, action invariant to actor, as well as the specific conjunction of actor and action. This paper addresses two questions. First, what are the invariance properties of individual neural representations (rather than the population representation) in STS? Second, what are the neural encoding mechanisms that can produce such individual neural representations from streams of pixel images? We find that a baseline model, one that simply computes a linear weighted sum of ventral and dorsal responses to short action “snippets”, produces surprisingly good fits to the neural data. Interestingly, even using inputs from a single stream, both actor-invariance and action-invariance can be produced simply by having different linear weights."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scoring Workers in Crowdsourcing", "Title": "How Many Control Questions are Enough?", "Abstract": "We study the problem of estimating continuous quantities, such as prices, probabilities, and point spreads, using a crowdsourcing approach.  A challenging aspect of combining the crowd's answers is that workers' reliabilities and biases are usually unknown and highly diverse.  Control items with known answers can be used to evaluate workers' performance, and hence improve the combined results on the target items with unknown answers.  This raises the problem of how many control items to use when the total number of items each workers can answer is limited: more control items evaluates the workers better, but leaves fewer resources for the target items that are of direct interest, and vice versa. We give theoretical results for this problem under different scenarios, and provide a simple rule of thumb for crowdsourcing practitioners.  As a byproduct, we also provide theoretical analysis of the accuracy of different consensus methods."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Visual Concept Learning", "Title": "Combining Machine Vision and Bayesian Generalization on Concept Hierarchies", "Abstract": "Learning a visual concept from a small number of positive examples is a significant challenge for machine learning algorithms. Current methods typically fail to find the appropriate level of generalization in a concept hierarchy for a given set of visual examples. Recent work in cognitive science on Bayesian models of generalization addresses this challenge, but prior results assumed that objects were perfectly  recognized. We present an algorithm for learning visual concepts directly from images, using  probabilistic predictions generated by visual classifiers as the input to a Bayesian generalization model. As no existing challenge data tests this paradigm, we collect and make available a new, large-scale dataset for visual concept learning using the ImageNet hierarchy as the source of possible concepts, with human annotators to provide ground truth labels as to whether a new image is an instance of each concept using a paradigm similar to that used in experiments studying word learning in children.  We compare the performance of our system to several baseline algorithms, and show a significant advantage results from combining visual classifiers with the ability to identify an appropriate level of abstraction using Bayesian generalization."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "When in Doubt, SWAP", "Title": "High-Dimensional Sparse Recovery from Correlated Measurements", "Abstract": "We consider the problem of accurately estimating a high-dimensional sparse vector using a small number of linear measurements that are contaminated by noise.  It is well known that standard computationally tractable sparse recovery algorithms, such as the Lasso, OMP, and their various extensions, perform poorly when the measurement matrix contains highly correlated columns.  We develop a simple greedy algorithm, called SWAP, that iteratively swaps variables until a desired loss function cannot be decreased any further.  SWAP is surprisingly effective in handling measurement matrices with high correlations.  We prove that SWAP can be easily used as a wrapper around standard sparse recovery algorithms for improved performance.  We theoretically quantify the statistical guarantees of SWAP and complement our analysis with numerical results on synthetic and real data."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Trading Computation for Communication", "Title": "Distributed Stochastic Dual Coordinate Ascent", "Abstract": "We present and study a distributed optimization algorithm by employing  a stochastic dual coordinate ascent method. Stochastic dual coordinate ascent methods enjoy strong theoretical guarantees and often have better performances than stochastic gradient descent methods in optimizing regularized loss minimization problems. It still lacks of efforts in studying them in a distributed framework. We make a progress along the line by presenting a distributed stochastic dual coordinate ascent algorithm in a star network, with an analysis of the tradeoff between  computation and  communication. We verify  our analysis by experiments on real data sets. Moreover, we compare the proposed algorithm with distributed stochastic gradient descent methods and distributed alternating direction methods of multipliers for optimizing SVMs in the same distributed framework, and observe competitive performances."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Policy Shaping", "Title": "Integrating Human Feedback with Reinforcement Learning", "Abstract": "A long term goal of Interactive Reinforcement Learning is to incorporate non-expert human feedback to solve complex tasks. State-of-the-art methods have approached this problem by mapping human information to reward and value signals to indicate preferences and then iterating over them to compute the necessary control policy. In this paper we argue for an alternate, more effective characterization of human feedback: Policy Shaping. We introduce Advise, a Bayesian approach that attempts to maximize the information gained from human feedback by utilizing it as direct labels on the policy. We compare Advise to state-of-the-art approaches and highlight scenarios where it outperforms them and importantly is robust to infrequent and inconsistent human feedback."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Speedup Matrix Completion with Side Information", "Title": "Application to Multi-Label Learning", "Abstract": "In standard matrix completion theory, it is required to have at least $O(n\\ln^2 n)$ observed entries to perfectly recover a low-rank matrix $M$ of size $n\\times n$, leading to a large number of observations when $n$ is large. In many real tasks, side information in addition to the observed entries is often available. In this work, we develop a novel theory of matrix completion that explicitly explore the side information to reduce the requirement on the number of observed entries. We show that, under appropriate conditions, with the assistance of side information matrices, the number of observed entries needed for a perfect recovery of matrix $M$ can be dramatically reduced to $O(\\ln n)$. We demonstrate the effectiveness of the proposed approach for matrix completion in transductive incomplete multi-label learning."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Binary to Bushy", "Title": "Bayesian Hierarchical Clustering with the Beta Coalescent", "Abstract": "Discovering hierarchical regularities in data is a key problem in interacting   with large datasets, modeling cognition, and encoding knowledge. A previous   Bayesian solution---Kingman's coalescent---provides a convenient probabilistic   model for data represented as a binary tree. Unfortunately, this is   inappropriate for data better described by bushier trees. We generalize an   existing belief propagation framework of Kingman's coalescent to the   beta coalescent, which models a wider range of tree structures.   Because of the complex combinatorial search over possible structures, we   develop new sampling schemes using sequential Monte Carlo and Dirichlet   process mixture models, which render inference efficient and tractable.     We present results on both synthetic and real data that show the beta coalescent      outperforms Kingman's coalescent on real datasets and is qualitatively better at    capturing data in bushy hierarchies."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Density estimation from unweighted k-nearest neighbor graphs", "Title": "a roadmap", "Abstract": "Consider an unweighted k-nearest neighbor graph   on n points that have been sampled i.i.d. from some unknown density p on R^d. We prove how one can estimate the density p just from the unweighted adjacency matrix of the graph, without knowing the points themselves or their distance or similarity scores. The key insights are that local differences in link numbers can be used to estimate some local function of p, and that integrating this function along shortest paths leads to an estimate of the underlying density."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularized M-estimators with nonconvexity", "Title": "Statistical and algorithmic theory for local optima", "Abstract": "We establish theoretical results concerning all local optima of various regularized M-estimators, where both loss and penalty functions are allowed to be nonconvex. Our results show that as long as the loss function satisfies restricted strong convexity and the penalty function satisfies suitable regularity conditions, any local optimum of the composite objective function lies within statistical precision of the true parameter vector. Our theory covers a broad class of nonconvex objective functions, including corrected versions of the Lasso for errors-in-variables linear models; regression in generalized linear models using nonconvex regularizers such as SCAD and MCP; and graph and inverse covariance matrix estimation. On the optimization side, we show that a simple adaptation of composite gradient descent may be used to compute a global optimum up to the statistical precision epsilon in log(1/epsilon) iterations, which is the fastest possible rate of any first-order method. We provide a variety of simulations to illustrate the sharpness of our theoretical predictions."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Provable Subspace Clustering", "Title": "When LRR meets SSC", "Abstract": "Sparse Subspace Clustering (SSC) and Low-Rank Representation (LRR) are both considered as the state-of-the-art methods for {\\em subspace clustering}. The two methods are fundamentally similar in that both are convex optimizations exploiting the intuition of Self-Expressiveness''. The main difference is that SSC minimizes the vector $\\ell_1$ norm of the representation matrix to induce sparsity while LRR minimizes nuclear norm (aka trace norm) to promote a low-rank structure. Because the representation matrix is often simultaneously sparse and low-rank,  we propose a new algorithm, termed Low-Rank Sparse Subspace Clustering (LRSSC), by combining SSC and LRR, and develops theoretical guarantees of when the algorithm succeeds. The results reveal interesting insights into the strength and weakness of SSC and LRR and demonstrate how LRSSC can take the advantages of both methods in preserving the \"Self-Expressiveness Property'' and \"Graph Connectivity'' at the same time.\""}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Pairwise", "Title": "Provably Fast Algorithms for Approximate $k$-Way  Similarity Search", "Abstract": "We go beyond the notion of pairwise similarity and look into  search problems with $k$-way similarity functions. In this paper, we focus on problems related to  \\emph{3-way Jaccard} similarity: $\\mathcal{R}^{3way}= \\frac{|S_1 \\cap S_2 \\cap S_3|}{|S_1 \\cup S_2 \\cup S_3|}$, $S_1, S_2, S_3 \\in \\mathcal{C}$, where $\\mathcal{C}$ is a size $n$ collection of sets (or binary vectors).  We show that approximate $\\mathcal{R}^{3way}$ similarity search problems admit  fast algorithms with  provable guarantees, analogous to the pairwise case. Our analysis and speedup guarantees naturally extend to $k$-way resemblance. In the process, we extend traditional framework of \\emph{locality sensitive hashing (LSH)} to handle higher order similarities, which could be of independent theoretical interest. The applicability of $\\mathcal{R}^{3way}$ search is shown on the Google sets\" application. In addition, we demonstrate the advantage of $\\mathcal{R}^{3way}$ resemblance over the pairwise case in improving retrieval quality.\""}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How to Hedge an Option Against an Adversary", "Title": "Black-Scholes Pricing is Minimax Optimal", "Abstract": "We consider a popular problem in finance, option pricing, through the lens of an online learning game between Nature and an Investor.  In the Black-Scholes option pricing model from 1973, the Investor can continuously hedge the risk of an option by trading the underlying asset, assuming that the asset's price fluctuates according to Geometric Brownian Motion (GBM). We consider a worst-case model, in which Nature chooses a sequence of price fluctuations under a cumulative quadratic volatility constraint, and the Investor can make a sequence of hedging decisions. Our main result is to show that the value of our proposed game, which is the regret'' of hedging strategy, converges to the Black-Scholes option price. We use significantly weaker assumptions than previous work---for instance, we allow large jumps in the asset price---and show that the Black-Scholes hedging strategy is near-optimal for the Investor even in this non-stochastic framework.\""}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "QUIC & DIRTY", "Title": "A Quadratic Approximation Approach for Dirty Statistical Models", "Abstract": "In this paper, we develop a family of algorithms for optimizing superposition-structured” or “dirty” statistical estimators for high-dimensional problems involving the minimization of the sum of a smooth loss function with a hybrid regularization. Most of the current approaches are first-order methods, including proximal gradient or Alternating Direction Method of Multipliers (ADMM). We propose a new family of second-order methods where we approximate the loss function using quadratic approximation. The superposition structured regularizer then leads to a subproblem that can be efficiently solved by alternating minimization. We propose a general active subspace selection approach to speed up the solver by utilizing the low-dimensional structure given by the regularizers, and provide convergence guarantees for our algorithm. Empirically, we show that our approach is more than 10 times faster than state-of-the-art first-order approaches for the latent variable graphical model selection problems and multi-task learning problems when there is more than one regularizer. For these problems, our approach appears to be the first algorithm that can extend active subspace ideas to multiple regularizers.\""}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On a Theory of Nonparametric Pairwise Similarity for Clustering", "Title": "Connecting Clustering to Classification", "Abstract": "Pairwise clustering methods partition the data space into clusters by the pairwise similarity between data points. The success of pairwise clustering largely depends on the pairwise similarity function defined over the data points, where kernel similarity is broadly used. In this paper, we present a novel pairwise clustering framework by bridging the gap between clustering and multi-class classification. This pairwise clustering framework learns an unsupervised nonparametric classifier from each data partition, and search for the optimal partition of the data by minimizing the generalization error of the learned classifiers associated with the data partitions. We consider two nonparametric classifiers in this framework, i.e. the nearest neighbor classifier and the plug-in classifier. Modeling the underlying data distribution by nonparametric kernel density estimation, the generalization error bounds for both unsupervised nonparametric classifiers are the sum of nonparametric pairwise similarity terms between the data points for the purpose of clustering. Under uniform distribution, the nonparametric similarity terms induced by both unsupervised classifiers exhibit a well known form of kernel similarity. We also prove that the generalization error bound for the unsupervised plug-in classifier is asymptotically equal to the weighted volume of cluster boundary for Low Density Separation, a widely used criteria for semi-supervised learning and clustering. Based on the derived nonparametric pairwise similarity using the plug-in classifier, we propose a new nonparametric exemplar-based clustering method with enhanced discriminative capability, whose superiority is evidenced by the experimental results."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Expectation Backpropagation", "Title": "Parameter-Free Training of Multilayer Neural Networks with Continuous or Discrete Weights", "Abstract": "Multilayer Neural Networks (MNNs) are commonly trained using gradient descent-based methods, such as BackPropagation (BP). Inference in probabilistic graphical models is often done using variational Bayes methods, such as Expectation Propagation (EP). We show how an EP based approach can also be used to train deterministic MNNs. Specifically, we approximate the posterior of the weights given the data using a “mean-field” factorized distribution, in an online setting. Using online EP and the central limit theorem we find an analytical approximation to the Bayes update of this posterior, as well as the resulting Bayes estimates of the weights and outputs. Despite a different origin, the resulting algorithm, Expectation BackPropagation (EBP), is very similar to BP in form and efficiency. However, it has several additional advantages: (1) Training is parameter-free, given initial conditions (prior) and the MNN architecture. This is useful for large-scale problems, where parameter tuning is a major challenge. (2) The weights can be restricted to have discrete values. This is especially useful for implementing trained MNNs in precision limited hardware chips, thus improving their speed and energy efficiency by several orders of magnitude. We test the EBP algorithm numerically in eight binary text classification tasks. In all tasks, EBP outperforms: (1) standard BP with the optimal constant learning rate (2) previously reported state of the art. Interestingly, EBP-trained MNNs with binary weights usually perform better than MNNs with continuous (real) weights - if we average the MNN output using the inferred posterior."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LSDA", "Title": "Large Scale Detection through Adaptation", "Abstract": "A major challenge in scaling object detection is the difficulty of obtaining labeled images for large numbers of categories. Recently, deep convolutional neural networks (CNNs) have emerged as clear winners on object classification benchmarks, in part due to training with 1.2M+ labeled classification images. Unfortunately, only a small fraction of those labels are available for the detection task. It is much cheaper and easier to collect large quantities of image-level labels from search engines than it is to collect detection data and label it with precise bounding boxes. In this paper, we propose Large Scale Detection through Adaptation (LSDA), an algorithm which learns the difference between the two tasks and transfers this knowledge to classifiers for categories without bounding box annotated data, turning them into detectors. Our method has the potential to enable detection for the tens of thousands of categories that lack bounding box annotations, yet have plenty of classification data. Evaluation on the ImageNet LSVRC-2013 detection challenge demonstrates the efficacy of our approach. This algorithm enables us to produce a >7.6K detector by using available classification data from leaf nodes in the ImageNet tree. We additionally demonstrate how to modify our architecture to produce a fast detector (running at 2fps for the 7.6K detector). Models and software are available at"}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Extracting Certainty from Uncertainty", "Title": "Transductive Pairwise Classification from Pairwise Similarities", "Abstract": "In this work, we study the problem of transductive pairwise classification from pairwise similarities~\\footnote{The pairwise similarities are usually derived from some side information instead of the underlying class labels.}. The goal of transductive pairwise classification from pairwise similarities is to infer the pairwise class relationships, to which we refer as pairwise labels, between all examples given a subset of class relationships for a small set of examples, to which we refer as labeled examples. We propose a very simple yet effective algorithm that consists of two simple steps: the first step is to complete the sub-matrix corresponding to the labeled examples and the second step is to reconstruct the label matrix from the completed sub-matrix and the provided similarity matrix. Our analysis exhibits that under several mild preconditions we can recover the label matrix with a small error, if the top eigen-space that corresponds to the largest eigenvalues of the similarity matrix covers well the column space of label matrix and is subject to a low coherence, and the number of observed pairwise labels is sufficiently enough. We demonstrate the effectiveness of the proposed algorithm by several experiments."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-View Perceptron", "Title": "a Deep Model for Learning Face Identity and View Representations", "Abstract": "Various factors, such as identities, views (poses), and illuminations, are coupled in face images. Disentangling the identity and view representations is a major challenge in face recognition. Existing face recognition systems either use handcrafted features or learn features discriminatively to improve recognition accuracy. This is different from the behavior of human brain. Intriguingly, even without accessing 3D data, human not only can recognize face identity, but can also imagine face images of a person under different viewpoints given a single 2D image, making face perception in the brain robust to view changes. In this sense, human brain has learned and encoded 3D face models from 2D images. To take into account this instinct, this paper proposes a novel deep neural net, named multi-view perceptron (MVP), which can untangle the identity and view features, and infer a full spectrum of multi-view images in the meanwhile, given a single 2D face image. The identity features of MVP achieve superior performance on the MultiPIE dataset. MVP is also capable to interpolate and predict images under viewpoints that are unobserved in the training data."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PEWA", "Title": "Patch-based Exponentially Weighted Aggregation for image denoising", "Abstract": "Patch-based methods have been widely used for noise reduction in recent years. In this paper, we propose a general statistical aggregation method which combines image patches denoised with several commonly-used algorithms. We show that weakly denoised versions of the input image obtained with standard methods, can serve to compute an efficient patch-based aggregated estimd aggregation (EWA) estimator. The resulting approach (PEWA) is based on a MCMC sampling and has a nice statistical foundation while producing denoising results that are comparable to the current state-of-the-art. We demonstrate the performance of the denoising algorithm on real images and we compare the results to several competitive methods."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attentional Neural Network", "Title": "Feature Selection Using Cognitive Feedback", "Abstract": "Attentional Neural Network is a new framework that integrates top-down cognitive bias and bottom-up feature extraction in one coherent architecture. The top-down influence is especially effective when dealing with high noise or difficult segmentation problems. Our system is modular and extensible. It is also easy to train and cheap to run, and yet can accommodate complex behaviors. We obtain classification accuracy better than or competitive with state of art results on the MNIST variation dataset, and successfully disentangle overlaid digits with high success rates. We view such a general purpose framework as an essential foundation for a larger system emulating the cognitive abilities of the whole brain."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Blinded Bandit", "Title": "Learning with Adaptive Feedback", "Abstract": "We study an online learning setting where the player is temporarily deprived of feedback each time it switches to a different action. Such model of \\emph{adaptive feedback} naturally occurs in scenarios where the environment reacts to the player's actions and requires some time to recover and stabilize after the algorithm switches actions. This motivates a variant of the multi-armed bandit problem, which we call the \\emph{blinded multi-armed bandit}, in which no feedback is given to the algorithm whenever it switches arms. We develop efficient online learning algorithms for this problem and prove that they guarantee the same asymptotic regret as the optimal algorithms for the standard multi-armed bandit problem. This result stands in stark contrast to another recent result, which states that adding a switching cost to the standard multi-armed bandit makes it substantially harder to learn, and provides a direct comparison of how feedback and loss contribute to the difficulty of an online learning problem. We also extend our results to the general prediction framework of bandit linear optimization, again attaining near-optimal regret bounds."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond the Birkhoff Polytope", "Title": "Convex Relaxations for Vector Permutation Problems", "Abstract": "The Birkhoff polytope (the convex hull of the set of permutation matrices), which is represented using $\\Theta(n^2)$ variables and constraints, is frequently invoked in formulating relaxations of optimization problems over permutations. Using a recent construction of Goemans (2010), we show that when optimizing over the convex hull of the permutation vectors (the permutahedron), we can reduce the number of variables and constraints to $\\Theta(n \\log n)$ in theory and $\\Theta(n \\log^2 n)$ in practice. We modify the recent convex formulation of the 2-SUM problem introduced by Fogel et al. (2013) to use this polytope, and demonstrate how we can attain results of similar quality in significantly less computational time for large $n$. To our knowledge, this is the first usage of Goemans' compact formulation of the permutahedron in a convex optimization problem. We also introduce a simpler regularization scheme for this convex formulation of the 2-SUM problem that yields good empirical results."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Poisson Process Jumping between an Unknown Number of Rates", "Title": "Application to Neural Spike Data", "Abstract": "We introduce a model where the rate of an inhomogeneous Poisson process is modified by a Chinese restaurant process. Applying a MCMC sampler to this model allows us to do posterior Bayesian inference about the number of states in Poisson-like data. Our sampler is shown to get accurate results for synthetic data and we apply it to V1 neuron spike data to find discrete firing rate states depending on the orientation of a stimulus."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Bayesian Case Model", "Title": "A Generative Approach for Case-Based Reasoning and Prototype Classification", "Abstract": "We present the Bayesian Case Model (BCM), a general framework for Bayesian case-based reasoning (CBR) and prototype classification and clustering. BCM brings the intuitive power of CBR to a Bayesian generative framework. The BCM learns prototypes, the ``quintessential observations that best represent clusters in a dataset, by performing joint inference on cluster labels, prototypes and important features. Simultaneously, BCM pursues sparsity by learning subspaces, the sets of features that play important roles in the characterization of the prototypes. The prototype and subspace representation provides quantitative benefits in interpretability while preserving classification accuracy. Human subject experiments verify statistically significant improvements to participants' understanding when using explanations produced by BCM, compared to those given by prior art.\""}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Graph Clustering With Missing Data", "Title": "Convex Algorithms and Analysis", "Abstract": "We consider the problem of finding clusters in an unweighted graph, when the graph is partially observed. We analyze two programs, one which works for dense graphs and one which works for both sparse and dense graphs, but requires some a priori knowledge of the total cluster size, that are based on the convex optimization approach for low-rank matrix recovery using nuclear norm minimization. For the commonly used Stochastic Block Model, we obtain \\emph{explicit} bounds on the parameters of the problem (size and sparsity of clusters, the amount of observed data) and the regularization parameter characterize the success and failure of the programs. We corroborate our theoretical findings through extensive simulations. We also run our algorithm on a real data set obtained from crowdsourcing an image classification task on the Amazon Mechanical Turk, and observe significant performance improvement over traditional methods such as k-means."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analysis of Variational Bayesian Latent Dirichlet Allocation", "Title": "Weaker Sparsity Than MAP", "Abstract": "Latent Dirichlet allocation (LDA) is a popular generative model of various objects such as texts and images, where an object is expressed as a mixture of latent topics. In this paper, we theoretically investigate variational Bayesian (VB) learning in LDA. More specifically, we analytically derive the leading term of the VB free energy under an asymptotic setup, and show that there exist transition thresholds in Dirichlet hyperparameters around which the sparsity-inducing behavior drastically changes. Then we further theoretically reveal the notable phenomenon that VB tends to induce weaker sparsity than MAP in the LDA model, which is opposed to other models. We experimentally demonstrate the practical validity of our asymptotic theory on real-world Last.FM music data."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Power-law Graph Computing", "Title": "Theoretical and Empirical Analysis", "Abstract": "With the emergence of big graphs in a variety of real applications like social networks, machine learning based on distributed graph-computing~(DGC) frameworks has attracted much attention from big data machine learning community. In DGC frameworks, the graph partitioning~(GP) strategy plays a key role to affect the performance, including the workload balance and communication cost. Typically, the degree distributions of natural graphs from real applications follow skewed power laws, which makes GP a challenging task. Recently, many methods have been proposed to solve the GP problem. However, the existing GP methods cannot achieve satisfactory performance for applications with power-law graphs. In this paper, we propose a novel vertex-cut method, called \\emph{degree-based hashing}~(DBH), for GP. DBH makes effective use of the skewed degree distributions for GP. We theoretically prove that DBH can achieve lower communication cost than existing methods and can simultaneously guarantee good workload balance. Furthermore, empirical results on several large power-law graphs also show that DBH can outperform the state of the art."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Transportability from Multiple Environments with Limited Experiments", "Title": "Completeness Results", "Abstract": "This paper addresses the problem of $mz$-transportability, that is, transferring causal knowledge collected in several heterogeneous domains to a target domain in which only passive observations and limited experimental data can be collected. The paper first establishes a necessary and sufficient condition for deciding the feasibility of $mz$-transportability, i.e., whether causal effects in the target domain are estimable from the information available. It further proves that a previously established algorithm for computing transport formula is in fact complete, that is, failure of the algorithm implies non-existence of a transport formula. Finally, the paper shows that the do-calculus is complete for the $mz$-transportability class."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multitask learning meets tensor factorization", "Title": "task imputation via convex optimization", "Abstract": "We study a multitask learning problem in which each task is parametrized by a weight vector and indexed by a pair of indices, which can be e.g, (consumer, time). The weight vectors can be collected into a tensor and the (multilinear-)rank of the tensor controls the amount of sharing of information among tasks. Two types of convex relaxations have recently been proposed for the tensor multilinear rank. However, we argue that both of them are not optimal in the context of multitask learning in which the dimensions or multilinear rank are typically heterogeneous. We propose a new norm, which we call the scaled latent trace norm and analyze the excess risk of all the three norms. The results apply to various settings including matrix and tensor completion, multitask learning, and multilinear multitask learning. Both the theory and experiments support the advantage of the new norm when the tensor is not equal-sized and we do not a priori know which mode is low rank."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mind the Nuisance", "Title": "Gaussian Process Classification using Privileged Noise", "Abstract": "The learning with privileged information setting has recently attracted a lot of attention within the machine learning community, as it allows the integration of additional knowledge into the training process of a classifier, even when this comes in the form of a data modality that is not available at test time. Here, we show that privileged information can naturally be treated as noise in the latent function of a Gaussian process classifier (GPC). That is, in contrast to the standard GPC setting, the latent function is not just a nuisance but a feature: it becomes a natural measure of confidence about the training data by modulating the slope of the GPC probit likelihood function. Extensive experiments on public datasets show that the proposed GPC method using privileged noise, called GPC+, improves over a standard GPC without privileged knowledge, and also over the current state-of-the-art SVM-based method, SVM+. Moreover, we show that advanced neural networks and deep learning methods can be compressed as privileged information."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Noisy Power Method", "Title": "A Meta Algorithm with Applications", "Abstract": "We provide a new robust convergence analysis of the well-known power method for computing the dominant singular vectors of a matrix that we call noisy power method. Our result characterizes the convergence behavior of the algorithm when a large amount noise is introduced after each matrix-vector multiplication. The noisy power method can be seen as a meta-algorithm that has recently found a number of important applications in a broad range of machine learning problems including alternating minimization for matrix completion, streaming principal component analysis (PCA), and privacy-preserving spectral analysis. Our general analysis subsumes several existing ad-hoc convergence bounds and resolves a number of open problems in multiple applications. A recent work of Mitliagkas et al.~(NIPS 2013) gives a space-efficient algorithm for PCA in a streaming model where samples are drawn from a spiked covariance model. We give a simpler and more general analysis that applies to arbitrary distributions. Moreover, even in the spiked covariance model our result gives quantitative improvements in a natural parameter regime. As a second application, we provide an algorithm for differentially private principal component analysis that runs in nearly linear time in the input sparsity and achieves nearly tight worst-case error bounds. Complementing our worst-case bounds, we show that the error dependence of our algorithm on the matrix dimension can be replaced by an essentially tight dependence on the coherence of the matrix. This result resolves the main problem left open by Hardt and Roth (STOC 2013) and leads to strong average-case improvements over the optimal worst-case bound."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RAAM", "Title": "The Benefits of Robustness in Approximating Aggregated MDPs in Reinforcement Learning", "Abstract": "We describe how to use robust Markov decision processes for value function approximation with state aggregation. The robustness serves to reduce the sensitivity to the approximation error of sub-optimal policies in comparison to classical methods such as fitted value iteration. This results in reducing the bounds on the gamma-discounted infinite horizon performance loss by a factor of 1/(1-gamma) while preserving polynomial-time computational complexity. Our experimental results show that using the robust representation can significantly improve the solution quality with minimal additional computational cost."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tighten after Relax", "Title": "Minimax-Optimal Sparse PCA in Polynomial Time", "Abstract": "We provide statistical and computational analysis of sparse Principal Component Analysis (PCA) in high dimensions. The sparse PCA problem is highly nonconvex in nature. Consequently, though its global solution attains the optimal statistical rate of convergence, such solution is computationally intractable to obtain. Meanwhile, although its convex relaxations are tractable to compute, they yield estimators with suboptimal statistical rates of convergence. On the other hand, existing nonconvex optimization procedures, such as greedy methods, lack statistical guarantees. In this paper, we propose a two-stage sparse PCA procedure that attains the optimal principal subspace estimator in polynomial time. The main stage employs a novel algorithm named sparse orthogonal iteration pursuit, which iteratively solves the underlying nonconvex problem. However, our analysis shows that this algorithm only has desired computational and statistical guarantees within a restricted region, namely the basin of attraction. To obtain the desired initial estimator that falls into this region, we solve a convex formulation of sparse PCA with early stopping. Under an integrated analytic framework, we simultaneously characterize the computational and statistical performance of this two-stage procedure. Computationally, our procedure converges at the rate of $1/\\sqrt{t}$ within the initialization stage, and at a geometric rate within the main stage. Statistically, the final principal subspace estimator achieves the minimax-optimal statistical rate of convergence with respect to the sparsity level $s^*$, dimension $d$ and sample size $n$. Our procedure motivates a general paradigm of tackling nonconvex statistical learning problems with provable statistical guarantees."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spectral Methods meet EM", "Title": "A Provably Optimal Algorithm for Crowdsourcing", "Abstract": "The Dawid-Skene estimator has been widely used for inferring the true labels from the noisy labels provided by non-expert crowdsourcing workers. However, since the estimator maximizes a non-convex log-likelihood function, it is hard to theoretically justify its performance. In this paper, we propose a two-stage efficient algorithm for multi-class crowd labeling problems. The first stage uses the spectral method to obtain an initial estimate of parameters. Then the second stage refines the estimation by optimizing the objective function of the Dawid-Skene estimator via the EM algorithm. We show that our algorithm achieves the optimal convergence rate up to a logarithmic factor. We conduct extensive experiments on synthetic and real datasets. Experimental results demonstrate that the proposed algorithm is comparable to the most accurate empirical approach, while outperforming several other recently proposed methods."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From MAP to Marginals", "Title": "Variational Inference in Bayesian Submodular Models", "Abstract": "Submodular optimization has found many applications in machine learning and beyond. We carry out the first systematic investigation of inference in probabilistic models defined through submodular functions, generalizing regular pairwise MRFs and Determinantal Point Processes. In particular, we present L-Field, a variational approach to general log-submodular and log-supermodular distributions based on sub- and supergradients. We obtain both lower and upper bounds on the log-partition function, which enables us to compute probability intervals for marginals, conditionals and marginal likelihoods. We also obtain fully factorized approximate posteriors, at the same computational cost as ordinary submodular optimization. Our framework results in convex problems for optimizing over differentials of submodular functions, which we show how to optimally solve. We provide theoretical guarantees of the approximation quality with respect to the curvature of the function. We further establish natural relations between our variational approach and the classical mean-field method. Lastly, we empirically demonstrate the accuracy of our inference scheme on several submodular models."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Submodular meets Structured", "Title": "Finding Diverse Subsets in Exponentially-Large Structured Item Sets", "Abstract": "To cope with the high level of ambiguity faced in domains such as Computer Vision or Natural Language processing, robust prediction methods often search for a diverse set of high-quality candidate solutions or proposals. In structured prediction problems, this becomes a daunting task, as the solution space (image labelings, sentence parses, etc.) is exponentially large. We study greedy algorithms for finding a diverse subset of solutions in structured-output spaces by drawing new connections between submodular functions over combinatorial item sets and High-Order Potentials (HOPs) studied for graphical models. Specifically, we show via examples that when marginal gains of submodular diversity functions allow structured representations, this enables efficient (sub-linear time) approximate maximization by reducing the greedy augmentation step to inference in a factor graph with appropriately constructed HOPs. We discuss benefits, tradeoffs, and show that our constructions lead to significantly better proposals."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-Step Stochastic ADMM in High Dimensions", "Title": "Applications to Sparse Optimization and Matrix Decomposition", "Abstract": "In this paper, we consider a multi-step version of the stochastic ADMM method with efficient guarantees for high-dimensional problems. We first analyze the simple setting, where the optimization problem consists of a loss function and a single regularizer (e.g. sparse optimization), and then extend to the multi-block setting with multiple regularizers and multiple variables (e.g. matrix decomposition into sparse and low rank components). For the sparse optimization problem, our method achieves the minimax rate of $O(s\\log d/T)$ for $s$-sparse problems in $d$ dimensions in $T$ steps, and is thus, unimprovable by any method up to constant factors. For the matrix decomposition problem with a general loss function, we analyze the multi-step ADMM with multiple blocks. We establish $O(1/T)$ rate and efficient scaling as the size of matrix grows. For natural noise models (e.g. independent noise), our convergence rate is minimax-optimal. Thus, we establish tight convergence guarantees for multi-block ADMM in high dimensions. Experiments show that for both sparse optimization and matrix decomposition problems, our algorithm outperforms the state-of-the-art methods."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Finding a sparse vector in a subspace", "Title": "Linear sparsity using alternating directions", "Abstract": "We consider the problem of recovering the sparsest vector in a subspace $ \\mathcal{S} \\in \\mathbb{R}^p $ with $ \\text{dim}(\\mathcal{S})=n$. This problem can be considered a homogeneous variant of the sparse recovery problem, and finds applications in sparse dictionary learning, sparse PCA, and other problems in signal processing and machine learning. Simple convex heuristics for this problem provably break down when the fraction of nonzero entries in the target sparse vector substantially exceeds $1/ \\sqrt{n}$. In contrast, we exhibit a relatively simple nonconvex approach based on alternating directions, which provably succeeds even when the fraction of nonzero entries is $\\Omega(1)$. To our knowledge, this is the first practical algorithm to achieve this linear scaling. This result assumes a planted sparse model, in which the target sparse vector is embedded in an otherwise random subspace. Empirically, our proposed algorithm also succeeds in more challenging data models arising, e.g., from sparse dictionary learning."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalized Dantzig Selector", "Title": "Application to the k-support norm", "Abstract": "We propose a Generalized Dantzig Selector (GDS) for linear models, in which any norm encoding the parameter structure can be leveraged for estimation. We investigate both computational and statistical aspects of the GDS. Based on conjugate proximal operator, a flexible inexact ADMM framework is designed for solving GDS. Thereafter, non-asymptotic high-probability bounds are established on the estimation error, which rely on Gaussian widths of the unit norm ball and the error set. Further, we consider a non-trivial example of the GDS using k-support norm. We derive an efficient method to compute the proximal operator for k-support norm since existing methods are inapplicable in this setting. For statistical analysis, we provide upper bounds for the Gaussian widths needed in the GDS analysis, yielding the first statistical recovery guarantee for estimation with the k-support norm. The experimental results confirm our theoretical analysis."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Convex Optimization Procedure for Clustering", "Title": "Theoretical Revisit", "Abstract": "In this paper, we present theoretical analysis of SON~--~a convex optimization procedure for clustering using a sum-of-norms (SON) regularization recently proposed in \\cite{ICML2011Hocking_419,SON, Lindsten650707, pelckmans2005convex}. In particular, we show if the samples are drawn from two cubes, each being one cluster, then SON can provably identify the cluster membership provided that the distance between the two cubes is larger than a threshold which (linearly) depends on the size of the cube and the ratio of numbers of samples in each cluster. To the best of our knowledge, this paper is the first to provide a rigorous analysis to understand why and when SON works. We believe this may provide important insights to develop novel convex optimization based algorithms for clustering."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Incremental Clustering", "Title": "The Case for Extra Clusters", "Abstract": "The explosion in the amount of data available for analysis often necessitates a transition from batch to incremental clustering methods, which process one element at a time and typically store only a small subset of the data. In this paper, we initiate the formal analysis of incremental clustering methods focusing on the types of cluster structure that they are able to detect. We find that the incremental setting is strictly weaker than the batch model, proving that a fundamental class of cluster structures that can readily be detected in the batch setting is impossible to identify using any incremental method. Furthermore, we show how the limitations of incremental clustering can be overcome by allowing additional clusters."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Zeta Hull Pursuits", "Title": "Learning Nonconvex Data Hulls", "Abstract": "Selecting a small informative subset from a given dataset, also called column sampling, has drawn much attention in machine learning. For incorporating structured data information into column sampling, research efforts were devoted to the cases where data points are fitted with clusters, simplices, or general convex hulls. This paper aims to study nonconvex hull learning which has rarely been investigated in the literature. In order to learn data-adaptive nonconvex hulls, a novel approach is proposed based on a graph-theoretic measure that leverages graph cycles to characterize the structural complexities of input data points. Employing this measure, we present a greedy algorithmic framework, dubbed Zeta Hulls, to perform structured column sampling. The process of pursuing a Zeta hull involves the computation of matrix inverse. To accelerate the matrix inversion computation and reduce its space complexity as well, we exploit a low-rank approximation to the graph adjacency matrix by using an efficient anchor graph technique. Extensive experimental results show that data representation learned by Zeta Hulls can achieve state-of-the-art accuracy in text and image classification tasks."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bandit Convex Optimization", "Title": "Towards Tight Bounds", "Abstract": "Bandit Convex Optimization (BCO) is a fundamental framework for decision making under uncertainty, which generalizes many problems from the realm of online and statistical learning. While the special case of linear cost functions is well understood, a gap on the attainable regret for BCO with nonlinear losses remains an important open question. In this paper we take a step towards understanding the best attainable regret bounds for BCO: we give an efficient and near-optimal regret algorithm for BCO with strongly-convex and smooth loss functions. In contrast to previous works on BCO that use time invariant exploration schemes, our method employs an exploration scheme that shrinks with time."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Inference by Learning", "Title": "Speeding-up Graphical Model Optimization via a Coarse-to-Fine Cascade of Pruning Classifiers", "Abstract": "We propose a general and versatile framework that significantly speeds-up graphical model optimization while maintaining an excellent solution accuracy. The proposed approach, refereed as Inference by Learning or IbyL, relies on a multi-scale pruning scheme that progressively reduces the solution space by use of a coarse-to-fine cascade of learnt classifiers. We thoroughly experiment with classic computer vision related MRF problems, where our novel framework constantly yields a significant time speed-up (with respect to the most efficient inference methods) and obtains a more accurate solution than directly optimizing the MRF. We make our code available on-line."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Augur", "Title": "Data-Parallel Probabilistic Modeling", "Abstract": "Implementing inference procedures for each new probabilistic model is time-consuming and error-prone. Probabilistic programming addresses this problem by allowing a user to specify the model and then automatically generating the inference procedure. To make this practical it is important to generate high performance inference code. In turn, on modern architectures, high performance requires parallel execution. In this paper we present Augur, a probabilistic modeling language and compiler for Bayesian networks designed to make effective use of data-parallel architectures such as GPUs. We show that the compiler can generate data-parallel inference code scalable to thousands of GPU cores by making use of the conditional independence relationships in the Bayesian network."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mondrian Forests", "Title": "Efficient Online Random Forests", "Abstract": "Ensembles of randomized decision trees, usually referred to as random forests, are widely used for classification and regression tasks in machine learning and statistics. Random forests achieve competitive predictive performance and are computationally efficient to train and test, making them excellent candidates for real-world prediction tasks. The most popular random forest variants (such as Breiman's random forest and extremely randomized trees) operate on batches of training data. Online methods are now in greater demand. Existing online random forests, however, require more training data than their batch counterpart to achieve comparable predictive performance. In this work, we use Mondrian processes (Roy and Teh, 2009) to construct ensembles of random decision trees we call Mondrian forests. Mondrian forests can be grown in an incremental/online fashion and remarkably, the distribution of online Mondrian forests is the same as that of batch Mondrian forests. Mondrian forests achieve competitive predictive performance comparable with existing online random forests and periodically re-trained batch random forests, while being more than an order of magnitude faster, thus representing a better computation vs accuracy tradeoff."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DFacTo", "Title": "Distributed Factorization of Tensors", "Abstract": "We present a technique for significantly speeding up Alternating Least Squares (ALS) and Gradient Descent (GD), two widely used algorithms for tensor factorization. By exploiting properties of the Khatri-Rao product, we show how to efficiently address a computationally challenging sub-step of both algorithms. Our algorithm, DFacTo, only requires two matrix-vector products and is easy to parallelize. DFacTo is not only scalable but also on average 4 to 10 times faster than competing algorithms on a variety of datasets. For instance, DFacTo only takes 480 seconds on 4 machines to perform one iteration of the ALS algorithm and 1,143 seconds to perform one iteration of the GD algorithm on a 6.5 million x 2.5 million x 1.5 million dimensional tensor with 1.2 billion non-zero entries."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neurons as Monte Carlo Samplers", "Title": "Bayesian ￼Inference and Learning in Spiking Networks", "Abstract": "We propose a two-layer spiking network capable of performing approximate inference and learning for a hidden Markov model. The lower layer sensory neurons detect noisy measurements of hidden world states. The higher layer neurons with recurrent connections infer a posterior distribution over world states from spike trains generated by sensory neurons. We show how such a neuronal network with synaptic plasticity can implement a form of Bayesian inference similar to Monte Carlo methods such as particle filtering. Each spike in the population of inference neurons represents a sample of a particular hidden world state. The spiking activity across the neural population approximates the posterior distribution of hidden state. The model provides a functional explanation for the Poisson-like noise commonly observed in cortical responses. Uncertainties in spike times provide the necessary variability for sampling during inference. Unlike previous models, the hidden world state is not observed by the sensory neurons, and the temporal dynamics of the hidden state is unknown. We demonstrate how this network can sequentially learn the hidden Markov model using a spike-timing dependent Hebbian learning rule and achieve power-law convergence rates."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Unified Semantic Embedding", "Title": "Relating Taxonomies and Attributes", "Abstract": "We propose a method that learns a discriminative yet semantic space for object categorization, where we also embed auxiliary semantic entities such as supercategories and attributes. Contrary to prior work which only utilized them as side information, we explicitly embed the semantic entities into the same space where we embed categories, which enables us to represent a category as their linear combination. By exploiting such a unified model for semantics, we enforce each category to be generated as a sparse combination of a supercategory + attributes, with an additional exclusive regularization to learn discriminative composition. The proposed reconstructive regularization guides the discriminative learning process to learn a better generalizing model, as well as generates compact semantic description of each category, which enables humans to analyze what has been learned."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SAGA", "Title": "A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives", "Abstract": "In this work we introduce a new fast incremental gradient method SAGA, in the spirit of SAG, SDCA, MISO and SVRG. SAGA improves on the theory behind SAG and SVRG, with better theoretical convergence rates, and support for composite objectives where a proximal operator is used on the regulariser. Unlike SDCA, SAGA supports non-strongly convex problems directly, and is adaptive to any inherent strong convexity of the problem. We give experimental results showing the effectiveness of our method."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Differential Equation for Modeling Nesterov’s Accelerated Gradient Method", "Title": "Theory and Insights", "Abstract": "We derive a second-order ordinary differential equation (ODE), which is the limit of Nesterov’s accelerated gradient method. This ODE exhibits approximate equivalence to Nesterov’s scheme and thus can serve as a tool for analysis. We show that the continuous time ODE allows for a better understanding of Nesterov’s scheme. As a byproduct, we obtain a family of schemes with similar convergence rates. The ODE interpretation also suggests restarting Nesterov’s scheme leading to an algorithm, which can be rigorously proven to converge at a linear rate whenever the objective is strongly convex."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SerialRank", "Title": "Spectral Ranking using Seriation", "Abstract": "We describe a seriation algorithm for ranking a set of n items given pairwise comparisons between these items. Intuitively, the algorithm assigns similar rankings to items that compare similarly with all others. It does so by constructing a similarity matrix from pairwise comparisons, using seriation methods to reorder this matrix and construct a ranking. We first show that this spectral seriation algorithm recovers the true ranking when all pairwise comparisons are observed and consistent with a total order. We then show that ranking reconstruction is still exact even when some pairwise comparisons are corrupted or missing, and that seriation based spectral ranking is more robust to noise than other scoring methods. An additional benefit of the seriation formulation is that it allows us to solve semi-supervised ranking problems. Experiments on both synthetic and real datasets demonstrate that seriation based spectral ranking achieves competitive and in some cases superior performance compared to classical ranking methods."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Altitude Training", "Title": "Strong Bounds for Single-Layer Dropout", "Abstract": "Dropout training, originally designed for deep neural networks, has been successful on high-dimensional single-layer natural language tasks. This paper proposes a theoretical explanation for this phenomenon: we show that, under a generative Poisson topic model with long documents, dropout training improves the exponent in the generalization bound for empirical risk minimization. Dropout achieves this gain much like a marathon runner who practices at altitude: once a classifier learns to perform reasonably well on training examples that have been artificially corrupted by dropout, it will do very well on the uncorrupted test set. We also show that, under similar conditions, dropout preserves the Bayes decision boundary and should therefore induce minimal bias in high dimensions."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Quartz", "Title": "Randomized Dual Coordinate Ascent with Arbitrary Sampling", "Abstract": "We study the problem of minimizing the average of a large number of smooth convex functions penalized with a strongly convex regularizer. We propose and analyze a novel primal-dual method (Quartz) which at every iteration samples and updates a random subset of the dual variables, chosen according to an arbitrary distribution. In contrast to typical analysis, we directly bound the decrease of the primal-dual error (in expectation), without the need to first analyze the dual error. Depending on the choice of the sampling, we obtain efficient serial and mini-batch variants of the method. In the serial case, our bounds match the best known bounds for SDCA (both with uniform and importance sampling). With standard mini-batching, our bounds predict initial data-independent speedup as well as additional data-driven speedup which depends on spectral and sparsity properties of the data."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SubmodBoxes", "Title": "Near-Optimal Search for a Set of Diverse Object Proposals", "Abstract": "This paper formulates the search for a set of bounding boxes (as needed in object proposal generation) as a monotone submodular maximization problem over the space of all possible bounding boxes in an image. Since the number of possible bounding boxes in an image is very large $O(#pixels^2)$, even a single linear scan to perform the greedy augmentation for submodular maximization is intractable. Thus, we formulate the greedy augmentation step as a Branch-and-Bound scheme. In order to speed up repeated application of B\\&B, we propose a novel generalization of Minoux’s ‘lazy greedy’ algorithm to the B\\&B tree. Theoretically, our proposed formulation provides a new understanding to the problem, and contains classic heuristic approaches such as Sliding Window+Non-Maximal Suppression (NMS) and and Efficient Subwindow Search (ESS) as special cases. Empirically, we show that our approach leads to a state-of-art performance on object proposal generation via a novel diversity measure."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Less is More", "Title": "Nyström Computational Regularization", "Abstract": "We study Nyström type subsampling approaches  to large   scale  kernel methods, and  prove   learning bounds in the  statistical learning setting,  where random sampling and high probability estimates are considered.   In particular, we prove that these approaches  can achieve optimal learning bounds, provided the subsampling level is suitably chosen. These results suggest a simple  incremental variant of Nyström kernel ridge regression, where the subsampling level  controls at the same time  regularization and computations.  Extensive experimental analysis shows that the considered approach achieves state of the art performances on benchmark large scale datasets."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Convolutional LSTM Network", "Title": "A Machine Learning Approach for Precipitation Nowcasting", "Abstract": "The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dependent Multinomial Models Made Easy", "Title": "Stick-Breaking with the Polya-gamma Augmentation", "Abstract": "Many practical modeling problems involve discrete data that are best represented as draws from multinomial or categorical distributions. For example, nucleotides in a DNA sequence, children's names in a given state and year, and text documents are all commonly modeled with multinomial distributions.  In all of these cases, we expect some form of dependency between the draws: the nucleotide at one position in the DNA strand may depend on the preceding nucleotides, children's names are highly correlated from year to year, and topics in text may be correlated and dynamic.  These dependencies are not naturally captured by the typical Dirichlet-multinomial formulation.  Here, we leverage a logistic stick-breaking representation and recent innovations in P\\'{o}lya-gamma augmentation to reformulate the multinomial distribution in terms of latent variables with jointly Gaussian likelihoods, enabling us to take advantage of a host of Bayesian inference techniques for Gaussian models with minimal overhead."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Tractable Approximation to Optimal Point Process Filtering", "Title": "Application to Neural Encoding", "Abstract": "The process of dynamic state estimation (filtering) based on point process observations is in general intractable. Numerical sampling techniques are often practically useful, but lead to limited conceptual insight about optimal encoding/decoding strategies, which are of significant relevance to Computational Neuroscience. We develop an analytically tractable Bayesian approximation to optimal filtering based on point process observations, which allows us to introduce distributional assumptions about sensory cell properties, that greatly facilitates the analysis of optimal encoding in situations deviating from common assumptions of uniform coding. The analytic framework leads to insights which are difficult to obtain from numerical algorithms, and is consistent with experiments about the distribution of tuning curve centers. Interestingly, we find that the information gained from the absence of spikes may be crucial to performance."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "High Dimensional EM Algorithm", "Title": "Statistical Optimization and Asymptotic Normality", "Abstract": "We provide a general theory of the expectation-maximization (EM) algorithm for inferring high dimensional latent variable models.   In particular, we make two contributions: (i) For parameter estimation, we propose a novel high dimensional EM algorithm which naturally incorporates sparsity structure into parameter estimation.  With an appropriate initialization, this algorithm converges at a geometric rate and attains an estimator with the (near-)optimal statistical rate of convergence.  (ii) Based on the obtained estimator, we propose a new inferential procedure for testing hypotheses for low dimensional components of high dimensional parameters.  For a broad family of statistical models,  our framework establishes the first computationally feasible approach for optimal estimation and asymptotic inference in high dimensions."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Faster R-CNN", "Title": "Towards Real-Time Object Detection with Region Proposal Networks", "Abstract": "State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet and Fast R-CNN have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully-convolutional network that simultaneously predicts object bounds and objectness scores at each position. RPNs are trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. With a simple alternating optimization, RPN and Fast R-CNN can be trained to share convolutional features. For the very deep VGG-16 model, our detection system has a frame rate of 5fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007 (73.2% mAP) and 2012 (70.4% mAP) using 300 proposals per image. Code is available at https://github.com/ShaoqingRen/faster_rcnn."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probabilistic Curve Learning", "Title": "Coulomb Repulsion and the Electrostatic Gaussian Process", "Abstract": "Learning of low dimensional structure in multidimensional data is a canonical problem in machine learning.  One common approach is to suppose that the observed data are close to a lower-dimensional smooth manifold.  There are a rich variety of manifold learning methods available, which allow mapping of data points to the manifold.  However, there is a clear lack of probabilistic methods that allow learning of the manifold along with the generative distribution of the observed data.  The best attempt is the Gaussian process latent variable model (GP-LVM), but identifiability issues lead to poor performance.  We solve these issues by proposing a novel Coulomb repulsive process (Corp) for locations of points on the manifold, inspired by physical models of electrostatic interactions among particles.  Combining this process with a GP prior for the mapping function yields a novel electrostatic GP (electroGP) process.  Focusing on the simple case of a one-dimensional manifold, we develop efficient inference algorithms, and illustrate substantially improved performance in a variety of experiments including filling in missing frames in video."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Precision-Recall-Gain Curves", "Title": "PR Analysis Done Right", "Abstract": "Precision-Recall analysis abounds in applications of binary classification where true negatives do not add value and hence should not affect assessment of the classifier's performance. Perhaps inspired by the many advantages of receiver operating characteristic (ROC) curves and the area under such curves for accuracy-based performance assessment, many researchers have taken to report Precision-Recall (PR) curves and associated areas as performance metric. We demonstrate in this paper that this practice is fraught with difficulties, mainly because of incoherent scale assumptions -- e.g., the area under a PR curve takes the arithmetic mean of precision values whereas the $F_{\\beta}$ score applies the harmonic mean. We show how to fix this by plotting PR curves in a different coordinate system, and demonstrate that the new Precision-Recall-Gain curves inherit all key advantages of ROC curves. In particular, the area under Precision-Recall-Gain curves conveys an expected $F_1$ score on a harmonic scale, and the convex hull of a Precision-Recall-Gain curve allows us to calibrate the classifier's scores so as to determine, for each operating point on the convex hull, the interval of $\\beta$ values for which the point optimises $F_{\\beta}$. We demonstrate experimentally that the area under traditional PR curves can easily favour models with lower expected $F_1$ score than others, and so the use of Precision-Recall-Gain curves will result in better model selection."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Learning for Adversaries with Memory", "Title": "Price of Past Mistakes", "Abstract": "The framework of online learning with memory naturally captures learning problems with temporal effects, and was previously studied for the experts setting. In this work we extend the notion of learning with memory to the general Online Convex Optimization (OCO) framework, and present two algorithms that attain low regret. The first algorithm applies to Lipschitz continuous loss functions, obtaining optimal regret bounds for both convex and strongly convex losses. The second algorithm attains the optimal regret bounds and applies more broadly to convex losses without requiring Lipschitz continuity, yet is more complicated to implement. We complement the theoretic results with two applications: statistical arbitrage in finance, and multi-step ahead prediction in statistics."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-class SVMs", "Title": "From Tighter Data-Dependent Generalization Bounds to Novel Algorithms", "Abstract": "This paper studies the generalization performance of multi-class classification algorithms, for which we obtain, for the first time, a data-dependent generalization error bound with a logarithmic dependence on the class size, substantially improving the state-of-the-art linear dependence in the existing data-dependent generalization analysis. The theoretical analysis motivates us to introduce a new multi-class classification machine based on lp-norm regularization, where the parameter p controls the complexity of the corresponding bounds. We derive an efficient optimization algorithm based on Fenchel duality theory. Benchmarks on several real-world datasets show that the proposed algorithm can achieve significant accuracy gains over the state of the art."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BinaryConnect", "Title": "Training Deep Neural Networks with binary weights during propagations", "Abstract": "Deep Neural Networks (DNN) have achieved state-of-the-art results in a wide range of tasks, with the best results obtained with large training sets and large models. In the past, GPUs enabled these breakthroughs because of their greater computational speed. In the future, faster computation at both training and test time is likely to be crucial for further progress and for consumer applications on low-power devices. As a result, there is much interest in research and development of dedicated hardware for Deep Learning (DL). Binary weights, i.e., weights which are constrained to only two possible values (e.g. -1 or 1), would bring great benefits to specialized DL hardware by replacing many multiply-accumulate operations by simple accumulations, as multipliers are the most space and power-hungry components of the digital implementation of neural networks. We introduce BinaryConnect, a method which consists in training a DNN with binary weights during the forward and backward propagations, while retaining precision of the stored weights in which gradients are accumulated. Like other dropout schemes, we show that BinaryConnect acts as regularizer and we obtain near state-of-the-art results with BinaryConnect on the permutation-invariant MNIST, CIFAR-10 and SVHN."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning with Symmetric Label Noise", "Title": "The Importance of Being Unhinged", "Abstract": "Convex potential minimisation is the de facto approach to binary classification. However, Long and Servedio [2008] proved that under symmetric label noise (SLN), minimisation of any convex potential over a linear function class can result in classification performance equivalent to random guessing. This ostensibly shows that convex losses are not SLN-robust. In this paper, we propose a convex, classification-calibrated loss and prove that it is SLN-robust. The loss avoids the Long and Servedio [2008] result by virtue of being negatively unbounded. The loss is a modification of the hinge loss, where one does not clamp at zero; hence, we call it the unhinged loss. We show that the optimal unhinged solution is equivalent to that of a strongly regularised SVM, and is the limiting solution for any convex potential; this implies that strong l2 regularisation makes most standard learners SLN-robust. Experiments confirm the unhinged loss’ SLN-robustness."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Visalogy", "Title": "Answering Visual Analogy Questions", "Abstract": "In this paper, we study the problem of answering visual analogy questions. These questions take the form of image A is to image B as image C is to what. Answering these questions entails discovering the mapping from image A to image B and then extending the mapping to image C and searching for the image D such that the relation from A to B holds for C to D. We pose this problem as learning an embedding that encourages pairs of analogous images with similar transformations to be close together using convolutional neural networks with a quadruple Siamese architecture. We introduce a dataset of visual analogy questions in natural images, and show first results of its kind on solving analogy questions on natural images."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bandit Smooth Convex Optimization", "Title": "Improving the Bias-Variance Tradeoff", "Abstract": "Bandit convex optimization is one of the fundamental problems in the field of online learning. The best algorithm for the general bandit convex optimization problem guarantees a regret of $\\widetilde{O}(T^{5/6})$, while the best known lower bound is $\\Omega(T^{1/2})$. Many attemptshave been made to bridge the huge gap between these bounds. A particularly interesting special case of this problem assumes that the loss functions are smooth. In this case, the best known algorithm guarantees a regret of $\\widetilde{O}(T^{2/3})$. We present an efficient algorithm for the banditsmooth convex optimization problem that guarantees a regret of $\\widetilde{O}(T^{5/8})$. Our result rules out an $\\Omega(T^{2/3})$ lower bound and takes a significant step towards the resolution of this open problem."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Compressive spectral embedding", "Title": "sidestepping the SVD", "Abstract": "Spectral embedding based on the Singular Value Decomposition (SVD) is a widely used preprocessing step in many learning tasks, typically leading to dimensionality reduction by projecting onto a number of dominant singular vectors and rescaling the coordinate axes (by a predefined function of the singular value). However, the number of such vectors required to capture problem structure grows with problem size, and even partial SVD computation becomes a bottleneck. In this paper, we propose a low-complexity it compressive spectral embedding algorithm, which employs random projections and finite order polynomial expansions to compute approximations to SVD-based embedding. For an m times n matrix with T non-zeros, its time complexity is O((T+m+n)log(m+n)), and the embedding dimension is O(log(m+n)), both of which are independent of the number of singular vectors whose effect we wish to capture. To the best of our knowledge, this is the first work to circumvent this dependence on the number of singular vectors for general SVD-based embeddings. The key to sidestepping the SVD is the observation that, for downstream inference tasks such as clustering and classification, we are only interested in using the resulting embedding to evaluate pairwise similarity metrics derived from the euclidean norm, rather than capturing the effect of the underlying matrix on arbitrary vectors as a partial SVD tries to do. Our numerical results on network datasets demonstrate the efficacy of the proposed method, and motivate further exploration of its application to large-scale inference tasks."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COEVOLVE", "Title": "A Joint Point Process Model for Information Diffusion and Network Co-evolution", "Abstract": "Information diffusion in online social networks is affected by the underlying network topology, but it also has the power to change it. Online users are constantly creating new links when exposed to new information sources, and in turn these links are alternating the way information spreads. However, these two highly intertwined stochastic processes, information diffusion and network evolution, have been predominantly studied separately, ignoring their co-evolutionary dynamics.We propose a temporal point process model, COEVOLVE, for such joint dynamics, allowing the intensity of one process to be modulated by that of the other. This model allows us to efficiently simulate interleaved diffusion and network events, and generate traces obeying common diffusion and network patterns observed in real-world networks. Furthermore, we also develop a convex optimization framework to learn the parameters of the model from historical diffusion and network evolution traces. We experimented with both synthetic data and data gathered from Twitter, and show that our model provides a good fit to the data as well as more accurate predictions than alternatives."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Return of the Gating Network", "Title": "Combining Generative Models and Discriminative Training in Natural Image Priors", "Abstract": "In recent years, approaches based on machine learning have achieved state-of-the-art performance on image restoration problems. Successful approaches include both generative models of natural images as well as discriminative training of deep neural networks. Discriminative training of feed forward architectures allows explicit control over the computational cost of performing restoration and therefore often leads to better performance at the same cost at run time.  In contrast, generative models have the advantage that they can be trained once and then adapted to any image restoration task by a simple use of Bayes' rule. In this paper we show how to combine the strengths of both approaches by training a discriminative, feed-forward architecture to predict the state of latent variables in a generative model of natural images. We apply this idea to the very successful Gaussian Mixture Model (GMM) of natural images. We show that it is possible to achieve comparable performance as the original GMM but with two orders of magnitude improvement in run time while maintaining the advantage of generative models."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Risk-Sensitive and Robust Decision-Making", "Title": "a CVaR Optimization Approach", "Abstract": "In this paper we address the problem of decision making within a Markov decision process (MDP) framework where risk and modeling errors are taken into account. Our approach is to  minimize a risk-sensitive conditional-value-at-risk (CVaR) objective, as opposed to a standard risk-neutral expectation. We refer to such problem as CVaR MDP. Our first contribution is to show that a CVaR objective, besides capturing risk sensitivity, has an alternative interpretation as expected cost under worst-case modeling errors, for a given error budget. This result, which is of independent interest,  motivates CVaR MDPs as a unifying framework for risk-sensitive and robust decision making. Our second contribution is to present a value-iteration algorithm for CVaR MDPs, and analyze its convergence rate. To our knowledge, this is the first solution algorithm for CVaR MDPs that enjoys error guarantees. Finally, we present results from numerical experiments that corroborate our theoretical findings and show the practicality of our approach."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning with Group Invariant Features", "Title": "A Kernel Perspective.", "Abstract": "We analyze in this paper a random feature map based on a  theory of invariance (\\emph{I-theory}) introduced in \\cite{AnselmiLRMTP13}. More specifically, a group invariant  signal signature is obtained through cumulative distributions of group-transformed random projections. Our analysis bridges invariant feature learning with kernel methods, as we show that this feature map defines an expected Haar-integration kernel that is invariant to the specified group action. We show how this non-linear random feature map approximates this group invariant kernel uniformly on a  set of $N$ points. Moreover, we show that it defines a function space that is dense in the equivalent Invariant Reproducing Kernel Hilbert Space. Finally, we quantify error rates of the convergence of the empirical risk minimization, as well as the reduction in the sample complexity of a learning algorithm using such an invariant representation for signal classification, in a classical supervised learning setting"}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SGD Algorithms based on Incomplete U-statistics", "Title": "Large-Scale Minimization of Empirical Risk", "Abstract": "In many learning problems, ranging from clustering to ranking through metric learning, empirical estimates of the risk functional consist of an average over tuples (e.g., pairs or triplets) of observations, rather than over individual observations. In this paper, we focus on how to best implement a stochastic approximation approach to solve such risk minimization problems. We argue that in the large-scale setting, gradient estimates should be obtained by sampling tuples of data points with replacement (incomplete U-statistics) instead of sampling data points without replacement (complete U-statistics based on subsamples). We develop a theoretical framework accounting for the substantial impact of this strategy on the generalization ability of the prediction model returned by the Stochastic Gradient Descent (SGD) algorithm. It reveals that the method we promote achieves a much better trade-off between statistical accuracy and computational cost. Beyond the rate bound analysis, experiments on AUC maximization and metric learning provide strong empirical evidence of the superiority of the proposed approach."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predtron", "Title": "A Family of Online Algorithms for General Prediction Problems", "Abstract": "Modern prediction problems arising in multilabel learning and learning to rank pose unique challenges to the classical theory of supervised learning. These problems have large prediction and label spaces of a combinatorial nature and involve sophisticated loss functions. We offer a general framework to derive mistake driven online algorithms and associated loss bounds.  The key ingredients in our framework are a general loss function, a general vector space representation of predictions, and a notion of margin with respect to a general norm. Our general algorithm, Predtron, yields the perceptron algorithm and its variants when instantiated on classic problems such as binary classification, multiclass classification, ordinal regression, and multilabel classification.  For multilabel ranking and subset ranking, we derive novel algorithms, notions of margins, and loss bounds. A simulation study confirms the behavior predicted by our bounds and demonstrates the flexibility of the design choices in our framework."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bandits with Unobserved Confounders", "Title": "A Causal Approach", "Abstract": "The Multi-Armed Bandit problem constitutes an archetypal setting for sequential decision-making, permeating multiple domains including engineering, business, and medicine. One of the hallmarks of a bandit setting is the agent's capacity to explore its environment through active intervention, which contrasts with the ability to collect passive data by estimating associational relationships between actions and payouts. The existence of unobserved confounders, namely unmeasured variables affecting both the action and the outcome variables, implies that these two data-collection modes will in general not coincide. In this paper, we show that formalizing this distinction has conceptual and algorithmic implications to the bandit setting. The current generation of bandit algorithms implicitly try to maximize rewards based on estimation of the experimental distribution, which we show is not always the best strategy to pursue. Indeed, to achieve low regret in certain realistic classes of bandit problems (namely, in the face of unobserved confounders), both experimental and observational quantities are required by the rational agent. After this realization, we propose an optimization metric (employing both experimental and observational distributions) that bandit agents should pursue, and illustrate its benefits over traditional algorithms."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Rank Elicitation for Plackett-Luce", "Title": "A Dueling Bandits Approach", "Abstract": "We study the problem of online rank elicitation, assuming that rankings of a set of alternatives obey the Plackett-Luce distribution. Following the setting of the dueling bandits problem, the learner is allowed to query pairwise comparisons between alternatives, i.e., to sample pairwise marginals of the distribution in an online fashion. Using this information, the learner seeks to reliably predict the most probable ranking (or top-alternative). Our approach is based on constructing a surrogate probability distribution over rankings based on a sorting procedure, for which the pairwise marginals provably coincide with the marginals of the Plackett-Luce distribution. In addition to a formal performance and complexity analysis, we present first experimental studies."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mind the Gap", "Title": "A Generative Approach to Interpretable Feature Selection and Extraction", "Abstract": "We present the Mind the Gap Model (MGM), an approach for interpretable feature extraction and selection.  By placing interpretability criteria directly into the model, we allow for the model to both optimize parameters related to interpretability and to directly report a global set of distinguishable dimensions to assist with further data exploration and hypothesis generation. MGM extracts distinguishing features on real-world datasets of animal features, recipes ingredients, and disease co-occurrence.  It also maintains or improves performance when compared to related approaches.  We perform a user study with domain experts to show the MGM's ability to help with dataset exploration."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Principal Differences Analysis", "Title": "Interpretable Characterization of Differences between Distributions", "Abstract": "We introduce principal differences analysis for analyzing differences between high-dimensional distributions. The method operates by finding the projection that maximizes the Wasserstein divergence between the resulting univariate populations. Relying on the Cramer-Wold device, it requires no assumptions about the form of the underlying distributions, nor the nature of their inter-class differences. A sparse variant of the method is introduced to identify features responsible for the differences. We provide algorithms for both the original minimax formulation as well as its semidefinite relaxation.  In addition to deriving some convergence results, we illustrate how the approach may be applied to identify differences between cell populations in the somatosensory cortex and hippocampus as manifested by single cell RNA-seq. Our broader framework extends beyond the specific choice of Wasserstein divergence."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NEXT", "Title": "A System for Real-World Development, Evaluation, and Application of Active Learning", "Abstract": "Active learning methods automatically adapt data collection by selecting the most informative samples in order to accelerate machine learning. Because of this, real-world testing and comparing active learning algorithms requires collecting new datasets (adaptively), rather than simply applying algorithms to benchmark datasets, as is the norm in (passive) machine learning research. To facilitate the development, testing and deployment of active learning for real applications, we have built an open-source software system for large-scale active learning research and experimentation.  The system, called NEXT,  provides a unique platform for real-world, reproducible active learning research. This paper details the challenges of building the system and demonstrates its capabilities with several experiments.  The results show how experimentation can help expose strengths and weaknesses of active learning algorithms, in sometimes unexpected and enlightening ways."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BACKSHIFT", "Title": "Learning causal cyclic graphs from unknown shift interventions", "Abstract": "We propose a simple method to learn linear causal cyclic models in the presence of latent variables. The method relies on equilibrium data of the model recorded under a specific kind of interventions (``shift interventions''). The location and strength of these interventions do not have to be known and can be estimated from the data. Our method, called BACKSHIFT, only uses second moments of the data and performs simple joint matrix diagonalization, applied to differences between covariance matrices. We give a sufficient and necessary condition for identifiability of the system, which is fulfilled almost surely under some quite general assumptions if and only if there are at least three distinct experimental settings, one of which can be pure observational data. We demonstrate the performance on some simulated data and applications in flow cytometry and financial time series."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularized EM Algorithms", "Title": "A Unified Framework and Statistical Guarantees", "Abstract": "Latent models are a fundamental modeling tool in machine learning applications, but they present significant computational and analytical challenges. The popular EM algorithm and its variants, is a much used algorithmic tool; yet our rigorous understanding of its performance is highly incomplete. Recently, work in [1] has demonstrated that for an important class of problems, EM exhibits linear local convergence. In the high-dimensional setting, however, the M-step may not be well defined. We address precisely this setting through a unified treatment using regularization. While regularization for high-dimensional problems is by now well understood, the iterative EM algorithm requires a careful balancing of making progress towards the solution while identifying the right structure (e.g., sparsity or low-rank). In particular, regularizing the M-step using the state-of-the-art high-dimensional prescriptions (e.g., `a la [19]) is not guaranteed to provide this balance. Our algorithm and analysis are linked in a way that reveals the balance between optimization and statistical errors. We specialize our general framework to sparse gaussian mixture models, high-dimensional mixed regression, and regression with missing variables, obtaining statistical guarantees for each of these examples."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Convexity", "Title": "Stochastic Quasi-Convex Optimization", "Abstract": "Stochastic convex optimization is a basic and well studied primitive in machine learning. It is well known that convex and Lipschitz functions can be minimized efficiently using Stochastic Gradient Descent (SGD).The Normalized Gradient Descent (NGD) algorithm, is an adaptation of Gradient Descent, which updates according to the direction of the gradients, rather than the gradients themselves. In this paper we analyze a stochastic version of NGD and prove its convergence to a global minimum for a wider class of functions: we require the functions to be quasi-convex and locally-Lipschitz. Quasi-convexity broadens the concept of unimodality to multidimensions and allows for certain types of saddle points, which are a known hurdle for first-order optimization methods such as gradient descent. Locally-Lipschitz functions are only required to be Lipschitz in a small region around the optimum. This assumption circumvents gradient explosion, which is another known hurdle for gradient descent variants. Interestingly, unlike the vanilla SGD algorithm, the stochastic normalized gradient descent algorithm provably requires a minimal minibatch size."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning From Small Samples", "Title": "An Analysis of Simple Decision Heuristics", "Abstract": "Simple decision heuristics are models of human and animal behavior that use few pieces of information---perhaps only a single piece of information---and integrate the pieces in simple ways, for example, by considering them sequentially, one at a time, or by giving them equal weight. It is unknown how quickly these heuristics can be learned from experience. We show, analytically and empirically, that only a few training samples lead to substantial progress in learning. We focus on three families of heuristics: single-cue decision making, lexicographic decision making, and tallying. Our empirical analysis is the most extensive to date, employing 63 natural data sets on diverse subjects."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Subsampled Power Iteration", "Title": "a Unified Algorithm for Block Models and Planted CSP's", "Abstract": "We present an algorithm for recovering planted solutions in two well-known models, the stochastic block model and planted constraint satisfaction problems (CSP), via a common generalization in terms of random bipartite graphs. Our algorithm matches up to a constant factor the best-known bounds  for the number of edges (or constraints) needed for perfect recovery and its running time is linear in the number of edges used. The time complexity is significantly better than both spectral and SDP-based approaches.The main contribution of the algorithm is in the case of unequal sizes in the bipartition that arises in our reduction from the planted CSP.  Here our algorithm succeeds at a significantly lower density than the spectral approaches, surpassing a barrier based on the spectral norm of a random matrix.Other significant features of the algorithm and analysis include (i) the critical use of power iteration with subsampling, which might be of independent interest; its analysis requires keeping track of multiple norms of an evolving solution (ii) the algorithm can be implemented statistically, i.e., with very limited access to the input distribution (iii) the algorithm is extremely simple to implement and runs in linear time, and thus is practical even for very large instances."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Taming the Wild", "Title": "A Unified Analysis of Hogwild-Style Algorithms", "Abstract": "Stochastic gradient descent (SGD) is a ubiquitous algorithm for a variety of machine learning problems. Researchers and industry have developed several techniques to optimize SGD's runtime performance, including asynchronous execution and reduced precision. Our main result is a martingale-based analysis that enables us to capture the rich noise models that may arise from such techniques. Specifically, we useour new analysis in three ways: (1) we derive convergence rates for the convex case (Hogwild) with relaxed assumptions on the sparsity of the problem; (2) we analyze asynchronous SGD algorithms for non-convex matrix problems including matrix completion; and (3) we design and analyze an asynchronous SGD algorithm, called Buckwild, that uses lower-precision arithmetic. We show experimentally that our algorithms run efficiently for a variety of problems on modern hardware."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking LDA", "Title": "Moment Matching for Discrete ICA", "Abstract": "We consider moment matching techniques for estimation in Latent Dirichlet Allocation (LDA). By drawing explicit links between LDA and discrete versions of independent component analysis (ICA), we first derive a new set of cumulant-based tensors, with an improved sample complexity. Moreover, we reuse standard ICA techniques such as joint diagonalization of tensors to improve over existing methods based on the tensor power method. In an extensive set of experiments on both synthetic and real datasets, we show that our new combination of tensors and orthogonal joint diagonalization techniques outperforms existing moment matching methods."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Individual Planning in Infinite-Horizon Multiagent Settings", "Title": "Inference, Structure and Scalability", "Abstract": "This  paper  provides  the first  formalization  of  self-interested planning in multiagent settings using expectation-maximization (EM). Our   formalization  in   the   context   of  infinite-horizon   and finitely-nested interactive  POMDPs (I-POMDP) is  distinct from EM formulations  for POMDPs  and cooperative  multiagent planning frameworks.  We  exploit the graphical model structure  specific to I-POMDPs, and present  a new  approach based  on block-coordinate  descent for  further speed up.  Forward  filtering-backward sampling -- a combination of exact filtering  with sampling -- is explored to exploit problem structure."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Embed to Control", "Title": "A Locally Linear Latent Dynamics Model for Control from Raw Images", "Abstract": "We introduce Embed to Control (E2C), a method for model learning and control of non-linear dynamical systems from raw pixel images. E2C consists of a deep generative model, belonging to the family of variational autoencoders, that learns to generate image trajectories from a latent space in which the dynamics is constrained to be locally linear. Our model is derived directly from an optimal control formulation in latent space, supports long-term prediction of image sequences and exhibits strong performance on a variety of complex control problems."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Newton-Stein Method", "Title": "A Second Order Method for GLMs via Stein's Lemma", "Abstract": "We consider the problem of efficiently computing the maximum likelihood estimator in Generalized Linear Models (GLMs)when the number of observations is much larger than the number of coefficients (n > > p > > 1). In this regime, optimization algorithms can immensely benefit fromapproximate second order information.We propose an alternative way of constructing the curvature information by formulatingit as an estimation problem and applying a Stein-type lemma, which allows further improvements through sub-sampling andeigenvalue thresholding.Our algorithm enjoys fast convergence rates, resembling that of second order methods, with modest per-iteration cost. We provide its convergence analysis for the case where the rows of the design matrix are i.i.d. samples with bounded support.We show that the convergence has two phases, aquadratic phase followed by a linear phase. Finally,we empirically demonstrate that our algorithm achieves the highest performancecompared to various algorithms on several datasets."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimization Monte Carlo", "Title": "Efficient and Embarrassingly Parallel Likelihood-Free Inference", "Abstract": "We describe an embarrassingly parallel, anytime Monte Carlo method for likelihood-free models.  The algorithm starts with the view that the stochasticity of the pseudo-samples generated by the simulator can be controlled externally by a vector of random numbers u, in such a way that the outcome, knowing u, is deterministic.  For each instantiation of u we run an optimization procedure to minimize the distance between summary statistics of the simulator and the data. After reweighing these samples using the prior and the Jacobian (accounting for the change of volume in transforming from the space of summary statistics to the space of parameters) we show that this weighted ensemble represents a Monte Carlo estimate of the posterior distribution. The procedure can be run embarrassingly parallel (each node handling one sample) and anytime (by allocating resources to the worst performing sample). The procedure is validated on six experiments."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "StopWasting My Gradients", "Title": "Practical SVRG", "Abstract": "We present and analyze several strategies for improving the performance ofstochastic variance-reduced gradient (SVRG) methods. We first show that theconvergence rate of these methods can be preserved under a decreasing sequenceof errors in the control variate, and use this to derive variants of SVRG that usegrowing-batch strategies to reduce the number of gradient calculations requiredin the early iterations. We further (i) show how to exploit support vectors to reducethe number of gradient computations in the later iterations, (ii) prove that thecommonly–used regularized SVRG iteration is justified and improves the convergencerate, (iii) consider alternate mini-batch selection strategies, and (iv) considerthe generalization error of the method."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Saliency, Scale and Information", "Title": "Towards a Unifying Theory", "Abstract": "In this paper we present a definition for visual saliency grounded in information theory. This proposal is shown to relate to a variety of classic research contributions in scale-space theory, interest point detection, bilateral filtering, and to existing models of visual saliency. Based on the proposed definition of visual saliency, we demonstrate results competitive with the state-of-the art for both prediction of human fixations, and segmentation of salient objects. We also characterize different properties of this model including robustness to image transformations, and extension to a wide range of other data types with 3D mesh models serving as an example. Finally, we relate this proposal more generally to the role of saliency computation in visual information processing and draw connections to putative mechanisms for saliency computation in human vision."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Matrix Completion from Fewer Entries", "Title": "Spectral Detectability and Rank Estimation", "Abstract": "The completion of low rank matrices from few entries is a task with many practical applications. We consider here two aspects of this problem: detectability, i.e. the ability to estimate the rank $r$ reliably from the fewest possible random entries, and performance in achieving small reconstruction error. We propose a spectral algorithm for these two tasks called MaCBetH (for Matrix Completion with the Bethe Hessian). The rank is estimated as the number of negative eigenvalues of the Bethe Hessian matrix, and the corresponding eigenvectors are used as initial condition for the minimization of the discrepancy between the estimated matrix and the revealed entries.  We analyze the performance in a random matrix setting using results from the statistical mechanics of the Hopfield neural network, and show in particular that MaCBetH efficiently detects the rank $r$ of a large $n\\times m$ matrix from $C(r)r\\sqrt{nm}$ entries, where $C(r)$ is a constant close to $1$.  We also evaluate the corresponding root-mean-square error empirically and show that MaCBetH compares favorably to other existing approaches."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Estimating Jaccard Index with Missing Observations", "Title": "A Matrix Calibration Approach", "Abstract": "The Jaccard index is a standard statistics for comparing the pairwise similarity between data samples. This paper investigates the problem of estimating a Jaccard index matrix when there are missing observations in data samples. Starting from a Jaccard index matrix approximated from the incomplete data, our method calibrates the matrix to meet the requirement of positive semi-definiteness and other constraints, through a simple alternating projection algorithm. Compared with conventional approaches that estimate the similarity matrix based on the imputed data, our method has a strong advantage in that the calibrated matrix is guaranteed to be closer to the unknown ground truth in the Frobenius norm than the un-calibrated matrix (except in special cases they are identical). We carried out a series of empirical experiments and the results confirmed our theoretical justification. The evaluation also reported significantly improved results in real learning tasks on benchmarked datasets."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Synaptic Sampling", "Title": "A Bayesian Approach to Neural Network Plasticity and Rewiring", "Abstract": "We reexamine in this article the conceptual and mathematical framework for understanding the organization of plasticity in spiking neural networks. We propose that inherent stochasticity enables synaptic plasticity to carry out probabilistic inference by sampling from a posterior distribution of synaptic parameters. This view provides a viable alternative to existing models that propose convergence of synaptic weights to maximum likelihood parameters. It explains how priors on weight distributions and connection probabilities can be merged optimally with learned experience. In simulations we show that our model for synaptic plasticity allows spiking neural networks to compensate continuously for unforeseen disturbances. Furthermore it provides a normative mathematical framework to better understand the permanent variability and rewiring observed in brain networks."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Frank-Wolfe Bayesian Quadrature", "Title": "Probabilistic Integration with Theoretical Guarantees", "Abstract": "There is renewed interest in formulating integration as an inference problem, motivated by obtaining a full distribution over numerical error that can be propagated through subsequent computation. Current methods, such as Bayesian Quadrature, demonstrate impressive empirical performance but lack theoretical analysis. An important challenge is to reconcile these probabilistic integrators with rigorous convergence guarantees. In this paper, we present the first probabilistic integrator that admits such theoretical treatment, called Frank-Wolfe Bayesian Quadrature (FWBQ). Under FWBQ, convergence to the true value of the integral is shown to be exponential and posterior contraction rates are proven to be superexponential. In simulations, FWBQ is competitive with state-of-the-art methods and out-performs alternatives based on Frank-Wolfe optimisation. Our approach is applied to successfully quantify numerical error in the solution to a challenging model choice problem in cellular biology."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Submodular Cover", "Title": "Succinctly Summarizing Massive Data", "Abstract": "How can one find a subset, ideally as small as possible, that well represents a massive dataset? I.e., its corresponding utility, measured according to a suitable utility function, should be comparable to that of the whole dataset. In this paper, we formalize this challenge as a submodular cover problem. Here, the utility is assumed to exhibit submodularity, a natural diminishing returns condition preva- lent in many data summarization applications. The classical greedy algorithm is known to provide solutions with logarithmic approximation guarantees compared to the optimum solution. However, this sequential, centralized approach is imprac- tical for truly large-scale problems. In this work, we develop the first distributed algorithm – DISCOVER – for submodular set cover that is easily implementable using MapReduce-style computations. We theoretically analyze our approach, and present approximation guarantees for the solutions returned by DISCOVER. We also study a natural trade-off between the communication cost and the num- ber of rounds required to obtain such a solution. In our extensive experiments, we demonstrate the effectiveness of our approach on several applications, includ- ing active set selection, exemplar based clustering, and vertex cover on tens of millions of data points using Spark."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Double or Nothing", "Title": "Multiplicative Incentive Mechanisms for Crowdsourcing", "Abstract": "Crowdsourcing has gained immense popularity in machine learning applications for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize workers to answer only the questions that they are sure of and skip the rest. We show that surprisingly, under a mild and natural no-free-lunch requirement, this mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentive-compatible  mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers.  Interestingly, this unique mechanism takes a multiplicative form. The simplicity of the mechanism is an added benefit.  In preliminary experiments involving over several hundred workers, we observe a significant reduction in the error rates under our unique mechanism for the same or lower monetary expenditure."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Asynchronous stochastic convex optimization", "Title": "the noise is in the noise and SGD don't care", "Abstract": "We show that asymptotically, completely asynchronous stochastic gradient procedures achieve optimal (even to constant factors) convergence rates for the solution of convex optimization problems under nearly the same conditions required for asymptotic optimality of standard stochastic gradient procedures. Roughly, the noise inherent to the stochastic approximation scheme dominates any noise from asynchrony. We also give empirical evidence demonstrating the strong performance of asynchronous, parallel stochastic optimization schemes, demonstrating that the robustness inherent to stochastic approximation problems allows substantially faster parallel and asynchronous solution methods. In short, we show that for many stochastic approximation problems, as Freddie Mercury sings in Queen's \\emph{Bohemian Rhapsody}, ``Nothing really matters.''"}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Limitation of Spectral Methods", "Title": "From the Gaussian Hidden Clique Problem to Rank-One Perturbations of Gaussian Tensors", "Abstract": "We consider the following detection problem: given a realization of asymmetric matrix $X$ of dimension $n$, distinguish between the hypothesisthat all upper triangular variables are i.i.d. Gaussians variableswith mean 0 and variance $1$ and the hypothesis that there is aplanted principal submatrix $B$ of dimension $L$ for which all upper triangularvariables are i.i.d. Gaussians with mean $1$ and variance $1$, whereasall other upper triangular elements of $X$ not in $B$ are i.i.d.Gaussians variables with mean 0 and variance $1$. We refer to this asthe `Gaussian hidden clique problem'. When $L=( 1 + \\epsilon) \\sqrt{n}$ ($\\epsilon > 0$), it is possible to solve thisdetection problem with probability $1 - o_n(1)$ by computing thespectrum of $X$ and considering the largest eigenvalue of $X$.We prove that when$L < (1-\\epsilon)\\sqrt{n}$ no algorithm that examines only theeigenvalues of $X$can detect the existence of a hiddenGaussian clique, with error probability vanishing as $n \\to \\infty$.The result above is an immediate consequence of a more general result on rank-oneperturbations of $k$-dimensional Gaussian tensors.In this context we establish a lower bound on the criticalsignal-to-noise ratio below which a rank-one signal cannot be detected."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Smooth and Strong", "Title": "MAP Inference with Linear Convergence", "Abstract": "Maximum a-posteriori (MAP) inference is an important task for many applications. Although the standard formulation gives rise to a hard combinatorial optimization problem, several effective approximations have been proposed and studied in recent years. We focus on linear programming (LP) relaxations, which have achieved state-of-the-art performance in many applications. However, optimization of the resulting program is in general challenging due to non-smoothness and complex non-separable constraints.Therefore, in this work we study the benefits of augmenting the objective function of the relaxation with strong convexity. Specifically, we introduce strong convexity by adding a quadratic term to the LP relaxation objective. We provide theoretical guarantees for the resulting programs, bounding the difference between their optimal value and the original optimum. Further, we propose suitable optimization algorithms and analyze their convergence."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Galileo", "Title": "Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning", "Abstract": "Humans demonstrate remarkable abilities to predict physical events in dynamic scenes, and to infer the physical properties of objects from static images. We propose a generative model for solving these problems of physical scene understanding from real-world videos and images. At the core of our generative model is a 3D physics engine, operating on an object-based representation of physical properties, including mass, position, 3D shape, and friction. We can infer these latent properties using relatively brief runs of MCMC, which drive simulations in the physics engine to fit key features of visual observations. We further explore directly mapping visual inputs to physical properties, inverting a part of the generative process using deep learning. We name our model Galileo, and evaluate it on a video dataset with simple yet physically rich scenarios. Results show that Galileo is able to infer the physical properties of objects and predict the outcome of a variety of physical events, with an accuracy comparable to human subjects. Our study points towards an account of human vision with generative physical knowledge at its core, and various recognition models as helpers leading to efficient inference."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayesian Manifold Learning", "Title": "The Locally Linear Latent Variable Model (LL-LVM)", "Abstract": "We introduce the Locally Linear Latent Variable Model (LL-LVM), a probabilistic model for non-linear manifold discovery that describes a joint distribution over observations, their manifold coordinates and locally linear maps conditioned on a set of neighbourhood relationships. The model allows straightforward variational optimisation of the posterior distribution on coordinates and locally linear maps from the latent space to the observation space given the data. Thus, the LL-LVM encapsulates the local-geometry preserving intuitions that underlie non-probabilistic methods such as locally linear embedding (LLE). Its probabilistic semantics make it easy to evaluate the quality of hypothesised neighbourhood relationships, select the intrinsic dimensionality of the manifold, construct out-of-sample extensions and to combine the manifold model with additional probabilistic models that capture the structure of coordinates within the manifold."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Competitive Distribution Estimation", "Title": "Why is Good-Turing Good", "Abstract": "Estimating distributions over large alphabets is a fundamental machine-learning tenet. Yet no method is known to estimate all distributions well.  For example, add-constant estimators are nearly min-max optimal but often perform poorly in practice, and practical estimators such as absolute discounting, Jelinek-Mercer, and Good-Turing are not known to be near optimal for essentially any distribution.We describe the first universally near-optimal probability estimators. For every discrete distribution, they are provably nearly the best in the following two competitive ways. First they estimate every distribution nearly as well as the best estimator designed with prior knowledge of the distribution up to a permutation. Second, they estimate every distribution nearly as well as the best estimator designed with prior knowledge of the exact distribution, but as all natural estimators, restricted to assign the same probability to all symbols appearing the same number of times.Specifically, for distributions over $k$ symbols and $n$ samples, we show that for both comparisons, a simple variant of Good-Turing estimator is always within KL divergence of $(3+o(1))/n^{1/3}$ from the best estimator, and that a more involved estimator is within $\\tilde{\\mathcal{O}}(\\min(k/n,1/\\sqrt n))$.  Conversely, we show that any estimator must have a KL divergence $\\ge\\tilde\\Omega(\\min(k/n,1/ n^{2/3}))$ over the best estimator for the first comparison, and $\\ge\\tilde\\Omega(\\min(k/n,1/\\sqrt{n}))$ for the second."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mixed Robust/Average Submodular Partitioning", "Title": "Fast Algorithms, Guarantees, and Applications", "Abstract": "We investigate two novel mixed robust/average-case submodular data partitioning problems that we collectively call Submodular Partitioning. These problems generalize purely robust instances of the problem, namely max-min submodular fair allocation (SFA) and \\emph{min-max submodular load balancing} (SLB), and also average-case instances, that is the submodular welfare problem (SWP) and submodular multiway partition (SMP). While the robust versions have been studied in the theory community, existing work has focused on tight approximation guarantees, and the resultant algorithms are not generally scalable to large real-world applications. This contrasts the average case instances, where most of the algorithms are scalable.  In the present paper, we bridge this gap, by proposing several new algorithms (including greedy, majorization-minimization, minorization-maximization, and relaxation algorithms) that not only scale to large datasets but that also achieve theoretical approximation guarantees comparable to the state-of-the-art. We moreover provide new scalable algorithms that apply to additive combinations of the robust and average-case objectives. We show that these problems have many applications in machine learning (ML), including data partitioning and load balancing for distributed ML, data clustering, and image segmentation. We empirically demonstrate the efficacy of our algorithms on real-world problems involving data partitioning for distributed optimization (of convex and deep neural network objectives), and also purely unsupervised image segmentation."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Stochastic Optimization", "Title": "From Sets to Paths", "Abstract": "Adaptive stochastic optimization optimizes an objective function adaptively under uncertainty. Adaptive stochastic optimization plays a crucial role in planning and learning under uncertainty, but is, unfortunately, computationally intractable in general.  This paper introduces two conditions on the objective function, the marginal likelihood rate bound and the marginal likelihood bound, which enable efficient approximate solution of adaptive stochastic optimization. Several interesting classes of functions satisfy these conditions naturally, e.g., the version space reduction function for hypothesis learning.  We describe Recursive Adaptive Coverage (RAC),  a new adaptive stochastic optimization algorithm that exploits these conditions, and apply it to two planning tasks under uncertainty. In constrast to the earlier submodular optimization approach, our algorithm applies to adaptive stochastic optimization algorithm over both sets and paths."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structured Estimation with Atomic Norms", "Title": "General Bounds and Applications", "Abstract": "For structured estimation problems with atomic norms, recent advances in the literature express sample complexity and estimation error bounds in terms of certain geometric measures, in particular Gaussian width of the unit norm ball, Gaussian width of a spherical cap induced by a tangent cone, and a restricted norm compatibility constant. However, given an atomic norm, bounding these geometric measures can be difficult. In this paper, we present general upper bounds for such geometric measures, which only require simple information of the atomic norm under consideration, and we establish tightness of these bounds by providing the corresponding lower bounds. We show applications of our analysis to certain atomic norms, especially k-support norm, for which existing result is incomplete."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Explore no more", "Title": "Improved high-probability regret bounds for non-stochastic bandits", "Abstract": "This work addresses the problem of regret minimization in non-stochastic multi-armed bandit problems, focusing on performance guarantees that hold with high probability. Such results are rather scarce in the literature since proving them requires a large deal of technical effort and significant modifications to the standard, more intuitive algorithms that come only with guarantees that hold on expectation. One of these modifications is forcing the learner to sample arms from the uniform distribution at least $\\Omega(\\sqrt{T})$ times over $T$ rounds, which can adversely affect performance if many of the arms are suboptimal. While it is widely conjectured that this property is essential for proving high-probability regret bounds, we show in this paper that it is possible to achieve such strong results without this undesirable exploration component. Our result relies on a simple and intuitive loss-estimation strategy called Implicit eXploration (IX) that allows a remarkably clean analysis. To demonstrate the flexibility of our technique, we derive several improved high-probability bounds for various extensions of the standard multi-armed bandit framework.Finally, we conduct a simple experiment that illustrates the robustness of our implicit exploration technique."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Path-SGD", "Title": "Path-Normalized Optimization in Deep Neural Networks", "Abstract": "We revisit the choice of SGD for training deep neural networks by reconsidering the appropriate geometry in which to optimize the weights.  We argue for a geometry invariant to rescaling of weights that does not affect the output of the network, and suggest Path-SGD, which is an approximate steepest descent method with respect to a path-wise regularizer related to max-norm regularization.  Path-SGD is easy and efficient to implement and leads to empirical gains over SGD and AdaGrad."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Softstar", "Title": "Heuristic-Guided Probabilistic Inference", "Abstract": "Recent machine learning methods for sequential behavior prediction estimate the motives of behavior rather than the behavior itself. This higher-level abstraction improves generalization in different prediction settings, but computing predictions often becomes intractable in large decision spaces.  We propose the Softstar algorithm, a softened heuristic-guided search technique for the maximum entropy inverse optimal control model of sequential behavior.  This approach supports probabilistic search with bounded approximation error at a significantly reduced computational cost when compared to sampling based methods.  We present the algorithm, analyze approximation guarantees, and compare performance with simulation-based inference on two distinct complex decision tasks."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HONOR", "Title": "Hybrid Optimization for NOn-convex Regularized problems", "Abstract": "Recent years have witnessed the superiority of non-convex sparse learning formulations over their convex counterparts in both theory and practice. However, due to the non-convexity and non-smoothness of the regularizer, how to efficiently solve the non-convex optimization problem for large-scale data is still quite challenging. In this paper, we propose an efficient \\underline{H}ybrid \\underline{O}ptimization algorithm for \\underline{NO}n convex \\underline{R}egularized problems (HONOR). Specifically, we develop a hybrid scheme which effectively integrates a Quasi-Newton (QN) step and a Gradient Descent (GD) step. Our contributions are as follows: (1) HONOR incorporates the second-order information to greatly speed up the convergence, while it avoids solving a regularized quadratic programming and only involves matrix-vector multiplications without explicitly forming the inverse Hessian matrix. (2)  We establish a rigorous convergence analysis for HONOR, which shows that convergence is guaranteed even for non-convex problems, while it is typically challenging to analyze the convergence for non-convex problems. (3) We conduct empirical studies on large-scale data sets and results demonstrate that HONOR converges significantly faster than state-of-the-art algorithms."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fixed-Length Poisson MRF", "Title": "Adding Dependencies to the Multinomial", "Abstract": "We propose a novel distribution that generalizes the Multinomial distribution to enable dependencies between dimensions. Our novel distribution is based on the parametric form of the Poisson MRF model [Yang et al., 2012] but is fundamentally different because of the domain restriction to a fixed-length vector like in a Multinomial where the number of trials is fixed or known. Thus, we propose the Fixed-Length Poisson MRF (LPMRF) distribution. We develop methods to estimate the likelihood and log partition function (i.e. the log normalizing constant), which was not developed for the Poisson MRF model. In addition, we propose novel mixture and topic models that use LPMRF as a base distribution and discuss the similarities and differences with previous topic models such as the recently proposed Admixture of Poisson MRFs [Inouye et al., 2014]. We show the effectiveness of our LPMRF distribution over Multinomial models by evaluating the test set perplexity on a dataset of abstracts and Wikipedia. Qualitatively, we show that the positive dependencies discovered by LPMRF are interesting and intuitive. Finally, we show that our algorithms are fast and have good scaling (code available online)."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Sub-Gaussian Measurements", "Title": "High-Dimensional Structured Estimation with Sub-Exponential Designs", "Abstract": "We consider the problem of high-dimensional structured estimation with norm-regularized estimators, such as Lasso, when the design matrix and noise are drawn from sub-exponential distributions.Existing results only consider sub-Gaussian designs and noise, and both the sample complexity and non-asymptotic estimation error have been shown to depend on the Gaussian width of suitable sets. In contrast, for the sub-exponential setting, we show that the sample complexity and the estimation error will depend on the exponential width of the corresponding sets, and the analysis holds for any norm. Further, using generic chaining, we show that the exponential width for any set will be at most $\\sqrt{\\log p}$ times the Gaussian width of the set, yielding Gaussian width based results even for the sub-exponential case. Further, for certain popular estimators, viz Lasso and Group Lasso, using a VC-dimension based analysis, we show that the sample complexity will in fact be the same order as Gaussian designs. Our general analysis and results are the first in the sub-exponential setting, and are readily applicable to special sub-exponential families such as log-concave and extreme-value distributions."}
{"Type": "conference", "Year": "2015", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Collaborative Filtering with Graph Information", "Title": "Consistency and Scalable Methods", "Abstract": "Low rank matrix completion plays a fundamental role in collaborative filtering applications, the key idea being that the variables lie in a smaller subspace than the ambient space. Often, additional information about the variables is known, and it is reasonable to assume that incorporating this information will lead to better predictions. We tackle the problem of matrix completion when pairwise relationships among variables are known, via a graph. We formulate and derive a highly efficient, conjugate gradient based alternating minimization scheme that solves optimizations with over 55 million observations up to 2 orders of magnitude faster than state-of-the-art (stochastic) gradient-descent based methods. On the theoretical front, we show that such methods generalize weighted nuclear norm formulations, and derive statistical consistency guarantees. We validate our results on both real and synthetic datasets."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tagger", "Title": "Deep Unsupervised Perceptual Grouping", "Abstract": "We present a framework for efficient perceptual inference that explicitly reasons about the segmentation of its inputs and features.  Rather than being trained for any specific segmentation, our framework learns the grouping process in an unsupervised manner or alongside any supervised task. We enable a neural network to group the representations of different objects in an iterative manner through a differentiable mechanism.  We achieve very fast convergence by allowing the system to amortize the joint iterative inference of the groupings and their representations.  In contrast to many other recently proposed methods for addressing multi-object scenes, our system does not assume the inputs to be images and can therefore directly handle other modalities. We evaluate our method on multi-digit classification of very cluttered images that require texture segmentation. Remarkably our method achieves improved classification performance over convolutional networks despite being fully connected, by making use of the grouping mechanism. Furthermore, we observe that our system greatly improves upon the semi-supervised result of a baseline Ladder network on our dataset. These results are evidence that grouping is a powerful tool that can help to improve sample efficiency."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Collaborative Recurrent Autoencoder", "Title": "Recommend while Learning to Fill in the Blanks", "Abstract": "Hybrid methods that utilize both content and rating information are commonly used in many recommender systems. However, most of them use either handcrafted features or the bag-of-words representation as a surrogate for the content information but they are neither effective nor natural enough. To address this problem, we develop a collaborative recurrent autoencoder (CRAE) which is a denoising recurrent autoencoder (DRAE) that models the generation of content sequences in the collaborative filtering (CF) setting. The model generalizes recent advances in recurrent deep learning from i.i.d. input to non-i.i.d. (CF-based) input and provides a new denoising scheme along with a novel learnable pooling scheme for the recurrent autoencoder. To do this, we first develop a hierarchical Bayesian model for the DRAE and then generalize it to the CF setting. The synergy between denoising and CF enables CRAE to make accurate recommendations while learning to fill in the blanks in sequences. Experiments on real-world datasets from different domains (CiteULike and Netflix) show that, by jointly modeling the order-aware generation of sequences for the content information and performing CF for the ratings, CRAE is able to significantly outperform the state of the art on both the recommendation task based on ratings and the sequence generation task based on content information."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Visual Dynamics", "Title": "Probabilistic Future Frame Synthesis via Cross Convolutional Networks", "Abstract": "We study the problem of synthesizing a number of likely future frames from a single input image. In contrast to traditional methods, which have tackled this problem in a deterministic or non-parametric way, we propose a novel approach which models future frames in a probabilistic manner. Our proposed method is therefore able to synthesize multiple possible next frames using the same model. Solving this challenging problem involves low- and high-level image and motion understanding for successful image synthesis. Here, we propose a novel network structure, namely a Cross Convolutional Network, that encodes images as feature maps and motion information as convolutional kernels to aid in synthesizing future frames. In experiments, our model performs well on both synthetic data, such as 2D shapes and animated game sprites, as well as on real-wold video data. We show that our model can also be applied to tasks such as visual analogy-making, and present analysis of the learned network representations."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast Distributed Submodular Cover", "Title": "Public-Private Data Summarization", "Abstract": "In this paper, we introduce the public-private framework of data summarization motivated by privacy concerns in personalized recommender systems and online social services. Such systems have usually access to massive data generated by a large pool of users. A major fraction of the data is public and is visible to (and can be used for) all users. However, each user can also contribute some private data that should not be shared with other users to ensure her privacy. The goal is to provide a succinct summary of massive dataset, ideally as small as possible, from which customized summaries can be built for each user, i.e. it can contain elements from the public data (for diversity) and users' private data (for personalization). To formalize the above challenge, we assume that the scoring function according to which a user evaluates the utility of her summary satisfies submodularity, a widely used notion in data summarization applications. Thus, we model the data summarization targeted to each user as an instance of a submodular cover problem. However, when the data is massive it is infeasible to use the centralized greedy algorithm to find a customized summary even for a single user. Moreover, for a large pool of users, it is too time consuming to find such summaries separately. Instead, we develop a fast distributed algorithm for submodular cover, FASTCOVER, that provides a succinct summary in one shot and for all users. We show that the solution provided by FASTCOVER is competitive with that of the centralized algorithm with the number of rounds that is exponentially smaller than state of the art results. Moreover, we have implemented FASTCOVER with Spark to demonstrate its practical performance on a number of concrete applications, including personalized location recommendation, personalized movie recommendation, and dominating set on tens of millions of data points and varying number of users."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Avoiding Imposters and Delinquents", "Title": "Adversarial Crowdsourcing and Peer Prediction", "Abstract": "We consider a crowdsourcing model in which n workers are asked to rate the quality of n items previously generated by other workers. An unknown set of $\\alpha n$ workers generate reliable ratings, while the remaining workers may behave arbitrarily and possibly adversarially. The manager of the experiment can also manually evaluate the quality of a small number of items, and wishes to curate together almost all of the high-quality items with at most an fraction of low-quality items. Perhaps surprisingly, we show that this is possible with an amount of work required of the manager, and each worker, that does not scale with n: the dataset can be curated with $\\tilde{O}(1/\\beta\\alpha\\epsilon^4)$ ratings per worker, and $\\tilde{O}(1/\\beta\\epsilon^2)$ ratings by the manager, where $\\beta$ is the fraction of high-quality items. Our results extend to the more general setting of peer prediction, including peer grading in online classrooms."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Efficient state-space modularization for planning", "Title": "theory, behavioral and neural signatures", "Abstract": "Even in state-spaces of modest size, planning is plagued by the “curse of dimensionality”. This problem is particularly acute in human and animal cognition given the limited capacity of working memory, and the time pressures under which planning often occurs in the natural environment. Hierarchically organized modular representations have long been suggested to underlie the capacity of biological systems to efficiently and flexibly plan in complex environments. However, the principles underlying efficient modularization remain obscure, making it difficult to identify its behavioral and neural signatures. Here, we develop a normative theory of efficient state-space representations which partitions an environment into distinct modules by minimizing the average (information theoretic) description length of planning within the environment, thereby optimally trading off the complexity of planning across and within modules. We show that such optimal representations provide a unifying account for a diverse range of hitherto unrelated phenomena at multiple levels of behavior and neural representation."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaGrad", "Title": "Multiple Learning Rates in Online Learning", "Abstract": "In online convex optimization it is well known that certain subclasses of objective functions are much easier than arbitrary convex functions. We are interested in designing adaptive methods that can automatically get fast rates in as many such subclasses as possible, without any manual tuning. Previous adaptive methods are able to interpolate between strongly convex and general convex functions. We present a new method, MetaGrad, that adapts to a much broader class of functions, including exp-concave and strongly convex functions, but also various types of stochastic and non-stochastic functions without any curvature. For instance, MetaGrad can achieve logarithmic regret on the unregularized hinge loss, even though it has no curvature, if the data come from a favourable probability distribution. MetaGrad's main feature is that it simultaneously considers multiple learning rates. Unlike all previous methods with provable regret guarantees, however, its learning rates are not monotonically decreasing over time and are not tuned based on a theoretically derived bound on the regret. Instead, they are weighted directly proportional to their empirical performance on the data using a tilted exponential weights master algorithm."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning under uncertainty", "Title": "a comparison between R-W and Bayesian approach", "Abstract": "Accurately differentiating between what are truly unpredictably random and systematic changes that occur at random can have profound effect on affect and cognition. To examine the underlying computational principles that guide different learning behavior in an uncertain environment, we compared an R-W model and a Bayesian approach in a visual search task with different volatility levels. Both R-W model and the Bayesian approach reflected an individual's estimation of the environmental volatility, and there is a strong correlation between the learning rate in R-W model and the belief of stationarity in the Bayesian approach in different volatility conditions. In a low volatility condition, R-W model indicates that learning rate positively correlates with lose-shift rate, but not choice optimality (inverted U shape). The Bayesian approach indicates that the belief of environmental stationarity positively correlates with choice optimality, but not lose-shift rate (inverted U shape). In addition, we showed that comparing to Expert learners, individuals with high lose-shift rate (sub-optimal learners) had significantly higher learning rate estimated from R-W model and lower belief of stationarity from the Bayesian model."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Professor Forcing", "Title": "A New Algorithm for Training Recurrent Networks", "Abstract": "The Teacher Forcing algorithm trains recurrent networks by supplying observed sequence values as inputs during training and using the network’s own one-step-ahead predictions to do multi-step sampling. We introduce the Professor Forcing algorithm, which uses adversarial domain adaptation to encourage the dynamics of the recurrent network to be the same when training the network and when sampling from the network over multiple time steps. We apply Professor Forcing to language modeling, vocal synthesis on raw waveforms, handwriting generation, and image generation. Empirically we find that Professor Forcing acts as a regularizer, improving test likelihood on character level Penn Treebank and sequential MNIST. We also find that the model qualitatively improves samples, especially when sampling for a large number of time steps.  This is supported by human evaluation of sample quality.  Trade-offs between Professor Forcing and Scheduled Sampling are discussed. We produce T-SNEs showing that Professor Forcing successfully makes the dynamics of the network during training and sampling more similar."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Total Variation Classes Beyond 1d", "Title": "Minimax Rates, and the Limitations of Linear Smoothers", "Abstract": "We consider the problem of estimating a function defined over $n$ locations on a $d$-dimensional grid (having all side lengths equal to $n^{1/d}$).  When the function is constrained to have discrete total variation bounded by $C_n$, we derive the minimax optimal (squared) $\\ell_2$ estimation error rate, parametrized by $n, C_n$. Total variation denoising, also known as the fused lasso, is seen to be rate optimal.  Several simpler estimators exist, such as Laplacian smoothing and Laplacian eigenmaps.  A natural question is: can these simpler estimators perform just as well?  We prove that these estimators, and more broadly all estimators given by linear transformations of the input data, are suboptimal over the class of functions with bounded variation. This extends fundamental findings of Donoho and Johnstone (1998) on 1-dimensional total variation spaces to higher dimensions.  The implication is that the computationally simpler methods cannot be used for such sophisticated denoising tasks, without sacrificing statistical accuracy. We also derive minimax rates for discrete Sobolev spaces over $d$-dimensional grids, which are, in some sense, smaller than the total variation function spaces.  Indeed, these are small enough spaces that linear estimators can be optimal---and a few well-known ones are, such as Laplacian smoothing and Laplacian eigenmaps, as we show.  Lastly, we investigate the adaptivity of the total variation denoiser to these smaller Sobolev function spaces."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "beta-risk", "Title": "a New Surrogate Risk for Learning from Weakly Labeled Data", "Abstract": "During the past few years, the machine learning community has paid attention to developping new methods for learning from weakly labeled data. This field covers different settings like semi-supervised learning, learning with label proportions, multi-instance learning, noise-tolerant learning, etc. This paper presents a generic framework to deal with these weakly labeled scenarios. We introduce the beta-risk as a generalized formulation of the standard empirical risk based on surrogate margin-based loss functions. This risk allows us to express the reliability on the labels and to derive different kinds of learning algorithms. We specifically focus on SVMs and propose a soft margin beta-svm algorithm  which behaves better that the state of the art."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RETAIN", "Title": "An Interpretable Predictive Model for Healthcare using Reverse Time Attention Mechanism", "Abstract": "Accuracy and interpretability are two dominant features of successful predictive models. Typically, a choice must be made in favor of complex black box models such as recurrent neural networks (RNN) for accuracy versus less accurate but more interpretable traditional models such as logistic regression. This tradeoff poses challenges in medicine where both accuracy and interpretability are important. We addressed this challenge by developing the REverse Time AttentIoN model (RETAIN) for application to Electronic Health Records (EHR) data. RETAIN achieves high accuracy while remaining clinically interpretable and is based on a two-level neural attention model that detects influential past visits and significant clinical variables within those visits (e.g. key diagnoses). RETAIN mimics physician practice by attending the EHR data in a reverse time order so that recent clinical visits are likely to receive higher attention. RETAIN was tested on a large health system EHR dataset with 14 million visits completed by 263K patients over an 8 year period and demonstrated predictive accuracy and computational scalability comparable to state-of-the-art methods such as RNN, and ease of interpretability comparable to traditional models."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generative Shape Models", "Title": "Joint Text Recognition and Segmentation with Very Little Training Data", "Abstract": "We demonstrate that a generative model for object shapes can achieve state of the art results on challenging scene text recognition tasks, and with orders of magnitude fewer training images than required for competing discriminative methods. In addition to transcribing text from challenging images, our method performs fine-grained instance segmentation of characters. We show that our model is more robust to both affine transformations and non-affine deformations compared to previous approaches."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Split LBI", "Title": "An Iterative Regularization Path with Structural Sparsity", "Abstract": "An iterative regularization path with structural sparsity is proposed in this paper based on variable splitting and the Linearized Bregman Iteration, hence called \\emph{Split LBI}. Despite its simplicity, Split LBI outperforms the popular generalized Lasso in both theory and experiments. A theory of path consistency is presented that equipped with a proper early stopping, Split LBI may achieve model selection consistency under a family of Irrepresentable Conditions which can be weaker than the necessary and sufficient condition for generalized Lasso. Furthermore, some $\\ell_2$ error bounds are also given at the minimax optimal rates. The utility and benefit of the algorithm are illustrated by applications on both traditional image denoising and a novel example on partial order ranking."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Graph Clustering", "Title": "Block-models and model free results", "Abstract": "Clustering graphs under the Stochastic Block Model (SBM) and extensions are well studied. Guarantees of correctness exist under the assumption that the data is sampled from a model. In this paper, we propose a framework, in which we obtain \"correctness\" guarantees without assuming the data comes from a model. The guarantees we obtain depend instead on the statistics of the data that can be checked. We also show that this framework ties in with the existing model-based framework, and that we can exploit results in model-based recovery, as well as strengthen the results existing in that area of research."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cyclades", "Title": "Conflict-free Asynchronous Machine Learning", "Abstract": "We present Cyclades, a general framework for parallelizing stochastic optimization algorithms in a shared memory setting. Cyclades is asynchronous during model updates, and requires no memory locking mechanisms, similar to Hogwild!-type algorithms. Unlike Hogwild!, Cyclades introduces no conflicts during parallel execution, and offers a black-box analysis for provable speedups across a large family of algorithms.  Due to its inherent cache locality and conflict-free nature,  our multi-core implementation of Cyclades consistently outperforms Hogwild!-type algorithms on sufficiently sparse datasets, leading to up to 40% speedup gains compared to Hogwild!, and up to 5\\times gains over asynchronous implementations of variance reduction algorithms."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Sound of APALM Clapping", "Title": "Faster Nonsmooth Nonconvex Optimization with Stochastic Asynchronous PALM", "Abstract": "We introduce the Stochastic Asynchronous Proximal Alternating Linearized Minimization (SAPALM) method, a block coordinate stochastic proximal-gradient method for solving nonconvex, nonsmooth optimization problems. SAPALM is the first asynchronous parallel optimization method that provably converges on a large class of nonconvex, nonsmooth problems. We prove that SAPALM matches the best known rates of convergence --- among synchronous or asynchronous methods --- on this problem class. We provide upper bounds on the number of workers for which we can expect to see a linear speedup, which match the best bounds known for less complex problems, and show that in practice SAPALM achieves this linear speedup. We demonstrate state-of-the-art performance on several matrix factorization problems."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "k*-Nearest Neighbors", "Title": "From Global to Local", "Abstract": "The weighted k-nearest neighbors  algorithm is one of the most fundamental non-parametric methods in pattern recognition and machine learning.  The question of setting the optimal number of neighbors as well as the optimal weights has received much attention throughout the years, nevertheless this problem seems to  have remained unsettled. In this paper we offer a simple approach to locally weighted regression/classification, where we make the bias-variance tradeoff explicit.  Our formulation enables us to phrase a notion of optimal weights, and to efficiently find these weights as well as the optimal number of neighbors  efficiently and adaptively, for each data point whose value we wish to estimate. The applicability of our approach is demonstrated on several datasets, showing superior performance over standard locally weighted methods."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Maximizing Influence in an Ising Network", "Title": "A Mean-Field Optimal Solution", "Abstract": "Influence maximization in social networks has typically been studied in the context of contagion models and irreversible processes. In this paper, we consider an alternate model that treats individual opinions as spins in an Ising system at dynamic equilibrium. We formalize the \\textit{Ising influence maximization} problem, which has a natural physical interpretation as maximizing the magnetization given a budget of external magnetic field. Under the mean-field (MF) approximation, we present a gradient ascent algorithm that uses the susceptibility to efficiently calculate local maxima of the magnetization, and we develop a number of sufficient conditions for when the MF magnetization is concave and our algorithm converges to a global optimum. We apply our algorithm on random and real-world networks, demonstrating, remarkably, that the MF optimal external fields (i.e., the external fields which maximize the MF magnetization) exhibit a phase transition from focusing on high-degree individuals at high temperatures to focusing on low-degree individuals at low temperatures. We also establish a number of novel results about the structure of steady-states in the ferromagnetic MF Ising model on general graphs, which are of independent interest."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Exchangeability", "Title": "The Chinese Voting Process", "Abstract": "Many online communities present user-contributed responses, such as reviews of products and answers to questions. User-provided helpfulness votes can highlight the most useful responses, but voting is a social process that can gain momentum based on the popularity of responses and the polarity of existing votes. We propose the Chinese Voting Process (CVP) which models the evolution of helpfulness votes as a self-reinforcing process dependent on position and presentation biases. We evaluate this model on Amazon product reviews and more than 80 StackExchange forums, measuring the intrinsic quality of individual responses and behavioral coefficients of different communities."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CNNpack", "Title": "Packing Convolutional Neural Networks in the Frequency Domain", "Abstract": "Deep convolutional neural networks (CNNs) are successfully used in a number of applications. However, their storage and computational requirements have largely prevented their widespread use on mobile devices. Here we present an effective CNN compression approach in the frequency domain, which focuses not only on smaller weights but on all the weights and their underlying connections. By treating convolutional filters as images, we decompose their representations in the frequency domain as common parts (i.e., cluster centers) shared by other similar filters and their individual private parts (i.e., individual residuals). A large number of low-energy frequency coefficients in both parts can be discarded to produce high compression without significantly compromising accuracy. We relax the computational burden of convolution operations in CNNs by linearly combining the convolution responses of discrete cosine transform (DCT) bases. The compression and speed-up ratios of the proposed algorithm are thoroughly analyzed and evaluated on benchmark image datasets to demonstrate its superiority over state-of-the-art methods."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Feature-distributed sparse regression", "Title": "a screen-and-clean approach", "Abstract": "Most existing approaches to distributed sparse regression assume the data is partitioned by samples. However, for high-dimensional data (D >> N), it is more natural to partition the data by features. We propose an algorithm to distributed sparse regression when the data is partitioned by features rather than samples. Our approach allows the user to tailor our general method to various distributed computing platforms by trading-off the total amount of data (in bits) sent over the communication network and the number of rounds of communication. We show that an implementation of our approach is capable of solving L1-regularized L2 regression problems with millions of features in minutes."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Local Maxima in the Likelihood of Gaussian Mixture Models", "Title": "Structural Results and Algorithmic Consequences", "Abstract": "We provide two fundamental results on the population (infinite-sample) likelihood function of Gaussian mixture models with $M \\geq 3$ components. Our first main result shows that the population likelihood function has bad local maxima even in the special case of equally-weighted mixtures of well-separated and spherical Gaussians. We prove that the log-likelihood value of these bad local maxima can be arbitrarily worse than that of any global optimum, thereby resolving an open question of Srebro (2007). Our second main result shows that the EM algorithm (or a first-order variant of it) with random initialization will converge to bad critical points with probability at least $1-e^{-\\Omega(M)}$. We further establish that a first-order variant of EM will not converge to strict saddle points almost surely, indicating that the poor performance of the first-order method can be attributed to the existence of bad local maxima rather than bad saddle points. Overall, our results highlight the necessity of careful initialization when using the EM algorithm in practice, even when applied in highly favorable settings."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neurally-Guided Procedural Models", "Title": "Amortized Inference for Procedural Graphics Programs using Neural Networks", "Abstract": "Probabilistic inference algorithms such as Sequential Monte Carlo (SMC) provide powerful tools for constraining procedural models in computer graphics, but they require many samples to produce desirable results. In this paper, we show how to create procedural models which learn how to satisfy constraints. We augment procedural models with neural networks which control how the model makes random choices based on the output it has generated thus far. We call such models neurally-guided procedural models. As a pre-computation, we train these models to maximize the likelihood of example outputs generated via SMC. They are then used as efficient SMC importance samplers, generating high-quality results with very few samples. We evaluate our method on L-system-like models with image-based constraints. Given a desired quality threshold, neurally-guided models can generate satisfactory results up to 10x faster than unguided models."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Breaking the Bandwidth Barrier", "Title": "Geometrical Adaptive Entropy Estimation", "Abstract": "Estimators of information theoretic measures such as entropy and mutual information from samples are a basic workhorse for many downstream applications in modern data science. State of the art approaches have been either geometric (nearest neighbor (NN) based) or kernel based (with bandwidth chosen to be data independent and vanishing sub linearly in the sample size). In this paper we combine both these approaches to design new estimators of entropy and mutual information that strongly outperform all state of the art methods. Our estimator uses bandwidth choice of fixed $k$-NN distances; such a choice is both data dependent and linearly vanishing in the sample size and necessitates a bias cancellation term that  is  universal and independent of the underlying distribution. As a byproduct, we obtain a unified way of obtaining both kernel and NN estimators.  The corresponding theoretical contribution relating the geometry of NN distances to asymptotic order statistics  is of independent mathematical interest."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-armed Bandits", "Title": "Competing with Optimal Sequences", "Abstract": "We consider sequential decision making problem in the adversarial setting, where regret is measured with respect to the optimal sequence of actions and the feedback adheres the bandit setting. It is well-known that obtaining sublinear regret in this setting is impossible in general, which arises the question of when can we do better than linear regret? Previous works show that when the environment is guaranteed to vary slowly and furthermore we are given prior knowledge regarding its variation (i.e., a limit on the amount of changes suffered by the environment), then this task is feasible. The caveat however is that such prior knowledge is not likely to be available in practice, which causes the obtained regret bounds to be somewhat irrelevant.   Our main result is a regret guarantee that scales with the variation parameter of the environment, without requiring any prior knowledge about it whatsoever. By that, we also resolve an open problem posted by [Gur, Zeevi and Besbes, NIPS' 14]. An important key component in our result is a statistical test for identifying non-stationarity in a sequence of independent random variables. This test either identifies non-stationarity or upper-bounds the absolute deviation of the corresponding sequence of mean values in terms of its total variation. This test is interesting on its own right and has the potential to be found useful in additional settings."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NESTT", "Title": "A Nonconvex Primal-Dual Splitting Method for Distributed and Stochastic Optimization", "Abstract": "We study a stochastic and distributed algorithm for nonconvex  problems whose objective consists a sum $N$ nonconvex $L_i/N$-smooth functions, plus a  nonsmooth regularizer. The proposed NonconvEx primal-dual SpliTTing (NESTT) algorithm splits the problem into $N$ subproblems, and utilizes an augmented Lagrangian based primal-dual scheme to solve it in a distributed and stochastic manner. With a special non-uniform sampling, a version of NESTT achieves $\\epsilon$-stationary solution  using $\\mathcal{O}((\\sum_{i=1}^N\\sqrt{L_i/N})^2/\\epsilon)$ gradient evaluations, which can be up to $\\mathcal{O}(N)$ times better than the (proximal) gradient descent methods. It also achieves Q-linear convergence rate for nonconvex $\\ell_1$ penalized quadratic problems with polyhedral constraints. Further, we reveal  a fundamental connection between {\\it primal-dual} based methods and a few {\\it primal only} methods such as IAG/SAG/SAGA."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Exploiting the Structure", "Title": "Stochastic Gradient Methods Using Raw Clusters", "Abstract": "The amount of data available in the world is growing faster than our ability to deal with it. However, if we take advantage of the internal structure, data may become much smaller for machine learning purposes. In this paper we focus on one of the fundamental machine learning tasks, empirical risk minimization (ERM), and provide faster algorithms with the help from the clustering structure of the data.  We introduce a simple notion of raw clustering that can be efficiently computed from the data, and propose two algorithms based on clustering information. Our accelerated algorithm ClusterACDM is built on a novel Haar transformation applied to the dual space of the ERM problem, and our variance-reduction based algorithm ClusterSVRG introduces a new gradient estimator using clustering. Our algorithms outperform their classical counterparts ACDM and SVRG respectively."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Using Social Dynamics to Make Individual Predictions", "Title": "Variational Inference with a Stochastic Kinetic Model", "Abstract": "Social dynamics is concerned primarily with interactions among individuals and the resulting group behaviors, modeling the temporal evolution of social systems via the interactions of individuals within these systems. In particular, the availability of large-scale data from social networks and sensor networks offers an unprecedented opportunity to predict state-changing events at the individual level. Examples of such events include disease transmission, opinion transition in elections, and rumor propagation. Unlike previous research focusing on the collective effects of social systems, this study makes efficient inferences at the individual level. In order to cope with dynamic interactions among a large number of individuals, we introduce the stochastic kinetic model to capture adaptive transition probabilities and propose an efficient variational inference algorithm the complexity of which grows linearly — rather than exponentially— with the number of individuals. To validate this method, we have performed epidemic-dynamics experiments on wireless sensor network data collected from more than ten thousand people over three years. The proposed algorithm was used to track disease transmission and predict the probability of infection for each individual. Our results demonstrate that this method is more efficient than sampling while nonetheless achieving high accuracy."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attend, Infer, Repeat", "Title": "Fast Scene Understanding with Generative Models", "Abstract": "We present a framework for efficient inference in structured image models that explicitly reason about objects. We achieve this by performing probabilistic inference using a recurrent neural network that attends to scene elements and processes them one at a time. Crucially, the model itself learns to choose the appropriate number of inference steps. We use this scheme to learn to perform inference in partially specified 2D models (variable-sized variational auto-encoders) and fully specified 3D models (probabilistic renderers). We show that such models learn to identify multiple objects - counting, locating and classifying the elements of a scene - without any supervision, e.g., decomposing 3D images with various numbers of objects in a single forward pass of a neural network at unprecedented speed. We further show that the networks produce accurate inferences when compared to supervised counterparts, and that their structure leads to improved generalization."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Following the Leader and Fast Rates in Linear Prediction", "Title": "Curved Constraint Sets and Other Regularities", "Abstract": "The follow the leader (FTL) algorithm, perhaps the simplest of all online learning algorithms, is known to perform well when the loss functions it is used on are positively curved. In this paper we ask whether there are other \"lucky\" settings when FTL achieves sublinear, \"small\" regret. In particular, we study the fundamental problem of linear prediction over a non-empty convex, compact domain. Amongst other results, we prove that the curvature of  the boundary of the domain can act as if the losses were curved: In this case, we prove that as long as the mean of the loss vectors have positive lengths bounded away from zero, FTL enjoys a logarithmic growth rate of regret, while, e.g., for polyhedral domains and stochastic data it enjoys finite expected regret. Building on a previously known meta-algorithm, we also get an algorithm that simultaneously enjoys the worst-case guarantees and the bound available for FTL."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "R-FCN", "Title": "Object Detection via Region-based Fully Convolutional Networks", "Abstract": "We present region-based, fully convolutional networks for accurate and efficient object detection. In contrast to previous region-based detectors such as Fast/Faster R-CNN that apply a costly per-region subnetwork hundreds of times, our region-based detector is fully convolutional with almost all computation shared on the entire image. To achieve this goal, we propose position-sensitive score maps to address a dilemma between translation-invariance in image classification and translation-variance in object detection. Our method can thus naturally adopt fully convolutional image classifier backbones, such as the latest Residual Networks (ResNets), for object detection. We show competitive results on the PASCAL VOC datasets (e.g., 83.6% mAP on the 2007 set) with the 101-layer ResNet. Meanwhile, our result is achieved at a test-time speed of 170ms per image, 2.5-20 times faster than the Faster R-CNN counterpart. Code is made publicly available at: https://github.com/daijifeng001/r-fcn."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Privacy Odometers and Filters", "Title": "Pay-as-you-Go Composition", "Abstract": "In this paper we initiate the study of adaptive composition in differential privacy when the length of the composition, and the privacy parameters themselves can be chosen adaptively, as a function of the outcome of previously run analyses. This case is much more delicate than the setting covered by existing composition theorems, in which the algorithms themselves can be chosen adaptively, but the privacy parameters must be fixed up front. Indeed, it isn't even clear how to define differential privacy in the adaptive parameter setting. We proceed by defining two objects which cover the two main use cases of composition theorems. A privacy filter is a stopping time rule that allows an analyst to halt a computation before his pre-specified privacy budget is exceeded. A privacy odometer allows the analyst to track realized privacy loss as he goes, without needing to pre-specify a privacy budget. We show that unlike the case in which privacy parameters are fixed, in the adaptive parameter setting, these two use cases are distinct. We show that there exist privacy filters with bounds comparable (up to constants) with existing privacy composition theorems. We also give a privacy odometer that nearly matches non-adaptive private composition theorems, but is sometimes worse by a small asymptotic factor. Moreover, we show that this is inherent, and that any valid privacy odometer in the adaptive parameter setting must lose this factor, which shows a formal separation between the filter and odometer use-cases."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "More Supervision, Less Computation", "Title": "Statistical-Computational Tradeoffs in Weakly Supervised Learning", "Abstract": "We consider the weakly supervised binary classification problem where the labels are randomly flipped with probability $1-\\alpha$. Although there exist numerous algorithms for this problem, it remains theoretically unexplored how the statistical accuracies and computational efficiency of these algorithms depend on the degree of supervision, which is quantified by $\\alpha$. In this paper, we characterize the effect of $\\alpha$ by establishing the information-theoretic and computational boundaries, namely, the minimax-optimal statistical accuracy that can be achieved by all algorithms, and polynomial-time algorithms under an oracle computational model. For small $\\alpha$, our result shows a gap between these two boundaries, which represents the computational price of achieving the information-theoretic boundary due to the lack of supervision. Interestingly, we also show that this gap narrows as $\\alpha$ increases. In other words, having more supervision, i.e., more correct labels, not only improves the optimal statistical accuracy as expected, but also enhances the computational efficiency for achieving such accuracy."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Phased LSTM", "Title": "Accelerating Recurrent Network Training for Long or Event-based Sequences", "Abstract": "Recurrent Neural Networks (RNNs) have become the state-of-the-art choice for extracting patterns from temporal sequences. Current RNN models are ill suited to process irregularly sampled data triggered by events generated in continuous time by sensors or other neurons. Such data can occur, for example, when the input comes from novel event-driven artificial sensors which generate sparse, asynchronous streams of events or from multiple conventional sensors with different update intervals. In this work, we introduce the Phased LSTM model, which extends the LSTM unit by adding a new time gate. This gate is controlled by a parametrized oscillation with a frequency range which require updates of the memory cell only during a small percentage of the cycle. Even with the sparse updates imposed by the oscillation, the Phased LSTM network achieves faster convergence than regular LSTMs on tasks which require learning of long sequences.   The model naturally integrates inputs from sensors of arbitrary sampling rates, thereby opening new areas of investigation for processing asynchronous sensory events that carry timing information.  It also greatly improves the performance of LSTMs in standard RNN applications, and does so with an order-of-magnitude fewer computes."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Only H is left", "Title": "Near-tight Episodic PAC RL", "Abstract": "In many applications such as advertisement placement or automated dialog systems, an intelligent system optimizes performance over a sequence of interactions with each user. Such tasks often involve many states and potentially time-dependent transition dynamics, and can be modeled well as episodic Markov decision processes (MDPs). In this paper, we present a PAC algorithm for reinforcement learning in episodic finite MDPs with time-dependent transitions that acts epsilon-optimal in all but O(S A H^3  / epsilon^2 log(1 / delta)) episodes. Our algorithm has a polynomial computational complexity, and our sample complexity bound accounts for the fact that we may only be able to approximately solve the internal planning problems. In addition, our PAC sample complexity bound has only linear dependency on the number of states S and actions A and strictly improves previous bounds with S^2 dependency in this setting. Compared against other methods for infinite horizon reinforcement learning with linear state space sample complexity our method has much lower dependency on the (effective) horizon. Indeed, our bound is optimal up to a factor of H."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayesian Optimization with a Finite Budget", "Title": "An Approximate Dynamic Programming Approach", "Abstract": "We consider the problem of optimizing an expensive objective function when a finite budget of total evaluations is prescribed. In that context, the optimal solution strategy for Bayesian optimization can be formulated as a dynamic programming instance. This results in a complex problem with uncountable, dimension-increasing state space and an uncountable control space. We show how to approximate the solution of this dynamic programming problem  using rollout, and propose rollout heuristics specifically designed for the Bayesian optimization setting. We present numerical experiments showing that the resulting algorithm for optimization with a finite budget outperforms several popular Bayesian optimization algorithms."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mutual information for symmetric rank-one matrix estimation", "Title": "A proof of the replica formula", "Abstract": "Factorizing low-rank matrices has many applications in machine learning and statistics. For probabilistic models in the Bayes optimal setting, a general expression for the mutual information has been proposed using heuristic statistical physics computations, and proven in few specific cases. Here, we show how to rigorously prove the conjectured formula for the symmetric rank-one case. This allows to express the minimal mean-square-error and to characterize the detectability phase transitions in a large set of estimation problems ranging from community detection to sparse PCA. We also show that for a large set of parameters, an iterative algorithm called approximate message-passing is Bayes optimal. There exists, however, a gap between what currently known polynomial algorithms can do and what is expected information theoretically. Additionally, the proof technique has an interest of its own and exploits three essential ingredients: the interpolation method introduced in statistical physics by Guerra, the analysis of the approximate message-passing algorithm and the theory of spatial coupling and threshold saturation in coding. Our approach is generic and applicable to other open problems in statistical estimation where heuristic statistical physics predictions are available."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SURGE", "Title": "Surface Regularized Geometry Estimation from a Single Image", "Abstract": "This paper introduces an approach to regularize 2.5D surface normal and depth predictions at each pixel given a single input image. The approach infers and reasons about the underlying 3D planar surfaces depicted in the image to snap predicted normals and depths to inferred planar surfaces, all while maintaining fine detail within objects. Our approach comprises two components: (i) a fourstream convolutional neural network (CNN) where depths, surface normals, and likelihoods of planar region and planar boundary are predicted at each pixel, followed by (ii) a dense conditional random field (DCRF) that integrates the four predictions such that the normals and depths are compatible with each other and regularized by the planar region and planar boundary information. The DCRF is formulated such that gradients can be passed to the surface normal and depth CNNs via backpropagation. In addition, we propose new planar wise metrics to evaluate geometry consistency within planar surfaces, which are more tightly related to dependent 3D editing applications. We show that our regularization yields a 30% relative improvement in planar consistency on the NYU v2 dataset."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CliqueCNN", "Title": "Deep Unsupervised Exemplar Learning", "Abstract": "Exemplar learning is a powerful paradigm for discovering visual similarities in an unsupervised manner. In this context, however, the recent breakthrough in deep learning could not yet unfold its full potential. With only a single positive sample, a great imbalance between one positive and many negatives, and unreliable relationships between most samples, training of convolutional neural networks is impaired. Given weak estimates of local distance we propose a single optimization problem to extract batches of samples with mutually consistent relations. Conflicting relations are distributed over different batches and similar samples are grouped into compact cliques. Learning exemplar similarities is framed as a sequence of clique categorization tasks. The CNN then consolidates transitivity relations within and between cliques and learns a single representation for all samples without the need for labels. The proposed unsupervised approach has shown competitive performance on detailed posture analysis and object classification."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Data Programming", "Title": "Creating Large Training Sets, Quickly", "Abstract": "Large labeled training sets are the critical building blocks of supervised learning methods and are key enablers of deep learning techniques. For some applications, creating labeled training sets is the most time-consuming and expensive part of applying machine learning. We therefore propose a paradigm for the programmatic creation of training sets called data programming in which users provide a set of labeling functions, which are programs that heuristically label subsets of the data, but that are noisy and may conflict. By viewing these labeling functions as implicitly describing a generative model for this noise, we show that we can recover the parameters of this model to \"denoise\" the generated training set, and establish theoretically that we can recover the parameters of these generative models in a handful of settings. We then show how to modify a discriminative loss function to make it noise-aware, and demonstrate our method over a range of discriminative models including logistic regression and LSTMs. Experimentally, on the 2014 TAC-KBP Slot Filling challenge, we show that data programming would have led to a new winning score, and also show that applying data programming to an LSTM model leads to a TAC-KBP score almost 6 F1 points over a state-of-the-art LSTM baseline (and into second place in the competition). Additionally, in initial user studies we observed that data programming may be an easier way for non-experts to create machine learning models when training data is limited or unavailable."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Blind Regression", "Title": "Nonparametric Regression for Latent Variable Models via Collaborative Filtering", "Abstract": "We introduce the framework of {\\em blind regression} motivated by {\\em matrix completion} for recommendation systems: given $m$ users, $n$ movies, and a subset of user-movie ratings, the goal is to predict the unobserved user-movie ratings given the data, i.e., to complete the partially observed matrix. Following the framework of non-parametric statistics, we posit that user $u$ and movie $i$ have features $x_1(u)$ and $x_2(i)$ respectively, and their corresponding rating $y(u,i)$ is a noisy measurement of $f(x_1(u), x_2(i))$ for some unknown function $f$. In contrast with classical regression, the features $x = (x_1(u), x_2(i))$ are not observed, making it challenging to apply standard regression methods to  predict the unobserved ratings.  Inspired by the classical Taylor's expansion for differentiable functions, we provide a prediction algorithm that is consistent for all Lipschitz functions. In fact, the analysis through our framework naturally leads to a variant of collaborative filtering, shedding insight into the widespread success of collaborative filtering in practice. Assuming each entry is sampled independently with probability at least $\\max(m^{-1+\\delta},n^{-1/2+\\delta})$ with $\\delta > 0$, we prove that the expected fraction of our estimates with error greater than $\\epsilon$ is less than $\\gamma^2 / \\epsilon^2$ plus a polynomially decaying term, where $\\gamma^2$ is the variance of the additive entry-wise noise term.  Experiments with the MovieLens and Netflix datasets suggest that our algorithm provides principled improvements over basic collaborative filtering and is competitive with matrix factorization methods."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Backprop KF", "Title": "Learning Discriminative Deterministic State Estimators", "Abstract": "Generative state estimators based on probabilistic filters and smoothers are one of the most popular classes of state estimators for robots and autonomous vehicles. However, generative models have limited capacity to handle rich sensory observations, such as camera images, since they must model the entire distribution over sensor readings. Discriminative models do not suffer from this limitation, but are typically more complex to train as latent variable models for state estimation. We present an alternative approach where the parameters of the latent state distribution are directly optimized as a deterministic computation graph, resulting in a simple and effective gradient descent algorithm for training discriminative state estimators. We show that this procedure can be used to train state estimators that use complex input, such as raw camera images, which must be processed using expressive nonlinear function approximators such as convolutional neural networks. Our model can be viewed as a type of recurrent neural network, and the connection to probabilistic filtering allows us to design a network architecture that is particularly well suited for state estimation. We evaluate our approach on synthetic tracking task with raw image inputs and on the visual odometry task in the KITTI dataset. The results show significant improvement over both standard generative approaches and regular recurrent neural networks."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Alternative Neural Network", "Title": "Exploring Contexts as Early as Possible for Action Recognition", "Abstract": "Contexts are crucial for action recognition in video. Current methods often mine contexts after extracting hierarchical local features and focus on their high-order encodings. This paper instead explores contexts as early as possible and leverages their evolutions for action recognition. In particular, we introduce a novel architecture called deep alternative neural network (DANN) stacking alternative layers. Each alternative layer consists of a volumetric convolutional layer followed by a recurrent layer. The former acts as local feature learner while the latter is used to collect contexts. Compared with feed-forward neural networks, DANN learns contexts of local features from the very beginning. This setting helps to preserve hierarchical context evolutions which we show are essential to recognize similar actions. Besides, we present an adaptive method to determine the temporal size for network input based on optical flow energy, and develop a volumetric pyramid pooling layer to deal with input clips of arbitrary sizes. We demonstrate the advantages of DANN on two benchmarks HMDB51 and UCF101 and report competitive or superior results to the state-of-the-art."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online ICA", "Title": "Understanding Global Dynamics of Nonconvex Optimization via Diffusion Processes", "Abstract": "Solving statistical learning problems often involves nonconvex optimization. Despite the empirical success of nonconvex statistical optimization methods, their global dynamics, especially convergence to the desirable local minima, remain less well understood in theory. In this paper, we propose a new analytic paradigm based on diffusion processes to characterize the global dynamics of nonconvex statistical optimization. As a concrete example, we study stochastic gradient descent (SGD) for the tensor decomposition formulation of independent component analysis. In particular, we cast different phases of SGD into diffusion processes, i.e., solutions to stochastic differential equations. Initialized from an unstable equilibrium, the global dynamics of SGD transit over three consecutive phases: (i) an unstable Ornstein-Uhlenbeck process slowly departing from the initialization, (ii) the solution to an ordinary differential equation, which quickly evolves towards the desirable local minimum, and (iii) a stable Ornstein-Uhlenbeck process oscillating around the desirable local minimum. Our proof techniques are based upon Stroock and Varadhan’s weak convergence of Markov chains to diffusion processes, which are of independent interest."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CRF-CNN", "Title": "Modeling Structured Information in Human Pose Estimation", "Abstract": "Deep convolutional neural networks (CNN) have achieved great success. On the other hand, modeling structural information has been proved critical in many vision problems. It is of great interest to integrate them effectively. In a classical neural network, there is no message passing between neurons in the same layer. In this paper, we propose a CRF-CNN framework which can simultaneously model structural information in both output and hidden feature layers in a probabilistic way, and it is applied to human pose estimation. A message passing scheme is proposed, so that in various layers each body joint receives messages from all the others in an efficient way. Such message passing can be implemented with convolution between features maps in the same layer, and it is also integrated with feedforward propagation in neural networks. Finally, a neural network implementation of end-to-end learning CRF-CNN is provided. Its effectiveness is demonstrated through experiments on two benchmark datasets."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Blazing the trails before beating the path", "Title": "Sample-efficient Monte-Carlo planning", "Abstract": "We study the sampling-based planning problem in Markov decision processes (MDPs) that we can access only through a generative model, usually referred to as Monte-Carlo planning. Our objective is to return a good estimate of the optimal value function at any state while minimizing the number of calls to the generative model, i.e. the sample complexity. We propose a new algorithm, TrailBlazer, able to handle MDPs with a finite or an infinite number of transitions from state-action to next states. TrailBlazer is an adaptive algorithm that exploits possible structures of the MDP by exploring only a subset of states reachable by following near-optimal policies. We provide bounds on its sample complexity that depend on a measure of the quantity of near-optimal states. The algorithm behavior can be considered as an extension of Monte-Carlo sampling (for estimating an expectation) to problems that alternate maximization (over actions) and expectation (over next states). Finally, another appealing feature of TrailBlazer is that it is simple to implement and computationally efficient."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scaling Factorial Hidden Markov Models", "Title": "Stochastic Variational Inference without Messages", "Abstract": "Factorial Hidden Markov Models (FHMMs) are powerful models for sequential data but they do not scale well with long sequences. We propose a scalable inference and learning algorithm for FHMMs that draws on ideas from the stochastic variational inference, neural network and copula literatures. Unlike existing approaches, the proposed algorithm requires no message passing procedure among latent variables and can be distributed to a network of computers to speed up learning. Our experiments corroborate that the proposed algorithm does not introduce further approximation bias compared to the proven structured mean-field algorithm, and achieves better performance with long sequences and large FHMMs."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "InfoGAN", "Title": "Interpretable Representation Learning by Information Maximizing Generative Adversarial Nets", "Abstract": "This paper describes InfoGAN, an information-theoretic extension to the Generative Adversarial Network that is able to learn disentangled representations in a completely unsupervised manner. InfoGAN is a generative adversarial network that also maximizes the mutual information between a small subset of the latent variables and the observation. We derive a lower bound to the mutual information objective that can be optimized efficiently, and show that our training procedure can be interpreted as a variation of the Wake-Sleep algorithm. Specifically, InfoGAN successfully disentangles writing styles from digit shapes on the MNIST dataset, pose from lighting of 3D rendered images, and background digits from the central digit on the SVHN dataset. It also discovers visual concepts that include hair styles, presence/absence of eyeglasses, and emotions on the CelebA face dataset. Experiments show that InfoGAN learns interpretable representations that are competitive with representations learned by existing fully supervised methods."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robustness of classifiers", "Title": "from adversarial to random noise", "Abstract": "Several recent works have shown that state-of-the-art classifiers are vulnerable to worst-case (i.e., adversarial) perturbations of the datapoints. On the other hand, it has been empirically observed that these same classifiers are relatively robust to random noise. In this paper, we propose to study a semi-random noise regime that generalizes both the random and worst-case noise regimes. We propose the first quantitative analysis of the robustness of nonlinear classifiers in this general noise regime. We establish precise theoretical bounds on the robustness of classifiers in this general regime, which depend on the curvature of the classifier's decision boundary. Our bounds confirm and quantify the empirical observations that classifiers satisfying curvature constraints are robust to random noise. Moreover, we quantify the robustness of classifiers in terms of the subspace dimension in the semi-random noise regime, and show that our bounds remarkably interpolate between the worst-case and random noise regimes. We perform experiments and show that the derived bounds provide very accurate estimates when applied to various state-of-the-art deep neural networks and datasets. This result suggests bounds on the curvature of the classifiers' decision boundaries that we support experimentally, and more generally offers important insights onto the geometry of high dimensional classification problems."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SoundNet", "Title": "Learning Sound Representations from Unlabeled Video", "Abstract": "We learn rich natural sound representations by capitalizing on large amounts of unlabeled sound data collected in the wild. We leverage the natural synchronization between vision and sound to learn an acoustic representation using two-million unlabeled videos. Unlabeled video has the advantage that it can be economically acquired at massive scales, yet contains useful signals about natural sound. We propose a student-teacher training procedure which transfers discriminative visual knowledge from well established visual recognition models into the sound modality using unlabeled video as a bridge. Our sound representation yields significant performance improvements over the state-of-the-art results on standard benchmarks for acoustic scene/object classification. Visualizations suggest some high-level semantics automatically emerge in the sound network, even though it is trained without ground truth labels."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Submodular Functions", "Title": "Definitions and Learning", "Abstract": "We propose and study a new class of submodular functions called deep submodular functions (DSFs). We define DSFs and situate them within the broader context of classes of submodular functions in relationship both to various matroid ranks and sums of concave composed with modular functions (SCMs). Notably, we find that DSFs constitute a strictly broader class than SCMs, thus motivating their use, but that they do not comprise all submodular functions.  Interestingly, some DSFs can be seen as special cases of certain deep neural networks (DNNs), hence the name.  Finally, we provide a method to learn DSFs in a max-margin framework, and offer preliminary results applying this both to synthetic and real-world data instances."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust k-means", "Title": "a Theoretical Revisit", "Abstract": "Over the last years, many variations of the quadratic k-means clustering procedure have been proposed, all aiming to robustify the performance of the algorithm in the presence of outliers. In general terms, two main approaches have been developed: one based on penalized regularization methods, and one based on trimming functions. In this work, we present a theoretical analysis of the robustness and consistency properties of a variant of the classical quadratic k-means algorithm, the robust k-means, which borrows ideas from outlier detection in regression. We show that two outliers in a dataset are enough to breakdown this clustering procedure. However, if we focus on “well-structured” datasets, then robust k-means can recover the underlying cluster structure in spite of the outliers. Finally, we show that, with slight modifications, the most general non-asymptotic results for consistency of quadratic k-means remain valid for this robust variant."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Causal meets Submodular", "Title": "Subset Selection with Directed Information", "Abstract": "We study causal subset selection with Directed Information as the measure of prediction causality. Two typical tasks, causal sensor placement and covariate selection, are correspondingly formulated into cardinality constrained directed information maximizations. To attack the NP-hard problems, we show that the first problem is submodular while not necessarily monotonic. And the second one is ``nearly'' submodular.  To substantiate the idea of approximate submodularity, we introduce a novel quantity, namely submodularity index (SmI), for general set functions. Moreover, we show that based on SmI, greedy algorithm has performance guarantee for the maximization of possibly non-monotonic and non-submodular functions, justifying its usage for a much broader class of problems. We evaluate the theoretical results with several case studies, and also illustrate the application of the subset selection to causal structure learning."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Crowdsourced Clustering", "Title": "Querying Edges vs Triangles", "Abstract": "We consider the task of clustering items using answers from non-expert crowd workers. In such cases, the workers are often not able to label the items directly, however, it is reasonable to assume that they can compare items and judge whether they are similar or not. An important question is what queries to make, and we compare two types: random edge queries, where a pair of items is revealed, and random triangles, where a triple is. Since it is far too expensive to query all possible edges and/or triangles, we need to work with partial observations subject to a fixed query budget constraint. When a generative model for the data is available (and we consider a few of these) we determine the cost of a query by its entropy; when such models do not exist we use the average response time per query of the workers as a surrogate for the cost. In addition to theoretical justification, through several simulations and experiments on two real data sets on Amazon Mechanical Turk, we empirically demonstrate that, for a fixed budget, triangle queries uniformly outperform edge queries. Even though, in contrast to edge queries, triangle queries reveal dependent edges, they provide more reliable edges and, for a fixed budget, many more of them. We also provide a sufficient condition on the number of observations, edge densities inside and outside the clusters and the minimum cluster size required for the exact recovery of the true adjacency matrix via triangle queries using a convex optimization-based clustering algorithm."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FPNN", "Title": "Field Probing Neural Networks for 3D Data", "Abstract": "Building discriminative representations for 3D data has been an important task in computer graphics and computer vision research. Convolutional Neural Networks (CNNs) have shown to operate on 2D images with great success for a variety of tasks. Lifting convolution operators to 3D (3DCNNs) seems like a plausible and promising next step. Unfortunately, the computational complexity of 3D CNNs grows cubically with respect to voxel resolution. Moreover, since most 3D geometry representations are boundary based, occupied regions do not increase proportionately with the size of the discretization, resulting in wasted computation. In this work, we represent 3D spaces as volumetric fields, and propose a novel design that employs field probing filters to efficiently extract features from them. Each field probing filter is a set of probing points -- sensors that perceive the space. Our learning algorithm optimizes not only the weights associated with the probing points, but also their locations, which deforms the shape of the probing filters and adaptively distributes them in 3D space. The optimized probing points sense the 3D space \"intelligently\", rather than operating blindly over the entire domain. We show that field probing is significantly more efficient than 3DCNNs, while providing state-of-the-art performance, on classification tasks for 3D object recognition benchmark datasets."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interaction Screening", "Title": "Efficient and Sample-Optimal Learning of Ising Models", "Abstract": "We consider the problem of learning the underlying graph of an unknown Ising model on p spins from a collection of i.i.d. samples generated from the model. We suggest a new estimator that is computationally efficient and requires a number of samples that is near-optimal with respect to previously established information theoretic lower-bound. Our statistical estimator has a physical interpretation in terms of \"interaction screening\". The estimator is consistent and is efficiently implemented using convex optimization. We prove that with appropriate regularization, the estimator recovers the underlying graph using a number of samples that is logarithmic in the system size p and exponential in the maximum coupling-intensity and maximum node-degree."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "“Congruent” and “Opposite” Neurons", "Title": "Sisters for Multisensory Integration and Segregation", "Abstract": "Experiments reveal that in the dorsal medial superior temporal (MSTd) and the ventral intraparietal (VIP) areas, where visual and vestibular cues are integrated to infer heading direction, there are two types of neurons with roughly the same number. One is “congruent” cells, whose preferred heading directions are similar in response to visual and vestibular cues; and the other is “opposite” cells, whose preferred heading directions are nearly “opposite” (with an offset of 180 degree) in response to visual vs. vestibular cues. Congruent neurons are known to be responsible for cue integration, but the computational role of opposite neurons remains largely unknown. Here, we propose that opposite neurons may serve to encode the disparity information between cues necessary for multisensory segregation. We build a computational model composed of two reciprocally coupled modules, MSTd and VIP, and each module consists of groups of congruent and opposite neurons. In the model, congruent neurons in two modules are reciprocally connected with each other in the congruent manner, whereas opposite neurons are reciprocally connected in the opposite manner. Mimicking the experimental protocol, our model reproduces the characteristics of congruent and opposite neurons, and demonstrates that in each module, the sisters of congruent and opposite neurons can jointly achieve optimal multisensory information integration and segregation. This study sheds light on our understanding of how the brain implements optimal multisensory integration and segregation concurrently in a distributed manner."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization of ERM in Stochastic Convex Optimization", "Title": "The Dimension Strikes Back", "Abstract": "In stochastic convex optimization the goal is to minimize a convex function $F(x) \\doteq \\E_{f\\sim D}[f(x)]$ over a convex set $\\K \\subset \\R^d$ where $D$ is some unknown distribution and each $f(\\cdot)$ in the support of $D$ is convex over $\\K$. The optimization is based on i.i.d.~samples $f^1,f^2,\\ldots,f^n$ from $D$. A common approach to such problems is empirical risk minimization (ERM) that optimizes $F_S(x) \\doteq \\frac{1}{n}\\sum_{i\\leq n} f^i(x)$. Here we consider the question of how many samples are necessary for ERM to succeed and the closely related question of uniform convergence of $F_S$ to $F$ over $\\K$. We demonstrate that in the standard $\\ell_p/\\ell_q$ setting of Lipschitz-bounded functions over a $\\K$ of bounded radius, ERM requires sample size that scales linearly with the dimension $d$. This nearly matches standard upper bounds and improves on $\\Omega(\\log d)$ dependence proved for $\\ell_2/\\ell_2$ setting in (Shalev-Shwartz et al.  2009). In stark contrast, these problems can be solved using dimension-independent number of samples for $\\ell_2/\\ell_2$ setting and $\\log d$ dependence for $\\ell_1/\\ell_\\infty$ setting using other approaches. We also demonstrate that for a more general class of range-bounded (but not Lipschitz-bounded) stochastic convex programs an even stronger gap appears already in dimension 2."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "What Makes Objects Similar", "Title": "A Unified Multi-Metric Learning Approach", "Abstract": "Linkages are essentially determined by similarity measures that may be derived from multiple perspectives. For example, spatial linkages are usually generated based on localities of heterogeneous data, whereas semantic linkages can come from various properties, such as different physical meanings behind social relations. Many existing metric learning models focus on spatial linkages, but leave the rich semantic factors unconsidered. Similarities based on these models are usually overdetermined on linkages. We propose a Unified Multi-Metric Learning (UM2L) framework to exploit multiple types of metrics. In UM2L, a type of combination operator is introduced for distance characterization from multiple perspectives, and thus can introduce flexibilities for representing and utilizing both spatial and semantic linkages. Besides, we propose a uniform solver for UM2L which is guaranteed to converge. Extensive experiments on diverse applications exhibit the superior classification performance and comprehensibility of UM2L. Visualization results also validate its ability on physical meanings discovery."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gradient-based Sampling", "Title": "An Adaptive Importance Sampling for Least-squares", "Abstract": "In modern data analysis, random sampling is an efficient and widely-used strategy to overcome the computational difficulties brought by large sample size. In previous studies, researchers conducted random sampling which is according to the input data but independent on the response variable, however the response variable may also be informative for sampling. In this paper we propose an adaptive sampling called the gradient-based sampling which is dependent on both the input data and the output for fast solving of least-square (LS) problems. We draw the data points by random sampling from the full data according to their gradient values. This sampling is computationally saving, since the running time of computing the sampling probabilities is reduced to O(nd) where n is the full sample size and d is the dimension of the input. Theoretically, we establish an error bound analysis of the general importance sampling with respect to LS solution from full data. The result establishes an improved performance of the use of our gradient-based sampling. Synthetic and real data sets are used to empirically argue that the gradient-based sampling has an obvious advantage over existing sampling methods from two aspects of statistical efficiency and computational saving."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Confusions over Time", "Title": "An Interpretable Bayesian Model to Characterize Trends in Decision Making", "Abstract": "We propose Confusions over Time (CoT), a novel generative framework which facilitates a multi-granular analysis of the decision making process. The CoT not only models the confusions or error properties of individual decision makers and their evolution over time, but also allows us to obtain diagnostic insights into the collective decision making process in an interpretable manner. To this end, the CoT models the confusions of the decision makers and their evolution over time via time-dependent confusion matrices. Interpretable insights are obtained by grouping similar decision makers (and items being judged) into clusters and representing each such cluster with an appropriate prototype and identifying the most important features characterizing the cluster via a subspace feature indicator vector. Experimentation with real world data on bail decisions, asthma treatments, and insurance policy approval decisions demonstrates that CoT can accurately model and explain the confusions of decision makers and their evolution over time."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Riemannian SVRG", "Title": "Fast Stochastic Optimization on Riemannian Manifolds", "Abstract": "We study optimization of finite sums of \\emph{geodesically} smooth functions on Riemannian manifolds. Although variance reduction techniques for optimizing finite-sums have witnessed tremendous attention in the recent years, existing work is limited to vector space problems. We introduce \\emph{Riemannian SVRG} (\\rsvrg), a new variance reduced Riemannian optimization method. We analyze \\rsvrg for both geodesically  \\emph{convex} and \\emph{nonconvex} (smooth) functions. Our analysis reveals that \\rsvrg inherits  advantages of the usual SVRG method, but with factors depending on curvature of the manifold that influence its convergence. To our knowledge, \\rsvrg is the first \\emph{provably fast} stochastic Riemannian method. Moreover, our paper presents the first non-asymptotic complexity analysis (novel even for the batch setting) for nonconvex Riemannian optimization. Our results have several implications; for instance, they offer a Riemannian perspective on variance reduced PCA, which promises a short, transparent convergence analysis."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel Observers", "Title": "Systems-Theoretic Modeling and Inference of Spatiotemporally Evolving Processes", "Abstract": "We consider the problem of estimating the latent state of a spatiotemporally evolving continuous function using very few sensor measurements. We show that layering a dynamical systems prior over temporal evolution of weights of a kernel model is a valid approach to spatiotemporal modeling that does not necessarily require the design of complex nonstationary kernels. Furthermore, we show that such a predictive model can be utilized to determine sensing locations that guarantee that the hidden state of the phenomena can be recovered with very few measurements. We provide sufficient conditions on the number and spatial location of samples required to guarantee state recovery, and provide a lower bound on the minimum number of samples required to robustly infer the hidden states. Our approach outperforms existing methods in numerical experiments."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Yggdrasil", "Title": "An Optimized System for Training Deep Decision Trees at Scale", "Abstract": "Deep distributed decision trees and tree ensembles have grown in importance due to the need to model increasingly large datasets.  However, PLANET, the standard distributed tree learning algorithm implemented in systems such as \\xgboost and Spark MLlib, scales poorly as data dimensionality and tree depths grow.  We present Yggdrasil, a new distributed tree learning method that outperforms existing methods by up to 24x.  Unlike PLANET, Yggdrasil is based on vertical partitioning of the data (i.e., partitioning by feature), along with a set of optimized data structures to reduce the CPU and communication costs of training. Yggdrasil (1) trains directly on compressed data for compressible features and labels; (2) introduces efficient data structures for training on uncompressed data; and (3) minimizes communication between nodes by using sparse bitvectors.  Moreover, while PLANET approximates split points through feature binning, Yggdrasil does not require binning, and we analytically characterize the impact of this approximation. We evaluate Yggdrasil against the MNIST 8M dataset and a high-dimensional dataset at Yahoo; for both, Yggdrasil is faster by up to an order of magnitude."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Graph Reconstruction via Empirical Risk Minimization", "Title": "Fast Learning Rates and Scalability", "Abstract": "The problem of predicting connections between a set of data points finds many applications, in systems biology and social network analysis among others. This paper focuses on the \\textit{graph reconstruction} problem, where the prediction rule is obtained by minimizing the average error over all n(n-1)/2 possible pairs of the n nodes of a training graph. Our first contribution is to derive learning rates of order O(log n / n) for this problem, significantly improving upon the slow rates of order O(1/√n) established in the seminal work of Biau & Bleakley (2006). Strikingly, these fast rates are universal, in contrast to similar results known for other statistical learning problems (e.g., classification, density level set estimation, ranking, clustering) which require strong assumptions on the distribution of the data. Motivated by applications to large graphs, our second contribution deals with the computational complexity of graph reconstruction. Specifically, we investigate to which extent the learning rates can be preserved when replacing the empirical reconstruction risk by a computationally cheaper Monte-Carlo version, obtained by sampling with replacement B << n² pairs of nodes. Finally, we illustrate our theoretical results by numerical experiments on synthetic and real graphs."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Short-Dot", "Title": "Computing Large Linear Transforms Distributedly Using Coded Short Dot Products", "Abstract": "Faced with saturation of Moore's law and increasing size and dimension of data, system designers have increasingly resorted to parallel and distributed computing to reduce computation time of machine-learning algorithms. However, distributed computing is often bottle necked by a small fraction of slow processors called \"stragglers\" that reduce the speed of computation because the fusion node has to wait for all processors to complete their processing. To combat the effect of stragglers, recent literature proposes introducing redundancy in computations across processors, e.g., using repetition-based strategies or erasure codes. The fusion node can exploit this redundancy by completing the computation using outputs from only a subset of the processors, ignoring the stragglers. In this paper, we propose a novel technique - that we call \"Short-Dot\" - to introduce redundant computations in a coding theory inspired fashion, for computing linear transforms of long vectors. Instead of computing long dot products as required in the original linear transform, we construct a larger number of redundant and short dot products that can be computed more efficiently at individual processors. Further, only a subset of these short dot products are required at the fusion node to finish the computation successfully. We demonstrate through probabilistic analysis as well as experiments on computing clusters that Short-Dot offers significant speed-up compared to existing techniques. We also derive trade-offs between the length of the dot-products and the resilience to stragglers (number of processors required to finish), for any such strategy and compare it to that achieved by our strategy."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VIME", "Title": "Variational Information Maximizing Exploration", "Abstract": "Scalable and effective exploration remains a key challenge in reinforcement learning (RL). While there are methods with optimality guarantees in the setting of discrete state and action spaces, these methods cannot be applied in high-dimensional deep RL scenarios. As such, most contemporary RL relies on simple heuristics such as epsilon-greedy exploration or adding Gaussian noise to the controls. This paper introduces Variational Information Maximizing Exploration (VIME), an exploration strategy based on maximization of information gain about the agent's belief of environment dynamics. We propose a practical implementation, using variational inference in Bayesian neural networks which efficiently handles continuous state and action spaces. VIME modifies the MDP reward function, and can be applied with several different underlying RL algorithms. We demonstrate that VIME achieves significantly better performance compared to heuristic exploration methods across a variety of continuous control tasks and algorithms, including tasks with very sparse rewards."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Toward Deeper Understanding of Neural Networks", "Title": "The Power of Initialization and a Dual View on Expressivity", "Abstract": "We develop a general duality between neural networks and compositional kernel Hilbert spaces. We introduce the notion of a computation skeleton, an acyclic graph that succinctly describes both a family of neural networks and a kernel space. Random neural networks are generated from a skeleton through node replication followed by sampling from a normal distribution to assign weights. The kernel space consists of functions that arise by compositions, averaging, and non-linear transformations governed by the skeleton's graph topology and activation functions. We prove that random networks induce representations which approximate the kernel space. In particular, it follows that random weight initialization often yields a favorable starting point for optimization despite the worst-case intractability of training neural networks."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Multiclass Classification", "Title": "A Risk Minimization Perspective", "Abstract": "Recently proposed adversarial classification methods have shown promising results for cost sensitive and multivariate losses. In contrast with empirical risk minimization (ERM) methods, which use convex surrogate losses to approximate the desired non-convex target loss function, adversarial methods minimize non-convex losses by treating the properties of the training data as being uncertain and worst case within a minimax game. Despite this difference in formulation, we recast adversarial classification under zero-one loss as an ERM method with a novel prescribed loss function. We demonstrate a number of theoretical and practical advantages over the very closely related hinge loss ERM methods. This establishes adversarial classification under the zero-one loss as a method that fills the long standing gap in multiclass hinge loss classification, simultaneously guaranteeing Fisher consistency and universal consistency, while also providing dual parameter sparsity and high accuracy predictions in practice."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stein Variational Gradient Descent", "Title": "A General Purpose Bayesian Inference Algorithm", "Abstract": "We propose a general purpose variational inference algorithm that forms a natural counterpart of gradient descent for optimization. Our method iteratively transports a set of particles to match the target distribution, by applying a form of functional gradient descent that minimizes the KL divergence. Empirical studies are performed on various real world models and datasets, on which our method is competitive with existing state-of-the-art methods. The derivation of our method is based on a new theoretical result that connects the derivative of KL divergence under smooth transforms with Stein’s identity and a recently proposed kernelized Stein discrepancy, which is of independent interest."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning in Games", "Title": "Robustness of Fast Convergence", "Abstract": "We show that learning algorithms satisfying a low approximate regret property experience fast convergence to approximate optimality in a large class of repeated games. Our property, which simply requires that each learner has small regret compared to a (1+eps)-multiplicative approximation to the best action in hindsight, is ubiquitous among learning algorithms; it is satisfied even by the vanilla Hedge forecaster. Our results improve upon recent work of Syrgkanis et al. in a number of ways. We require only that players observe payoffs under other players' realized actions, as opposed to expected payoffs. We further show that convergence occurs with high probability, and show convergence under bandit feedback. Finally, we improve upon the speed of convergence by a factor of n, the number of players. Both the scope of settings and the class of algorithms for which our analysis provides fast convergence are considerably broader than in previous work. Our framework applies to dynamic population games via a low approximate regret property for shifting experts. Here we strengthen the results of Lykouris et al. in two ways: We allow players to select learning algorithms from a larger class, which includes a minor variant of the basic Hedge algorithm, and we increase the maximum churn in players for which approximate optimality is achieved. In the bandit setting we present a new algorithm which provides a \"small loss\"-type bound with improved dependence on the number of actions in utility settings, and is both simple and efficient. This result may be of independent interest."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Causal Bandits", "Title": "Learning Good Interventions via Causal Inference", "Abstract": "We study the problem of using causal models to improve the rate at which good interventions can be learned online in a stochastic environment. Our formalism combines multi-arm bandits and causal inference to model a novel type of bandit feedback that is not exploited by existing approaches. We propose a new algorithm that exploits the causal feedback and prove a bound on its simple regret that is strictly better (in all quantities) than algorithms that do not use the additional causal information."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Showing versus doing", "Title": "Teaching by demonstration", "Abstract": "People often learn from others' demonstrations, and classic inverse reinforcement learning (IRL) algorithms have brought us closer to realizing this capacity in machines. In contrast, teaching by demonstration has been less well studied computationally. Here, we develop a novel Bayesian model for teaching by demonstration. Stark differences arise when demonstrators are intentionally teaching a task versus simply performing a task. In two experiments, we show that human participants systematically modify their teaching behavior consistent with the predictions of our model. Further, we show that even standard IRL algorithms benefit when learning from behaviors that are intentionally pedagogical. We conclude by discussing IRL algorithms that can take advantage of intentional pedagogy."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DISCO Nets ", "Title": "DISsimilarity COefficients Networks", "Abstract": "We present a new type of probabilistic model which we call DISsimilarity COefficient Networks (DISCO Nets). DISCO Nets allow us to efficiently sample from a posterior distribution parametrised by a neural network. During training, DISCO Nets are learned by minimising the dissimilarity coefficient between the true distribution and the estimated distribution. This allows us to tailor the training to the loss related to the task at hand. We empirically show that (i) by modeling uncertainty on the output value, DISCO Nets outperform equivalent non-probabilistic predictive networks and (ii) DISCO Nets accurately model the uncertainty of the output, outperforming existing probabilistic models based on deep neural networks."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Poke by Poking", "Title": "Experiential Learning of Intuitive Physics", "Abstract": "We investigate an experiential learning paradigm for acquiring an internal model of intuitive physics. Our model is evaluated on a real-world robotic manipulation task that requires displacing objects to target locations by poking. The robot gathered over 400 hours of experience by executing more than 50K pokes on different objects. We propose a novel approach based on deep neural networks for modeling the dynamics of robot's interactions directly from images, by jointly estimating forward and inverse models of dynamics. The inverse model objective provides supervision to construct informative visual features, which the forward model can then predict and in turn regularize the feature space for the inverse model. The interplay between these two objectives creates useful, accurate models that can then be used for multi-step decision making. This formulation has the additional benefit that it is possible to learn forward models in an abstract feature space and thus alleviate the need of predicting pixels. Our experiments show that this joint modeling approach outperforms alternative methods. We also demonstrate that active data collection using the learned model further improves performance."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LightRNN", "Title": "Memory and Computation-Efficient Recurrent Neural Networks", "Abstract": "Recurrent neural networks (RNNs) have achieved state-of-the-art performances in many natural language processing tasks, such as language modeling and machine translation. However, when the vocabulary is large, the RNN model will become very big (e.g., possibly beyond the memory capacity of a GPU device) and its training will become very inefficient. In this work, we propose a novel technique to tackle this challenge. The key idea is to use 2-Component (2C) shared embedding for word representations. We allocate every word in the vocabulary into a table, each row of which is associated with a vector, and each column associated with another vector. Depending on its position in the table, a word is jointly represented by two components: a row vector and a column vector. Since the words in the same row share the row vector and the words in the same column share the column vector, we only need $2 \\sqrt{|V|}$ vectors to represent a vocabulary of $|V|$ unique words, which are far less than the $|V|$ vectors required by existing approaches. Based on the 2-Component shared embedding, we design a new RNN algorithm and evaluate it using the language modeling task on several benchmark datasets. The results show that our algorithm significantly reduces the model size and speeds up the training process, without sacrifice of accuracy (it achieves similar, if not better, perplexity as compared to state-of-the-art language models). Remarkably, on the One-Billion-Word benchmark Dataset, our algorithm achieves comparable perplexity to previous language models, whilst reducing the model size by a factor of 40-100, and speeding up the training process by a factor of 2. We name our proposed algorithm \\emph{LightRNN} to reflect its very small model size and very high training speed."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Clustering with Bregman Divergences", "Title": "an Asymptotic Analysis", "Abstract": "Clustering, in particular $k$-means clustering, is a central topic in data analysis. Clustering with Bregman divergences is a recently proposed generalization of $k$-means clustering which has already been widely used in applications.  In this paper we analyze theoretical properties of Bregman clustering when the number of the clusters $k$ is large. We establish quantization rates and describe the limiting distribution of the centers as $k\\to \\infty$, extending well-known results for  $k$-means clustering."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Swapout", "Title": "Learning an ensemble of deep architectures", "Abstract": "We describe Swapout, a new stochastic training method, that outperforms ResNets of identical network structure yielding impressive results on CIFAR-10 and CIFAR-100. Swapout samples from a rich set of architectures including dropout, stochastic depth and residual architectures as special cases. When viewed as a regularization method swapout not only inhibits co-adaptation of units in a layer, similar to dropout, but also across network layers. We conjecture that swapout achieves strong regularization by implicitly tying the parameters across layers. When viewed as an ensemble training method, it samples a much richer set of architectures than existing methods such as dropout or stochastic depth. We propose a parameterization that reveals connections to exiting architectures and suggests a much richer set of architectures to be explored. We show that our formulation suggests an efficient training method and validate our conclusions on CIFAR-10 and CIFAR-100 matching state of the art accuracy. Remarkably, our 32 layer wider model performs similar to a 1001 layer ResNet model."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LazySVD", "Title": "Even Faster SVD Decomposition Yet Without Agonizing Pain", "Abstract": "We study k-SVD that is to obtain the first k singular vectors of a matrix A. Recently, a few breakthroughs have been discovered on k-SVD: Musco and Musco [1] proved the first gap-free convergence result using the block Krylov method, Shamir [2] discovered the first variance-reduction stochastic method, and Bhojanapalli et al. [3] provided the fastest $O(\\mathsf{nnz}(A) + \\mathsf{poly}(1/\\varepsilon))$-time algorithm using alternating minimization.\r\n\r\nIn this paper, we put forward a new and simple LazySVD framework to improve the above breakthroughs. This framework leads to a faster gap-free method outperforming [1], and the first accelerated and stochastic method outperforming [2]. In the $O(\\mathsf{nnz}(A) + \\mathsf{poly}(1/\\varepsilon))$ running-time regime, LazySVD outperforms [3] in certain parameter regimes without even using alternating minimization."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from Rational Behavior", "Title": "Predicting Solutions to Unknown Linear Programs", "Abstract": "We define and study the problem of predicting the solution to a linear program (LP) given only partial information about its objective and constraints. This generalizes the problem of learning to predict the purchasing behavior of a rational agent who has an unknown objective function, that has been studied under the name “Learning from Revealed Preferences\". We give mistake bound learning algorithms in two settings: in the first, the objective of the LP is known to the learner but there is an arbitrary, fixed set of constraints which are unknown. Each example is defined by an additional known constraint and the goal of the learner is to predict the optimal solution of the LP given the union of the known and unknown constraints. This models the problem of predicting the behavior of a rational agent whose goals are known, but whose resources are unknown. In the second setting, the objective of the LP is unknown, and changing in a controlled way. The constraints of the LP may also change every day, but are known. An example is given by a set of constraints and partial information about the objective, and the task of the learner is again to predict the optimal solution of the partially known LP."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Truncated Variance Reduction", "Title": "A Unified Approach to Bayesian Optimization and Level-Set Estimation", "Abstract": "We present a new algorithm, truncated variance reduction (TruVaR), that treats Bayesian optimization (BO) and level-set estimation (LSE) with Gaussian processes in a unified fashion. The algorithm greedily shrinks a sum of truncated variances within a set of potential maximizers (BO) or unclassified points (LSE), which is updated based on confidence bounds.  TruVaR is effective in several important settings that are typically non-trivial to incorporate into myopic algorithms, including pointwise costs and heteroscedastic noise.  We provide a general theoretical guarantee for TruVaR covering these aspects, and use it to recover and strengthen existing results on BO and LSE.  Moreover, we provide a new result for a setting where one can select from a number of noise levels having associated costs.  We demonstrate the effectiveness of the algorithm on both synthetic and real-world data sets."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "f-GAN", "Title": "Training Generative Neural Samplers using Variational Divergence Minimization", "Abstract": "Generative neural networks are probabilistic models that implement sampling using feedforward neural networks: they take a random input vector and produce a sample from a probability distribution defined by the network weights. These models are expressive and allow efficient computation of samples and derivatives, but cannot be used for computing likelihoods or for marginalization. The generative-adversarial training method allows to train such models through the use of an auxiliary discriminative neural network. We show that the generative-adversarial approach is a special case of an existing more general variational divergence estimation approach. We show that any $f$-divergence can be used for training generative neural networks. We discuss the benefits of various choices of divergence functions on training complexity and the quality of the obtained generative models."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Anchor-Free Correlated Topic Modeling", "Title": "Identifiability and Algorithm", "Abstract": "In topic modeling, many algorithms that guarantee identifiability of the topics have been developed under the premise that there exist anchor words -- i.e., words that only appear (with positive probability) in one topic. Follow-up work has resorted to three or higher-order statistics of the data corpus to relax the anchor word assumption. Reliable estimates of higher-order statistics are hard to obtain, however, and the identification of topics under those models hinges on uncorrelatedness of the topics, which can be unrealistic. This paper revisits topic modeling based on second-order moments, and proposes an anchor-free topic mining framework. The proposed approach guarantees the identification of the topics under a much milder condition compared to the anchor-word assumption, thereby exhibiting much better robustness in practice. The associated algorithm only involves one eigen-decomposition and a few small linear programs. This makes it easy to implement and scale up to very large problem instances. Experiments using the TDT2 and Reuters-21578 corpus demonstrate that the proposed anchor-free approach exhibits very favorable performance (measured using coherence, similarity count, and clustering accuracy metrics) compared to the prior art."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Launch and Iterate", "Title": "Reducing Prediction Churn", "Abstract": "Practical applications of machine learning often involve successive training iterations with changes to features and training examples. Ideally, changes in the output of any new model should only be improvements (wins) over the previous iteration, but in practice the predictions may change neutrally for many examples, resulting in extra net-zero wins and losses, referred to as unnecessary churn. These changes in the predictions are problematic for usability for some applications, and make it harder and more expensive to measure if a change is statistically significant positive. In this paper, we formulate the problem and present a stabilization operator to regularize a classifier towards a previous classifier. We use a Markov chain Monte Carlo stabilization operator to produce a model with more consistent predictions without adversely affecting accuracy. We investigate the properties of the proposal with theoretical analysis. Experiments on benchmark datasets for different classification algorithms demonstrate the method and the resulting reduction in churn."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scan Order in Gibbs Sampling", "Title": "Models in Which it Matters and Bounds on How Much", "Abstract": "Gibbs sampling is a Markov Chain Monte Carlo sampling technique that iteratively samples variables from their conditional distributions. There are two common scan orders for the variables: random scan and systematic scan. Due to the benefits of locality in hardware, systematic scan is commonly used, even though most statistical guarantees are only for random scan. While it has been conjectured that the mixing times of random scan and systematic scan do not differ by more than a logarithmic factor, we show by counterexample that this is not the case, and we prove that that the mixing times do not differ by more than a polynomial factor under mild conditions. To prove these relative bounds, we introduce a method of augmenting the state space to study systematic scan using conductance."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Perspective Transformer Nets", "Title": "Learning Single-View 3D Object Reconstruction without 3D Supervision", "Abstract": "Understanding the 3D world is a fundamental problem in computer vision. However, learning a good representation of 3D objects is still an open problem due to the high dimensionality of the data and many factors of variation involved. In this work, we investigate the task of single-view 3D object reconstruction from a learning agent's perspective. We formulate the learning process as an interaction between 3D and 2D representations and propose an encoder-decoder network with a novel projection loss defined by the projective transformation. More importantly, the projection loss enables the unsupervised learning using 2D observation without explicit 3D supervision. We demonstrate the ability of the model in generating 3D volume from a single 2D image with three sets of experiments: (1) learning from single-class objects; (2) learning from multi-class objects and (3) testing on novel object classes. Results show superior performance and better generalization ability for 3D object reconstruction when the projection loss is involved."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fairness in Learning", "Title": "Classic and Contextual Bandits", "Abstract": "We introduce the study of fairness in multi-armed bandit problems. Our fairness definition demands that, given a pool of applicants, a worse applicant is never favored over a better one, despite a learning algorithm’s uncertainty over the true payoffs. In the classic stochastic bandits problem we provide a provably fair algorithm based on “chained” confidence intervals, and prove a cumulative regret bound with a cubic dependence on the number of arms. We further show that any fair algorithm must have such a dependence, providing a strong separation between fair and unfair learning that extends to the general contextual case. In the general contextual case, we prove a tight connection between fairness and the KWIK (Knows What It Knows) learning model: a KWIK algorithm for a class of functions can be transformed into a provably fair contextual bandit algorithm and vice versa. This tight connection allows us to provide a provably fair algorithm for the linear contextual bandit problem with a polynomial dependence on the dimension, and to show (for a different class of functions) a worst-case exponential gap in regret between fair and non-fair learning algorithms."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weight Normalization", "Title": "A Simple Reparameterization to Accelerate Training of Deep Neural Networks", "Abstract": "We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as LSTMs and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Correlated-PCA", "Title": "Principal Components' Analysis when Data and Noise are Correlated", "Abstract": "Given a matrix of observed data, Principal Components Analysis (PCA) computes a small number of orthogonal directions that contain most of its variability. Provably accurate solutions for PCA have been in use for a long time. However, to the best of our knowledge, all existing theoretical guarantees for it assume that the data and the corrupting noise  are mutually independent, or at least uncorrelated. This is valid in practice often, but not always. In this paper, we study the PCA problem in the setting where the data and noise can be correlated. Such noise is often also referred to as ``data-dependent noise\". We obtain a correctness result for the standard eigenvalue decomposition (EVD) based solution to PCA under simple assumptions on the data-noise correlation. We also develop and analyze a generalization of EVD, cluster-EVD, that improves upon EVD in certain regimes."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PerforatedCNNs", "Title": "Acceleration through Elimination of Redundant Convolutions", "Abstract": "We propose a novel approach to reduce the computational cost of evaluation of convolutional neural networks, a factor that has hindered their deployment in low-power devices such as mobile phones. Inspired by the loop perforation technique from source code optimization, we speed up the bottleneck convolutional layers by skipping their evaluation in some of the spatial positions. We propose and analyze several strategies of choosing these positions. We demonstrate that perforation can accelerate modern convolutional networks such as AlexNet and VGG-16 by a factor of 2x - 4x. Additionally, we show that perforation is complementary to the recently proposed acceleration method of Zhang et al."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hierarchical Deep Reinforcement Learning", "Title": "Integrating Temporal Abstraction and Intrinsic Motivation", "Abstract": "Learning goal-directed behavior in environments with sparse feedback is a major challenge for reinforcement learning algorithms. One of the key difficulties is insufficient exploration, resulting in an agent being unable to learn robust policies. Intrinsically motivated agents can explore new behavior for their own sake rather than to directly solve external goals. Such intrinsic behaviors could eventually help the agent solve tasks posed by the environment. We present hierarchical-DQN (h-DQN), a framework to integrate hierarchical action-value functions, operating at different temporal scales, with goal-driven intrinsically motivated deep reinforcement learning. A top-level q-value function learns a policy over intrinsic goals, while a lower-level function learns a policy over atomic actions to satisfy the given goals. h-DQN allows for flexible goal specifications, such as functions over entities and relations. This provides an efficient space for exploration in complicated environments. We demonstrate the strength of our approach on two problems with very sparse and delayed feedback: (1) a complex discrete stochastic decision process with stochastic transitions, and (2) the classic ATARI game -- `Montezuma's Revenge'."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SPALS", "Title": "Fast Alternating Least Squares via Implicit Leverage Scores Sampling", "Abstract": "Tensor CANDECOMP/PARAFAC (CP) decomposition is a powerful but computationally challenging tool in modern data analytics. In this paper, we show ways of sampling intermediate steps of alternating minimization algorithms for computing low rank tensor CP decompositions, leading to the sparse alternating least squares (SPALS) method. Specifically, we sample the the Khatri-Rao product, which arises as an intermediate object during the iterations of alternating least squares. This product captures the interactions between different tensor modes, and form the main computational bottleneck for solving many tensor related tasks. By exploiting the spectral structures of the matrix Khatri-Rao product, we provide efficient access to its statistical leverage scores. When applied to the tensor CP decomposition, our method leads to the first algorithm that runs in sublinear time per-iteration and approximates the output of deterministic alternating least squares algorithms. Empirical evaluations of this approach show significantly speedups over existing randomized and deterministic routines for performing CP decomposition. On a tensor of the size 2.4m by 6.6m by 92k with over 2 billion nonzeros formed by Amazon product reviews, our routine converges in two minutes to the same error as deterministic ALS."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Testing for Differences in Gaussian Graphical Models", "Title": "Applications to Brain Connectivity", "Abstract": "Functional brain networks are well described and estimated from data with Gaussian Graphical Models (GGMs), e.g.\\ using sparse inverse covariance estimators. Comparing functional connectivity of subjects in two populations calls for comparing these estimated GGMs. Our goal is to identify differences in GGMs known to have similar structure. We characterize the uncertainty of differences with confidence intervals obtained using a parametric distribution on parameters of a sparse estimator. Sparse penalties enable statistical guarantees and interpretable models even in high-dimensional and low-sample settings. Characterizing the distributions of sparse models is inherently challenging as the penalties produce a biased estimator. Recent work invokes the sparsity assumptions to effectively remove the bias from a sparse estimator such as the lasso.  These distributions can be used to give confidence intervals on edges in GGMs, and by extension their differences. However, in the case of comparing GGMs, these estimators do not make use of any assumed joint structure among the GGMs. Inspired by priors from brain functional connectivity we derive the distribution of parameter differences under a joint penalty when parameters are known to be sparse in the difference. This leads us to introduce the debiased multi-task fused lasso, whose distribution can be characterized in an efficient manner. We then show how the debiased lasso and multi-task fused lasso can be used to obtain confidence intervals on edge differences in GGMs. We validate the techniques proposed on a set of synthetic examples as well as neuro-imaging dataset created for the study of autism."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dueling Bandits", "Title": "Beyond Condorcet Winners to General Tournament Solutions", "Abstract": "Recent work on deriving $O(\\log T)$ anytime regret bounds for stochastic dueling bandit problems has considered mostly Condorcet winners, which do not always exist, and more recently, winners defined by the Copeland set, which do always exist. In this work, we consider a broad notion of winners defined by tournament solutions in social choice theory, which include the Copeland set as a special case but also include several other notions of winners such as the top cycle, uncovered set, and Banks set, and which, like the Copeland set, always exist. We develop a family of UCB-style dueling bandit algorithms for such general tournament solutions, and show $O(\\log T)$ anytime regret bounds for them. Experiments confirm the ability of our algorithms to achieve low regret relative to the target winning set of interest."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Balancing Suspense and Surprise", "Title": "Timely Decision Making with Endogenous Information Acquisition", "Abstract": "We develop a Bayesian model for decision-making under time pressure with endogenous information acquisition. In our model, the decision-maker decides when to observe (costly) information by sampling an underlying continuous-time stochastic process (time series) that conveys information about the potential occurrence/non-occurrence of an adverse event which will terminate the decision-making process. In her attempt to predict the occurrence of the adverse event, the decision-maker follows a policy that determines when to acquire information from the time series (continuation), and when to stop acquiring information and make a final prediction (stopping). We show that the optimal policy has a \"rendezvous\" structure, i.e. a structure in which whenever a new information sample is gathered from the time series, the optimal \"date\" for acquiring the next sample becomes computable. The optimal interval between two information samples balances a trade-off between the decision maker’s \"surprise\", i.e. the drift in her posterior belief after observing new information, and \"suspense\", i.e. the probability that the adverse event occurs in the time interval between two information samples. Moreover, we characterize the continuation and stopping regions in the decision-maker’s state-space, and show that they depend not only on the decision-maker’s beliefs, but also on the \"context\", i.e. the current realization of the time series."}
{"Type": "conference", "Year": "2016", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Natural-Parameter Networks", "Title": "A Class of Probabilistic Neural Networks", "Abstract": "Neural networks (NN) have achieved state-of-the-art performance in various applications. Unfortunately in applications where training data is insufficient, they are often prone to overfitting. One effective way to alleviate this problem is to exploit the Bayesian approach by using Bayesian neural networks (BNN). Another shortcoming of NN is the lack of flexibility to customize different distributions for the weights and neurons according to the data, as is often done in probabilistic graphical models. To address these problems, we propose a class of probabilistic neural networks, dubbed natural-parameter networks (NPN), as a novel and lightweight Bayesian treatment of NN. NPN allows the usage of arbitrary exponential-family distributions to model the weights and neurons. Different from traditional NN and BNN, NPN takes distributions as input and goes through layers of transformation before producing distributions to match the target output distributions. As a Bayesian treatment, efficient backpropagation (BP) is performed to learn the natural parameters for the distributions over both the weights and neurons. The output distributions of each layer, as byproducts, may be used as second-order representations for the associated tasks such as link prediction. Experiments on real-world datasets show that NPN can achieve state-of-the-art performance."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Worst-case", "Title": "A Probabilistic Analysis of Affine Policies in Dynamic Optimization", "Abstract": "Affine policies (or control) are widely used as a solution approach in dynamic optimization where computing an optimal adjustable solution is usually intractable. While the worst case performance of affine policies can be significantly bad, the empirical performance is observed to be near-optimal for a large class of problem instances. For instance, in the two-stage dynamic robust optimization problem with linear covering constraints and uncertain right hand side, the worst-case approximation bound for affine policies is $O(\\sqrt m)$ that is also tight (see Bertsimas and Goyal (2012)), whereas observed empirical performance is near-optimal. In this paper, we aim to address this stark-contrast between the worst-case and the empirical performance of affine policies. In particular, we  show that affine policies give a good approximation for the two-stage adjustable robust optimization problem with high probability on random instances where the constraint coefficients are generated i.i.d. from a large class of distributions; thereby, providing a theoretical justification of the observed empirical performance. On the other hand, we also present a distribution such that the performance bound for affine policies on instances generated according to that distribution is $\\Omega(\\sqrt m)$ with high probability; however, the constraint coefficients are not i.i.d.. This demonstrates that the empirical performance of affine policies can depend on the generative model for instances."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FALKON", "Title": "An Optimal Large Scale Kernel Method", "Abstract": "Kernel methods provide a principled way to perform non linear, nonparametric learning. They rely on solid functional analytic foundations and enjoy optimal statistical properties. However, at least in their basic form,  they have limited  applicability in large scale scenarios because of stringent computational requirements  in terms of time and especially memory. In this paper, we take a substantial step in scaling up kernel methods, proposing FALKON, a novel algorithm that allows to efficiently process millions of points. FALKON is derived combining several algorithmic principles, namely stochastic subsampling, iterative solvers and preconditioning. Our theoretical analysis shows that  optimal statistical accuracy  is achieved  requiring essentially $O(n)$ memory and $O(n\\sqrt{n})$  time. An extensive experimental analysis on large scale datasets shows that, even with a single machine,  FALKON   outperforms  previous state of the art solutions, which exploit parallel/distributed architectures."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Breaking the Nonsmooth Barrier", "Title": "A Scalable Parallel Method for Composite Optimization", "Abstract": "Due to their simplicity and excellent performance, parallel asynchronous variants of stochastic gradient descent have become popular methods to solve a wide range of large-scale optimization problems on multi-core architectures. Yet, despite their practical success, support for nonsmooth objectives is still lacking, making them unsuitable for many problems of interest in machine learning, such as the Lasso, group Lasso or empirical risk minimization with convex constraints.   In this work, we propose and analyze ProxASAGA, a fully asynchronous sparse method inspired by SAGA, a variance reduced incremental gradient algorithm. The proposed method is easy to implement and significantly outperforms the state of the art on several nonsmooth, large-scale problems. We prove that our method achieves a theoretical linear speedup with respect to the sequential version under assumptions on the sparsity of gradients and block-separability of the proximal term. Empirical benchmarks on a multi-core architecture illustrate practical speedups of up to 12x on a 20-core machine."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Best of Both Worlds", "Title": "Transferring Knowledge from Discriminative Learning to a Generative Visual Dialog Model", "Abstract": "We present a novel training framework for neural sequence models, particularly for grounded dialog generation. The standard training paradigm for these models is maximum likelihood estimation (MLE), or minimizing the cross-entropy of the human responses. Across a variety of domains, a recurring problem with MLE trained generative neural dialog models (G) is that they tend to produce 'safe' and generic responses like \"I don't know\", \"I can't tell\"). In contrast, discriminative dialog models (D) that are trained to rank a list of candidate human responses outperform their generative counterparts; in terms of automatic metrics, diversity, and informativeness of the responses. However, D is not useful in practice since it can not be deployed to have real conversations with users.   Our work aims to achieve the best of both worlds -- the practical usefulness of G and the strong performance of D -- via knowledge transfer from D to G. Our primary contribution is an end-to-end trainable generative visual dialog model, where G receives gradients from D as a perceptual (not adversarial) loss of the sequence sampled from G. We leverage the recently proposed Gumbel-Softmax (GS) approximation to the discrete distribution -- specifically, a RNN is augmented with a sequence of GS samplers, which coupled with the straight-through gradient estimator enables end-to-end differentiability. We also introduce a stronger encoder for visual dialog, and employ a self-attention mechanism for answer encoding along with a metric learning loss to aid D in better capturing semantic similarities in answer responses. Overall, our proposed model outperforms state-of-the-art on the VisDial dataset by a significant margin (2.67% on recall@10). The source code can be downloaded from https://github.com/jiasenlu/visDial.pytorch"}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PASS-GLM", "Title": "polynomial approximate sufficient statistics for scalable Bayesian GLM inference", "Abstract": "Generalized linear models (GLMs)---such as logistic regression, Poisson regression, and robust regression---provide interpretable models for diverse data types. Probabilistic approaches, particularly Bayesian ones, allow coherent estimates of uncertainty, incorporation of prior information, and sharing of power across experiments via hierarchical models. In practice, however, the approximate Bayesian methods necessary for inference have either failed to scale to large data sets or failed to provide theoretical guarantees on the quality of inference. We propose a new approach based on constructing polynomial approximate sufficient statistics for GLMs (PASS-GLM). We demonstrate that our method admits a simple algorithm as well as trivial streaming and distributed extensions that do not compound error across computations. We provide theoretical guarantees on the quality of point (MAP) estimates, the approximate posterior, and posterior mean and uncertainty estimates. We validate our approach empirically in the case of logistic regression using a quadratic approximation and show competitive performance with stochastic gradient descent, MCMC, and the Laplace approximation in terms of  speed and multiple measures of accuracy---including on an advertising data set with 40 million data points and 20,000 covariates."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distral", "Title": "Robust multitask reinforcement learning", "Abstract": "Most deep reinforcement learning algorithms are data inefficient in complex and rich environments, limiting their applicability to many scenarios. One direction for improving data efficiency is multitask learning with shared neural network parameters, where efficiency may be improved through transfer across related tasks. In practice, however,  this is not usually observed, because gradients from different tasks can interfere negatively, making learning unstable and sometimes even less data efficient. Another issue is the different reward schemes between tasks, which can easily lead to one task dominating the learning of a shared model. We propose a new  approach for joint training of multiple tasks, which we refer to as Distral (DIStill & TRAnsfer Learning). Instead of sharing parameters between the different workers, we propose to share a distilled policy that captures common behaviour across tasks. Each worker is trained to solve its own task while constrained to stay close to the shared policy, while the shared policy is trained by distillation to be the centroid of all task policies. Both aspects of the learning process are derived by optimizing a joint objective function. We show that our approach supports efficient transfer on complex 3D environments, outperforming several related methods. Moreover, the proposed learning process is more robust and more stable---attributes that are critical in deep reinforcement learning."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "When Worlds Collide", "Title": "Integrating Different Counterfactual Assumptions in Fairness", "Abstract": "Machine learning is now being used to make crucial decisions about people's lives. For nearly all of these decisions there is a risk that individuals of a certain race, gender, sexual orientation, or any other subpopulation are unfairly discriminated against. Our recent method has demonstrated how to use techniques from counterfactual inference to make predictions fair across different subpopulations. This method requires that one provides the causal model that generated the data at hand. In general, validating all causal implications of the model is not possible without further assumptions. Hence, it is desirable to integrate competing causal models to provide counterfactually fair decisions, regardless of which causal \"world\" is the correct one. In this paper, we show how it is possible to make predictions that are approximately fair with respect to multiple possible causal models at once, thus mitigating the problem of exact causal specification. We frame the goal of learning a fair classifier as an optimization problem with fairness constraints entailed by competing causal explanations. We show how this optimization problem can be efficiently solved using gradient-based methods. We demonstrate the flexibility of our model on two real-world fair classification problems. We show that our model can seamlessly balance fairness in multiple worlds with prediction accuracy."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "k-Support and Ordered Weighted Sparsity for Overlapping Groups", "Title": "Hardness and Algorithms", "Abstract": "The k-support and OWL norms generalize the l1 norm, providing better prediction accuracy and better handling of correlated variables. We study the norms obtained from extending the k-support norm and OWL norms to the setting in which there are overlapping groups. The resulting norms are in general NP-hard to compute, but they are tractable for certain collections of groups. To demonstrate this fact, we  develop a dynamic program for the problem of projecting onto the set of vectors supported by a fixed number of groups. Our dynamic program utilizes tree decompositions and its complexity scales with the treewidth. This program can be converted to an extended formulation which, for the associated group structure, models the k-group support norms and an overlapping group variant of the ordered weighted l1 norm. Numerical results demonstrate the efficacy of the new penalties."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unifying PAC and Regret", "Title": "Uniform PAC Bounds for Episodic Reinforcement Learning", "Abstract": "Statistical performance bounds for reinforcement learning (RL) algorithms can be critical for high-stakes applications like healthcare. This paper introduces a new framework for theoretically measuring the performance of such algorithms called Uniform-PAC, which is a strengthening of the classical Probably Approximately Correct (PAC) framework. In contrast to the PAC framework, the uniform version may be used to derive high probability regret guarantees and so forms a bridge between the two setups that has been missing in the literature. We demonstrate the benefits of the new framework for finite-state episodic MDPs with a new algorithm that is Uniform-PAC and simultaneously achieves optimal regret and PAC guarantees except for a factor of the horizon."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "YASS", "Title": "Yet Another Spike Sorter", "Abstract": "Spike sorting is a critical first step in extracting neural signals from large-scale electrophysiological data.  This manuscript describes an efficient, reliable pipeline for spike sorting on dense multi-electrode arrays (MEAs), where neural signals appear across many electrodes and spike sorting currently represents a major computational bottleneck. We present several new techniques that make dense MEA spike sorting more robust and scalable. Our pipeline is based on an efficient multi-stage ''triage-then-cluster-then-pursuit'' approach that initially extracts only clean, high-quality waveforms from the electrophysiological time series by temporarily skipping noisy or ''collided'' events (representing two neurons firing synchronously). This is accomplished by developing a neural network detection method followed by efficient outlier triaging. The clean waveforms are then used to infer the set of neural spike waveform templates through nonparametric Bayesian clustering. Our clustering approach adapts a ''coreset'' approach for data reduction and uses efficient inference methods in a Dirichlet process mixture model framework to dramatically improve the scalability and reliability of the entire pipeline. The ''triaged'' waveforms are then finally recovered with matching-pursuit deconvolution techniques. The proposed methods improve on the state-of-the-art in terms of accuracy and stability on both real and biophysically-realistic simulated MEA data. Furthermore, the proposed pipeline is efficient, learning templates and clustering faster than real-time for a 500-electrode dataset, largely on a single CPU core."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Tensor Train Rank Minimization ", "Title": "Statistical Efficiency and Scalable Algorithm", "Abstract": "Tensor train (TT) decomposition provides a space-efficient representation for higher-order tensors. Despite its advantage, we face two crucial limitations when we apply the TT decomposition to machine learning problems: the lack of statistical theory and of scalable algorithms. In this paper, we address the limitations. First, we introduce a convex relaxation of the TT decomposition problem and derive its error bound for the tensor completion task. Next, we develop a randomized optimization method, in which the time complexity is as efficient as the space complexity is. In experiments, we numerically confirm the derived bounds and empirically demonstrate the performance of our method with a real higher-order tensor."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EX2", "Title": "Exploration with Exemplar Models for Deep Reinforcement Learning", "Abstract": "Deep reinforcement learning algorithms have been shown to learn complex tasks using highly general policy classes. However, sparse reward problems remain a significant challenge. Exploration methods based on novelty detection have been particularly successful in such settings but typically require generative or predictive models of the observations, which can be difficult to train when the observations are very high-dimensional and complex, as in the case of raw images. We propose a novelty detection algorithm for exploration that is based entirely on discriminatively trained exemplar models, where classifiers are trained to discriminate each visited state against all others. Intuitively, novel states are easier to distinguish against other states seen during training. We show that this kind of discriminative modeling corresponds to implicit density estimation, and that it can be combined with count-based exploration to produce competitive results on a range of popular benchmark tasks, including state-of-the-art results on challenging egocentric observations in the vizDoom benchmark."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Training Quantized Nets", "Title": "A Deeper Understanding", "Abstract": "Currently, deep neural networks are deployed on low-power portable devices by first training a full-precision model using powerful hardware, and then deriving a corresponding low-precision model for efficient inference on such systems. However, training models directly with coarsely quantized weights is a key step towards learning on embedded platforms that have limited computing resources, memory capacity, and power consumption.  Numerous recent publications have studied methods for training quantized networks, but these studies have mostly been empirical. In this work, we investigate training methods for quantized neural networks from a theoretical viewpoint.  We first explore accuracy guarantees for training methods under convexity assumptions.  We then look at the behavior of these algorithms for non-convex problems, and show that training algorithms that exploit high-precision representations have an important greedy search phase that purely quantized training methods lack, which explains the difficulty of training using low-precision arithmetic."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learned in Translation", "Title": "Contextualized Word Vectors", "Abstract": "Computer vision has benefited from initializing multiple deep layers with weights pretrained on large supervised training sets like ImageNet. Natural language processing (NLP) typically sees initialization of only the lowest layer of deep models with pretrained word vectors. In this paper, we use a deep LSTM encoder from an attentional sequence-to-sequence model trained for machine translation (MT) to contextualize word vectors. We show that adding these context vectors (CoVe) improves performance over using only unsupervised word and character vectors on a wide variety of common NLP tasks: sentiment analysis (SST, IMDb), question classification (TREC), entailment (SNLI), and question answering (SQuAD). For fine-grained sentiment analysis and entailment, CoVe improves performance of our baseline models to the state of the art."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularizing Deep Neural Networks by Noise", "Title": "Its Interpretation and Optimization", "Abstract": "Overfitting is one of the most critical challenges in deep neural networks, and there are various types of regularization methods to improve generalization performance. Injecting noises to hidden units during training, e.g., dropout, is known as a successful regularizer, but it is still not clear enough why such training techniques work well in practice and how we can maximize their benefit in the presence of two conflicting objectives---optimizing to true data distribution and preventing overfitting by regularization. This paper addresses the above issues by 1) interpreting that the conventional training methods with regularization by noise injection optimize the lower bound of the true objective and 2) proposing a technique to achieve a tighter lower bound using multiple noise samples per training example  in a stochastic gradient descent iteration. We demonstrate the effectiveness of our idea in several computer vision applications."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-View Decision Processes", "Title": "The Helper-AI Problem", "Abstract": "We consider a  two-player sequential game in which agents have the same reward function but may disagree on the transition probabilities of an underlying Markovian model of the world. By committing to play a specific policy, the agent with the correct model can steer the behavior of the other agent, and seek to improve utility. We model this setting as a multi-view decision process, which we use to formally analyze the positive effect of steering policies. Furthermore, we develop an algorithm for computing the agents' achievable joint policy, and we experimentally show that it can lead to a large utility increase when the agents' models diverge."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DPSCREEN", "Title": "Dynamic Personalized Screening", "Abstract": "Screening is important for the diagnosis and treatment of a wide variety of diseases.  A good screening  policy should be personalized to the disease, to the features of the patient and to the dynamic history of the patient (including the history of screening).  The growth of electronic health records data  has led to the development of many  models to  predict the onset and progression of different diseases. However, there has been limited work to address the personalized screening for these different diseases. In this work, we develop the first framework to construct screening policies for a large class of disease models. The disease is modeled as a finite state stochastic process with an absorbing disease state. The patient observes an  external information process (for instance, self-examinations, discovering comorbidities, etc.) which can trigger the patient to arrive at the clinician earlier than scheduled screenings. The clinician carries out the tests; based on the test results and the  external information it schedules the next arrival.  Computing the exactly optimal screening policy that balances the delay in the detection against the frequency of screenings is computationally intractable; this paper provides a computationally tractable construction of an approximately optimal policy.  As an illustration, we make use of a large breast cancer data set.  The constructed policy screens patients more or less often according to their initial risk -- it is personalized to the features of the patient -- and according to the results of previous screens – it is personalized to the  history of the patient. In comparison with existing clinical policies, the constructed policy leads to large reductions (28-68 %) in the number of screens performed while achieving the same expected delays in disease detection."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A-NICE-MC", "Title": "Adversarial Training for MCMC", "Abstract": "Existing Markov Chain Monte Carlo (MCMC)  methods are either based on general-purpose and domain-agnostic schemes, which can lead to slow convergence, or require hand-crafting of problem-specific proposals by an expert. We propose A-NICE-MC, a novel method to train flexible parametric Markov chain kernels to produce samples with desired properties.   First, we propose an efficient likelihood-free adversarial training method to train a Markov chain and mimic a given data distribution. Then, we leverage flexible volume preserving flows to obtain parametric kernels for MCMC. Using a bootstrap approach, we show how to train efficient Markov Chains to sample from a prescribed posterior distribution by iteratively improving the quality of both the model and the samples. A-NICE-MC provides the first framework to automatically design efficient domain-specific MCMC proposals. Empirical results demonstrate that A-NICE-MC combines the strong guarantees of MCMC with the expressiveness of deep neural networks, and is able to significantly outperform competing methods such as Hamiltonian Monte Carlo."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scalable Generalized Linear Bandits", "Title": "Online Computation and Hashing", "Abstract": "Generalized Linear Bandits (GLBs), a natural extension of the stochastic linear bandits, has been popular and successful in recent years.  However, existing GLBs scale poorly with the number of rounds and the number of arms, limiting their utility in practice.  This paper proposes new, scalable solutions to the GLB problem in two respects.  First, unlike existing GLBs, whose per-time-step space and time complexity grow at least linearly with time $t$, we propose a new algorithm that performs online computations to enjoy a constant space and time complexity.  At its heart is a novel Generalized Linear extension of the Online-to-confidence-set Conversion (GLOC method) that takes \\emph{any} online learning algorithm and turns it into a GLB algorithm.  As a special case, we apply GLOC to the online Newton step algorithm, which results in a low-regret GLB algorithm with much lower time and memory complexity than prior work.  Second, for the case where the number $N$ of arms is very large, we propose new algorithms in which each next arm is selected via an inner product search.  Such methods can be implemented via hashing algorithms (i.e., ``hash-amenable'') and result in a time complexity sublinear in $N$.  While a Thompson sampling extension of GLOC is hash-amenable, its regret bound for $d$-dimensional arm sets scales with $d^{3/2}$, whereas GLOC's regret bound scales with $d$.  Towards closing this gap, we propose a new hash-amenable algorithm whose regret bound scales with $d^{5/4}$.  Finally, we propose a fast approximate hash-key computation (inner product) with a better accuracy than the state-of-the-art, which can be of independent interest.  We conclude the paper with preliminary experimental results confirming the merits of our methods."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "InfoGAIL", "Title": "Interpretable Imitation Learning from Visual Demonstrations", "Abstract": "The goal of imitation learning is to mimic expert behavior without access to an explicit reward signal. Expert demonstrations provided by humans, however, often show significant variability due to latent factors that are typically not explicitly modeled. In this paper, we propose a new algorithm that can infer the latent structure of expert demonstrations in an unsupervised way. Our method, built on top of Generative Adversarial Imitation Learning, can not only imitate complex behaviors, but also learn interpretable and meaningful representations of complex behavioral data, including visual demonstrations. In the driving domain, we show that a model learned from human demonstrations is able to both accurately reproduce a variety of behaviors and accurately anticipate human actions using raw visual inputs. Compared with various baselines, our method can better capture the latent structure underlying expert demonstrations, often recovering semantically meaningful factors of variation in the data."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Affinity Clustering", "Title": "Hierarchical Clustering at Scale", "Abstract": "Graph clustering is a fundamental task in many data-mining and machine-learning pipelines. In particular, identifying a good hierarchical structure is at the same time a fundamental and challenging problem for several applications. The amount of data to analyze is increasing at an astonishing rate each day. Hence there is a need for new solutions to efficiently compute effective hierarchical clusterings on such huge data.  The main focus of this paper is on minimum spanning tree (MST) based clusterings. In particular, we propose affinity, a novel hierarchical clustering based on Boruvka's MST algorithm. We prove certain theoretical guarantees for affinity (as well as some other classic algorithms) and show that in practice it is superior to several other state-of-the-art clustering algorithms.   Furthermore, we present two MapReduce implementations for affinity. The first one works for the case where the input graph is dense and takes constant rounds. It is based on a Massively Parallel MST algorithm for dense graphs that improves upon the state-of-the-art algorithm of Lattanzi et al. (SPAA 2011). Our second algorithm has no assumption on the density of the input graph and finds the affinity clustering in $O(\\log n)$ rounds using Distributed Hash Tables (DHTs). We show experimentally that our algorithms are scalable for huge data sets, e.g., for graphs with trillions of edges."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Active Bias", "Title": "Training More Accurate Neural Networks by Emphasizing High Variance Samples", "Abstract": "Self-paced learning and hard example mining re-weight training instances to improve learning accuracy. This paper presents two improved alternatives based on lightweight estimates of sample uncertainty in stochastic gradient descent (SGD): the variance in predicted probability of the correct class across iterations of mini-batch SGD, and the proximity of the correct class probability to the decision threshold. Extensive experimental results on six datasets show that our methods reliably improve accuracy in various network architectures, including additional gains on top of other popular training techniques, such as residual learning, momentum, ADAM, batch normalization, dropout, and distillation."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SchNet", "Title": "A continuous-filter convolutional neural network for modeling quantum interactions", "Abstract": "Deep learning has the potential to revolutionize quantum chemistry as it is ideally suited to learn representations for structured data and speed up the exploration of chemical space. While convolutional neural networks have proven to be the first choice for images, audio and video data, the atoms in molecules are not restricted to a grid. Instead, their precise locations contain essential physical information, that would get lost if discretized. Thus, we propose to use continuous-filter convolutional layers to be able to model local correlations without requiring the data to lie on a grid. We apply those layers in SchNet: a novel deep learning architecture modeling quantum interactions in molecules. We obtain a joint model for the total energy and interatomic forces that follows fundamental quantum-chemical principles. Our architecture achieves state-of-the-art performance for benchmarks of equilibrium molecules and molecular dynamics trajectories. Finally, we introduce a more challenging benchmark with chemical and structural variations that suggests the path for further work."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GibbsNet", "Title": "Iterative Adversarial Inference for Deep Graphical Models", "Abstract": "Directed latent variable models that formulate the joint distribution as $p(x,z) = p(z) p(x \\mid z)$ have the advantage of fast and exact sampling. However, these models have the weakness of needing to specify $p(z)$, often with a simple fixed prior that limits the expressiveness of the model.  Undirected latent variable models discard the requirement that $p(z)$ be specified with a prior, yet sampling from them generally requires an iterative procedure such as blocked Gibbs-sampling that may require many steps to draw samples from the joint distribution $p(x, z)$.  We propose a novel approach to learning the joint distribution between the data and a latent code which uses an adversarially learned iterative procedure to gradually refine the joint distribution, $p(x, z)$, to better match with the data distribution on each step.  GibbsNet is the best of both worlds both in theory and in practice.  Achieving the speed and simplicity of a directed latent variable model, it is guaranteed (assuming the adversarial game reaches the virtual training criteria global minimum) to produce samples from $p(x, z)$ with only a few sampling iterations.  Achieving the expressiveness and flexibility of an undirected latent variable model, GibbsNet does away with the need for an explicit $p(z)$ and has the ability to do attribute prediction, class-conditional generation, and joint image-attribute modeling in a single model which is not trained for any of these specific tasks.  We show empirically that GibbsNet is able to learn a more complex $p(z)$ and show that this leads to improved inpainting and iterative refinement of $p(x, z)$ for dozens of steps and stable generation without collapse for thousands of steps, despite being trained on only a few steps."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Expressive Power of Neural Networks", "Title": "A View from the Width", "Abstract": "The expressive power of neural networks is important for understanding deep learning. Most existing works consider this problem from the view of the depth of a network. In this paper, we study how width affects the expressiveness of neural networks. Classical results state that depth-bounded (e.g. depth-2) networks with suitable activation functions are universal approximators. We show a universal approximation theorem for width-bounded ReLU networks: width-(n + 4) ReLU networks, where n is the input dimension, are universal approximators. Moreover, except for a measure zero set, all functions cannot be approximated by width-n ReLU networks, which exhibits a phase transition. Several recent works demonstrate the benefits of depth by proving the depth-efficiency of neural networks. That is, there are classes of deep networks which cannot be realized by any shallow network whose size is no more than an exponential bound. Here we pose the dual question on the width-efficiency of ReLU networks: Are there wide networks that cannot be realized by narrow networks whose size is not substantially larger? We show that there exist classes of wide networks which cannot be realized by any narrow network whose depth is no more than a polynomial bound. On the other hand, we demonstrate by extensive experiments that narrow networks whose size exceed the polynomial bound by a constant factor can approximate wide and shallow network with high accuracy. Our results provide more comprehensive evidence that depth may be more effective than width for the expressiveness of ReLU networks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The power of absolute discounting", "Title": "all-dimensional distribution estimation", "Abstract": "Categorical models are a natural fit for many problems. When learning the distribution of categories from samples, high-dimensionality may dilute the data. Minimax optimality is too pessimistic to remedy this issue. A serendipitously discovered estimator, absolute discounting, corrects empirical frequencies by subtracting a constant from observed categories, which it then redistributes among the unobserved. It outperforms classical estimators empirically, and has been used extensively in natural language modeling. In this paper, we rigorously explain the prowess of this estimator using less pessimistic notions. We show  that (1) absolute discounting recovers classical minimax KL-risk rates, (2) it is \\emph{adaptive} to an effective dimension rather than the true dimension, (3) it is strongly related to the Good-Turing estimator and inherits its \\emph{competitive} properties. We use power-law distributions as the cornerstone of these results. We validate the theory via synthetic data and an application to the Global Terrorism Database."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimistic posterior sampling for reinforcement learning", "Title": "worst-case regret bounds", "Abstract": "We present an algorithm based on posterior sampling (aka Thompson sampling) that achieves near-optimal worst-case regret bounds when the underlying Markov Decision Process (MDP) is communicating with a finite, though unknown, diameter. Our main result is a high probability regret upper bound of $\\tilde{O}(D\\sqrt{SAT})$ for any communicating MDP with $S$ states, $A$ actions and diameter $D$, when $T\\ge S^5A$. Here, regret compares the total reward achieved by the algorithm to the total expected reward of an optimal infinite-horizon undiscounted average reward policy, in time horizon $T$. This result improves over the best previously known upper bound of $\\tilde{O}(DS\\sqrt{AT})$ achieved by any algorithm in this setting, and matches the dependence on $S$ in the established lower bound of $\\Omega(\\sqrt{DSAT})$ for this problem. Our techniques involve proving some novel results about the anti-concentration of Dirichlet distribution, which may be of independent interest."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "#Exploration", "Title": "A Study of Count-Based Exploration for Deep Reinforcement Learning", "Abstract": "Count-based exploration algorithms are known to perform near-optimally when used in conjunction with tabular reinforcement learning (RL) methods for solving small discrete Markov decision processes (MDPs). It is generally thought that count-based methods cannot be applied in high-dimensional state spaces, since most states will only occur once. Recent deep RL exploration strategies are able to deal with high-dimensional continuous state spaces through complex heuristics, often relying on optimism in the face of uncertainty or intrinsic motivation. In this work, we describe a surprising finding: a simple generalization of the classic count-based approach can reach near state-of-the-art performance on various high-dimensional and/or continuous deep RL benchmarks. States are mapped to hash codes, which allows to count their occurrences with a hash table. These counts are then used to compute a reward bonus according to the classic count-based exploration theory. We find that simple hash functions can achieve surprisingly good results on many challenging tasks. Furthermore, we show that a domain-dependent learned hash code may further improve these results. Detailed analysis reveals important aspects of a good hash function: 1) having appropriate granularity and 2) encoding information relevant to solving the MDP. This exploration strategy achieves near state-of-the-art performance on both continuous control tasks and Atari 2600 games, hence providing a simple yet powerful baseline for solving MDPs that require considerable exploration."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Streaming Robust Submodular Maximization", "Title": "A Partitioned Thresholding Approach", "Abstract": "We study the classical problem of maximizing a monotone submodular function subject to a cardinality constraint k, with two additional twists: (i) elements arrive in a streaming fashion, and (ii) m items from the algorithm’s memory are removed after the stream is finished. We develop a robust submodular algorithm STAR-T. It is based on a novel partitioning structure and an exponentially decreasing thresholding rule. STAR-T makes one pass over the data and retains a short but robust summary. We show that after the removal of any m elements from the obtained summary, a simple greedy algorithm STAR-T-GREEDY that runs on the remaining elements achieves a constant-factor approximation guarantee. In two different data summarization tasks, we demonstrate that it matches or outperforms existing greedy and streaming methods, even if they are allowed the benefit of knowing the removed subset in advance."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Higher-Order Total Variation Classes on Grids", "Title": "Minimax Theory and Trend Filtering Methods", "Abstract": "We consider the problem of estimating the values of a function over $n$ nodes of a $d$-dimensional grid graph (having equal side lengths $n^{1/d}$) from noisy observations. The function is assumed to be smooth, but is allowed to exhibit different amounts of smoothness at different regions in the grid. Such heterogeneity eludes classical measures of smoothness from nonparametric statistics, such as Holder smoothness. Meanwhile, total variation (TV) smoothness classes allow for heterogeneity, but are restrictive in another sense: only constant functions count as perfectly smooth (achieve zero TV). To move past this, we define two new higher-order TV classes, based on two ways of compiling the discrete derivatives of a parameter across the nodes. We relate these two new classes to Holder classes, and derive lower bounds on their minimax errors. We also analyze two naturally associated trend filtering methods; when $d=2$, each is seen to be rate optimal over the appropriate class."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Net-Trim", "Title": "Convex Pruning of Deep Neural Networks with Performance Guarantee", "Abstract": "We introduce and analyze a new technique for model reduction for deep neural networks. While large networks are theoretically capable of learning arbitrarily complex models, overfitting and model redundancy negatively affects the prediction accuracy and model variance.  Our Net-Trim algorithm prunes (sparsifies) a trained network layer-wise, removing connections at each layer by solving a convex optimization program.  This program seeks a sparse set of weights at each layer that keeps the layer inputs and outputs consistent with the originally trained model.  The algorithms and associated analysis are applicable to neural networks operating with the rectified linear unit (ReLU) as the nonlinear activation. We present both parallel and cascade versions of the algorithm.  While the latter can achieve slightly simpler models with the same generalization performance, the former can be computed in a distributed manner.  In both cases, Net-Trim significantly reduces the number of connections in the network, while also providing enough regularization to slightly reduce the generalization error. We also provide a mathematical analysis of the consistency between the initial network and the retrained model.  To analyze the model sample complexity, we derive the general sufficient conditions for the recovery of a sparse transform matrix. For a single layer taking independent Gaussian random vectors of length $N$ as inputs,  we show that if the network response can be described using a maximum number of $s$ non-zero weights per node, these weights can be learned from $\\mathcal{O}(s\\log N)$ samples."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ELF", "Title": "An Extensive, Lightweight and Flexible Research Platform for Real-time Strategy Games", "Abstract": "In this paper, we propose ELF, an Extensive, Lightweight and Flexible platform for fundamental reinforcement learning research. Using ELF, we implement a highly customizable real-time strategy (RTS) engine with three game environments (Mini-RTS, Capture the Flag and Tower Defense). Mini-RTS, as a miniature version of StarCraft, captures key game dynamics and runs at 165K frame-per-second (FPS) on a laptop. When coupled with modern reinforcement learning methods, the system can train a full-game bot against built-in AIs end-to-end in one day with 6 CPUs and 1 GPU. In addition, our platform is flexible in terms of environment-agent communication topologies, choices of RL methods, changes in game parameters, and can host existing C/C++-based game environments like ALE. Using ELF, we thoroughly explore training parameters and show that a network with Leaky ReLU and Batch Normalization coupled with long-horizon training and progressive curriculum beats the rule-based built-in AI more than 70% of the time in the full game of Mini-RTS. Strong performance is also achieved on the other two games. In game replays, we show our agents learn interesting strategies. ELF, along with its RL platform, is open-sourced at https://github.com/facebookresearch/ELF."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fader Networks", "Title": "Manipulating Images by Sliding Attributes", "Abstract": "This paper introduces a new encoder-decoder architecture that is trained to reconstruct images by disentangling the salient information of the image and the values of attributes directly in the latent space. As a result, after training, our model can generate different realistic versions of an input image by varying the attribute values. By using continuous attribute values, we can choose how much a specific attribute is perceivable in the generated image. This property could allow for applications where users can modify an image using sliding knobs, like faders on a mixing console, to change the facial expression of a portrait, or to update the color of some objects. Compared to the state-of-the-art which mostly relies on training adversarial networks in pixel space by altering attribute values at train time, our approach results in much simpler training schemes and nicely scales to multiple attributes. We present evidence that our model can significantly change the perceived value of the attributes while preserving the naturalness of images."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VEEGAN", "Title": "Reducing Mode Collapse in GANs using Implicit Variational Learning", "Abstract": "Deep generative models provide powerful tools for distributions over complicated manifolds, such as those of natural images.  But many of these methods, including generative adversarial networks (GANs), can be difficult to train, in part because they are prone to mode collapse, which means that they characterize only a few modes of the true distribution.  To address this, we introduce VEEGAN, which features a reconstructor network, reversing the action of the generator by mapping from data to noise.  Our training objective retains the original asymptotic consistency guarantee of GANs, and can be interpreted as a novel autoencoder loss over the noise.  In sharp contrast to a traditional autoencoder over data points, VEEGAN does not require specifying a loss function over the data, but rather only over the representations, which are standard normal by assumption.  On an extensive set of synthetic and real world image datasets, VEEGAN indeed resists mode collapsing to a far greater extent than other recent GAN variants, and produces more realistic samples."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Variational Walkback", "Title": "Learning a Transition Operator as a Stochastic Recurrent Net", "Abstract": "We propose a novel method to {\\it directly} learn a stochastic transition operator whose repeated application provides generated samples. Traditional undirected graphical models approach this problem indirectly by learning a Markov chain model whose stationary distribution obeys detailed balance with respect to a parameterized energy function. The energy function is then modified so the model and data distributions match, with no guarantee on the number of steps required for the Markov chain to converge. Moreover, the detailed balance condition is highly restrictive: energy based models corresponding to neural networks must have symmetric weights, unlike biological neural circuits. In contrast, we develop a method for directly learning arbitrarily parameterized transition operators capable of expressing non-equilibrium stationary distributions that violate detailed balance, thereby enabling us to learn more biologically plausible asymmetric neural networks and more general non-energy based dynamical systems.   The proposed training objective, which we derive via principled variational methods, encourages the transition operator to \"walk back\" (prefer to revert its steps) in multi-step trajectories that start at data-points, as quickly as possible back to the original data points. We present a series of experimental results illustrating the soundness of the proposed approach, Variational Walkback (VW), on the MNIST, CIFAR-10, SVHN and CelebA datasets, demonstrating superior samples compared to earlier attempts to learn a transition operator. We also show that although each rapid training trajectory is limited to a finite but variable number of steps, our transition operator continues to generate good samples well past the length of such trajectories, thereby demonstrating the match of its non-equilibrium stationary distribution to the data distribution. Source Code:http://github.com/anirudh9119/walkback_nips17"}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Partial Hard Thresholding", "Title": "Towards A Principled Analysis of Support Recovery", "Abstract": "In machine learning and compressed sensing, it is of central importance to understand when a tractable algorithm recovers the support of a sparse signal from its compressed measurements. In this paper, we present a principled analysis on the support recovery performance for a family of hard thresholding algorithms. To this end, we appeal to the partial hard thresholding (PHT) operator proposed recently by Jain et al. [IEEE Trans. Information Theory, 2017]. We show that under proper conditions, PHT recovers an arbitrary \"s\"-sparse signal within O(s kappa log kappa) iterations where \"kappa\" is an appropriate condition number. Specifying the PHT operator, we obtain the best known result for hard thresholding pursuit and orthogonal matching pursuit with replacement. Experiments on the simulated data complement our theoretical findings and also illustrate the effectiveness of PHT compared to other popular recovery methods."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SVD-Softmax", "Title": "Fast Softmax Approximation on Large Vocabulary Neural Networks", "Abstract": "We propose a fast approximation method of a softmax function with a very large vocabulary using singular value decomposition (SVD). SVD-softmax targets fast and accurate probability estimation of the topmost probable words during inference of neural network language models. The proposed method transforms the weight matrix used in the calculation of the output vector by using SVD. The approximate probability of each word can be estimated with only a small part of the weight matrix by using a few large singular values and the corresponding elements for most of the words. We applied the technique to language modeling and neural machine translation and present a guideline for good approximation. The algorithm requires only approximately 20\\% of arithmetic operations for an 800K vocabulary case and shows more than a three-fold speedup on a GPU."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OnACID", "Title": "Online Analysis of Calcium Imaging Data in Real Time", "Abstract": "Optical imaging methods using calcium indicators are critical for monitoring the activity of large neuronal populations in vivo. Imaging experiments typically generate a large amount of data that needs to be processed to extract the activity of the imaged neuronal sources. While deriving such processing algorithms is an active area of research, most existing methods require the processing of large amounts of data at a time, rendering them vulnerable to the volume of the recorded data, and preventing real-time experimental interrogation. Here we introduce OnACID, an Online framework for the Analysis of streaming Calcium Imaging Data, including i) motion artifact correction, ii) neuronal source extraction, and iii) activity denoising and deconvolution. Our approach combines and extends previous work on online dictionary learning and calcium imaging data analysis, to deliver an automated pipeline that can discover and track the activity of hundreds of cells in real time, thereby enabling new types of closed-loop experiments. We apply our algorithm on two large scale experimental datasets, benchmark its performance on manually annotated data, and show that it outperforms a popular offline approach."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ExtremeWeather", "Title": "A large-scale climate dataset for semi-supervised detection, localization, and understanding of extreme weather events", "Abstract": "Then detection and identification of extreme weather events in large-scale climate simulations is an important problem for risk management, informing governmental policy decisions and advancing our basic understanding of the climate system. Recent work has shown that fully supervised convolutional neural networks (CNNs) can yield acceptable accuracy for classifying well-known types of extreme weather events when large amounts of labeled data are available. However, many different types of spatially localized climate patterns are of interest including hurricanes, extra-tropical cyclones, weather fronts, and blocking events among others. Existing labeled data for these patterns can be incomplete in various ways, such as covering only certain years or geographic areas and having false negatives. This type of climate data therefore poses a number of interesting machine learning challenges. We present a multichannel spatiotemporal CNN architecture for semi-supervised bounding box prediction and exploratory data analysis. We demonstrate that our approach is able to leverage temporal information and unlabeled data to improve the localization of extreme weather events. Further, we explore the representations learned by our model in order to better understand this important data. We present a dataset, ExtremeWeather, to encourage machine learning research in this area and to help facilitate further work in understanding and mitigating the effects of climate change. The dataset is available at extremeweatherdataset.github.io and the code is available at https://github.com/eracah/hur-detect."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Unknown Markov Decision Processes", "Title": "A Thompson Sampling Approach", "Abstract": "We consider the problem of learning an unknown Markov Decision Process (MDP) that is weakly communicating in the infinite horizon setting. We propose a Thompson Sampling-based reinforcement learning algorithm with dynamic episodes (TSDE). At the beginning of each episode, the algorithm generates a sample from the posterior distribution over the unknown model parameters. It then follows the optimal stationary policy for the sampled model for the rest of the episode. The duration of each episode is dynamically determined by two stopping criteria. The first stopping criterion controls the growth rate of episode length. The second stopping criterion happens when the number of visits to any state-action pair is doubled. We establish $\\tilde O(HS\\sqrt{AT})$ bounds on expected regret under a Bayesian setting, where $S$ and $A$ are the sizes of the state and action spaces, $T$ is time, and $H$ is the bound of the span. This regret bound matches the best available bound for weakly communicating MDPs. Numerical results show it to perform better than existing algorithms for infinite horizon MDPs."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisiting Perceptron", "Title": "Efficient and Label-Optimal Learning of Halfspaces", "Abstract": "It has been a long-standing problem to efficiently learn a halfspace using as few labels as possible in the presence of noise. In this work, we propose an efficient Perceptron-based algorithm for actively learning homogeneous halfspaces under the uniform distribution over the unit sphere. Under the bounded noise condition~\\cite{MN06}, where each label is flipped with probability at most $\\eta < \\frac 1 2$, our algorithm achieves a near-optimal label complexity of $\\tilde{O}\\left(\\frac{d}{(1-2\\eta)^2}\\ln\\frac{1}{\\epsilon}\\right)$ in time $\\tilde{O}\\left(\\frac{d^2}{\\epsilon(1-2\\eta)^3}\\right)$. Under the adversarial noise condition~\\cite{ABL14, KLS09, KKMS08}, where at most a $\\tilde \\Omega(\\epsilon)$ fraction of labels can be flipped, our algorithm achieves a near-optimal label complexity of $\\tilde{O}\\left(d\\ln\\frac{1}{\\epsilon}\\right)$ in time $\\tilde{O}\\left(\\frac{d^2}{\\epsilon}\\right)$. Furthermore, we show that our active learning algorithm can be converted to an efficient passive learning algorithm that has near-optimal sample complexities with respect to $\\epsilon$ and $d$."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Continuous DR-submodular  Maximization", "Title": "Structure and Algorithms", "Abstract": "DR-submodular continuous functions are important objectives with wide real-world applications spanning MAP inference in  determinantal point processes (DPPs), and mean-field inference for probabilistic submodular models, amongst others. DR-submodularity captures a subclass of non-convex functions that enables both exact minimization and approximate maximization in polynomial time.  In this work we study the  problem of maximizing  non-monotone DR-submodular continuous functions under general down-closed convex constraints. We start by investigating geometric properties that underlie such objectives, e.g., a strong relation between  (approximately) stationary points and global optimum is proved. These properties are then used to devise two optimization algorithms with provable guarantees. Concretely, we first devise a \"two-phase'' algorithm with 1/4 approximation guarantee. This algorithm allows the use of existing methods for finding (approximately) stationary points as a subroutine, thus, harnessing recent progress in non-convex optimization. Then we present a non-monotone Frank-Wolfe variant with 1/e approximation guarantee and sublinear convergence rate. Finally, we extend our approach to a broader class of generalized DR-submodular continuous functions, which captures a wider spectrum of applications. Our theoretical findings are validated on synthetic and real-world problem instances."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dykstra's Algorithm, ADMM, and Coordinate Descent", "Title": "Connections, Insights, and Extensions", "Abstract": "We study connections between Dykstra's algorithm for projecting onto an intersection of convex sets, the augmented Lagrangian method of multipliers or ADMM, and block coordinate descent. We prove that coordinate descent for a regularized regression problem, in which the penalty is a separable sum of support functions, is exactly equivalent to Dykstra's algorithm applied to the dual problem. ADMM on the dual problem is also seen to be equivalent, in the special case of two sets, with one being a linear subspace. These connections, aside from being interesting in their own right, suggest new ways of analyzing and extending coordinate descent. For example, from existing convergence theory on Dykstra's algorithm over polyhedra, we discern that coordinate descent for the lasso problem converges at an (asymptotically) linear rate. We also develop two parallel versions of coordinate descent, based on the Dykstra and ADMM connections."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SafetyNets", "Title": "Verifiable Execution of Deep Neural Networks on an Untrusted Cloud", "Abstract": "Inference using deep neural networks is often outsourced to the cloud since it is a computationally demanding task.  However, this raises a fundamental issue of trust. How can a client be sure that the cloud has performed inference correctly? A lazy cloud provider might use a simpler but less accurate model to reduce its own computational load, or worse, maliciously modify the inference results sent to the client. We propose SafetyNets, a framework that enables an untrusted server (the cloud) to provide a client with a short mathematical proof of the correctness of inference tasks that they perform on behalf of the client. Specifically, SafetyNets develops and implements a specialized interactive proof (IP) protocol for verifiable execution of a class of deep neural networks, i.e., those that can be represented as arithmetic circuits. Our empirical results on three- and four-layer deep neural networks demonstrate the run-time costs of SafetyNets for both the client and server are low. SafetyNets detects any incorrect computations of the neural network by the untrusted server with high probability, while achieving state-of-the-art accuracy on the MNIST digit recognition (99.4%) and TIMIT speech recognition tasks (75.22%)."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predictive-State Decoders", "Title": "Encoding the Future into Recurrent Networks", "Abstract": "Recurrent neural networks (RNNs) are a vital modeling technique that rely on internal states learned indirectly by optimization of a supervised, unsupervised, or reinforcement training loss. RNNs are used to model dynamic processes that are characterized by underlying latent states whose form is often unknown, precluding its analytic representation inside an RNN. In the Predictive-State Representation (PSR) literature, latent state processes are modeled by an internal state representation that directly models the distribution of future observations, and most recent work in this area has relied on explicitly representing and targeting sufficient statistics of this probability distribution. We seek to combine the advantages of RNNs and PSRs by augmenting existing state-of-the-art recurrent neural networks with Predictive-State Decoders (PSDs), which add supervision to the network's internal state representation to target predicting future observations. PSDs are simple to implement and easily incorporated into existing training pipelines via additional loss regularization. We demonstrate the effectiveness of PSDs with experimental results in three different domains:  probabilistic filtering, Imitation Learning, and Reinforcement Learning. In each, our method improves statistical performance of state-of-the-art recurrent baselines and does so with fewer iterations and less data."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Fine-Grained Complexity of Empirical Risk Minimization", "Title": "Kernel Methods and Neural Networks", "Abstract": "Empirical risk minimization (ERM) is ubiquitous in machine learning and underlies most supervised learning methods. While there is a large body of work on algorithms for various ERM problems, the exact computational complexity of ERM is still not understood. We address this issue for multiple popular ERM problems including kernel SVMs, kernel ridge regression, and training the final layer of a neural network. In particular, we give conditional hardness results for these problems based on complexity-theoretic assumptions such as the Strong Exponential Time Hypothesis. Under these assumptions, we show that there are no algorithms that solve the aforementioned ERM problems to high accuracy in sub-quadratic time. We also give similar hardness results for computing the gradient of the empirical loss, which is the main computational burden in many non-convex learning tasks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LightGBM", "Title": "A Highly Efficient Gradient Boosting Decision Tree", "Abstract": "Gradient Boosting Decision Tree (GBDT) is a popular machine learning algorithm, and has quite a few effective implementations such as XGBoost and pGBRT. Although many engineering optimizations have been adopted in these implementations, the efficiency and scalability are still unsatisfactory when the feature dimension is high and data size is large. A major reason is that for each feature, they need to scan all the data instances to estimate the information gain of all possible split points, which is very time consuming. To tackle this problem, we propose two novel techniques: \\emph{Gradient-based One-Side Sampling} (GOSS) and \\emph{Exclusive Feature Bundling} (EFB). With GOSS, we exclude a significant proportion of data instances with small gradients, and only use the rest to estimate the information gain. We prove that, since the data instances with larger gradients play a more important role in the computation of information gain, GOSS can obtain quite accurate estimation of the information gain with a much smaller data size. With EFB, we bundle mutually exclusive features (i.e., they rarely take nonzero values simultaneously), to reduce the number of features. We prove that finding the optimal bundling of exclusive features is NP-hard, but a greedy algorithm can achieve quite good approximation ratio (and thus can effectively reduce the number of features without hurting the accuracy of split point determination by much). We call our new GBDT implementation with GOSS and EFB \\emph{LightGBM}. Our experiments on multiple public datasets show that, LightGBM speeds up the training process of conventional GBDT by up to over 20 times while achieving almost the same accuracy."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Neural Hawkes Process", "Title": "A Neurally Self-Modulating Multivariate Point Process", "Abstract": "Many events occur in the world. Some event types are stochastically excited or inhibited—in the sense of having their probabilities elevated or decreased—by patterns in the sequence of previous events. Discovering such patterns can help us predict which type of event will happen next and when. We model streams of discrete events in continuous time, by constructing a neurally self-modulating multivariate point process in which the intensities of multiple event types evolve according to a novel continuous-time LSTM. This generative model allows past events to influence the future in complex and realistic ways, by conditioning future event intensities on the hidden state of a recurrent neural network that has consumed the stream of past events. Our model has desirable qualitative properties. It achieves competitive likelihood and predictive accuracy on real and synthetic datasets, including under missing-data conditions."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mean teachers are better role models", "Title": "Weight-averaged consistency targets improve semi-supervised deep learning results", "Abstract": "The recently proposed Temporal Ensembling has achieved state-of-the-art results in several semi-supervised learning benchmarks. It maintains an exponential moving average of label predictions on each training example, and penalizes predictions that are inconsistent with this target. However, because the targets change only once per epoch, Temporal Ensembling becomes unwieldy when learning large datasets. To overcome this problem, we propose Mean Teacher, a method that averages model weights instead of label predictions. As an additional benefit, Mean Teacher improves test accuracy and enables training with fewer labels than Temporal Ensembling. Without changing the network architecture, Mean Teacher achieves an error rate of 4.35% on SVHN with 250 labels, outperforming Temporal Ensembling trained with 1000 labels. We also show that a good network architecture is crucial to performance. Combining Mean Teacher and Residual Networks, we improve the state of the art on CIFAR-10 with 4000 labels from 10.55% to 6.28%, and on ImageNet 2012 with 10% of the labels from 35.24% to 9.11%."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "QSGD", "Title": "Communication-Efficient SGD via Gradient Quantization and Encoding", "Abstract": "Parallel implementations of stochastic gradient descent (SGD) have received significant research attention, thanks to its excellent scalability properties. A fundamental barrier when parallelizing SGD is the high bandwidth cost of communicating gradient updates between nodes; consequently, several lossy compresion heuristics have been proposed, by which nodes only communicate quantized gradients. Although effective in practice, these heuristics do not always guarantee convergence, and it is not clear whether they can be improved.  In this paper, we propose Quantized SGD (QSGD), a family of compression schemes for gradient updates which provides convergence guarantees. QSGD allows the user to smoothly trade off \\emph{communication bandwidth} and \\emph{convergence time}: nodes can adjust the number of bits sent per iteration, at the cost of possibly higher variance. We show that this trade-off is inherent, in the sense that improving it past some threshold would violate  information-theoretic lower bounds. QSGD guarantees convergence for convex and non-convex objectives,  under asynchrony, and can be extended to stochastic variance-reduced techniques.   When applied to  training deep neural networks for image classification and  automated speech recognition, QSGD leads to significant reductions in  end-to-end training time. For example, on 16GPUs, we can train the ResNet152  network to full accuracy on ImageNet 1.8x faster than the full-precision  variant."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MaskRNN", "Title": "Instance Level Video Object Segmentation", "Abstract": "Instance level video object segmentation is an important technique for video editing and compression. To capture the temporal coherence, in this paper, we develop MaskRNN, a recurrent neural net approach which fuses in each frame the output of two deep nets for each object instance - a binary segmentation net providing a mask and a localization net providing a bounding box. Due to the recurrent component and the localization component, our method is able to take advantage of long-term temporal structures of the video data as well as rejecting outliers. We validate the proposed algorithm on three challenging benchmark datasets, the DAVIS-2016 dataset, the DAVIS-2017 dataset, and the Segtrack v2 dataset, achieving state-of-the-art performance on all of them."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Emergence of Language with Multi-agent Games", "Title": "Learning to Communicate with Sequences of Symbols", "Abstract": "Learning to communicate through interaction, rather than relying on explicit supervision, is often considered a prerequisite for developing a general AI. We study a setting where two agents engage in playing a referential game and, from scratch, develop a communication protocol necessary to succeed in this game. Unlike previous work, we require that messages they exchange, both at train and test time, are in the form of a language (i.e. sequences of discrete symbols). We compare a reinforcement learning approach and one using a differentiable relaxation (straight-through Gumbel-softmax estimator) and observe that the latter is much faster to converge and it results in more effective protocols. Interestingly, we also observe that the protocol we induce by optimizing the communication success  exhibits a degree of compositionality and variability (i.e. the same information can be phrased in different ways), both properties characteristic of natural languages.    As the ultimate goal is to ensure that communication is accomplished in natural language, we also perform experiments where we inject prior information about natural language into our model  and study properties of the resulting protocol."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Wider and Deeper, Cheaper and Faster", "Title": "Tensorized LSTMs for Sequence Learning", "Abstract": "Long Short-Term Memory (LSTM) is a popular approach to boosting the ability of Recurrent Neural Networks to store longer term temporal information. The capacity of an LSTM network can be increased by widening and adding layers. However, usually the former introduces additional parameters, while the latter increases the runtime. As an alternative we propose the Tensorized LSTM in which the hidden states are represented by tensors and updated via a cross-layer convolution. By increasing the tensor size, the network can be widened efficiently without additional parameters since the parameters are shared across different locations in the tensor; by delaying the output, the network can be deepened implicitly with little additional runtime since deep computations for each timestep are merged into temporal computations of the sequence. Experiments conducted on five challenging sequence learning tasks show the potential of the proposed model."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Solid Harmonic Wavelet Scattering", "Title": "Predicting Quantum Molecular Energy from Invariant Descriptors of 3D  Electronic Densities", "Abstract": "We introduce a solid harmonic wavelet scattering representation, invariant  to rigid motion and stable to deformations, for regression and classification  of 2D and 3D signals. Solid harmonic wavelets are computed by multiplying solid  harmonic functions with Gaussian windows dilated at different scales. Invariant  scattering coefficients are obtained by cascading such wavelet transforms with  the complex modulus nonlinearity. We study an application of solid harmonic  scattering invariants to the estimation of quantum molecular energies, which  are also invariant to rigid motion and stable with respect to deformations. A multilinear regression  over scattering invariants provides close to state of the art results over  small and large databases of organic molecules."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalizing GANs", "Title": "A Turing Perspective", "Abstract": "Recently, a new class of machine learning algorithms has emerged, where models and discriminators are generated in a competitive setting. The most prominent example is Generative Adversarial Networks (GANs). In this paper we examine how these algorithms relate to the Turing test, and derive what - from a Turing perspective - can be considered their defining features. Based on these features, we outline directions for generalizing GANs - resulting in the family of algorithms referred to as Turing Learning. One such direction is to allow the discriminators to interact with the processes from which the data samples are obtained, making them \"interrogators\", as in the Turing test. We validate this idea using two case studies. In the first case study, a computer infers the behavior of an agent while controlling its environment. In the second case study, a robot infers its own sensor configuration while controlling its movements. The results confirm that by allowing discriminators to interrogate, the accuracy of models is improved."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VAIN", "Title": "Attentional Multi-agent Predictive Modeling", "Abstract": "Multi-agent predictive modeling is an essential step for understanding physical, social and team-play systems. Recently, Interaction Networks (INs) were proposed for the task of modeling multi-agent physical systems. One of the drawbacks of INs is scaling with the number of interactions in the system (typically quadratic or higher order in the number of agents). In this paper we introduce VAIN, a novel attentional architecture for multi-agent predictive modeling that scales linearly with the number of agents. We show that VAIN is effective for multi-agent predictive modeling. Our method is evaluated on tasks from challenging multi-agent prediction domains: chess and soccer, and outperforms competing multi-agent approaches."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Clone MCMC", "Title": "Parallel High-Dimensional Gaussian Gibbs Sampling", "Abstract": "We propose a generalized Gibbs sampler algorithm for obtaining samples approximately distributed from a high-dimensional Gaussian distribution. Similarly to Hogwild methods, our approach does not target the original Gaussian distribution of interest, but an approximation to it. Contrary to Hogwild methods, a single parameter allows us to trade bias for variance. We show empirically that our method is very flexible and performs well compared to Hogwild-type algorithms."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from uncertain curves", "Title": "The 2-Wasserstein metric for Gaussian processes", "Abstract": "We introduce a novel framework for statistical analysis of populations of non-degenerate Gaussian processes (GPs), which are natural representations of uncertain curves. This allows inherent variation or uncertainty in function-valued data to be properly incorporated in the population analysis. Using the 2-Wasserstein metric we geometrize the space of GPs with L2 mean and covariance functions over compact index spaces. We prove uniqueness of the barycenter of a population of GPs, as well as convergence of the metric and the barycenter of their finite-dimensional counterparts. This justifies practical computations. Finally, we demonstrate our framework through experimental validation on GP datasets representing brain connectivity and climate development. A Matlab library for relevant computations will be published at https://sites.google.com/view/antonmallasto/software."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Thy Friend is My Friend", "Title": "Iterative Collaborative Filtering for Sparse Matrix Estimation", "Abstract": "The sparse matrix estimation problem consists of estimating the distribution of an $n\\times n$  matrix $Y$, from a sparsely observed single instance of this matrix where the entries of $Y$ are independent random variables. This captures a wide array of problems; special instances include matrix completion in the context of recommendation systems, graphon estimation, and community detection in (mixed membership) stochastic block models. Inspired by classical collaborative filtering for recommendation systems, we propose a novel iterative, collaborative filtering-style algorithm for matrix estimation in this generic setting. We show that the mean squared error (MSE) of our estimator converges to $0$ at the rate of $O(d^2 (pn)^{-2/5})$ as long as $\\omega(d^5 n)$ random entries from a total of $n^2$ entries of $Y$ are observed (uniformly sampled), $\\E[Y]$ has rank $d$, and the entries of $Y$ have bounded support. The maximum squared error across all entries converges to $0$ with high probability as long as we observe a little more, $\\Omega(d^5 n \\ln^5(n))$ entries. Our results are the best known sample complexity results in this generality."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mean Field Residual Networks", "Title": "On the Edge of Chaos", "Abstract": "We study randomly initialized residual networks using mean field theory and the theory of difference equations. Classical feedforward neural networks, such as those with tanh activations, exhibit exponential behavior on the average when propagating inputs forward or gradients backward. The exponential forward dynamics causes rapid collapsing of the input space geometry, while the exponential backward dynamics causes drastic vanishing or exploding gradients. We show, in contrast, that by adding skip connections, the network will, depending on the nonlinearity, adopt subexponential forward and backward dynamics, and in many cases in fact polynomial. The exponents of these polynomials are obtained through analytic methods and proved and verified empirically to be correct. In terms of the \"edge of chaos\" hypothesis, these subexponential and polynomial laws allow residual networks to \"hover over the boundary between stability and chaos,\" thus preserving the geometry of the input space and the gradient information flow. In our experiments, for each activation function we study here, we initialize residual networks with different hyperparameters and train them on MNIST. Remarkably, our initialization time theory can accurately predict test time performance of these networks, by tracking either the expected amount of gradient explosion or the expected squared distance between the images of two input vectors. Importantly, we show, theoretically as well as empirically, that common initializations such as the Xavier or the He schemes are not optimal for residual networks, because the optimal initialization variances depend on the depth. Finally, we have made mathematical contributions by deriving several new identities for the kernels of powers of ReLU functions by relating them to the zeroth Bessel function of the second kind."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Working hard to know your neighbor's margins", "Title": "Local descriptor learning loss", "Abstract": "We introduce a loss for metric learning, which is inspired by the Lowe's matching criterion for SIFT. We show that the proposed loss, that maximizes the distance between the closest positive and closest negative example in the batch, is better than complex regularization methods; it works well for both shallow and deep convolution network architectures. Applying the novel loss to the L2Net CNN architecture results in a compact descriptor named HardNet. It has the same dimensionality as SIFT (128) and shows state-of-art performance in wide baseline stereo, patch verification and instance retrieval benchmarks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hiding Images in Plain Sight", "Title": "Deep Steganography", "Abstract": "Steganography is the practice of concealing a secret message within another, ordinary, message.  Commonly, steganography is used to unobtrusively hide a small message within the noisy regions of a larger image.  In this study, we attempt to place a full size color image within another image of the same size.  Deep neural networks are simultaneously trained to create the hiding and revealing processes and are designed to specifically work as a pair.  The system is trained on images drawn randomly from the ImageNet database, and works well on natural images from a wide variety of sources.  Beyond demonstrating the successful application of deep learning to hiding images, we carefully examine how the result is achieved and explore extensions.  Unlike many popular steganographic methods that encode the secret message within the least significant bits of the carrier image, our approach compresses and distributes the secret image's representation across all of the available bits."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learned D-AMP", "Title": "Principled Neural Network based Compressive Image Recovery", "Abstract": "Compressive image recovery is a challenging problem that requires fast and accurate algorithms. Recently, neural networks have been applied to this problem with promising results. By exploiting massively parallel GPU processing architectures and oodles of training data, they can run orders of magnitude faster than existing techniques. However, these methods are largely unprincipled black boxes that are difficult to train and often-times specific to a single measurement matrix.  It was recently demonstrated that iterative sparse-signal-recovery algorithms can be ``unrolled’' to form interpretable deep networks. Taking inspiration from this work, we develop a novel neural network architecture that mimics the behavior of the denoising-based approximate message passing (D-AMP) algorithm. We call this new network {\\em Learned} D-AMP (LDAMP).  The LDAMP network is easy to train, can be applied to a variety of different measurement matrices, and comes with a state-evolution heuristic that accurately predicts its performance. Most importantly, it outperforms the state-of-the-art BM3D-AMP and NLR-CS algorithms in terms of both accuracy and run time. At high resolutions, and when used with sensing matrices that have fast implementations, LDAMP runs over $50\\times$ faster than BM3D-AMP and hundreds of times faster than NLR-CS."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accuracy First", "Title": "Selecting a Differential Privacy Level for Accuracy Constrained ERM", "Abstract": "Traditional approaches to differential privacy assume a fixed privacy requirement ε for a computation, and attempt to maximize the accuracy of the computation subject to the privacy constraint. As differential privacy is increasingly deployed in practical settings, it may often be that there is instead a fixed accuracy requirement for a given computation and the data analyst would like to maximize the privacy of the computation subject to the accuracy constraint. This raises the question of how to find and run a maximally private empirical risk minimizer subject to a given accuracy requirement. We propose a general “noise reduction” framework that can apply to a variety of private empirical risk minimization (ERM) algorithms, using them to “search” the space of privacy levels to find the empirically strongest one that meets the accuracy constraint, and incurring only logarithmic overhead in the number of privacy levels searched. The privacy analysis of our algorithm leads naturally to a version of differential privacy where the privacy parameters are dependent on the data, which we term ex-post privacy, and which is related to the recently introduced notion of privacy odometers. We also give an ex-post privacy analysis of the classical AboveThreshold privacy tool, modifying it to allow for queries chosen depending on the database. Finally, we apply our approach to two common objective functions, regularized linear and logistic regression, and empirically compare our noise reduction methods to (i) inverting the theoretical utility guarantees of standard private ERM algorithms and (ii) a stronger empirical baseline based on binary search."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TernGrad", "Title": "Ternary Gradients to Reduce Communication in Distributed Deep Learning", "Abstract": "High network communication cost for synchronizing gradients and parameters is the well-known bottleneck of distributed training. In this work, we propose TernGrad that uses ternary gradients to accelerate distributed deep learning in data parallelism. Our approach requires only three numerical levels {-1,0,1}, which can aggressively reduce the communication time. We mathematically prove the convergence of TernGrad under the assumption of a bound on gradients. Guided by the bound, we propose layer-wise ternarizing and gradient clipping to improve its convergence. Our experiments show that applying TernGrad on AlexNet does not incur any accuracy loss and can even improve accuracy. The accuracy loss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, a performance model is proposed to study the scalability of TernGrad. Experiments show significant speed gains for various deep neural networks. Our source code is available."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fully Decentralized Policies for Multi-Agent Systems", "Title": "An Information Theoretic Approach", "Abstract": "Learning cooperative policies for multi-agent systems is often challenged by partial observability and a lack of coordination. In some settings, the structure of a problem allows a distributed solution with limited communication. Here, we consider a scenario where no communication is available, and instead we learn local policies for all agents that collectively mimic the solution to a centralized multi-agent static optimization problem. Our main contribution is an information theoretic framework based on rate distortion theory which facilitates analysis of how well the resulting fully decentralized policies are able to reconstruct the optimal solution. Moreover, this framework provides a natural extension that addresses which nodes an agent should communicate with to improve the  performance of its individual policy."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Visual Interaction Networks", "Title": "Learning a Physics Simulator from Video", "Abstract": "From just a glance, humans can make rich predictions about the future of a wide range of physical systems.  On the other hand, modern approaches from engineering, robotics, and graphics are often restricted to narrow domains or require information about the underlying state. We introduce the Visual Interaction Network, a general-purpose model for learning the dynamics of a physical system from raw visual observations. Our model consists of a perceptual front-end based on convolutional neural networks and a dynamics predictor based on interaction networks. Through joint training, the perceptual front-end learns to parse a dynamic visual scene into a set of factored latent object representations. The dynamics predictor learns to roll these states forward in time by computing their interactions, producing a predicted physical trajectory of arbitrary length. We found that from just six input video frames the Visual Interaction Network can generate accurate future trajectories of hundreds of time steps on a wide range of physical systems. Our model can also be applied to scenes with invisible objects, inferring their future states from their effects on the visible objects, and can implicitly infer the unknown mass of objects. This work opens new opportunities for model-based decision-making and planning from raw sensory observations in complex physical environments."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Associative Embedding", "Title": "End-to-End Learning for Joint Detection and Grouping", "Abstract": "We introduce associative embedding, a novel method for supervising convolutional neural networks for the task of detection and grouping. A number of computer vision problems can be framed in this manner including multi-person pose estimation, instance segmentation, and multi-object tracking. Usually the grouping of detections is achieved with multi-stage pipelines, instead we propose an approach that teaches a network to simultaneously output detections and group assignments. This technique can be easily integrated into any state-of-the-art network architecture that  produces pixel-wise predictions. We show how to apply this method to  multi-person pose estimation and report state-of-the-art performance  on the MPII and MS-COCO datasets."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Z-Forcing", "Title": "Training Stochastic Recurrent Networks", "Abstract": "Many efforts have been devoted to training generative latent variable models with autoregressive decoders, such as recurrent neural networks (RNN). Stochastic recurrent models have been successful in capturing the variability observed in natural sequential data such as speech. We unify successful ideas from recently proposed architectures into a stochastic recurrent model: each step in the sequence is associated with a latent variable that is used to condition the recurrent dynamics for future steps. Training is performed with amortised variational inference where the approximate posterior is augmented with a RNN that runs backward through the sequence. In addition to maximizing the variational lower bound, we ease training of the latent variables by adding an auxiliary cost which forces them to reconstruct the state of the backward recurrent network. This provides the latent variables with a task-independent objective that enhances the performance of the overall model. We found this strategy to perform better than alternative approaches such as KL annealing. Although being conceptually simple, our model achieves state-of-the-art results on standard speech benchmarks such as TIMIT and Blizzard and competitive performance on sequential MNIST. Finally, we apply our model to language modeling on the IMDB dataset where the auxiliary cost helps in learning interpretable latent variables."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Nearest-Neighbor Sample Compression", "Title": "Efficiency, Consistency, Infinite Dimensions", "Abstract": "We examine the Bayes-consistency of a recently proposed 1-nearest-neighbor-based multiclass learning algorithm. This algorithm is derived from sample compression bounds and enjoys the statistical advantages of tight, fully empirical generalization bounds, as well as the algorithmic advantages of a faster runtime and memory savings. We prove that this algorithm is strongly Bayes-consistent in metric spaces with finite doubling dimension --- the first consistency result for an efficient nearest-neighbor sample compression scheme. Rather surprisingly, we discover that this algorithm continues to be Bayes-consistent even in a certain infinite-dimensional setting, in which the basic measure-theoretic conditions on which classic consistency proofs hinge are violated. This is all the more surprising, since it is known that k-NN is not Bayes-consistent in this setting. We pose several challenging open problems for future research."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Estimating Accuracy from Unlabeled Data", "Title": "A Probabilistic Logic Approach", "Abstract": "We propose an efficient method to estimate the accuracy of classifiers using only unlabeled data. We consider a setting with multiple classification problems where the target classes may be tied together through logical constraints. For example, a set of classes may be mutually exclusive, meaning that a data instance can belong to at most one of them. The proposed method is based on the intuition that: (i) when classifiers agree, they are more likely to be correct, and (ii) when the classifiers make a prediction that violates the constraints, at least one classifier must be making an error. Experiments on four real-world data sets produce accuracy estimates within a few percent of the true accuracy, using solely unlabeled data. Our models also outperform existing state-of-the-art solutions in both estimating accuracies, and combining multiple classifier outputs. The results emphasize the utility of logical constraints in estimating accuracy, thus validating our intuition."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisit Fuzzy Neural Network", "Title": "Demystifying Batch Normalization and ReLU with Generalized Hamming Network", "Abstract": "We revisit fuzzy neural network with a cornerstone notion of generalized hamming distance, which provides a novel and theoretically justified framework to re-interpret many useful neural network techniques in terms of fuzzy logic. In particular, we conjecture and empirically illustrate that, the celebrated batch normalization (BN) technique actually adapts the “normalized” bias such that it approximates the rightful bias induced by the generalized hamming distance. Once the due bias is enforced analytically, neither the optimization of bias terms nor the sophisticated batch normalization is needed. Also in the light of generalized hamming distance, the popular rectified linear units (ReLU) can be treated as setting a minimal hamming distance threshold between network inputs and weights. This thresholding scheme, on the one hand, can be improved by introducing double-thresholding on both positive and negative extremes of neuron outputs. On the other hand, ReLUs turn out to be non-essential and can be removed from networks trained for simple tasks like MNIST classification. The proposed generalized hamming network (GHN) as such not only lends itself to rigorous analysis and interpretation within the fuzzy logic theory but also demonstrates fast learning speed, well-controlled behaviour and state-of-the-art performances on a variety of learning tasks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GP CaKe", "Title": "Effective brain connectivity with causal kernels", "Abstract": "A fundamental goal in network neuroscience is to understand how activity in one brain region drives activity elsewhere, a process referred to as effective connectivity. Here we propose to model this causal interaction using integro-differential equations and causal kernels that allow for a rich analysis of effective connectivity. The approach combines the tractability and flexibility of autoregressive modeling with the biophysical interpretability of dynamic causal modeling. The causal kernels are learned nonparametrically using Gaussian process regression, yielding an efficient framework for causal inference. We construct a novel class of causal covariance functions that enforce the desired properties of the causal kernels, an approach which we call GP CaKe. By construction, the model and its hyperparameters have biophysical meaning and are therefore easily interpretable. We demonstrate the efficacy of GP CaKe on a number of simulations and give an example of a realistic application on magnetoencephalography (MEG) data."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Flexpoint", "Title": "An Adaptive Numerical Format for Efficient Training of Deep Neural Networks", "Abstract": "Deep neural networks are commonly developed and trained in 32-bit floating point format. Significant gains in performance and energy efficiency could be realized by training and inference in numerical formats optimized for deep learning. Despite advances in limited precision inference in recent years, training of neural networks in low bit-width remains a challenging problem. Here we present the Flexpoint data format, aiming at a complete replacement of 32-bit floating point format training and inference, designed to support modern deep network topologies without modifications. Flexpoint tensors have a shared exponent that is dynamically adjusted to minimize overflows and maximize available dynamic range. We validate Flexpoint by training AlexNet, a deep residual network and a generative adversarial network, using a simulator implemented with the \\emph{neon} deep learning framework. We demonstrate that 16-bit Flexpoint closely matches 32-bit floating point in training all three models, without any need for tuning of model hyperparameters. Our results suggest Flexpoint as a promising numerical format for future hardware for training and inference."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Early stopping for kernel boosting algorithms", "Title": "A general analysis with localized complexities", "Abstract": "Early stopping of iterative algorithms is a widely-used form of regularization in statistical learning, commonly used in conjunction with boosting and related gradient-type algorithms. Although consistency results have been established in some settings, such estimators are less well-understood than their analogues based on penalized regularization.  In this paper, for a relatively broad   class of loss functions and boosting algorithms (including   $L^2$-boost, LogitBoost and AdaBoost, among others), we connect the performance of a stopped iterate to the localized  Rademacher/Gaussian complexity of the associated function class. This connection allows us to show that local fixed point analysis, now standard in the analysis of penalized estimators, can be used to derive optimal stopping rules.  We derive such stopping rules in detail for various kernel classes, and illustrate the correspondence of our theory with practice for Sobolev kernel classes."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interpolated Policy Gradient", "Title": "Merging On-Policy and Off-Policy Gradient Estimation for Deep Reinforcement Learning", "Abstract": "Off-policy model-free deep reinforcement learning methods using previously collected data can improve sample efficiency over on-policy policy gradient techniques. On the other hand, on-policy algorithms are often more stable and easier to use. This paper examines, both theoretically and empirically, approaches to merging on- and off-policy updates for deep reinforcement learning.  Theoretical results show that off-policy updates with a value function estimator can be interpolated with on-policy policy gradient updates whilst still satisfying performance bounds. Our analysis uses control variate methods to produce a family of policy gradient algorithms, with several recently proposed algorithms being special cases of this family. We then provide an empirical comparison of these techniques with the remaining algorithmic details fixed, and show how different mixing of off-policy gradient estimates with on-policy samples contribute to improvements in empirical performance. The final algorithm provides a generalization and unification of existing deep policy gradient techniques, has theoretical guarantees on the bias introduced by off-policy updates, and improves on the state-of-the-art model-free deep RL methods on a number of OpenAI Gym continuous control benchmarks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Train longer, generalize better", "Title": "closing the generalization gap in large batch training of neural networks", "Abstract": "Background: Deep learning models are typically trained using stochastic gradient descent or one of its variants. These methods update the weights using their gradient, estimated from a small fraction of the training data. It has been observed that when using large batch sizes there is a persistent degradation in generalization performance -  known as the \"generalization gap\" phenomenon. Identifying the origin of this gap and closing it had remained an open problem.  Contributions: We examine the initial high learning rate training phase. We find that the weight distance from its initialization grows logarithmically with the number of weight updates. We therefore propose a \"random walk on a random landscape\" statistical model which is known to exhibit similar \"ultra-slow\" diffusion behavior. Following this hypothesis we conducted experiments to show empirically that the \"generalization gap\" stems from the relatively small number of updates rather than the batch size, and can be completely eliminated by adapting the training regime used. We further investigate different techniques to train models in the large-batch regime and present a novel algorithm named \"Ghost Batch Normalization\" which enables significant decrease in the generalization gap without increasing the number of updates. To validate our findings we conduct several additional experiments on MNIST, CIFAR-10, CIFAR-100 and ImageNet. Finally, we reassess common practices and beliefs concerning training of deep models and suggest they may not be optimal to achieve good generalization."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Learning for Precipitation Nowcasting", "Title": "A Benchmark and A New Model", "Abstract": "With the goal of making high-resolution forecasts of regional rainfall, precipitation nowcasting has become an important and fundamental technology underlying various public services ranging from rainstorm warnings to flight safety. Recently, the Convolutional LSTM (ConvLSTM) model has been shown to outperform traditional optical flow based methods for precipitation nowcasting, suggesting that deep learning models have a huge potential for solving the problem. However, the convolutional recurrence structure in ConvLSTM-based models is location-invariant while natural motion and transformation (e.g., rotation) are location-variant in general. Furthermore, since deep-learning-based precipitation nowcasting is a newly emerging area, clear evaluation protocols have not yet been established. To address these problems, we propose both a new model and a benchmark for precipitation nowcasting. Specifically, we go beyond ConvLSTM and propose the Trajectory GRU (TrajGRU) model that can actively learn the location-variant structure for recurrent connections. Besides, we provide a benchmark that includes a real-world large-scale dataset from the Hong Kong Observatory, a new training loss, and a comprehensive evaluation protocol to facilitate future research and gauge the state of the art."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Matching neural paths", "Title": "transfer from recognition to correspondence search", "Abstract": "Many machine learning tasks require finding per-part correspondences between objects. In this work we focus on low-level correspondences --- a highly ambiguous matching problem. We propose to use a hierarchical semantic representation of the objects, coming from a convolutional neural network, to solve this ambiguity. Training it for low-level correspondence prediction directly might not be an option in some domains where the ground-truth correspondences are hard to obtain. We show how transfer from recognition can be used to avoid such training. Our idea is to mark parts as \"matching\" if their features are close to each other at all the levels of convolutional feature hierarchy (neural paths). Although the overall number of such paths is exponential in the number of layers, we propose a polynomial algorithm for aggregating all of them in a single backward pass. The empirical validation is done on the task of stereo correspondence and demonstrates that we achieve competitive results among the methods which do not use labeled target domain data."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AIDE", "Title": "An algorithm for measuring the accuracy of probabilistic inference algorithms", "Abstract": "Approximate probabilistic inference algorithms are central to many fields. Examples include sequential Monte Carlo inference in robotics, variational inference in machine learning, and Markov chain Monte Carlo inference in statistics. A key problem faced by practitioners is measuring the accuracy of an approximate inference algorithm on a specific data set. This paper introduces the auxiliary inference divergence estimator (AIDE), an algorithm for measuring the accuracy of approximate inference algorithms. AIDE is based on the observation that inference algorithms can be treated as probabilistic models and the random variables used within the inference algorithm can be viewed as auxiliary variables. This view leads to a new estimator for the symmetric KL divergence between the approximating distributions of two inference algorithms. The paper illustrates application of AIDE to algorithms for inference in regression, hidden Markov, and Dirichlet process mixture models. The experiments show that AIDE captures the qualitative behavior of a broad class of inference algorithms and can detect failure modes of inference algorithms that are missed by standard heuristics."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MarrNet", "Title": "3D Shape Reconstruction via 2.5D Sketches", "Abstract": "3D object reconstruction from a single image is a highly under-determined problem, requiring strong prior knowledge of plausible 3D shapes. This introduces challenge for learning-based approaches, as 3D object annotations in real images are scarce. Previous work chose to train on synthetic data with ground truth 3D information, but suffered from the domain adaptation issue when tested on real data.  In this work, we propose an end-to-end trainable framework, sequentially estimating 2.5D sketches and 3D object shapes. Our disentangled, two-step formulation has three advantages. First, compared to full 3D shape, 2.5D sketches are much easier to be recovered from a 2D image, and to transfer from synthetic to real data. Second, for 3D reconstruction from the 2.5D sketches, we can easily transfer the learned model on synthetic data to real images, as rendered 2.5D sketches are invariant to object appearance variations in real images, including lighting, texture, etc. This further relieves the domain adaptation problem. Third, we derive differentiable projective functions from 3D shape to 2.5D sketches, making the framework end-to-end trainable on real images, requiring no real-image annotations. Our framework achieves state-of-the-art performance on 3D shape reconstruction."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ALICE", "Title": "Towards Understanding Adversarial Learning for Joint Distribution Matching", "Abstract": "We investigate the non-identifiability issues associated with bidirectional adversarial training for joint distribution matching. Within a framework of conditional entropy, we propose both adversarial and non-adversarial approaches to learn desirable matched joint distributions for unsupervised and supervised tasks. We unify a broad family of adversarial models as joint distribution matching problems. Our approach stabilizes learning of unsupervised bidirectional adversarial learning methods. Further, we introduce an extension for semi-supervised learning tasks. Theoretical results are validated in synthetic data and real-world applications."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Plan, Attend, Generate", "Title": "Planning for Sequence-to-Sequence Models", "Abstract": "We investigate the integration of a planning mechanism into sequence-to-sequence models using attention. We develop a model which can plan ahead in the future when it computes its alignments between input and output sequences, constructing a matrix of proposed future alignments and a commitment vector that governs whether to follow or recompute the plan. This mechanism is inspired by the recently proposed strategic attentive reader and writer (STRAW) model for Reinforcement Learning. Our proposed model is end-to-end trainable using primarily differentiable operations. We show that it outperforms a strong baseline on character-level translation tasks from WMT'15, the algorithmic task of finding Eulerian circuits of graphs, and question generation from the text. Our analysis demonstrates that the model computes qualitatively intuitive alignments, converges faster than the baselines, and achieves superior performance with fewer parameters."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tomography of the London Underground", "Title": "a Scalable Model for Origin-Destination Data", "Abstract": "The paper addresses the classical network tomography problem of inferring local traffic given origin-destination observations. Focussing on large complex public transportation systems, we build a scalable model that exploits input-output information to estimate the unobserved link/station loads and the users path preferences. Based on the reconstruction of the users' travel time distribution, the model is flexible enough to capture possible different path-choice strategies and correlations between users travelling on similar paths at similar times. The corresponding likelihood function is intractable for medium or large-scale networks and we propose two distinct strategies, namely the exact maximum-likelihood inference of an approximate but tractable model and the variational inference of the original intractable model. As an application of our approach, we consider the emblematic case of the London Underground network, where a tap-in/tap-out system tracks the start/exit time and location of all journeys in a day. A set of synthetic simulations and real data provided by Transport For London are used to validate and test the model on the predictions of observable and unobservable quantities."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bregman Divergence for Stochastic Variance Reduction", "Title": "Saddle-Point and Adversarial Prediction", "Abstract": "Adversarial machines, where a learner competes against an adversary, have regained much recent interest in machine learning. They are naturally in the form of saddle-point optimization, often with separable structure but sometimes also with unmanageably large dimension. In this work we show that adversarial prediction under multivariate losses can be solved much faster than they used to be. We first reduce the problem size exponentially by using appropriate sufficient statistics, and then we adapt the new stochastic variance-reduced algorithm of Balamurugan & Bach (2016) to allow any Bregman divergence. We prove that the same linear rate of convergence is retained and we show that for adversarial prediction using KL-divergence we can further achieve a speedup of #example times compared with the Euclidean alternative. We verify the theoretical findings through extensive experiments on two example applications: adversarial prediction and LPboosting."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Diving into the shallows", "Title": "a computational perspective on large-scale shallow learning", "Abstract": "Remarkable recent success of deep neural networks has not been easy to analyze theoretically. It has been  particularly hard to disentangle relative significance of architecture and optimization in achieving accurate classification on large datasets. On the flip side, shallow methods (such as kernel methods) have  encountered obstacles in scaling to large data, despite excellent performance on smaller datasets, and extensive theoretical analysis. Practical methods, such as variants of gradient descent used so successfully in deep learning, seem to perform below par when applied to kernel methods. This difficulty has sometimes been attributed to the limitations of shallow  architecture.   In this paper we  identify a basic limitation in gradient descent-based optimization methods when used in conjunctions with smooth kernels. Our analysis demonstrates that only a vanishingly small fraction of the function space is reachable after a polynomial number of gradient descent iterations. That drastically limits the approximating power of gradient descent leading to over-regularization. The issue is purely algorithmic, persisting even in the limit of infinite data.  To address this shortcoming in practice, we introduce EigenPro iteration, a simple and direct preconditioning scheme using a small number of approximately computed eigenvectors. It can also be viewed as learning a kernel optimized for gradient descent. Injecting this small, computationally inexpensive and SGD-compatible, amount of approximate second-order information leads to major improvements in convergence. For large data, this leads to a  significant performance  boost over the state-of-the-art kernel methods. In particular, we are able to match or improve the results reported in the literature at a small fraction of their computational budget. For complete version of this paper see https://arxiv.org/abs/1703.10622."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Q-LDA", "Title": "Uncovering Latent Patterns in Text-based Sequential Decision Processes", "Abstract": "In sequential decision making, it is often important and useful for end users to understand the underlying patterns or causes that lead to the corresponding decisions. However, typical deep reinforcement learning algorithms seldom provide such information due to their black-box nature. In this paper, we present a probabilistic model, Q-LDA, to uncover latent patterns in text-based sequential decision processes. The model can be understood as a variant of latent topic models that are tailored to maximize total rewards; we further draw an interesting connection between an approximate maximum-likelihood estimation of Q-LDA and the celebrated Q-learning algorithm.  We demonstrate in the text-game domain that our proposed method not only provides a viable mechanism to uncover latent patterns in decision processes, but also obtains state-of-the-art rewards in these games."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Streaming Weak Submodularity", "Title": "Interpreting Neural Networks on the Fly", "Abstract": "In many machine learning applications, it is important to explain the predictions of a black-box classifier. For example, why does a deep neural network assign an image to a particular class? We cast interpretability of black-box classifiers as a combinatorial maximization problem and propose an efficient streaming algorithm to solve it subject to cardinality constraints. By extending ideas from Badanidiyuru et al. [2014], we provide a constant factor approximation guarantee for our algorithm in the case of random stream order and a weakly submodular objective function. This is the first such theoretical guarantee for this general class of functions, and we also show that no such algorithm exists for a worst case stream order. Our algorithm obtains similar explanations of Inception V3 predictions 10 times faster than the state-of-the-art LIME framework of Ribeiro et al. [2016]."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Decomposable Submodular Function Minimization", "Title": "Discrete and Continuous", "Abstract": "This paper investigates connections between discrete and continuous approaches for decomposable submodular function minimization. We provide improved running time estimates for the state-of-the-art continuous algorithms for the problem using combinatorial arguments. We also provide a systematic experimental comparison of the two types of methods, based on a clear distinction between level-0 and level-1 algorithms."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Submodular Maximization", "Title": "The Case of Coverage Functions", "Abstract": "Stochastic optimization of continuous objectives is at the heart of modern machine learning. However, many important problems are of discrete nature and often involve submodular objectives. We seek to unleash the power of stochastic continuous optimization, namely stochastic gradient descent and its variants, to such discrete problems. We first introduce the problem of stochastic submodular optimization, where one needs to optimize a submodular objective which is given as an expectation. Our model captures situations where the discrete objective arises as an empirical risk (e.g., in the case of exemplar-based clustering), or is given as an explicit stochastic model (e.g., in the case of influence maximization in social networks). By exploiting that common extensions act linearly on the class of submodular functions, we employ projected stochastic gradient ascent and its variants in the continuous domain, and perform rounding to obtain discrete solutions. We focus on the rich and widely used family of weighted coverage functions. We show that our approach yields solutions that are guaranteed to match the optimal approximation guarantees, while reducing the computational cost by several orders of magnitude, as we demonstrate empirically."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Batch Renormalization", "Title": "Towards Reducing Minibatch Dependence in Batch-Normalized Models", "Abstract": "Batch Normalization is quite effective at accelerating and improving the training of deep models. However, its effectiveness diminishes when the training minibatches are small, or do not consist of independent samples. We hypothesize that this is due to the dependence of model layer inputs on all the examples in the minibatch, and different activations being produced between training and inference. We propose Batch Renormalization, a simple and effective extension to ensure that the training and inference models generate the same outputs that depend on individual examples rather than the entire minibatch. Models trained with Batch Renormalization perform substantially better than batchnorm when training with small  or non-i.i.d. minibatches. At the same time, Batch Renormalization retains the benefits of batchnorm such as insensitivity to initialization and training efficiency."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Voice 2", "Title": "Multi-Speaker Neural Text-to-Speech", "Abstract": "We introduce a technique for augmenting neural text-to-speech (TTS) with low-dimensional trainable speaker embeddings to generate different voices from a single model. As a starting point, we show improvements over the two state-of-the-art approaches for single-speaker neural TTS: Deep Voice 1 and Tacotron. We introduce Deep Voice 2, which is based on a similar pipeline with Deep Voice 1, but constructed with higher performance building blocks and demonstrates a significant audio quality improvement over Deep Voice 1. We improve Tacotron by introducing a post-processing neural vocoder, and demonstrate a significant audio quality improvement. We then demonstrate our technique for multi-speaker speech synthesis for both Deep Voice 2 and Tacotron on two multi-speaker TTS datasets. We show that a single neural TTS system can learn hundreds of unique voices from less than half an hour of data per speaker, while achieving high audio quality synthesis and preserving the speaker identities almost perfectly."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deliberation Networks", "Title": "Sequence Generation Beyond One-Pass Decoding", "Abstract": "The encoder-decoder framework has achieved promising progress for many sequence generation tasks, including machine translation, text summarization, dialog system, image captioning, etc. Such a framework adopts an one-pass forward process while decoding and generating a sequence, but lacks the deliberation process: A generated sequence is directly used as final output without further polishing. However, deliberation is a common behavior in human's daily life like reading news and writing papers/articles/books. In this work, we introduce the deliberation process into the encoder-decoder framework and propose deliberation networks for sequence generation. A deliberation network has two levels of decoders, where the first-pass decoder generates a raw sequence and the second-pass decoder polishes and refines the raw sentence with deliberation. Since the second-pass deliberation decoder has global information about what the sequence to be generated might be, it has the potential to generate a better sequence by looking into future words in the raw sentence. Experiments on neural machine translation and text summarization demonstrate the effectiveness of the proposed deliberation networks. On the WMT 2014 English-to-French translation task, our model establishes a new state-of-the-art BLEU score of 41.5."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PRUNE", "Title": "Preserving Proximity and Global Ranking for Network Embedding", "Abstract": "We investigate an unsupervised generative approach for network embedding. A multi-task Siamese neural network structure is formulated to connect embedding vectors and our objective to preserve the global node ranking and local proximity of nodes. We provide deeper analysis to connect the proposed proximity objective to link prediction and community detection in the network. We show our model can satisfy the following design properties: scalability, asymmetry, unity and simplicity. Experiment results not only verify the above design properties but also demonstrate the superior performance in learning-to-rank, classification, regression, and link prediction tasks."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AdaGAN", "Title": "Boosting Generative Models", "Abstract": "Generative Adversarial Networks (GAN) are an effective method for training generative models of complex data such as natural images. However, they are notoriously hard to train and can suffer from the problem of missing modes where the model is not able to produce examples in certain regions of the space. We propose an iterative procedure, called AdaGAN, where at every step we add a new component into a mixture model by running a GAN algorithm on a re-weighted sample. This is inspired by boosting algorithms, where many potentially weak individual predictors are greedily aggregated to form a strong composite predictor. We prove analytically that such an incremental procedure leads to convergence to the true distribution in a finite number of steps if each step is optimal, and convergence at an exponential rate otherwise. We also illustrate experimentally that this procedure addresses the problem of missing modes."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Semi-supervised Learning with GANs", "Title": "Manifold Invariance with Improved Inference", "Abstract": "Semi-supervised learning methods using Generative adversarial networks (GANs) have shown promising empirical success recently. Most of these methods use a shared discriminator/classifier which discriminates real examples from fake while also predicting the class label. Motivated by the ability of the GANs generator to capture the data manifold well, we propose to estimate the tangent space to the data manifold using GANs and employ it to inject invariances into the classifier. In the process, we propose enhancements over existing methods for learning the inverse mapping (i.e., the encoder)  which greatly improves in terms of semantic similarity of the reconstructed sample with the input sample. We observe considerable empirical gains in semi-supervised learning over baselines, particularly in the cases when the number of labeled examples is low. We also provide insights into how fake examples influence the semi-supervised learning procedure."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Houdini", "Title": "Fooling Deep Structured Visual and Speech Recognition Models with Adversarial Examples", "Abstract": "Generating adversarial examples is a critical step for evaluating and improving the robustness of learning machines. So far, most existing methods only work for classification and are not designed to alter the true performance measure of the problem at hand. We introduce a novel flexible approach named Houdini for generating adversarial examples specifically tailored for the final performance measure of the task considered, be it combinatorial and non-decomposable. We successfully apply Houdini to a range of applications such as speech recognition, pose estimation and semantic segmentation. In all cases, the attacks based on Houdini achieve higher success rate than those based on the traditional surrogates used to train the models while using a less perceptible adversarial perturbation."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attend and Predict", "Title": "Understanding Gene Regulation by Selective Attention on Chromatin", "Abstract": "The past decade has seen a revolution in genomic technologies that enabled a flood of genome-wide profiling of chromatin marks.  Recent literature tried to understand gene regulation by predicting gene expression from large-scale chromatin measurements.  Two fundamental challenges exist for such learning tasks: (1) genome-wide chromatin signals are spatially structured, high-dimensional and highly modular; and (2) the core aim is to understand what are the relevant factors and how they work together.  Previous studies either failed to model complex dependencies among input signals or relied on separate feature analysis to explain the decisions. This paper presents an attention-based deep learning approach; AttentiveChrome, that uses a unified architecture to model and to interpret dependencies among chromatin factors for controlling gene regulation. AttentiveChrome uses a hierarchy of multiple Long Short-Term Memory (LSTM) modules to encode the input signals and to model how various chromatin marks cooperate automatically. AttentiveChrome trains two levels of attention jointly with the target prediction, enabling it to attend differentially to relevant marks and to locate important positions per mark. We evaluate the model across 56 different cell types (tasks) in human. Not only is the proposed architecture more accurate, but its attention scores also provide a better interpretation than state-of-the-art feature visualization methods such as saliency map."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PointNet++", "Title": "Deep Hierarchical Feature Learning on Point Sets in a Metric Space", "Abstract": "Few prior works study deep learning on point sets. PointNet is a pioneer in this direction. However, by design PointNet does not capture local structures induced by the metric space points live in, limiting its ability to recognize fine-grained patterns and generalizability to complex scenes. In this work, we introduce a hierarchical neural network that applies PointNet recursively on a nested partitioning of the input point set. By exploiting metric space distances, our network is able to learn local features with increasing contextual scales. With further observation that point sets are usually sampled with varying densities, which results in greatly decreased performance for networks trained on uniform densities, we propose novel set learning layers to adaptively combine features from multiple scales. Experiments show that our network called PointNet++ is able to learn deep point set features efficiently and robustly. In particular, results significantly better than state-of-the-art have been obtained on challenging benchmarks of 3D point clouds."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Approximation Bounds for Hierarchical Clustering", "Title": "Average Linkage, Bisecting K-means, and Local Search", "Abstract": "Hierarchical clustering is a data analysis method that has been used for decades. Despite its widespread use, the method has an underdeveloped analytical foundation. Having a well understood foundation would both support the currently used methods and help guide future improvements. The goal of this paper is to give an analytic framework to better understand observations seen in practice. This paper considers the dual of a problem framework for hierarchical clustering introduced by Dasgupta. The main result is that one of the most popular algorithms used in practice, average linkage agglomerative clustering, has a small constant approximation ratio for this objective. Furthermore, this paper establishes that using bisecting k-means divisive clustering has a very poor lower bound on its approximation ratio for the same objective.  However, we show that there are divisive algorithms that perform well with respect to this objective by giving two constant approximation algorithms. This paper is some of the first work to establish guarantees on widely used hierarchical algorithms for a natural objective function.  This objective and analysis give insight into what these popular algorithms are optimizing and when they will perform well."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Resurrecting the sigmoid in deep learning through dynamical isometry", "Title": "theory and practice", "Abstract": "It is well known that weight initialization in deep networks can have a dramatic impact on learning speed. For example, ensuring the mean squared singular value of a network's input-output Jacobian is O(1) is essential for avoiding exponentially vanishing or exploding gradients. Moreover, in deep linear networks, ensuring that all singular values of the Jacobian are concentrated near 1 can yield a dramatic additional speed-up in learning; this is a property known as dynamical isometry. However, it is unclear how to achieve dynamical isometry in nonlinear deep networks.  We address this question by employing powerful tools from free probability theory to analytically compute the {\\it entire} singular value distribution of a deep network's input-output Jacobian. We explore the dependence of the singular value distribution on the depth of the network, the weight initialization, and the choice of nonlinearity. Intriguingly, we find that ReLU networks are incapable of dynamical isometry. On the other hand, sigmoidal networks can achieve isometry, but only with orthogonal weight initialization. Moreover, we demonstrate empirically that deep nonlinear networks achieving dynamical isometry learn orders of magnitude faster than networks that do not. Indeed, we show that properly-initialized deep sigmoidal networks consistently outperform deep ReLU networks. Overall, our analysis reveals that controlling the entire distribution of Jacobian singular values is an important design consideration in deep learning."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DropoutNet", "Title": "Addressing Cold Start in Recommender Systems", "Abstract": "Latent models have become the default choice for recommender systems due to their performance and scalability. However, research in this area has primarily focused on modeling user-item interactions,  and few latent models have been developed for cold start. Deep learning has recently achieved remarkable success showing excellent results for diverse input types. Inspired by these results we propose a neural network based latent model called DropoutNet to address the cold start problem in recommender systems. Unlike existing approaches that incorporate additional content-based objective terms, we instead focus on the optimization and show that neural network models can be explicitly trained for cold start through dropout. Our model can  be applied on top of any existing latent model effectively providing cold start capabilities, and full power of deep architectures. Empirically we demonstrate  state-of-the-art accuracy on publicly available benchmarks. Code is available at  https://github.com/layer6ai-labs/DropoutNet."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SVCCA", "Title": "Singular Vector Canonical Correlation Analysis for Deep Learning Dynamics and Interpretability", "Abstract": "We propose a new technique, Singular Vector Canonical Correlation Analysis (SVCCA), a tool for quickly comparing two representations in a way that is both invariant to affine transform (allowing comparison between different layers and networks) and fast to compute (allowing more comparisons to be calculated than with previous methods).  We deploy this tool to measure the intrinsic dimensionality of layers, showing in some cases needless over-parameterization; to probe learning dynamics throughout training, finding that networks converge to final representations from the bottom up; to show where class-specific information in networks is formed; and to suggest new training regimes that simultaneously save computation and overfit less."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MMD GAN", "Title": "Towards Deeper Understanding of Moment Matching Network", "Abstract": "Generative moment matching network (GMMN) is a deep generative model that differs from Generative Adversarial Network (GAN) by replacing the discriminator in GAN with a two-sample test based on kernel maximum mean discrepancy (MMD). Although some theoretical guarantees of MMD have been studied, the empirical performance of GMMN is still not as competitive as that of GAN on challenging and large benchmark datasets. The computational efficiency of GMMN is also less desirable in comparison with GAN, partially due to its requirement for a rather large batch size during the training. In this paper, we propose to improve both the model expressiveness of GMMN and its computational efficiency by introducing {\\it adversarial kernel learning} techniques, as the replacement of a fixed Gaussian kernel in the original GMMN. The new approach combines the key ideas in both GMMN and GAN, hence we name it MMD-GAN. The new distance measure in MMD-GAN is a meaningful loss that enjoys the advantage of weak$^*$ topology and can be optimized via gradient descent with relatively small batch sizes. In our evaluation on multiple benchmark datasets, including MNIST, CIFAR-10, CelebA and LSUN, the performance of MMD-GAN significantly outperforms GMMN, and is competitive with other representative GAN works."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PredRNN", "Title": "Recurrent Neural Networks for Predictive Learning using Spatiotemporal LSTMs", "Abstract": "The predictive learning of spatiotemporal sequences aims to generate future images by learning from the historical frames, where spatial appearances and temporal variations are two crucial structures. This paper models these structures by presenting a predictive recurrent neural network (PredRNN). This architecture is enlightened by the idea that spatiotemporal predictive learning should memorize both spatial appearances and temporal variations in a unified memory pool. Concretely, memory states are no longer constrained inside each LSTM unit. Instead, they are allowed to zigzag in two directions: across stacked RNN layers vertically and through all RNN states horizontally. The core of this network is a new Spatiotemporal LSTM (ST-LSTM) unit that extracts and memorizes spatial and temporal  representations simultaneously. PredRNN achieves the state-of-the-art prediction performance on three video prediction datasets and is a more general framework, that can be easily extended to other predictive learning tasks by integrating with other architectures."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Parity", "Title": "Fairness Objectives for Collaborative Filtering", "Abstract": "We study fairness in collaborative-filtering recommender systems, which are sensitive to discrimination that exists in historical data. Biased data can lead collaborative-filtering methods to make unfair predictions for users from minority groups. We identify the insufficiency of existing fairness metrics and propose four new metrics that address different forms of unfairness. These fairness metrics can be optimized by adding fairness terms to the learning objective. Experiments on synthetic and real data show that our new metrics can better measure fairness than the baseline, and that the fairness objectives effectively help reduce unfairness."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Polynomial Codes", "Title": "an Optimal Design for High-Dimensional Coded Matrix Multiplication", "Abstract": "We consider a large-scale matrix multiplication problem where the computation is carried out using a distributed system with a master node and multiple worker nodes, where each worker can store parts of the input matrices. We propose a computation strategy that leverages ideas from coding theory to design intermediate computations at the worker nodes, in order to optimally deal with straggling workers. The proposed strategy, named as \\emph{polynomial codes}, achieves the optimum recovery threshold, defined as the minimum number of workers that the master needs to wait for in order to compute the output. This is the first code that achieves the optimal utilization of redundancy for tolerating stragglers or failures in distributed matrix multiplication. Furthermore, by leveraging the algebraic structure of polynomial codes, we can map the reconstruction problem of the final output to a polynomial interpolation problem, which can be solved efficiently.   Polynomial codes provide order-wise improvement over the state of the art in terms of recovery threshold, and are also optimal in terms of several other metrics including computation latency and communication load.  Moreover, we extend this code to distributed convolution and show its order-wise optimality."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sticking the Landing", "Title": "Simple, Lower-Variance Gradient Estimators for Variational Inference", "Abstract": "We propose a simple and general variant of the standard reparameterized gradient estimator for the variational evidence lower bound. Specifically, we remove a part of the total derivative with respect to the variational parameters that corresponds to the score function. Removing this term produces an unbiased gradient estimator whose variance approaches zero as the approximate posterior approaches the exact posterior. We analyze the behavior of this gradient estimator theoretically and empirically, and generalize it to more complex variational distributions such as mixtures and importance-weighted posteriors."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multiplicative Weights Update with Constant Step-Size in Congestion Games", "Title": "Convergence, Limit Cycles and Chaos", "Abstract": "The Multiplicative Weights Update (MWU) method is a ubiquitous meta-algorithm that works as follows: A distribution is maintained on a certain set, and at each step the probability assigned to action $\\gamma$ is multiplied by $(1 -\\epsilon C(\\gamma))>0$ where $C(\\gamma)$ is the ``cost\" of action $\\gamma$ and then rescaled to ensure that the new values form a distribution.  We analyze MWU in congestion games where agents use \\textit{arbitrary admissible constants} as learning rates $\\epsilon$ and prove convergence to \\textit{exact Nash equilibria}. Interestingly, this convergence result does not carry over to the nearly homologous MWU variant where at each step the probability assigned to action $\\gamma$ is multiplied by $(1 -\\epsilon)^{C(\\gamma)}$ even for the simplest case of two-agent, two-strategy load balancing games, where such dynamics can provably lead to limit cycles or even chaotic behavior."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "QMDP-Net", "Title": "Deep Learning for Planning under Partial Observability", "Abstract": "This paper introduces the QMDP-net, a neural network architecture for planning under partial observability. The QMDP-net combines the strengths of model-free learning and model-based planning. It is a recurrent policy network, but it represents a policy for a parameterized set of tasks by connecting a model with a planning algorithm that solves the model, thus embedding the solution structure of planning in a network learning architecture. The QMDP-net is fully differentiable and allows for end-to-end training. We train a QMDP-net on different tasks so that it can generalize to new ones in the parameterized task set and “transfer” to other similar tasks beyond the set. In preliminary experiments, QMDP-net showed strong performance on several robotic tasks in simulation. Interestingly, while QMDP-net encodes the QMDP algorithm, it sometimes outperforms the QMDP algorithm in the experiments, as a result of end-to-end learning."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ADMM without a Fixed Penalty Parameter", "Title": "Faster Convergence with New Adaptive Penalization", "Abstract": "Alternating direction method of multipliers (ADMM) has received tremendous interest for solving numerous  problems in machine learning, statistics and signal processing. However, it is known that the performance of ADMM and many of its variants is very sensitive to the penalty parameter of a quadratic penalty applied to the equality constraints. Although several approaches have been proposed for dynamically changing this parameter during the course of optimization, they do not yield theoretical improvement in the convergence rate and are not directly applicable to stochastic ADMM. In this paper, we develop a new ADMM and its linearized variant with a new adaptive scheme to update the penalty parameter. Our methods can be applied under both deterministic and stochastic optimization settings for structured non-smooth objective function. The novelty of the proposed scheme lies at that it is adaptive to a local sharpness property of the objective function, which marks the key difference from previous adaptive scheme that adjusts the penalty parameter per-iteration based on certain conditions on iterates. On theoretical side, given the local sharpness characterized by an exponent $\\theta\\in(0, 1]$,  we show that the proposed ADMM enjoys an improved iteration complexity of $\\widetilde O(1/\\epsilon^{1-\\theta})$\\footnote{$\\widetilde O()$ suppresses a logarithmic factor.} in the deterministic setting and an iteration complexity of $\\widetilde O(1/\\epsilon^{2(1-\\theta)})$ in the stochastic setting without smoothness and strong convexity assumptions. The complexity in either setting improves that of the standard ADMM which only uses a fixed penalty parameter. On the practical side, we demonstrate that the proposed algorithms converge comparably to, if not much faster than, ADMM with a fine-tuned fixed penalty parameter."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond normality", "Title": "Learning sparse probabilistic graphical models in the non-Gaussian setting", "Abstract": "We present an algorithm to identify sparse dependence structure in continuous and non-Gaussian probability distributions, given a corresponding set of data. The conditional independence structure of an arbitrary distribution can be represented as an undirected graph (or Markov random field), but most algorithms for learning this structure are restricted to the discrete or Gaussian cases. Our new approach allows for more realistic and accurate descriptions of the distribution in question, and in turn better estimates of its sparse Markov structure. Sparsity in the graph is of interest as it can accelerate inference, improve sampling methods, and reveal important dependencies between variables. The algorithm relies on exploiting the connection between the sparsity of the graph and the sparsity of transport maps, which deterministically couple one probability measure to another."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "REBAR", "Title": "Low-variance, unbiased gradient estimates for discrete latent variable models", "Abstract": "Learning in models with discrete latent variables is challenging due to high variance gradient estimators. Generally, approaches have relied on control variates to reduce the variance of the REINFORCE estimator. Recent work \\citep{jang2016categorical, maddison2016concrete} has taken a different approach, introducing a continuous relaxation of discrete variables to produce low-variance, but biased, gradient estimates. In this work, we combine the two approaches through a novel control variate that produces low-variance, \\emph{unbiased} gradient estimates. Then, we introduce a modification to the continuous relaxation and show that the tightness of the relaxation can be adapted online, removing it as a hyperparameter. We show state-of-the-art variance reduction on several benchmark generative modeling tasks, generally leading to faster convergence to a better final log-likelihood."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Differentially Private Empirical Risk Minimization Revisited", "Title": "Faster and More General", "Abstract": "In this paper we study differentially private Empirical Risk Minimization(ERM) in different settings. For smooth (strongly) convex loss function with or without (non)-smooth regularization, we give algorithms which achieve either optimal or near optimal utility bound with less gradient complexity compared with previous work.  For ERM with smooth convex loss function in high-dimension($p\\gg n$) setting, we give an algorithm which achieves the upper bound with less gradient complexity than previous ones. At last, we generalize the expected excess empirical risk from convex to Polyak-Lojasiewicz condition and give a tighter upper bound of the utility comparing with the result in \\cite{DBLP:journals/corr/ZhangZMW17}."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Machine Learning with Adversaries", "Title": "Byzantine Tolerant Gradient Descent", "Abstract": "We study the resilience  to Byzantine failures of distributed implementations of Stochastic Gradient Descent (SGD). So far, distributed machine learning frameworks have largely ignored the possibility of failures, especially  arbitrary (i.e., Byzantine) ones. Causes of failures include software bugs, network asynchrony, biases in local datasets, as well as attackers trying to compromise the entire system. Assuming a set of $n$ workers, up to $f$  being Byzantine,  we ask how resilient  can SGD be, without limiting the dimension, nor the size of the parameter space. We first show that no gradient aggregation rule based on a linear combination of the vectors proposed by the workers (i.e, current approaches) tolerates a single Byzantine failure. We then formulate a resilience  property of the aggregation rule capturing the basic requirements to guarantee convergence despite $f$   Byzantine workers. We propose \\emph{Krum}, an aggregation rule that satisfies our resilience  property, which we argue is the first provably Byzantine-resilient algorithm for distributed SGD. We also report on experimental evaluations of Krum."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Reversible Residual Network", "Title": "Backpropagation Without Storing Activations", "Abstract": "Residual Networks (ResNets) have demonstrated significant improvement over traditional Convolutional Neural Networks (CNNs) on image classification, increasing in performance as networks grow both deeper and wider.  However, memory consumption becomes a bottleneck as one needs to store all the intermediate activations for calculating gradients using backpropagation. In this work, we present the Reversible Residual Network (RevNet), a variant of ResNets where each layer's activations can be reconstructed exactly from the next layer's. Therefore, the activations for most layers need not be stored in memory during backprop. We demonstrate the effectiveness of RevNets on CIFAR and ImageNet, establishing nearly identical performance to equally-sized ResNets, with activation storage requirements independent of depth."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EEG-GRAPH", "Title": "A Factor-Graph-Based Model for Capturing Spatial, Temporal, and Observational Relationships in Electroencephalograms", "Abstract": "This paper presents a probabilistic-graphical model that can be used to infer characteristics of instantaneous brain activity by jointly analyzing spatial and temporal dependencies observed in electroencephalograms (EEG). Specifically, we describe a factor-graph-based model with customized factor-functions defined based on domain knowledge, to infer pathologic brain activity with the goal of identifying seizure-generating brain regions in epilepsy patients. We utilize an inference technique based on the graph-cut algorithm to exactly solve graph inference in polynomial time. We validate the model by using clinically collected intracranial EEG data from 29 epilepsy patients to show that the model correctly identifies seizure-generating brain regions. Our results indicate that our model outperforms two conventional approaches used for seizure-onset localization (5-7% better AUC: 0.72, 0.67, 0.65) and that the proposed inference technique provides 3-10% gain in AUC (0.72, 0.62, 0.69) compared to sampling-based alternatives."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Natural Value Approximators", "Title": "Learning when to Trust Past Estimates", "Abstract": "Neural networks have a smooth initial inductive bias, such that small changes in input do not lead to large changes in output. However, in reinforcement learning domains with sparse rewards, value functions have non-smooth structure with a characteristic asymmetric discontinuity whenever rewards arrive. We propose a mechanism that learns an interpolation between a direct value estimate and a projected value estimate computed from the encountered reward and the previous estimate. This reduces the need to learn about discontinuities, and thus improves the value function approximation. Furthermore, as the interpolation is learned and state-dependent, our method can deal with heterogeneous observability. We demonstrate that this one change leads to significant improvements on multiple Atari games, when applied to the state-of-the-art A3C algorithm."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Expxorcist", "Title": "Nonparametric Graphical Models Via Conditional Exponential Densities", "Abstract": "Non-parametric multivariate density estimation faces strong statistical and computational bottlenecks, and the more practical approaches impose near-parametric assumptions on the form of the density functions. In this paper, we leverage recent developments to propose a class of non-parametric models which have very attractive computational and statistical properties. Our approach relies on the simple function space assumption that the conditional distribution of each variable conditioned on the other variables has a non-parametric exponential family form."}
{"Type": "conference", "Year": "2017", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeuralFDR", "Title": "Learning Discovery Thresholds from Hypothesis Features", "Abstract": "As datasets grow richer, an important challenge is to leverage the full features in the data to maximize the number of useful discoveries while controlling for false positives. We address this problem in the context of multiple hypotheses testing, where for each hypothesis, we observe a p-value along with a set of features specific to that hypothesis. For example, in genetic association studies, each hypothesis tests the correlation between a variant and the trait. We have a rich set of features for each variant (e.g. its location, conservation, epigenetics etc.) which could inform how likely the variant is to have a true association. However popular testing approaches, such as Benjamini-Hochberg's procedure (BH) and independent hypothesis weighting (IHW), either ignore these features or assume that the features are categorical. We propose a new algorithm, NeuralFDR, which automatically learns a discovery threshold as a function of all the hypothesis features. We parametrize the discovery threshold as a neural network, which enables flexible handling of multi-dimensional discrete and continuous features as well as efficient end-to-end optimization. We prove that NeuralFDR has strong false discovery rate (FDR) guarantees, and show that it makes substantially more discoveries in synthetic and real datasets. Moreover, we demonstrate that the learned discovery threshold is directly interpretable."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KDGAN", "Title": "Knowledge Distillation with Generative Adversarial Networks", "Abstract": "Knowledge distillation (KD) aims to train a lightweight classifier suitable to provide accurate inference with constrained resources in multi-label learning. Instead of directly consuming feature-label pairs, the classifier is trained by a teacher, i.e., a high-capacity model whose training may be resource-hungry. The accuracy of the classifier trained this way is usually suboptimal because it is difficult to learn the true data distribution from the teacher. An alternative method is to adversarially train the classifier against a discriminator in a two-player game akin to generative adversarial networks (GAN), which can ensure the classifier to learn the true data distribution at the equilibrium of this game. However, it may take excessively long time for such a two-player game to reach equilibrium due to high-variance gradient updates. To address these limitations, we propose a three-player game named KDGAN consisting of a classifier, a teacher, and a discriminator. The classifier and the teacher learn from each other via distillation losses and are adversarially trained against the discriminator via adversarial losses. By simultaneously optimizing the distillation and adversarial losses, the classifier will learn the true data distribution at the equilibrium. We approximate the discrete distribution learned by the classifier (or the teacher) with a concrete distribution. From the concrete distribution, we generate continuous samples to obtain low-variance gradient updates, which speed up the training. Extensive experiments using real datasets confirm the superiority of KDGAN in both accuracy and training speed."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Contextual bandits with surrogate losses", "Title": "Margin bounds and efficient algorithms", "Abstract": "We use surrogate losses to obtain several new regret bounds and new algorithms for contextual bandit learning. Using the ramp loss, we derive a new margin-based regret bound in terms of standard sequential complexity measures of a benchmark class of real-valued regression functions. Using the hinge loss, we derive an efficient algorithm with a $\\sqrt{dT}$-type mistake bound against benchmark policies induced by $d$-dimensional regressors. Under realizability assumptions, our results also yield classical regret bounds."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dimensionality Reduction has Quantifiable Imperfections", "Title": "Two Geometric Bounds", "Abstract": "In this paper, we investigate Dimensionality reduction (DR) maps in an information retrieval setting from a quantitative topology point of view. In particular, we show that no DR maps can achieve perfect precision and perfect recall simultaneously. Thus a continuous DR map must have imperfect precision. We further prove an upper bound on the precision of Lipschitz continuous DR maps. While precision is a natural measure in an information retrieval setting, it does not measure `how' wrong the retrieved data is. We therefore propose a new measure based on Wasserstein distance that comes with similar theoretical guarantee. A key technical step in our proofs is a particular optimization problem of the $L_2$-Wasserstein distance over a constrained set of distributions. We provide a complete solution to this optimization problem, which can be of independent interest on the technical side."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cooperative neural networks (CoNN)", "Title": "Exploiting prior independence structure for improved classification", "Abstract": "We propose a new approach, called cooperative neural networks (CoNN), which use a set of cooperatively trained neural networks to capture latent representations that exploit prior given independence structure. The model is more flexible than traditional graphical models based on exponential family distributions, but incorporates more domain specific prior structure than traditional deep networks or variational autoencoders. The framework is very general and can be used to exploit the independence structure of any graphical model. We illustrate the technique by showing that we can transfer the independence structure of the popular Latent Dirichlet Allocation (LDA) model to a cooperative neural network, CoNN-sLDA. Empirical evaluation of CoNN-sLDA on supervised text classification tasks demonstrate that the theoretical advantages of prior independence structure can be realized in practice - we demonstrate a 23 percent reduction in error on the challenging MultiSent data set compared to state-of-the-art."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COLA", "Title": "Decentralized Linear Learning", "Abstract": "Decentralized machine learning is a promising emerging paradigm in view of global challenges of data ownership and privacy. We consider learning of linear classification and regression models, in the setting where the training data is decentralized over many user devices, and the learning algorithm must run on-device, on an arbitrary communication network, without a central coordinator.\nWe propose COLA, a new decentralized training algorithm with strong theoretical guarantees and superior practical performance. Our framework overcomes many limitations of existing methods, and achieves communication efficiency, scalability, elasticity as well as resilience to changes in data and allows for unreliable and heterogeneous participating devices."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Answerer in Questioner's Mind", "Title": "Information Theoretic Approach to Goal-Oriented Visual Dialog", "Abstract": "Goal-oriented dialog has been given attention due to its numerous applications in artificial intelligence.\nGoal-oriented dialogue tasks occur when a questioner asks an action-oriented question and an answerer responds with the intent of letting the questioner know a correct action to take. \nTo ask the adequate question, deep learning and reinforcement learning have been recently applied. \nHowever, these approaches struggle to find a competent recurrent neural questioner, owing to the complexity of learning a series of sentences.\nMotivated by theory of mind, we propose \"Answerer in Questioner's Mind\" (AQM), a novel information theoretic algorithm for goal-oriented dialog. \nWith AQM, a questioner asks and infers based on an approximated probabilistic model of the answerer.\nThe questioner figures out the answerer’s intention via selecting a plausible question by explicitly calculating the information gain of the candidate intentions and possible answers to each question.\nWe test our framework on two goal-oriented visual dialog tasks: \"MNIST Counting Dialog\" and \"GuessWhat?!\".\nIn our experiments, AQM outperforms comparative algorithms by a large margin."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Weight Consolidation", "Title": "A Brain Segmentation Case Study", "Abstract": "Collecting the large datasets needed to train deep neural networks can be very difficult, particularly for the many applications for which sharing and pooling data is complicated by practical, ethical, or legal concerns. However, it may be the case that derivative datasets or predictive models developed within individual sites can be shared and combined with fewer restrictions. Training on distributed data and combining the resulting networks is often viewed as continual learning, but these methods require networks to be trained sequentially. In this paper, we introduce distributed weight consolidation (DWC), a continual learning method to consolidate the weights of separate neural networks, each trained on an independent dataset. We evaluated DWC with a brain segmentation case study, where we consolidated dilated convolutional neural networks trained on independent structural magnetic resonance imaging (sMRI) datasets from different sites. We found that DWC led to increased performance on test sets from the different sites, while maintaining generalization performance for a very large and completely independent multi-site dataset, compared to an ensemble baseline."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "IntroVAE", "Title": "Introspective Variational Autoencoders for Photographic Image Synthesis", "Abstract": "We present a novel introspective variational autoencoder (IntroVAE) model for synthesizing high-resolution photographic images. IntroVAE is capable of self-evaluating the quality of its generated samples and improving itself accordingly. Its inference and generator models are jointly trained in an introspective way. On one hand, the generator is required to reconstruct the input images from the noisy outputs of the inference model as normal VAEs. On the other hand, the inference model is encouraged to classify between the generated and real samples while the generator tries to fool it as GANs. These two famous generative frameworks are integrated in a simple yet efficient single-stream architecture that can be trained in a single stage. IntroVAE preserves the advantages of VAEs, such as stable training and nice latent manifold. Unlike most other hybrid models of VAEs and GANs, IntroVAE requires no extra discriminators, because the inference model itself serves as a discriminator to distinguish between the generated and real samples.  Experiments demonstrate that our method produces high-resolution photo-realistic images (e.g., CELEBA images at (1024^{2})), which are comparable to or better than the state-of-the-art GANs."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MixLasso", "Title": "Generalized Mixed Regression via Convex Atomic-Norm Regularization", "Abstract": "We consider a generalization of mixed regression where the response is an additive combination of several mixture components. Standard mixed regression is a special case where each response is generated from exactly one component. Typical approaches to the mixture regression problem employ local search methods such as Expectation Maximization (EM) that are prone to spurious local optima. On the other hand, a number of recent theoretically-motivated \\emph{Tensor-based methods} either have high sample complexity, or require the knowledge of the input distribution, which is not available in most of practical situations. In this work, we study a novel convex estimator \\emph{MixLasso} for the estimation of generalized mixed regression, based on an atomic norm specifically constructed to regularize the number of mixture components. Our algorithm gives a risk bound that trades off between prediction accuracy and model sparsity without imposing stringent assumptions on the input/output distribution, and can be easily adapted to the case of non-linear functions. In our numerical experiments on mixtures of linear as well as nonlinear regressions, the proposed method yields high-quality solutions in a wider range of settings than existing approaches."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predict Responsibly", "Title": "Improving Fairness and Accuracy by Learning to Defer", "Abstract": "In many machine learning applications, there are multiple decision-makers involved, both automated and human. The interaction between these agents often goes unaddressed in algorithmic development. In this work, we explore a simple version of this interaction with a two-stage framework containing an automated model and an external decision-maker. The model can choose to say PASS, and pass the decision downstream, as explored in rejection learning. We extend this concept by proposing \"learning to defer\", which generalizes rejection learning by considering the effect of other agents in the decision-making process. We propose a learning algorithm which accounts for potential biases held by external decision-makers in a system. Experiments demonstrate that learning to defer can make systems not only more accurate but also less biased. Even when working with inconsistent or biased users, we show that deferring models still greatly improve the accuracy and/or fairness of the entire system."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Skip Intervals", "Title": "Temporal Abstraction for Recurrent Dynamical Models", "Abstract": "We introduce a method which enables a recurrent dynamics model to be temporally abstract. Our approach, which we call Adaptive Skip Intervals (ASI), is based on the observation that in many sequential prediction tasks, the exact time at which events occur is irrelevant to the underlying objective. Moreover, in many situations, there exist prediction intervals which result in particularly easy-to-predict transitions. We show that there are prediction tasks for which we gain both computational efficiency and prediction accuracy by allowing the model to make predictions at a sampling rate which it can choose itself."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-Class Learning", "Title": "From Theory to Algorithm", "Abstract": "In this paper, we study the generalization performance of multi-class classification and obtain a shaper data-dependent generalization error bound with fast convergence rate, substantially improving the state-of-art bounds in the existing data-dependent generalization analysis. The theoretical analysis motivates us to devise two effective multi-class kernel learning algorithms with statistical guarantees. Experimental results show that our proposed methods can significantly outperform the existing multi-class classification methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Greedy Hash", "Title": "Towards Fast Optimization for Accurate Hash Coding in CNN", "Abstract": "To convert the input into binary code, hashing algorithm has been widely used for approximate nearest neighbor search on large-scale image sets due to its computation and storage efficiency. Deep hashing further improves the retrieval quality by combining the hash coding with deep neural network. However, a major difficulty in deep hashing lies in the discrete constraints imposed on the network output, which generally makes the optimization NP hard. In this work, we adopt the greedy principle to tackle this NP hard problem by iteratively updating the network toward the probable optimal discrete solution in each iteration. A hash coding layer is designed to implement our approach which strictly uses the sign function in forward propagation to maintain the discrete constraints, while in back propagation the gradients are transmitted intactly to the front layer to avoid the vanishing gradients. In addition to the theoretical derivation, we provide a new perspective to visualize and understand the effectiveness and efficiency of our algorithm. Experiments on benchmark datasets show that our scheme outperforms state-of-the-art hashing methods in both supervised and unsupervised tasks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CatBoost", "Title": "unbiased boosting with categorical features", "Abstract": "This paper presents the key algorithmic techniques behind CatBoost, a new gradient boosting toolkit. Their combination leads to CatBoost outperforming other publicly available boosting implementations in terms of quality on a variety of datasets. Two critical algorithmic advances introduced in CatBoost are the implementation of ordered boosting, a permutation-driven alternative to the classic algorithm, and an innovative algorithm for processing categorical features. Both techniques were created to fight a prediction shift caused by a special kind of target leakage present in all currently existing implementations of gradient boosting algorithms. In this paper, we provide a detailed analysis of this problem and demonstrate that proposed algorithms solve it effectively, leading to excellent empirical results."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SPIDER", "Title": "Near-Optimal Non-Convex Optimization via Stochastic Path-Integrated Differential Estimator", "Abstract": "In this paper, we propose a new technique named \\textit{Stochastic Path-Integrated Differential EstimatoR} (SPIDER), which can be used to track many deterministic quantities of interests with significantly reduced computational cost. \nCombining SPIDER with the method of normalized gradient descent, we propose SPIDER-SFO that solve non-convex stochastic optimization problems using stochastic gradients only. \nWe provide a few error-bound results on its convergence rates.\nSpecially, we prove that the SPIDER-SFO algorithm achieves a gradient computation cost of $\\mathcal{O}\\left(  \\min( n^{1/2} \\epsilon^{-2}, \\epsilon^{-3} ) \\right)$ to find an $\\epsilon$-approximate first-order stationary point. \nIn addition, we prove that SPIDER-SFO nearly matches the algorithmic lower bound for finding stationary point under the gradient Lipschitz assumption in the finite-sum setting.\nOur SPIDER technique can be further applied to find an $(\\epsilon, \\mathcal{O}(\\ep^{0.5}))$-approximate second-order stationary point at a gradient computation cost of $\\tilde{\\mathcal{O}}\\left(  \\min( n^{1/2} \\epsilon^{-2}+\\epsilon^{-2.5}, \\epsilon^{-3} ) \\right)$."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Decentralize and Randomize", "Title": "Faster Algorithm for Wasserstein Barycenters", "Abstract": "We study the decentralized distributed computation of discrete approximations for the regularized Wasserstein barycenter of a finite set of continuous probability measures distributedly stored over a network. We assume there is a network of agents/machines/computers, and each agent holds a private continuous probability measure and seeks to compute the barycenter of all the measures in the network by getting samples from its local measure and exchanging information with its neighbors. Motivated by this problem, we develop, and analyze, a novel accelerated primal-dual stochastic gradient method for general stochastic convex optimization problems with linear equality constraints. Then, we apply this method to the decen- tralized distributed optimization setting to obtain a new algorithm for the distributed semi-discrete regularized Wasserstein barycenter problem. Moreover, we show explicit non-asymptotic complexity for the proposed algorithm. Finally, we show the effectiveness of our method on the distributed computation of the regularized Wasserstein barycenter of univariate Gaussian and von Mises distributions, as well as some applications to image aggregation."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SNIPER", "Title": "Efficient Multi-Scale Training", "Abstract": "We present SNIPER, an algorithm for performing efficient multi-scale training in instance level visual recognition tasks. Instead of processing every pixel in an image pyramid, SNIPER processes context regions around ground-truth instances (referred to as chips) at the appropriate scale. For background sampling, these context-regions are generated using proposals extracted from a region proposal network trained with a short learning schedule. Hence, the number of chips generated per image during training adaptively changes based on the scene complexity. SNIPER only processes 30% more pixels compared to the commonly used single scale training at 800x1333 pixels on the COCO dataset. But, it also observes samples from extreme resolutions of the image pyramid, like 1400x2000 pixels. As SNIPER operates on resampled low resolution chips (512x512 pixels), it can have a batch size as large as 20 on a single GPU even with a ResNet-101 backbone. Therefore it can benefit from batch-normalization during training without the need for synchronizing batch-normalization statistics across GPUs. SNIPER brings training of instance level recognition tasks like object detection closer to the protocol for image classification and suggests that the commonly accepted guideline that it is important to train on high resolution images for instance level visual recognition tasks might not be correct. Our implementation based on Faster-RCNN with a ResNet-101 backbone obtains an mAP of 47.6% on the COCO dataset for bounding box detection and can process 5 images per second during inference with a single GPU. Code is available at https://github.com/MahyarNajibi/SNIPER/ ."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Delta-encoder", "Title": "an effective sample synthesis method for few-shot object recognition", "Abstract": "Learning to classify new categories based on just one or a few examples is a long-standing challenge in modern computer vision. In this work, we propose a simple yet effective method for few-shot (and one-shot) object recognition. Our approach is based on a modified auto-encoder, denoted delta-encoder, that learns to synthesize new samples for an unseen category just by seeing few examples from it. The synthesized samples are then used to train a classifier. The proposed approach learns to both extract transferable intra-class deformations, or \"deltas\", between same-class pairs of training examples, and to apply those deltas to the few provided examples of a novel class (unseen during training) in order to efficiently synthesize samples from that new class. The proposed method improves the state-of-the-art of one-shot object-recognition and performs comparably in the few-shot case."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Code Comprehension", "Title": "A Learnable Representation of Code Semantics", "Abstract": "With the recent success of embeddings in natural language processing, research has been conducted into applying similar methods to code analysis. Most works attempt to process the code directly or use a syntactic tree representation, treating it like sentences written in a natural language. However, none of the existing methods are sufficient to comprehend program semantics robustly, due to structural features such as function calls, branching, and interchangeable order of statements. In this paper, we propose a novel processing technique to learn code semantics, and apply it to a variety of program analysis tasks. In particular, we stipulate that a robust distributional hypothesis of code applies to both human- and machine-generated programs. Following this hypothesis, we define an embedding space, inst2vec, based on an Intermediate Representation (IR) of the code that is independent of the source programming language. We provide a novel definition of contextual flow for this IR, leveraging both the underlying data- and control-flow of the program. We then analyze the embeddings qualitatively using analogies and clustering, and evaluate the learned representation on three different high-level tasks. We show that even without fine-tuning, a single RNN architecture and fixed inst2vec embeddings outperform specialized approaches for performance prediction (compute device mapping, optimal thread coarsening); and algorithm classification from raw code (104 classes), where we set a new state-of-the-art."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PAC-Bayes Tree", "Title": "weighted subtrees with guarantees", "Abstract": "We present a weighted-majority classification approach over subtrees of a fixed tree, which provably achieves excess-risk of the same order as the best tree-pruning. Furthermore, the computational efficiency of pruning is maintained at both training and testing time despite having to aggregate over an exponential number of subtrees. We believe this is the first subtree aggregation approach with such guarantees."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Parameters as interacting particles", "Title": "long time convergence and asymptotic error scaling of neural networks", "Abstract": "The performance of neural networks on high-dimensional data\n  distributions suggests that it may be possible to parameterize a\n  representation of a given high-dimensional function with\n  controllably small errors, potentially outperforming standard\n  interpolation methods.  We demonstrate, both theoretically and\n  numerically, that this is indeed the case.  We map the parameters of\n  a neural network to a system of particles relaxing with an\n  interaction potential determined by the loss function.  We show that\n  in the limit that the number of parameters $n$ is large, the\n  landscape of the mean-squared error becomes convex and the\n  representation error in the function scales as $O(n^{-1})$.\n  In this limit, we prove a dynamical variant of the universal\n  approximation theorem showing that the optimal\n  representation can be attained by stochastic gradient\n  descent, the algorithm ubiquitously used for parameter optimization\n  in machine learning.  In the asymptotic regime, we study the\n  fluctuations around the optimal representation and show that they\n  arise at a scale $O(n^{-1})$.  These fluctuations in the landscape\n  identify the natural scale for the noise in stochastic gradient\n  descent.  Our results apply to both single and multi-layer neural\n  networks, as well as standard kernel methods like radial basis\n  functions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gen-Oja", "Title": "Simple & Efficient Algorithm for Streaming Generalized Eigenvector Computation", "Abstract": "In this paper, we study the problems of principle Generalized Eigenvector computation and Canonical Correlation Analysis in the stochastic setting. We propose a simple and efficient algorithm for these problems. We prove the global convergence of our algorithm, borrowing ideas from the theory of fast-mixing Markov chains and two-Time-Scale Stochastic Approximation, showing that it achieves the optimal rate of convergence. In the process, we develop tools for understanding stochastic processes with Markovian noise which might be of independent interest."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BRUNO", "Title": "A Deep Recurrent Model for Exchangeable Data", "Abstract": "We present a novel model architecture which leverages deep learning tools to perform exact Bayesian inference on sets of high dimensional, complex observations. Our model is provably exchangeable, meaning that the joint distribution over observations is invariant under permutation: this property lies at the heart of Bayesian inference. The model does not require variational approximations to train, and new samples can be generated conditional on previous samples, with cost linear in the size of the conditioning set. The advantages of our architecture are demonstrated on learning tasks that require generalisation from short observed sequences while modelling sequence variability, such as conditional image generation, few-shot learning, and anomaly detection."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Solving Non-smooth Constrained Programs with Lower Complexity than $\\mathcal{O}(1/\\varepsilon)$", "Title": "A Primal-Dual Homotopy Smoothing Approach", "Abstract": "We propose a new primal-dual homotopy smoothing algorithm for a linearly constrained convex program, where neither the primal nor the dual function has to be smooth or strongly convex. The best known iteration complexity solving such a non-smooth problem is $\\mathcal{O}(\\varepsilon^{-1})$. In this paper, \nwe show that by leveraging a local error bound condition on the dual function, the proposed algorithm can achieve a better primal convergence time of  $\\mathcal{O}\\l(\\varepsilon^{-2/(2+\\beta)}\\log_2(\\varepsilon^{-1})\\r)$, where $\\beta\\in(0,1]$ is a local error bound parameter. \nAs an example application, we show that the distributed geometric median problem, which can be formulated as a constrained convex program, has its dual function non-smooth but satisfying the aforementioned local error bound condition with $\\beta=1/2$, therefore enjoying a convergence time of $\\mathcal{O}\\l(\\varepsilon^{-4/5}\\log_2(\\varepsilon^{-1})\\r)$. This result improves upon the $\\mathcal{O}(\\varepsilon^{-1})$ convergence time bound achieved by existing distributed optimization algorithms. Simulation experiments also demonstrate the performance of our proposed algorithm."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "cpSGD", "Title": "Communication-efficient and differentially-private distributed SGD", "Abstract": "Distributed stochastic gradient descent is an important subroutine in distributed learning. A setting of particular interest is when the clients are mobile devices, where two important concerns are communication efficiency and the privacy of the clients. Several recent works have focused on reducing the communication cost or introducing privacy guarantees, but none of the proposed communication efficient methods are known to be privacy preserving and none of the known privacy mechanisms are known to be communication efficient. To this end, we study algorithms that achieve both communication efficiency and differential privacy. For $d$ variables and $n \\approx d$ clients, the proposed method uses $\\cO(\\log \\log(nd))$ bits of communication per client per coordinate and ensures constant privacy.\n\nWe also improve previous analysis of the \\emph{Binomial mechanism} showing that it achieves nearly the same utility as the Gaussian mechanism, while requiring fewer representation bits, which can be of independent interest."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GPyTorch", "Title": "Blackbox Matrix-Matrix Gaussian Process Inference with GPU Acceleration", "Abstract": "Despite advances in scalable models, the inference tools used for Gaussian processes (GPs) have yet to fully capitalize on developments in computing hardware. We present an efficient and general approach to GP inference based on Blackbox Matrix-Matrix multiplication (BBMM). BBMM inference uses a modified batched version of the conjugate gradients algorithm to derive all terms for training and inference in a single call. BBMM reduces the asymptotic complexity of exact GP inference from O(n^3) to O(n^2). Adapting this algorithm to scalable approximations and complex GP models simply requires a routine for efficient matrix-matrix multiplication with the kernel and its derivative. In addition, BBMM uses a specialized preconditioner to substantially speed up convergence. In experiments we show that BBMM effectively uses GPU hardware to dramatically accelerate both exact GP inference and scalable approximations. Additionally, we provide GPyTorch, a software platform for scalable GP inference via BBMM, built on PyTorch."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PacGAN", "Title": "The power of two samples in generative adversarial networks", "Abstract": "Generative adversarial networks (GANs) are a technique for learning generative models of complex data distributions from samples. Despite remarkable advances in generating realistic images, a major shortcoming of GANs is the fact that they tend to produce samples with little diversity, even when trained on diverse datasets. This phenomenon, known as mode collapse, has been the focus of much recent work. We study a principled approach to handling mode collapse, which we call packing. The main idea is to modify the discriminator to make decisions based on multiple samples from the same class, either real or artificially generated. We draw analysis tools from binary hypothesis testing---in particular the seminal result of Blackwell---to prove a fundamental connection between packing and mode collapse. We show that packing naturally penalizes generators with mode collapse, thereby favoring generator distributions with less mode collapse during the training process. Numerical experiments on benchmark datasets suggest that packing provides significant improvements."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multilingual Anchoring", "Title": "Interactive Topic Modeling and Alignment Across Languages", "Abstract": "Multilingual topic models can reveal patterns in cross-lingual document collections. However, existing models lack speed and interactivity, which prevents adoption in everyday corpora exploration or quick moving situations (e.g., natural disasters, political instability). First, we propose a multilingual anchoring algorithm that builds an anchor-based topic model for documents in different languages. Then, we incorporate interactivity to develop MTAnchor (Multilingual Topic Anchors), a system that allows users to refine the topic model. We test our algorithms on labeled English, Chinese, and Sinhalese documents. Within minutes, our methods can produce interpretable topics that are useful for specific classification tasks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepPINK", "Title": "reproducible feature selection in deep neural networks", "Abstract": "Deep learning has become increasingly popular in both supervised and unsupervised machine learning thanks to its outstanding empirical performance. However, because of their intrinsic complexity, most deep learning methods are largely treated as black box tools with little interpretability. Even though recent attempts have been made to facilitate the interpretability of deep neural networks (DNNs), existing methods are susceptible to noise and lack of robustness. Therefore, scientists are justifiably cautious about the reproducibility of the discoveries, which is often related to the interpretability of the underlying statistical models. In this paper, we describe a method to increase the interpretability and reproducibility of DNNs by incorporating the idea of feature selection with controlled error rate. By designing a new DNN architecture and integrating it with the recently proposed knockoffs framework, we perform feature selection with a controlled error rate, while maintaining high power. This new method, DeepPINK (Deep feature selection using Paired-Input Nonlinear Knockoffs), is applied to both simulated and real data sets to demonstrate its empirical utility."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Supervised autoencoders", "Title": "Improving generalization performance with unsupervised regularizers", "Abstract": "Generalization performance is a central goal in machine learning, particularly when learning representations with large neural networks. A common strategy to improve generalization has been through the use of regularizers, typically as a norm constraining the parameters. Regularizing hidden layers in a neural network architecture, however, is not straightforward. There have been a few effective layer-wise suggestions, but without theoretical guarantees for improved performance. In this work, we theoretically and empirically analyze one such model, called a supervised auto-encoder: a neural network that predicts both inputs (reconstruction error) and targets jointly. We provide a novel generalization result for linear auto-encoders, proving uniform stability based on the inclusion of the reconstruction error---particularly as an improvement on simplistic regularization such as norms or even on more advanced regularizations such as the use of auxiliary tasks. Empirically, we then demonstrate that, across an array of architectures with a different number of hidden units and activation functions, the supervised auto-encoder compared to the corresponding standard neural network never harms performance and can significantly improve generalization."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Plug-in Estimation in High-Dimensional Linear Inverse Problems", "Title": "A Rigorous Analysis", "Abstract": "Estimating a vector $\\mathbf{x}$ from noisy linear measurements $\\mathbf{Ax+w}$ often requires use of prior knowledge or structural constraints\non $\\mathbf{x}$ for accurate reconstruction. Several recent works have considered combining linear least-squares estimation with a generic or plug-in ``denoiser\" function that can be designed in a modular manner based on the prior knowledge about $\\mathbf{x}$. While these methods have shown excellent performance, it has been difficult to obtain rigorous performance guarantees. This work considers plug-in denoising combined with the recently-developed Vector Approximate Message Passing (VAMP) algorithm, which is itself derived via Expectation Propagation techniques. It shown that the mean squared error of this ``plug-in\"  VAMP can be exactly predicted for a large class of high-dimensional random $\\Abf$ and denoisers. The method is illustrated in image reconstruction and parametric bilinear estimation."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pipe-SGD", "Title": "A Decentralized Pipelined SGD Framework for Distributed Deep Net Training", "Abstract": "Distributed training of deep nets is an important technique to address some of the present day computing challenges like memory consumption and computational demands. Classical distributed approaches, synchronous or asynchronous, are based on the parameter server architecture, i.e., worker nodes compute gradients which are communicated to the parameter server while updated parameters are returned. Recently, distributed training with AllReduce operations gained popularity as well. While many of those operations seem appealing, little is reported about wall-clock training time improvements. In this paper, we carefully analyze the AllReduce based setup, propose timing models which include network latency, bandwidth, cluster size and compute time, and demonstrate that a pipelined training with a width of two combines the best of both synchronous and asynchronous training. Specifically, for a setup consisting of a four-node GPU cluster we show wall-clock time training improvements of up to 5.4x compared to conventional approaches."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Diverse Ensemble Evolution", "Title": "Curriculum Data-Model Marriage", "Abstract": "We study a new method (``Diverse Ensemble Evolution (DivE$^2$)'') to train an ensemble of machine learning models that assigns data to models at each training epoch based on each model's current expertise and an intra- and inter-model diversity reward.  DivE$^2$ schedules, over the course of training epochs, the relative importance of these characteristics; it starts by selecting easy samples for each model, and then gradually adjusts towards the models having specialized and complementary expertise on subsets of the training data, thereby encouraging high accuracy of the ensemble.  We utilize an intra-model diversity term on data assigned to each model, and an inter-model diversity term on data assigned to pairs of models, to penalize both within-model and cross-model redundancy.  We formulate the data-model marriage problem as a generalized bipartite matching, represented as submodular maximization subject to two matroid constraints. DivE$^2$ solves a sequence of continuous-combinatorial optimizations with slowly varying objectives and constraints. The combinatorial part handles the data-model marriage while the continuous part updates model parameters based on the assignments. In experiments, DivE$^2$ outperforms other ensemble training methods under a variety of model aggregation techniques, while also maintaining competitive efficiency."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Modular Networks", "Title": "Learning to Decompose Neural Computation", "Abstract": "Scaling model capacity has been vital in the success of deep learning. For a typical network, necessary compute resources and training time grow dramatically with model size. Conditional computation is a promising way to increase the number of parameters with a relatively small increase in resources. We propose a training algorithm that flexibly chooses neural modules based on the data to be processed. Both the decomposition and modules are learned end-to-end. In contrast to existing approaches, training does not rely on regularization to enforce diversity in module use. We apply modular networks both to image recognition and language modeling tasks, where we achieve superior performance compared to several baselines. Introspection reveals that modules specialize in interpretable contexts."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deepcode", "Title": "Feedback Codes via Deep Learning", "Abstract": "We break this logjam by integrating information theoretic insights harmoniously with recurrent-neural-network based encoders and decoders to create novel codes that outperform known codes by 3 orders of magnitude in reliability. We also demonstrate several desirable properties in the codes: (a) generalization to larger block lengths; (b) composability with known codes; (c) adaptation to practical constraints. This result also presents broader ramifications to coding theory: even when the channel has a clear mathematical model, deep learning methodologies, when combined with channel specific information-theoretic insights, can potentially beat state-of-the-art codes, constructed over decades of mathematical research."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ATOMO", "Title": "Communication-efficient Learning via Atomic Sparsification", "Abstract": "Distributed model training suffers from communication overheads due to frequent gradient updates transmitted between compute nodes. To mitigate these overheads, several studies propose the use of sparsified stochastic gradients. We argue that these are facets of a general sparsification method that can operate on any possible atomic decomposition. Notable examples include element-wise, singular value, and Fourier decompositions. We present ATOMO, a general framework for atomic sparsification of stochastic gradients. Given a gradient, an atomic decomposition, and a sparsity budget, ATOMO gives a random unbiased sparsification of the atoms minimizing variance. We show that recent methods such as QSGD and TernGrad are special cases of ATOMO, and that sparsifiying the singular value decomposition of neural networks gradients, rather than their coordinates, can lead to significantly faster distributed training."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Risk and Robustness", "Title": "General Definitions and Implications for the Uniform Distribution", "Abstract": "Using the error-region definition of adversarial perturbations, we then study inherent bounds on risk and robustness of any classifier for any classification problem whose instances are uniformly distributed over {0,1}^n. Using the isoperimetric inequality for the Boolean hypercube, we show that for initial error 0.01, there always exists an adversarial perturbation that changes O(√n) bits of the instances to increase the risk to 0.5, making classifier's decisions meaningless. Furthermore, by also using the central limit theorem we show that when n→∞, at most c√n bits of perturbations, for a universal constant c<1.17, suffice for increasing the risk to 0.5, and the same c√n bits of perturbations on average suffice to increase the risk to 1, hence bounding the robustness by c√n."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Backpropagation with Callbacks", "Title": "Foundations for Efficient and Expressive Differentiable Programming", "Abstract": "Our approach achieves the same flexibility as other reverse-mode automatic\ndifferentiation (AD) techniques, but it can be implemented without any auxiliary\ndata structures besides the function call stack, and it can easily be combined\nwith graph construction and native code generation techniques through forms of\nmulti-stage programming, leading to a highly efficient implementation that\ncombines the performance benefits of define-then-run software frameworks such\nas TensorFlow with the expressiveness of define-by-run frameworks such as PyTorch."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Graphical model inference", "Title": "Sequential Monte Carlo meets deterministic approximations", "Abstract": "Approximate inference in probabilistic graphical models (PGMs) can be grouped into deterministic methods and Monte-Carlo-based methods. The former can often provide accurate and rapid inferences, but are typically associated with biases that are hard to quantify. The latter enjoy asymptotic consistency, but can suffer from high computational costs. In this paper we present a way of bridging the gap between deterministic and stochastic inference. Specifically, we suggest an efficient sequential Monte Carlo (SMC) algorithm for PGMs which can leverage the output from deterministic inference methods. While generally applicable, we show explicitly how this can be done with loopy belief propagation, expectation propagation, and Laplace approximations. The resulting algorithm can be viewed as a post-correction of the biases associated with these methods and, indeed, numerical results show clear improvements over the baseline deterministic methods as well as over \"plain\" SMC."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DropMax", "Title": "Adaptive Variational Softmax", "Abstract": "We propose DropMax, a stochastic version of softmax classifier which at each iteration drops non-target classes according to dropout probabilities adaptively decided for each instance. Specifically, we overlay binary masking variables over class output probabilities, which are input-adaptively learned via variational inference. This stochastic regularization has an effect of building an ensemble classifier out of exponentially many classifiers with different decision boundaries. Moreover, the learning of dropout rates for non-target classes on each instance allows the classifier to focus more on classification against the most confusing classes. We validate our model on multiple public datasets for classification, on which it obtains significantly improved accuracy over the regular softmax classifier and other baselines. Further analysis of the learned dropout probabilities shows that our model indeed selects confusing classes more often when it performs classification."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rest-Katyusha", "Title": "Exploiting the Solution's Structure via Scheduled Restart Schemes", "Abstract": "We propose a structure-adaptive variant of the state-of-the-art stochastic variance-reduced gradient algorithm Katyusha for  regularized empirical risk minimization. The proposed method is able to exploit the intrinsic low-dimensional structure of the solution, such as sparsity or low rank which is enforced by a non-smooth regularization, to achieve even faster convergence rate. This provable algorithmic improvement is done by restarting the Katyusha algorithm according to restricted strong-convexity constants. We demonstrate the effectiveness of our approach via numerical experiments."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mesh-TensorFlow", "Title": "Deep Learning for Supercomputers", "Abstract": "Batch-splitting (data-parallelism) is the dominant distributed Deep Neural Network (DNN) training strategy, due to its universal applicability and its amenability to Single-Program-Multiple-Data (SPMD) programming.  However, batch-splitting suffers from problems including the inability to train very large models (due to memory constraints), high latency, and inefficiency at small batch sizes.  All of these can be solved by more general distribution strategies (model-parallelism).  Unfortunately, efficient model-parallel algorithms tend to be complicated to discover, describe, and to implement, particularly on large clusters.  We introduce Mesh-TensorFlow, a language for specifying a general class of distributed tensor computations.  Where data-parallelism can be viewed as splitting tensors and operations along the \"batch\" dimension, in Mesh-TensorFlow, the user can specify any tensor-dimensions to be split across any dimensions of a multi-dimensional mesh of processors.  A Mesh-TensorFlow graph compiles into a SPMD program consisting of parallel operations coupled with collective communication primitives such as Allreduce.  We use Mesh-TensorFlow to implement an efficient data-parallel, model-parallel version of the Transformer sequence-to-sequence model.  Using TPU meshes of up to 512 cores, we train Transformer models with up to 5 billion parameters, surpassing SOTA results on WMT'14 English-to-French translation task and the one-billion-word Language modeling benchmark.  Mesh-Tensorflow is available at https://github.com/tensorflow/mesh"}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Privacy Amplification by Subsampling", "Title": "Tight Analyses via Couplings and Divergences", "Abstract": "Differential privacy comes equipped with multiple analytical tools for the\ndesign of private data analyses. One important tool is the so-called \"privacy\namplification by subsampling\" principle, which ensures that a differentially\nprivate mechanism run on a random subsample of a population provides higher\nprivacy guarantees than when run on the entire population. Several instances\nof this principle have been studied for different random subsampling methods,\neach with an ad-hoc analysis.  In this paper we present a general method that\nrecovers and improves prior analyses, yields lower bounds and derives new\ninstances of privacy amplification by subsampling. Our method leverages a\ncharacterization of differential privacy as a divergence which emerged in the\nprogram verification community. Furthermore, it introduces new tools,\nincluding advanced joint convexity and privacy profiles, which might be of\nindependent interest."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The challenge of realistic music generation", "Title": "modelling raw audio at scale", "Abstract": "Realistic music generation is a challenging task. When building generative models of music that are learnt from data, typically high-level representations such as scores or MIDI are used that abstract away the idiosyncrasies of a particular performance. But these nuances are very important for our perception of musicality and realism, so in this work we embark on modelling music in the raw audio domain. It has been shown that autoregressive models excel at generating raw audio waveforms of speech, but when applied to music, we find them biased towards capturing local signal structure at the expense of modelling long-range correlations. This is problematic because music exhibits structure at many different timescales. In this work, we explore autoregressive discrete autoencoders (ADAs) as a means to enable autoregressive models to capture long-range correlations in waveforms. We find that they allow us to unconditionally generate piano music directly in the raw audio domain, which shows stylistic consistency across tens of seconds."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Designing by Training", "Title": "Acceleration Neural Network for Fast High-Dimensional Convolution", "Abstract": "The high-dimensional convolution is widely used in various disciplines but has a serious performance problem due to its high computational complexity. Over the decades, people took a handmade approach to design fast algorithms for the Gaussian convolution. Recently, requirements for various non-Gaussian convolutions have emerged and are continuously getting higher. However, the handmade acceleration approach is no longer feasible for so many different convolutions since it is a time-consuming and painstaking job. Instead, we propose an Acceleration Network (AccNet) which turns the work of designing new fast algorithms to training the AccNet. This is done by: 1, interpreting splatting, blurring, slicing operations as convolutions; 2, turning these convolutions to $g$CP layers to build AccNet. After training,  the activation function $g$ together with AccNet weights automatically define the new splatting, blurring and slicing operations. Experiments demonstrate AccNet is able to design acceleration algorithms for a ton of convolutions including Gaussian/non-Gaussian convolutions and produce state-of-the-art results."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Lipschitz-Margin Training", "Title": "Scalable Certification of Perturbation Invariance for Deep Neural Networks", "Abstract": "High sensitivity of neural networks against malicious perturbations on inputs causes security concerns. To take a steady step towards robust classifiers, we aim to create neural network models provably defended from perturbations. Prior certification work requires strong assumptions on network structures and massive computational costs, and thus the range of their applications was limited. From the relationship between the Lipschitz constants and prediction margins, we present a computationally efficient calculation technique to lower-bound the size of adversarial perturbations that can deceive networks, and that is widely applicable to various complicated networks. Moreover, we propose an efficient training procedure that robustifies networks and significantly improves the provably guarded areas around data points. In experimental evaluations, our method showed its ability to provide a non-trivial guarantee and enhance robustness for even large networks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "3D Steerable CNNs", "Title": "Learning Rotationally Equivariant Features in Volumetric Data", "Abstract": "We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived analytically in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R^3. Our experimental results confirm the effectiveness of 3D Steerable CNNs for the problem of amino acid propensity prediction and protein structure classification, both of which have inherent SE(3) symmetry."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Functional Dictionaries", "Title": "Learning Consistent Semantic Structures on 3D Models from Functions", "Abstract": "Various 3D semantic attributes such as segmentation masks, geometric features, keypoints, and materials can be encoded as per-point probe functions on 3D geometries. Given a collection of related 3D shapes, we consider how to jointly analyze such probe functions over different shapes, and how to discover common latent structures using a neural network — even in the absence of any correspondence information. Our network is trained on point cloud representations of shape geometry and associated semantic functions on that point cloud. These functions express a shared semantic understanding of the shapes but are not coordinated in any way. For example, in a segmentation task, the functions can be indicator functions of arbitrary sets of shape parts, with the particular combination involved not known to the network. Our network is able to produce a small dictionary of basis functions for each shape, a dictionary whose span includes the semantic functions provided for that shape. Even though our shapes have independent discretizations and no functional correspondences are provided, the network is able to generate latent bases, in a consistent order, that reflect the shared semantic structure among the shapes. We demonstrate the effectiveness of our technique in various segmentation and keypoint selection applications."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Moonshine", "Title": "Distilling with Cheap Convolutions", "Abstract": "Many engineers wish to deploy modern neural networks in memory-limited settings; but the development of flexible methods for reducing memory use is in its infancy, and there is little knowledge of the resulting cost-benefit. We propose structural model distillation for memory reduction using a strategy that produces a student architecture that is a simple transformation of the teacher architecture: no redesign is needed, and the same hyperparameters can be used. Using attention transfer, we provide Pareto curves/tables for distillation of residual networks with four benchmark datasets, indicating the memory versus accuracy payoff. We show that substantial memory savings are possible with very little loss of accuracy, and confirm that distillation provides student network performance that is better than training that student architecture directly on data."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Exploiting Numerical Sparsity for Efficient Learning ", "Title": "Faster Eigenvector Computation and Regression", "Abstract": "In this paper, we obtain improved running times for regression and top eigenvector computation for numerically sparse matrices. Given a data matrix $\\mat{A} \\in \\R^{n \\times d}$ where every row $a \\in \\R^d$ has $\\|a\\|_2^2 \\leq L$ and numerical sparsity $\\leq s$, i.e. $\\|a\\|_1^2 / \\|a\\|_2^2 \\leq s$, we provide faster algorithms for these problems for many parameter settings.\n\nFor top eigenvector computation, when $\\gap > 0$ is the relative gap between the top two eigenvectors of $\\mat{A}^\\top \\mat{A}$ and $r$ is the stable rank of $\\mat{A}$ we obtain a running time of $\\otilde(nd + r(s + \\sqrt{r s}) / \\gap^2)$ improving upon the previous best unaccelerated running time of $O(nd + r d / \\gap^2)$. As $r \\leq d$ and $s \\leq d$ our algorithm everywhere improves or matches the previous bounds for all parameter settings.\n\nFor regression, when $\\mu > 0$ is the smallest eigenvalue of $\\mat{A}^\\top \\mat{A}$ we obtain a running time of $\\otilde(nd + (nL / \\mu) \\sqrt{s nL / \\mu})$ improving upon the previous best unaccelerated running time of $\\otilde(nd + n L d / \\mu)$. This result expands when regression can be solved in nearly linear time from when $L/\\mu = \\otilde(1)$ to when $L / \\mu = \\otilde(d^{2/3} / (sn)^{1/3})$.\n\nFurthermore, we obtain similar improvements even when row norms and numerical sparsities are non-uniform and we show how to achieve even faster running times by accelerating using approximate proximal point \\cite{frostig2015regularizing} / catalyst \\cite{lin2015universal}. Our running times depend only on the size of the input and natural numerical measures of the matrix, i.e. eigenvalues and $\\ell_p$ norms, making progress on a key open problem regarding optimal running times for efficient large-scale learning."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Everlasting Database", "Title": "Statistical Validity at a Fair Price", "Abstract": "The problem of handling adaptivity in data analysis, intentional or not,  permeates\n  a variety of fields, including  test-set overfitting in ML challenges and the\n  accumulation of invalid scientific discoveries.\n  We propose a mechanism for answering an arbitrarily long sequence of\n  potentially adaptive statistical queries, by charging a price for\n  each query and using the proceeds to collect additional samples.\n  Crucially, we guarantee statistical validity without any assumptions on\n  how the queries are generated. We also ensure with high probability that\n  the cost for $M$ non-adaptive queries is $O(\\log M)$,\n  while the cost to a potentially adaptive user who makes $M$\n  queries that do not depend on any others is $O(\\sqrt{M})$."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimization of Smooth Functions with Noisy Observations", "Title": "Local Minimax Rates", "Abstract": "We consider the problem of global optimization of an unknown non-convex smooth function with noisy zeroth-order feedback. We propose a local minimax framework to study the fundamental difficulty of optimizing smooth functions with adaptive function evaluations. We show that for functions with fast growth around their global minima, carefully designed optimization algorithms can identify a near global minimizer with many fewer queries than worst-case global minimax theory predicts. For the special case of strongly convex and smooth functions, our implied convergence rates match the ones developed for zeroth-order convex optimization problems. On the other hand, we show that in the worst case no algorithm can converge faster than the minimax rate of estimating an unknown functions in linf-norm. Finally, we show that non-adaptive algorithms, although optimal in a global minimax sense, do not attain the optimal local minimax rate."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "e-SNLI", "Title": "Natural Language Inference with Natural Language Explanations", "Abstract": "In order for machine learning to garner widespread public adoption, models must be able to provide interpretable and robust explanations for their decisions, as well as learn from human-provided explanations at train time. In this work, we extend the Stanford Natural Language Inference dataset with an additional layer of human-annotated natural language explanations of the entailment relations. We further implement models that incorporate these explanations into their training process and output them at test time. We show how our corpus of explanations, which we call e-SNLI, can be used for various goals, such as obtaining full sentence justifications of a model’s decisions, improving universal sentence representations and transferring to out-of-domain NLI datasets. Our dataset thus opens up a range of research directions for using natural language explanations, both for improving models and for asserting their trust"}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaGAN", "Title": "An Adversarial Approach to Few-Shot Learning", "Abstract": "In this paper, we propose a conceptually simple and general framework called MetaGAN for few-shot learning problems. Most state-of-the-art few-shot classification models can be integrated with MetaGAN in a principled and straightforward way. By introducing an adversarial generator conditioned on tasks, we augment vanilla few-shot classification models with the ability to discriminate between real and fake data.  We argue that this GAN-based approach can help few-shot classifiers to learn sharper decision boundary, which could generalize better. We show that with our MetaGAN framework, we can extend supervised few-shot learning models to naturally cope with unsupervised data. Different from previous work in semi-supervised few-shot learning, our algorithms can deal with semi-supervision at both sample-level and task-level. We give theoretical justifications of the strength of MetaGAN, and validate the effectiveness of MetaGAN on challenging few-shot image classification benchmarks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Grids", "Title": "Learning Graph Representations for Visual Recognition", "Abstract": "We propose learning graph representations from 2D feature maps for visual recognition. Our method draws inspiration from region based recognition, and learns to transform a 2D image into a graph structure. The vertices of the graph define clusters of pixels (\"regions\"), and the edges measure the similarity between these clusters in a feature space. Our method further learns to propagate information across all vertices on the graph, and is able to project the learned graph representation back into 2D grids. Our graph representation facilitates reasoning beyond regular grids and can capture long range dependencies among regions. We demonstrate that our model can be trained from end-to-end, and is easily integrated into existing networks. Finally, we evaluate our method on three challenging recognition tasks: semantic segmentation, object detection and object instance segmentation. For all tasks, our method outperforms state-of-the-art methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularization Learning Networks", "Title": "Deep Learning for Tabular Datasets", "Abstract": "Despite their impressive performance, Deep Neural Networks (DNNs) typically underperform Gradient Boosting Trees (GBTs) on many tabular-dataset learning tasks. We propose that applying a different regularization coefficient to each weight might boost the performance of DNNs by allowing them to make more use of the more relevant inputs. However, this will lead to an intractable number of hyperparameters. Here, we introduce Regularization Learning Networks (RLNs), which overcome this challenge by introducing an efficient hyperparameter tuning scheme which minimizes a new Counterfactual Loss. Our results show that RLNs significantly improve DNNs on tabular datasets, and achieve comparable results to GBTs, with the best performance achieved with an ensemble that combines GBTs and RLNs. RLNs produce extremely sparse networks, eliminating up to 99.8% of the network edges and 82% of the input features, thus providing more interpretable models and reveal the importance that the network assigns to different inputs. RLNs could efficiently learn a single network in datasets that comprise both tabular and unstructured data, such as in the setting of medical imaging accompanied by electronic health records. An open source implementation of RLN can be found at https://github.com/irashavitt/regularizationlearningnetworks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bias and Generalization in Deep Generative Models", "Title": "An Empirical Study", "Abstract": "In high dimensional settings, density estimation algorithms rely crucially on their inductive bias. Despite recent empirical success, the inductive bias of deep generative models is not well understood. In this paper we propose a framework to systematically investigate bias and generalization in deep generative models of images by probing the learning algorithm with carefully designed training datasets. By measuring properties of the learned distribution, we are able to find interesting patterns of generalization. We verify that these patterns are consistent across datasets, common models and architectures."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SING", "Title": "Symbol-to-Instrument Neural Generator", "Abstract": "Recent progress in deep learning for audio synthesis opens\nthe way to models that directly produce the waveform, shifting away\nfrom the traditional paradigm of relying on vocoders or MIDI synthesizers for speech or music generation. Despite\ntheir successes, current state-of-the-art neural audio synthesizers such\nas WaveNet and SampleRNN suffer from prohibitive training and inference times because they are based on\nautoregressive models that generate audio samples one at a time at a rate of 16kHz. In\nthis work, we study the more computationally efficient alternative of generating the waveform frame-by-frame with large strides.\nWe present a lightweight neural audio synthesizer for the original task of generating musical notes given desired instrument, pitch and velocity. Our model is trained end-to-end to generate notes from nearly 1000 instruments with a single decoder, thanks to a new loss function that minimizes the distances between the log spectrograms of the generated and target waveforms.\nOn the generalization task of synthesizing notes for pairs of pitch and instrument not seen during training, SING produces audio with significantly improved perceptual quality compared to a state-of-the-art autoencoder based on WaveNet  as measured by a Mean Opinion Score (MOS), and is about 32 times faster for training and 2, 500 times faster for inference."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LinkNet", "Title": "Relational Embedding for Scene Graph", "Abstract": "Objects and their relationships are critical contents for image understanding. A scene graph provides a structured description that captures these properties of an image. However, reasoning about the relationships between objects is very challenging and only a few recent works have attempted to solve the problem of generating a scene graph from an image. In this paper, we present a novel method that improves scene graph generation by explicitly modeling inter-dependency among the entire object instances. We design a simple and effective relational embedding module that enables our model to jointly represent connections among all related objects, rather than focus on an object in isolation. Our novel method significantly benefits two main parts of the scene graph generation task: object classification and relationship classification. Using it on top of a basic Faster R-CNN, our model achieves state-of-the-art results on the Visual Genome benchmark. We further push the performance by introducing global context encoding module and geometrical layout encoding module. We validate our final model, LinkNet, through extensive ablation studies, demonstrating its efficacy in scene graph generation."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Tangent Kernel", "Title": "Convergence and Generalization in Neural Networks", "Abstract": "Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GLoMo", "Title": "Unsupervised Learning of Transferable Relational Graphs", "Abstract": "Modern deep transfer learning approaches have mainly focused on learning generic feature vectors from one task that are transferable to other tasks, such as word embeddings in language and pretrained convolutional features in vision. However, these approaches usually transfer unary features and largely ignore more structured graphical representations. This work explores the possibility of learning generic latent relational graphs that capture dependencies between pairs of data units (e.g., words or pixels) from large-scale unlabeled data and transferring the graphs to downstream tasks. Our proposed transfer learning framework improves performance on various tasks including question answering, natural language inference, sentiment analysis, and image classification. We also show that the learned graphs are generic enough to be transferred to different embeddings on which the graphs have not been trained (including GloVe embeddings, ELMo embeddings, and task-specific RNN hidden units), or embedding-free units such as image pixels."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural-Symbolic VQA", "Title": "Disentangling Reasoning from Vision and Language Understanding", "Abstract": "We marry two powerful ideas: deep representation learning for visual recognition and language understanding, and symbolic program execution for reasoning. Our neural-symbolic visual question answering (NS-VQA) system first recovers a structural scene representation from the image and a program trace from the question. It then executes the program on the scene representation to obtain an answer. Incorporating symbolic structure as prior knowledge offers three unique advantages. First, executing programs on a symbolic space is more robust to long program traces; our model can solve complex reasoning tasks better, achieving an accuracy of 99.8% on the CLEVR dataset. Second, the model is more data- and memory-efficient: it performs well after learning on a small number of training data; it can also encode an image into a compact representation, requiring less storage than existing methods for offline question answering. Third, symbolic program execution offers full transparency to the reasoning process; we are thus able to interpret and diagnose each execution step."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Towards Understanding Learning Representations", "Title": "To What Extent Do Different Neural Networks Learn the Same Representation", "Abstract": "It is widely believed that learning good representations is one of the main reasons for the success of deep neural networks. Although highly intuitive, there is a lack of theory and systematic approach quantitatively characterizing what representations do deep neural networks learn. In this work, we move a tiny step towards a theory and better understanding of the representations. Specifically, we study a simpler problem: How similar are the representations learned by two networks with identical architecture but trained from different initializations.  We develop a rigorous theory based on the neuron activation subspace match model. The theory gives a complete characterization of the structure of neuron activation subspace matches, where the core concepts are maximum match and simple match which describe the overall and the finest similarity between sets of neurons in two networks respectively. We also propose efficient algorithms to find the maximum match and simple matches. Finally, we conduct extensive experiments using our algorithms. Experimental results suggest that, surprisingly, representations learned by the same convolutional layers of networks trained from different initializations are not as similar as prevalently expected, at least in terms of subspace match."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learn What Not to Learn", "Title": "Action Elimination with Deep Reinforcement Learning", "Abstract": "Learning how to act when there are many available actions in each state is a challenging task for Reinforcement Learning (RL) agents, especially when many of the actions are redundant or irrelevant. In such cases, it is easier to learn which actions not to take. In this work, we propose the Action-Elimination Deep Q-Network (AE-DQN) architecture that combines a Deep RL algorithm with an Action Elimination Network (AEN) that eliminates sub-optimal actions. The AEN is trained to predict invalid actions, supervised by an external elimination signal provided by the environment. Simulations demonstrate a considerable speedup and added robustness over vanilla DQN in text-based games with over a thousand discrete actions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaReg", "Title": "Towards Domain Generalization using Meta-Regularization", "Abstract": "Training models that generalize to new domains at test time is a problem of fundamental importance in machine learning. In this work, we encode this notion of domain generalization using a novel regularization function. We pose the problem of finding such a regularization function in a Learning to Learn (or) meta-learning framework. The objective of domain generalization is explicitly modeled by learning a regularizer that makes the model trained on one domain to perform well on another domain. Experimental validations on computer vision and natural language datasets indicate that our method can learn regularizers that achieve good cross-domain generalization."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How SGD Selects the Global Minima in Over-parameterized Learning", "Title": "A Dynamical Stability Perspective", "Abstract": "The question of which global minima are accessible by a stochastic gradient decent (SGD)  algorithm with specific learning rate and batch size is studied from the perspective of dynamical stability.  The concept of non-uniformity is introduced, which, together with sharpness, characterizes the stability property of a global minimum and hence the accessibility of a particular SGD algorithm to that global minimum. In particular, this analysis shows that  learning rate and batch size play different roles in minima selection.  Extensive empirical results seem to correlate well with the theoretical findings and provide further support to these  claims."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TADAM", "Title": "Task dependent adaptive metric for improved few-shot learning", "Abstract": "Few-shot learning has become essential for producing models that generalize from few examples. In this work, we identify that metric scaling and metric task conditioning are important to improve the performance of few-shot algorithms. Our analysis reveals that simple metric scaling completely changes the nature of few-shot algorithm parameter updates. Metric scaling provides improvements up to 14% in accuracy for certain metrics on the mini-Imagenet 5-way 5-shot classification task. We further propose a simple and effective way of conditioning a learner on the task sample set, resulting in learning a task-dependent metric space. Moreover, we propose and empirically test a practical end-to-end optimization procedure based on auxiliary task co-training to learn a task-dependent metric space. The resulting few-shot learning model based on the task-dependent scaled metric achieves state of the art on mini-Imagenet. We confirm these results on another few-shot dataset that we introduce in this paper based on CIFAR100."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "New Insight into Hybrid Stochastic Gradient Descent", "Title": "Beyond With-Replacement Sampling and Convexity", "Abstract": "As an incremental-gradient algorithm, the hybrid stochastic gradient descent (HSGD)  enjoys  merits of both stochastic and full gradient methods for finite-sum minimization problem. However, the existing rate-of-convergence analysis for HSGD is made under with-replacement sampling (WRS) and is restricted to convex problems. It is not clear whether HSGD still carries these advantages under the common practice of without-replacement sampling (WoRS) for non-convex problems. In this paper, we affirmatively answer this open question by showing that under WoRS and for both convex and non-convex problems, it is still possible for HSGD (with constant step-size) to match full gradient descent in rate of convergence, while maintaining comparable sample-size-independent incremental first-order oracle  complexity to stochastic gradient descent. For a special class of finite-sum problems with linear prediction models, our convergence results can be further improved in some cases. Extensive numerical results confirm our theoretical affirmation and demonstrate the favorable efficiency of WoRS-based HSGD."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RenderNet", "Title": "A deep convolutional network for differentiable rendering from 3D shapes", "Abstract": "Traditional computer graphics rendering pipelines are designed for procedurally\ngenerating 2D images from 3D shapes with high performance. The nondifferentiability due to discrete operations (such as visibility computation) makes it hard to explicitly correlate rendering parameters and the resulting image, posing a significant challenge for inverse rendering tasks. Recent work on differentiable rendering achieves differentiability either by designing surrogate gradients for non-differentiable operations or via an approximate but differentiable renderer. These methods, however, are still limited when it comes to handling occlusion, and restricted to particular rendering effects. We present RenderNet, a differentiable rendering convolutional network with a novel projection unit that can render 2D images from 3D shapes. Spatial occlusion and shading calculation are automatically encoded in the network. Our experiments show that RenderNet can successfully learn to implement different shaders, and can be used in inverse rendering tasks to estimate shape, pose, lighting and texture from a single image."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaAnchor", "Title": "Learning to Detect Objects with Customized Anchors", "Abstract": "We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks. Unlike many previous detectors model anchors via a predefined manner, in MetaAnchor anchor functions could be dynamically generated from the arbitrary customized prior boxes. Taking advantage of weight prediction, MetaAnchor is able to work with most of the anchor-based object detection systems such as RetinaNet. Compared with the predefined anchor scheme, we empirically find that MetaAnchor is more robust to anchor settings and bounding box distributions; in addition, it also shows the potential on the transfer task. Our experiment on COCO detection task shows MetaAnchor consistently outperforms the counterparts in various scenarios."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ChannelNets", "Title": "Compact and Efficient Convolutional Neural Networks via Channel-Wise Convolutions", "Abstract": "Convolutional neural networks (CNNs) have shown great capability of solving various artificial intelligence tasks. However, the increasing model size has raised challenges in employing them in resource-limited applications. In this work, we propose to compress deep models by using channel-wise convolutions, which replace dense connections among feature maps with sparse ones in CNNs. Based on this novel operation, we build light-weight CNNs known as ChannelNets. ChannelNets use three instances of channel-wise convolutions; namely group channel-wise convolutions, depth-wise separable channel-wise convolutions, and the convolutional classification layer. Compared to prior CNNs designed for mobile devices, ChannelNets achieve a significant reduction in terms of the number of parameters and computational cost without loss in accuracy. Notably, our work represents the first attempt to compress the fully-connected classification layer, which usually accounts for about 25% of total parameters in compact CNNs. Experimental results on the ImageNet dataset demonstrate that ChannelNets achieve consistently better performance compared to prior methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Paraphrasing Complex Network", "Title": "Network Compression via Factor Transfer", "Abstract": "Many researchers have sought ways of model compression to reduce the size of a deep neural network (DNN) with minimal performance degradation in order to use DNNs in embedded systems. Among the model compression methods, a method called knowledge transfer is to train a student network with a stronger teacher network. In this paper, we propose a novel knowledge transfer method which uses convolutional operations to paraphrase teacher's knowledge and to translate it for the student. This is done by two convolutional modules, which are called a paraphraser and a translator. The paraphraser is trained in an unsupervised manner to extract the teacher factors which are defined as paraphrased information of the teacher network. The translator located at the student network extracts the student factors and helps to translate the teacher factors by mimicking them. We observed that our student network trained with the proposed factor transfer method outperforms the ones trained with conventional knowledge transfer methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Where Do You Think You're Going?", "Title": "Inferring Beliefs about Dynamics from Behavior", "Abstract": "Inferring intent from observed behavior has been studied extensively within the frameworks of Bayesian inverse planning and inverse reinforcement learning. These methods infer a goal or reward function that best explains the actions of the observed agent, typically a human demonstrator. Another agent can use this inferred intent to predict, imitate, or assist the human user. However, a central assumption in inverse reinforcement learning is that the demonstrator is close to optimal. While models of suboptimal behavior exist, they typically assume that suboptimal actions are the result of some type of random noise or a known cognitive bias, like temporal inconsistency. In this paper, we take an alternative approach, and model suboptimal behavior as the result of internal model misspecification: the reason that user actions might deviate from near-optimal actions is that the user has an incorrect set of beliefs about the rules -- the dynamics -- governing how actions affect the environment. Our insight is that while demonstrated actions may be suboptimal in the real world, they may actually be near-optimal with respect to the user's internal model of the dynamics. By estimating these internal beliefs from observed behavior, we arrive at a new method for inferring intent. We demonstrate in simulation and in a user study with 12 participants that this approach enables us to more accurately model human intent, and can be used in a variety of applications, including offering assistance in a shared autonomy framework and inferring human preferences."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast Rates of ERM and Stochastic Approximation", "Title": "Adaptive to Error Bound Conditions", "Abstract": "Error bound conditions (EBC) are properties that characterize the growth of an objective function when a point is moved away from the optimal set. They have  recently received increasing attention in the field  of optimization for developing optimization algorithms with fast convergence.  However,  the studies of EBC in statistical learning are hitherto still limited.  The main contributions of this paper are two-fold. First,  we develop fast and intermediate rates of  empirical risk minimization (ERM) under EBC for risk minimization with Lipschitz continuous, and  smooth  convex random functions. Second, we establish fast and intermediate rates of an efficient stochastic approximation (SA) algorithm for risk minimization  with Lipschitz continuous random functions, which requires only one pass of $n$ samples and adapts to EBC. For both approaches, the convergence rates span a full spectrum between $\\widetilde O(1/\\sqrt{n})$ and $\\widetilde O(1/n)$ depending on the power constant in EBC, and could be even faster than $O(1/n)$ in special cases for ERM. Moreover, these  convergence rates are automatically adaptive without using any knowledge of EBC. Overall, this work not only strengthens the understanding of ERM for statistical learning but also brings new fast stochastic algorithms for solving a broad range of statistical learning problems."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Learning without Distress", "Title": "Privacy-Preserving Empirical Risk Minimization", "Abstract": "Distributed learning allows a group of independent data owners to collaboratively learn a model over their data sets without exposing their private data. We present a distributed learning approach that combines differential privacy with secure multi-party computation. We explore two popular methods of differential privacy, output perturbation and gradient perturbation, and advance the state-of-the-art for both methods in the distributed learning setting. In our output perturbation method, the parties combine local models within a secure computation and then add the required differential privacy noise before revealing the model. In our gradient perturbation method, the data owners collaboratively train a global model via an iterative learning algorithm.  At each iteration, the parties aggregate their local gradients within a secure computation, adding sufficient noise to ensure privacy before the gradient updates are revealed. For both methods, we show that the noise can be reduced in the multi-party setting by adding the noise inside the secure computation after aggregation, asymptotically improving upon the best previous results. Experiments on real world data sets demonstrate that our methods provide substantial utility gains for typical privacy requirements."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BRITS", "Title": "Bidirectional Recurrent Imputation for Time Series", "Abstract": "Time series are widely used as signals in many classification/regression tasks. It is ubiquitous that time series contains many missing values. Given multiple correlated time series data, how to fill in missing values and to predict their class labels? Existing imputation methods often impose strong assumptions of the underlying data generating process, such as linear dynamics in the state space. \nIn this paper, we propose BRITS, a novel method based on recurrent neural networks for missing value imputation in time series data.  Our proposed method directly learns the missing values in a bidirectional recurrent dynamical system, without any specific assumption. The imputed values are treated as variables of RNN graph and can be effectively updated during the backpropagation. BRITS has three advantages: (a) it can handle multiple correlated missing values in time series; (b) it generalizes to time series with nonlinear dynamics underlying; (c) it provides a data-driven imputation procedure and applies to general settings with missing data.\nWe evaluate our model on three real-world datasets, including an air quality dataset, a health-care data, and a localization data for human activity.\nExperiments show that our model outperforms the state-of-the-art methods in both imputation and classification/regression accuracies."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VideoCapsuleNet", "Title": "A Simplified Network for Action Detection", "Abstract": "The recent advances in Deep Convolutional Neural Networks (DCNNs) have shown extremely good results for video human action classification, however, action detection is still a challenging problem. The current action detection approaches follow a complex pipeline which involves multiple tasks such as tube proposals, optical flow, and tube classification. In this work, we present a more elegant solution for action detection based on the recently developed capsule network. We propose a 3D capsule network for videos, called VideoCapsuleNet: a unified network for action detection which can jointly perform pixel-wise action segmentation along with action classification. The proposed network is a generalization of capsule network from 2D to 3D, which takes a sequence of video frames as input. The 3D generalization drastically increases the number of capsules in the network, making capsule routing computationally expensive. We introduce capsule-pooling in the convolutional capsule layer to address this issue and make the voting algorithm tractable. The routing-by-agreement in the network inherently models the action representations and various action characteristics are captured by the predicted capsules. This inspired us to utilize the capsules for action localization and the class-specific capsules predicted by the network are used to determine a pixel-wise localization of actions. The localization is further improved by parameterized skip connections with the convolutional capsule layers and the network is trained end-to-end with a classification as well as localization loss. The proposed network achieves state-of-the-art performance on multiple action detection datasets including UCF-Sports, J-HMDB, and UCF-101 (24 classes) with an impressive ~20% improvement on UCF-101 and ~15% improvement on J-HMDB in terms of v-mAP scores."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sequential Attend, Infer, Repeat", "Title": "Generative Modelling of Moving Objects", "Abstract": "We present Sequential Attend, Infer, Repeat (SQAIR), an interpretable deep generative model for image sequences.\nIt can reliably discover and track objects through the sequence; it can also conditionally generate future frames, thereby simulating expected motion of objects. \nThis is achieved by explicitly encoding object numbers, locations and appearances in the latent variables of the model.\nSQAIR retains all strengths of its predecessor, Attend, Infer, Repeat (AIR, Eslami et. al. 2016), including unsupervised learning, made possible by inductive biases present in the model structure.\nWe use a moving multi-\\textsc{mnist} dataset to show limitations of AIR in detecting overlapping or partially occluded objects, and show how \\textsc{sqair} overcomes them by leveraging temporal consistency of objects.\nFinally, we also apply SQAIR to real-world pedestrian CCTV data, where it learns to reliably detect, track and generate walking pedestrians with no supervision."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Interaction Transparency (NIT)", "Title": "Disentangling Learned Interactions for Improved Interpretability", "Abstract": "Neural networks are known to model statistical interactions, but they entangle the interactions at intermediate hidden layers for shared representation learning. We propose a framework, Neural Interaction Transparency (NIT), that disentangles the shared learning across different interactions to obtain their intrinsic lower-order and interpretable structure. This is done through a novel regularizer that directly penalizes interaction order. We show that disentangling interactions reduces a feedforward neural network to a generalized additive model with interactions, which can lead to transparent models that perform comparably to the state-of-the-art models. NIT is also flexible and efficient; it can learn generalized additive models with maximum $K$-order interactions by training only $O(1)$ models."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tangent", "Title": "Automatic differentiation using source-code transformation for dynamically typed array programming", "Abstract": "The need to efficiently calculate first- and higher-order derivatives of increasingly complex models expressed in Python has stressed or exceeded the capabilities of available tools. In this work, we explore techniques from the field of automatic differentiation (AD) that can give researchers expressive power, performance and strong usability. These include source-code transformation (SCT), flexible gradient surgery, efficient in-place array operations, and higher-order derivatives. We implement and demonstrate these ideas in the Tangent software library for Python, the first AD framework for a dynamic language that uses SCT."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GILBO", "Title": "One Metric to Measure Them All", "Abstract": "We propose a simple, tractable lower bound on the mutual information contained in the joint generative density of any latent variable generative model: the GILBO (Generative Information Lower BOund). It offers a data-independent measure of the complexity of the learned latent variable description, giving the log of the effective description length. It is well-defined for both VAEs and GANs. We compute the GILBO for 800 GANs and VAEs each trained on four datasets (MNIST, FashionMNIST, CIFAR-10 and CelebA) and discuss the results."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FishNet", "Title": "A Versatile Backbone for Image, Region, and Pixel Level Prediction", "Abstract": "The basic principles in designing convolutional neural network (CNN) structures for predicting objects on different levels, e.g., image-level, region-level, and pixel-level, are diverging. Generally, network structures designed specifically for image classification are directly used as default backbone structure for other tasks including detection and segmentation, but there is seldom backbone structure designed under the consideration of unifying the advantages of networks designed for pixel-level or region-level predicting tasks, which may require very deep features with high resolution. Towards this goal, we design a fish-like network, called FishNet. In FishNet, the information of all resolutions is preserved and refined for the final task. Besides, we observe that existing works still cannot \\emph{directly} propagate the gradient information from deep layers to shallow layers. Our design can better handle this problem. Extensive experiments have been conducted to demonstrate the remarkable performance of the FishNet. In particular, on ImageNet-1k, the accuracy of FishNet is able to surpass the performance of DenseNet and ResNet with fewer parameters. FishNet was applied as one of the modules in the winning entry of the COCO Detection 2018 challenge. The code is available at https://github.com/kevin-ssy/FishNet."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Automatic differentiation in ML", "Title": "Where we are and where we should be going", "Abstract": "We review the current state of automatic differentiation (AD) for array programming in machine learning (ML), including the different approaches such as operator overloading (OO) and source transformation (ST) used for AD, graph-based intermediate representations for programs, and source languages. Based on these insights, we introduce a new graph-based intermediate representation (IR) which specifically aims to efficiently support fully-general AD for array programming. Unlike existing dataflow programming representations in ML frameworks, our IR naturally supports function calls, higher-order functions and recursion, making ML models easier to implement. The ability to represent closures allows us to perform AD using ST without a tape, making the resulting derivative (adjoint) program amenable to ahead-of-time optimization using tools from functional language compilers, and enabling higher-order derivatives. Lastly, we introduce a proof of concept compiler toolchain called Myia which uses a subset of Python as a front end."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Demystifying excessively volatile human learning", "Title": "A Bayesian persistent prior and a neural approximation", "Abstract": "Understanding how humans and animals learn about statistical regularities in stable and volatile environments, and utilize these regularities to make predictions and decisions, is an important problem in neuroscience and psychology. Using a Bayesian modeling framework, specifically the Dynamic Belief Model (DBM), it has previously been shown that humans tend to make the {\\it default} assumption that environmental statistics undergo abrupt, unsignaled changes, even when environmental statistics are actually stable. Because exact Bayesian inference in this setting, an example of switching state space models, is computationally intense, a number of approximately Bayesian and heuristic algorithms have been proposed to account for learning/prediction in the brain. Here, we examine a neurally plausible algorithm, a special case of leaky integration dynamics we denote as EXP (for exponential filtering), that is significantly simpler than all previously suggested algorithms except for the delta-learning rule, and which far outperforms the delta rule in approximating Bayesian prediction performance. We derive the theoretical relationship between DBM and EXP, and show that EXP gains computational efficiency by foregoing the representation of inferential uncertainty (as does the delta rule), but that it nevertheless achieves near-Bayesian performance due to its ability to incorporate a \"persistent prior\" influence unique to DBM and absent from the other algorithms. Furthermore, we show that EXP is comparable to DBM but better than all other models in reproducing human behavior in a visual search task, suggesting that human learning and prediction also incorporates an element of persistent prior. More broadly, our work demonstrates that when observations are information-poor, detecting changes or modulating the learning rate is both {\\it difficult} and (thus) {\\it unnecessary} for making Bayes-optimal predictions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Natasha 2", "Title": "Faster Non-Convex Optimization Than SGD", "Abstract": "We design a stochastic algorithm to find $\\varepsilon$-approximate local minima of any smooth nonconvex function in rate $O(\\varepsilon^{-3.25})$, with only oracle access to stochastic gradients. The best result before this work was $O(\\varepsilon^{-4})$ by stochastic gradient descent (SGD)."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NAIS-Net", "Title": "Stable Deep Networks from Non-Autonomous  Differential Equations", "Abstract": "This paper introduces Non-Autonomous Input-Output Stable Network (NAIS-Net), a very deep architecture where each stacked processing block is derived from a time-invariant non-autonomous dynamical system. Non-autonomy is implemented by skip connections from the block input to each of the unrolled processing stages and allows stability to be enforced so that blocks can be unrolled adaptively to a  pattern-dependent processing depth. NAIS-Net induces non-trivial, Lipschitz input-output maps, even for an infinite unroll length. We prove that the network is globally asymptotically stable so that for every initial condition there is exactly one input-dependent equilibrium assuming tanh units, and multiple stable equilibria for ReL units. An efficient implementation that enforces the stability under derived conditions for both fully-connected and convolutional layers is also presented. Experimental results show how NAIS-Net exhibits stability in practice, yielding a significant reduction in generalization gap compared to ResNets."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sequential Test for the Lowest Mean", "Title": "From Thompson to Murphy Sampling", "Abstract": "Learning the minimum/maximum mean among a finite set of distributions is a fundamental sub-problem in planning, game tree search and reinforcement learning. We formalize this learning task as the problem of sequentially testing how the minimum mean among a finite set of distributions compares to a given threshold. We develop refined non-asymptotic lower bounds, which show that optimality mandates very different sampling behavior for a low vs high true minimum. We show that Thompson Sampling and the intuitive Lower Confidence Bounds policy each nail only one of these cases. We develop a novel approach that we call Murphy Sampling. Even though it entertains exclusively low true minima, we prove that MS is optimal for both possibilities. We then design advanced self-normalized deviation inequalities, fueling more aggressive stopping rules. We complement our theoretical guarantees by experiments showing that MS works best in practice."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Latent Gaussian Activity Propagation", "Title": "Using Smoothness and Structure to Separate and Localize Sounds in Large Noisy Environments", "Abstract": "We present an approach for simultaneously separating and localizing\nmultiple sound sources using recorded microphone data. Inspired by topic\nmodels, our approach is based on a probabilistic model of inter-microphone\nphase differences, and poses separation and localization as a Bayesian\ninference problem. We assume sound activity is locally smooth across time,\nfrequency, and location, and use the known position of the microphones to\nobtain a consistent separation. We compare the performance of our method\nagainst existing algorithms on simulated anechoic voice data and find that it\nobtains high performance across a variety of input conditions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DropBlock", "Title": "A regularization method for convolutional networks", "Abstract": "Deep neural networks often work well when they are over-parameterized and trained with a massive amount of noise and regularization, such as weight decay and dropout. Although dropout is widely used as a regularization technique for fully connected layers, it is often less effective for convolutional layers. This lack of success of dropout for convolutional layers is perhaps due to the fact that activation units in  convolutional layers are spatially correlated so information can still flow through convolutional networks despite dropout. Thus a structured form of dropout is needed to regularize convolutional networks. In this paper, we introduce DropBlock, a form of structured dropout, where units in a contiguous region of a feature map are dropped together. We found that applying DropbBlock in skip connections in addition to the convolution layers increases the accuracy. Also, gradually increasing number of dropped units during training leads to better accuracy and more robust to hyperparameter choices. Extensive experiments show that DropBlock works better than dropout in regularizing convolutional networks.\n  On ImageNet classification, ResNet-50 architecture with DropBlock achieves $78.13\\%$ accuracy, which is more than $1.6\\%$ improvement on the baseline. On COCO detection, DropBlock improves Average Precision of RetinaNet from $36.8\\%$ to $38.4\\%$."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RetGK", "Title": "Graph Kernels based on Return Probabilities of Random Walks", "Abstract": "Graph-structured data arise in wide applications, such as computer vision, bioinformatics, and social networks. Quantifying similarities among graphs is a fundamental problem. In this paper, we develop a framework for computing graph kernels, based on return probabilities of random walks. The advantages of our proposed kernels are that they can effectively exploit various node attributes, while being scalable to large datasets. We conduct extensive graph classification experiments to evaluate our graph kernels. The experimental results show that our graph kernels significantly outperform other state-of-the-art approaches in both accuracy and computational efficiency."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisiting Multi-Task Learning with ROCK", "Title": "a Deep Residual Auxiliary Block for Visual Detection", "Abstract": "Multi-Task Learning (MTL) is appealing for deep learning regularization. In this paper, we tackle a specific MTL context denoted as primary MTL, where the ultimate goal is to improve the performance of a given primary task by leveraging several other auxiliary tasks. Our main methodological contribution is to introduce ROCK, a new generic multi-modal fusion block for deep learning tailored to the primary MTL context. ROCK architecture is based on a residual connection, which makes forward prediction explicitly impacted by the intermediate auxiliary representations. The auxiliary predictor's architecture is also specifically designed to our primary MTL context, by incorporating intensive pooling operators for maximizing complementarity of intermediate representations. Extensive experiments on NYUv2 dataset (object detection with scene classification, depth prediction, and surface normal estimation as auxiliary tasks) validate the relevance of the approach and its superiority to flat MTL approaches. Our method outperforms state-of-the-art object detection models on NYUv2 dataset by a large margin, and is also able to handle large-scale heterogeneous inputs (real and synthetic images) with missing annotation modalities."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from Group Comparisons", "Title": "Exploiting Higher Order Interactions", "Abstract": "We study the problem of learning from group comparisons, with applications in predicting outcomes of sports and online games. Most of the previous works in this area focus on learning individual effects---they assume each player has an underlying score, and the ''ability'' of the team is modeled by the sum of team members' scores. Therefore, all the current approaches cannot model deeper interaction between team members: some players perform much better if they play together, and some players perform poorly together. In this paper, we propose a new model that takes the player-interaction effects into consideration. However, under certain circumstances, the total number of individuals can be very large, and number of player interactions grows quadratically, which makes learning intractable. In this case, we propose a latent factor model, and show that the sample complexity of our model is bounded under mild assumptions. Finally, we show that our proposed models have much better prediction power on several E-sports datasets, and furthermore can be used to reveal interesting patterns that cannot be discovered by previous methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cooperative Holistic Scene Understanding", "Title": "Unifying 3D Object, Layout, and Camera Pose Estimation", "Abstract": "Holistic 3D indoor scene understanding refers to jointly recovering the i) object bounding boxes, ii) room layout, and iii) camera pose, all in 3D. The existing methods either are ineffective or only tackle the problem partially. In this paper, we propose an end-to-end model that simultaneously solves all three tasks in real-time given only a single RGB image. The essence of the proposed method is to improve the prediction by i) parametrizing the targets (e.g., 3D boxes) instead of directly estimating the targets, and ii) cooperative training across different modules in contrast to training these modules individually. Specifically, we parametrize the 3D object bounding boxes by the predictions from several modules, i.e., 3D camera pose and object attributes. The proposed method provides two major advantages: i) The parametrization helps maintain the consistency between the 2D image and the 3D world, thus largely reducing the prediction variances in 3D coordinates. ii) Constraints can be imposed on the parametrization to train different modules simultaneously. We call these constraints \"cooperative losses\" as they enable the joint training and inference. We employ three cooperative losses for 3D bounding boxes, 2D projections, and physical constraints to estimate a geometrically consistent and physically plausible 3D scene. Experiments on the SUN RGB-D dataset shows that the proposed method significantly outperforms prior approaches on 3D layout estimation, 3D object detection, 3D camera pose estimation, and holistic scene understanding."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HitNet", "Title": "Hybrid Ternary Recurrent Neural Network", "Abstract": "Quantization is a promising technique to reduce the model size, memory footprint, and massive computation operations of recurrent neural networks (RNNs) for embedded devices with limited resources. Although extreme low-bit quantization has achieved impressive success on convolutional neural networks, it still suffers from huge accuracy degradation on RNNs with the same low-bit precision. In this paper, we first investigate the accuracy degradation on RNN models under different quantization schemes, and the distribution of tensor values in the full precision model. Our observation reveals that due to the difference between the distributions of weights and activations, different quantization methods are suitable for different parts of models. Based on our observation, we propose HitNet, a hybrid ternary recurrent neural network, which bridges the accuracy gap between the full precision model and the quantized model. In HitNet, we develop a hybrid quantization method to quantize weights and activations. Moreover, we introduce a sloping factor motivated by prior work on Boltzmann machine to activation functions, further closing the accuracy gap between the full precision model and the quantized model. Overall, our HitNet can quantize RNN models into ternary values, {-1, 0, 1}, outperforming the state-of-the-art quantization methods on RNN models significantly. We test it on typical RNN models, such as Long-Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), on which the results outperform previous work significantly. For example, we improve the perplexity per word (PPW) of a ternary LSTM on Penn Tree Bank (PTB) corpus from 126 (the state-of-the-art result to the best of our knowledge) to 110.3 with a full precision model in 97.2, and a ternary GRU from 142 to 113.5 with a full precision model in 102.7."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SLAYER", "Title": "Spike Layer Error Reassignment in Time", "Abstract": "Configuring deep Spiking Neural Networks (SNNs) is an exciting research avenue for low power spike event based computation. However, the spike generation function is non-differentiable and therefore not directly compatible with the standard error backpropagation algorithm. In this paper, we introduce a new general backpropagation mechanism for learning synaptic weights and axonal delays which overcomes the problem of non-differentiability of the spike function and uses a temporal credit assignment policy for backpropagating error to preceding layers. We describe and release a GPU accelerated software implementation of our method which allows training both fully connected and convolutional neural network (CNN) architectures. Using our software, we compare our method against existing SNN based learning approaches and standard ANN to SNN conversion techniques and show that our method achieves state of the art performance for an SNN on the MNIST, NMNIST, DVS Gesture, and TIDIGITS datasets."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Support Recovery for Orthogonal Matching Pursuit", "Title": "Upper and Lower bounds", "Abstract": "This paper studies the problem of sparse regression where the goal is to learn a sparse vector that best optimizes a given objective function. Under the assumption that the objective function satisfies restricted strong convexity (RSC), we analyze orthogonal matching pursuit (OMP), a greedy algorithm that is used heavily in applications, and obtain support recovery result as well as a tight generalization error bound for OMP. Furthermore, we obtain lower bounds for OMP, showing that both our results on support recovery and generalization error are tight up to logarithmic factors. To the best of our knowledge, these support recovery and generalization bounds are the first such matching upper and lower bounds (up to logarithmic factors) for {\\em any} sparse regression algorithm under the RSC assumption."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beauty-in-averageness and its contextual modulations", "Title": "A Bayesian statistical account", "Abstract": "Understanding how humans perceive the likability of high-dimensional objects'' such as faces is an important problem in both cognitive science and AI/ML. Existing models generally assume these preferences to be fixed. However, psychologists have found human assessment of facial attractiveness to be context-dependent. Specifically, the classical Beauty-in-Averageness (BiA) effect, whereby a blended face is judged to be more attractive than the originals, is significantly diminished or reversed when the original faces are recognizable, or when the blend is mixed-race/mixed-gender and the attractiveness judgment is preceded by a race/gender categorization, respectively. This \"Ugliness-in-Averageness\" (UiA) effect has previously been explained via a qualitative disfluency account, which posits that the negative affect associated with the difficult race or gender categorization is inadvertently interpreted by the brain as a dislike for the face itself. In contrast, we hypothesize that human preference for an object is increased when it incurs lower encoding cost, in particular when its perceived {\\it statistical typicality} is high, in consonance with Barlow's seminalefficient coding hypothesis.'' This statistical coding cost account explains both BiA, where facial blends generally have higher likelihood than ``parent faces'', and UiA, when the preceding context or task restricts face representation to a task-relevant subset of features, thus redefining statistical typicality and encoding cost within that subspace. We use simulations to show that our model provides a parsimonious, statistically grounded, and quantitative account of both BiA and UiA. We validate our model using experimental data from a gender categorization task. We also propose a novel experiment, based on model predictions, that will be able to arbitrate between the disfluency account and our statistical coding cost account of attractiveness."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The committee machine", "Title": "Computational to statistical gaps in learning a two-layers neural network", "Abstract": "Heuristic tools from statistical physics have been used in the past to compute the optimal learning and generalization errors in the teacher-student scenario in multi- layer neural networks. In this contribution, we provide a rigorous justification of these approaches for a two-layers neural network model called the committee machine. We also introduce a version of the approximate message passing (AMP) algorithm for the committee machine that allows to perform optimal learning in polynomial time for a large set of parameters. We find that there are regimes in which a low generalization error is information-theoretically achievable while the AMP algorithm fails to deliver it; strongly suggesting that no efficient algorithm exists for those cases, and unveiling a large computational gap."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TETRIS", "Title": "TilE-matching the TRemendous Irregular Sparsity", "Abstract": "In this work, we propose a novel method, TETRIS, to achieve both better hardware utilization and higher sparsity. Just like a tile-matching game, we cluster the irregularly distributed weights with small value into structured groups by reordering the input/output dimension and structurally prune them. Results show that it can achieve comparable sparsity with the irregular element-wise pruning and demonstrate negligible accuracy loss. The experiments also shows ideal speedup, which is proportional to the sparsity, on GPU platforms. Our proposed method provides a new solution toward algorithm and architecture co-optimization for accuracy-efficiency trade-off."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BourGAN", "Title": "Generative Networks with Metric Embeddings", "Abstract": "This paper addresses the mode collapse for generative adversarial networks (GANs). We view modes as a geometric structure of data distribution in a metric space. Under this geometric lens, we embed subsamples of the dataset from an arbitrary metric space into the L2 space, while preserving their pairwise distance distribution. Not only does this metric embedding determine the dimensionality of the latent space automatically, it also enables us to construct a mixture of Gaussians to draw latent space random vectors. We use the Gaussian mixture model in tandem with a simple augmentation of the objective function to train GANs. Every major step of our method is supported by theoretical analysis, and our experiments on real and synthetic data confirm that the generator is able to produce samples spreading over most of the modes while avoiding unwanted samples, outperforming several recent GAN variants on a number of metrics and offering new features."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Watch Your Step", "Title": "Learning Node Embeddings via Graph Attention", "Abstract": "Graph embedding methods represent nodes in a continuous vector space,\npreserving different types of relational information from the graph.\nThere are many hyper-parameters to these methods (e.g. the length of a random walk) which have to be manually tuned for every graph.\nIn this paper, we replace previously fixed hyper-parameters with trainable ones that we automatically learn via backpropagation. \nIn particular, we propose a novel attention model on the power series of the transition matrix, which guides the random walk to optimize an upstream objective.\nUnlike previous approaches to attention models, the method that we propose utilizes attention parameters exclusively on the data itself (e.g. on the random walk), and are not used by the model for inference.\nWe experiment on link prediction tasks, as we aim to produce embeddings that best-preserve the graph structure, generalizing to unseen information. \nWe improve state-of-the-art results on a comprehensive suite of real-world graph datasets including social, collaboration, and biological networks, where we observe that our graph attention model can reduce the error by up to 20\\%-40\\%.\nWe show that our automatically-learned attention parameters can vary significantly per graph, and correspond to the optimal choice of hyper-parameter if we manually tune existing methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hybrid-MST", "Title": "A Hybrid Active Sampling Strategy for Pairwise Preference Aggregation", "Abstract": "In this paper we present a hybrid active sampling strategy for pairwise preference aggregation, which aims at recovering the underlying rating of the test candidates from sparse and noisy pairwise labeling. Our method employs Bayesian optimization framework and Bradley-Terry model to construct the utility function, then to obtain the Expected Information Gain (EIG) of each pair. For computational efficiency, Gaussian-Hermite quadrature is used for estimation of EIG. In this work, a hybrid active sampling strategy is proposed, either using Global Maximum (GM) EIG sampling or Minimum Spanning Tree (MST) sampling in each trial, which is determined by the test budget. The proposed method has been validated on both simulated and real-world datasets, where it shows higher preference aggregation ability than the state-of-the-art methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Composite Mirror Descent", "Title": "Optimal Bounds with High Probabilities", "Abstract": "We study stochastic composite mirror descent, a class of scalable algorithms able to exploit the geometry and composite structure of a problem. We consider both convex and strongly convex objectives with non-smooth loss functions, for each of which we establish high-probability convergence rates optimal up to a logarithmic factor. We apply the derived computational error bounds to study the generalization performance of multi-pass stochastic gradient descent (SGD) in a non-parametric setting. Our high-probability generalization bounds enjoy a logarithmical dependency on the number of passes provided that the step size sequence is square-summable, which improves the existing bounds in expectation with a polynomial dependency and therefore gives a strong justification on the ability of multi-pass SGD to overcome overfitting. Our analysis removes boundedness assumptions on subgradients often imposed in the literature. Numerical results are reported to support our theoretical findings."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Defense", "Title": "Training DNNs with Improved Adversarial Robustness", "Abstract": "Despite the efficacy on a variety of computer vision tasks, deep neural networks (DNNs) are vulnerable to adversarial attacks, limiting their applications in security-critical systems. Recent works have shown the possibility of generating imperceptibly perturbed image inputs (a.k.a., adversarial examples) to fool well-trained DNN classifiers into making arbitrary predictions. To address this problem, we propose a training recipe named \"deep defense\". Our core idea is to integrate an adversarial perturbation-based regularizer into the classification objective, such that the obtained models learn to resist potential attacks, directly and precisely. The whole optimization problem is solved just like training a recursive network. Experimental results demonstrate that our method outperforms training with adversarial/Parseval regularizations by large margins on various datasets (including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code and models for reproducing our results are available at https://github.com/ZiangYan/deepdefense.pytorch."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MacNet", "Title": "Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models", "Abstract": "Machine Comprehension (MC) is one of the core problems in natural language processing, requiring both understanding of the natural language and knowledge about the world. Rapid progress has been made since the release of several benchmark datasets, and recently the state-of-the-art models even surpass human performance on the well-known SQuAD evaluation. In this paper, we transfer knowledge learned from machine comprehension to the sequence-to-sequence tasks to deepen the understanding of the text. We propose MacNet: a novel encoder-decoder supplementary architecture to the widely used attention-based sequence-to-sequence models. Experiments on neural machine translation (NMT) and abstractive text summarization show that our proposed framework can significantly improve the performance of the baseline models, and our method for the abstractive text summarization achieves the state-of-the-art results on the Gigaword dataset."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SplineNets", "Title": "Continuous Neural Decision Graphs", "Abstract": "We present SplineNets, a practical and novel approach for using conditioning in convolutional neural networks (CNNs). SplineNets are continuous generalizations of neural decision graphs, and they can dramatically reduce runtime complexity and computation costs of CNNs, while maintaining or even increasing accuracy. Functions of SplineNets are both dynamic (i.e., conditioned on the input) and hierarchical (i.e.,conditioned on the computational path). SplineNets employ a unified loss function with a desired level of smoothness over both the network and decision parameters, while allowing for sparse activation of a subset of nodes for individual samples. In particular, we embed infinitely many function weights (e.g. filters) on smooth, low dimensional manifolds parameterized by compact B-splines, which are indexed by a position parameter. Instead of sampling from a categorical distribution to pick a branch, samples choose a continuous position to pick a function weight. We further show that by maximizing the mutual information between spline positions and class labels, the network can be optimally utilized and specialized for classification tasks. Experiments show that our approach can significantly increase the accuracy of ResNets with negligible cost in speed, matching the precision of a 110 level ResNet with a 32 level SplineNet."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Post", "Title": "Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization", "Abstract": "Training deep neural networks requires an exorbitant amount of computation resources, including a heterogeneous mix of GPU and CPU devices. It is critical to place operations in a neural network on these devices in an optimal way, so that the training process can complete within the shortest amount of time. The state-of-the-art uses reinforcement learning to learn placement skills by repeatedly performing Monte-Carlo experiments. However, due to its equal treatment of placement samples, we argue that there remains ample room for significant improvements. In this paper, we propose a new joint learning algorithm, called Post, that integrates cross-entropy minimization and proximal policy optimization to achieve theoretically guaranteed optimal efficiency. In order to incorporate the cross-entropy method as a sampling technique, we propose to represent placements using discrete probability distributions, which allows us to estimate an optimal probability mass by maximal likelihood estimation, a powerful tool with the best possible efficiency. We have implemented Post in the Google Cloud platform, and our extensive experiments with several popular neural network training benchmarks have demonstrated clear evidence of superior performance: with the same amount of learning time, it leads to placements that have training times up to 63.7% shorter over the state-of-the-art."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Visual Object Networks", "Title": "Image Generation with Disentangled 3D Representations", "Abstract": "Recent progress in deep generative models has led to tremendous breakthroughs in image generation. While being able to synthesize photorealistic images, existing models lack an understanding of our underlying 3D world. Different from previous works built on 2D datasets and models, we present a new generative model, Visual Object Networks (VONs), synthesizing natural images of objects with a disentangled 3D representation. Inspired by classic graphics rendering pipelines, we unravel the image formation process into three conditionally independent factors---shape, viewpoint, and texture---and present an end-to-end adversarial learning framework that jointly models 3D shape and 2D texture. Our model first learns to synthesize 3D shapes that are indistinguishable from real shapes. It then renders the object's 2.5D sketches (i.e., silhouette and depth map) from its shape under a sampled viewpoint. Finally, it learns to add realistic textures to these 2.5D sketches to generate realistic images. The VON not only generates images that are more realistic than the state-of-the-art 2D image synthesis methods but also enables many 3D operations such as changing the viewpoint of a generated image,  shape and texture editing, linear interpolation in texture and shape space, and transferring appearance across different objects and viewpoints."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MiME", "Title": "Multilevel Medical Embedding of Electronic Health Records for Predictive Healthcare", "Abstract": "Deep learning models exhibit state-of-the-art performance for many predictive healthcare tasks using electronic health records (EHR) data, but these models typically require training data volume that exceeds the capacity of most healthcare systems.\nExternal resources such as medical ontologies are used to bridge the data volume constraint, but this approach is often not directly applicable or useful because of inconsistencies with terminology.\nTo solve the data insufficiency challenge, we leverage the inherent multilevel structure of EHR data and, in particular, the encoded relationships among medical codes.\nWe propose Multilevel Medical Embedding (MiME) which learns the multilevel embedding of EHR data while jointly performing auxiliary prediction tasks that rely on this inherent EHR structure without the need for external labels. \nWe conducted two prediction tasks, heart failure prediction and sequential disease prediction, where MiME outperformed baseline methods in diverse evaluation settings.\nIn particular, MiME consistently outperformed all baselines when predicting heart failure on datasets of different volumes, especially demonstrating the greatest performance improvement (15% relative gain in PR-AUC over the best baseline) on the smallest dataset, demonstrating its ability to effectively model the multilevel structure of EHR data."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Persistence Fisher Kernel", "Title": "A Riemannian Manifold Kernel for Persistence Diagrams", "Abstract": "Algebraic topology methods have recently played an important role for statistical analysis with complicated geometric structured data such as shapes, linked twist maps, and material data. Among them, \\textit{persistent homology} is a well-known tool to extract robust topological features, and outputs as \\textit{persistence diagrams} (PDs). However, PDs are point multi-sets which can not be used in machine learning algorithms for vector data. To deal with it, an emerged approach is to use kernel methods, and an appropriate geometry for PDs is an important factor to measure the similarity of PDs. A popular geometry for PDs is the \\textit{Wasserstein metric}. However, Wasserstein distance is not \\textit{negative definite}. Thus, it is limited to build positive definite kernels upon the Wasserstein distance \\textit{without approximation}. In this work, we rely upon the alternative \\textit{Fisher information geometry} to propose a positive definite kernel for PDs \\textit{without approximation}, namely the Persistence Fisher (PF) kernel. Then, we analyze eigensystem of the integral operator induced by the proposed kernel for kernel machines. Based on that, we derive generalization error bounds via covering numbers and Rademacher averages for kernel machines with the PF kernel. Additionally, we show some nice properties such as stability and infinite divisibility for the proposed kernel. Furthermore, we also propose a linear time complexity over the number of points in PDs for an approximation of our proposed kernel with a bounded error. Throughout experiments with many different tasks on various benchmark datasets, we illustrate that the PF kernel compares favorably with other baseline kernels for PDs."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "See and Think", "Title": "Disentangling Semantic Scene Completion", "Abstract": "Semantic scene completion predicts volumetric occupancy and object category of a 3D scene, which helps intelligent agents to understand and interact with the surroundings. In this work, we propose a disentangled framework, sequentially carrying out 2D semantic segmentation, 2D-3D reprojection and 3D semantic scene completion. This three-stage framework has three advantages: (1) explicit semantic segmentation significantly boosts performance; (2) flexible fusion ways of sensor data bring good extensibility; (3) progress in any subtask will promote the holistic performance. Experimental results show that regardless of inputing a single depth or RGB-D, our framework can generate high-quality semantic scene completion, and outperforms state-of-the-art approaches on both synthetic and real datasets."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "L4", "Title": "Practical loss-based stepsize adaptation for deep learning", "Abstract": "We propose a stepsize adaptation scheme for stochastic gradient descent.\nIt operates directly with the loss function and rescales the gradient in order to make fixed predicted progress on the loss.\nWe demonstrate its capabilities by conclusively improving the performance of Adam and Momentum optimizers.\nThe enhanced optimizers with default hyperparameters\n consistently outperform their constant stepsize counterparts, even the best ones,\n without a measurable increase in computational cost.\nThe performance is validated on multiple architectures including dense nets, CNNs, ResNets, and the recurrent Differential Neural Computer on classical datasets MNIST, fashion MNIST, CIFAR10 and others."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pelee", "Title": "A Real-Time Object Detection System on Mobile Devices", "Abstract": "An increasing need of running Convolutional Neural Network (CNN) models on mobile devices with limited computing power and memory resource encourages studies on efficient model design. A number of efficient architectures have been proposed in recent years, for example, MobileNet, ShuffleNet, and MobileNetV2. However, all these models are heavily dependent on depthwise separable convolution which lacks efficient implementation in most deep learning frameworks. In this study, we propose an efficient architecture named PeleeNet, which is built with conventional convolution instead. On ImageNet ILSVRC 2012 dataset, our proposed PeleeNet achieves a higher accuracy and 1.8 times faster speed than MobileNet and MobileNetV2 on NVIDIA TX2. Meanwhile, PeleeNet is only 66% of the model size of MobileNet. We then propose a real-time object detection system by combining PeleeNet with Single Shot MultiBox Detector (SSD) method and optimizing the architecture for fast speed. Our proposed detection system, named Pelee, achieves 76.4% mAP (mean average precision) on PASCAL VOC2007 and 22.4 mAP on MS COCO dataset at the speed of 23.6 FPS on iPhone 8 and 125 FPS on NVIDIA TX2. The result on COCO outperforms YOLOv2 in consideration of a higher precision, 13.6 times lower computational cost and 11.3 times smaller model size. The code and models are open sourced."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How To Make the Gradients Small Stochastically", "Title": "Even Faster Convex and Nonconvex SGD", "Abstract": "Stochastic gradient descent (SGD) gives an optimal convergence rate when minimizing convex stochastic objectives $f(x)$. However, in terms of making the gradients small, the original SGD does not give an optimal rate, even when $f(x)$ is convex.\n\nIf $f(x)$ is convex, to find a point with gradient norm $\\varepsilon$, we design an algorithm SGD3 with a near-optimal rate $\\tilde{O}(\\varepsilon^{-2})$, improving the best known rate $O(\\varepsilon^{-8/3})$. If $f(x)$ is nonconvex, to find its $\\varepsilon$-approximate local minimum, we design an algorithm SGD5 with rate $\\tilde{O}(\\varepsilon^{-3.5})$, where previously SGD variants only achieve $\\tilde{O}(\\varepsilon^{-4})$. This is no slower than the best known stochastic version of Newton's method in all parameter regimes."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Autoconj", "Title": "Recognizing and Exploiting Conjugacy Without a Domain-Specific Language", "Abstract": "Deriving conditional and marginal distributions using conjugacy relationships can be time consuming and error prone. In this paper, we propose a strategy for automating such derivations. Unlike previous systems which focus on relationships between pairs of random variables, our system (which we call Autoconj) operates directly on Python functions that compute log-joint distribution functions. Autoconj provides support for conjugacy-exploiting algorithms in any Python-embedded PPL. This paves the way for accelerating development of novel inference algorithms and structure-exploiting modeling strategies. The package can be downloaded at https://github.com/google-research/autoconj."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Semi-supervised Deep Kernel Learning", "Title": "Regression with Unlabeled Data by Minimizing Predictive Variance", "Abstract": "Large amounts of labeled data are typically required to train deep learning models. For many real-world problems, however, acquiring additional data can be expensive or even impossible. We present semi-supervised deep kernel learning (SSDKL), a semi-supervised regression model based on minimizing predictive variance in the posterior regularization framework. SSDKL combines the hierarchical representation learning of neural networks with the probabilistic modeling capabilities of Gaussian processes. By leveraging unlabeled data, we show improvements  on a diverse set of real-world regression tasks over supervised deep kernel learning and semi-supervised methods such as VAT and mean teacher adapted for regression."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sigsoftmax", "Title": "Reanalysis of the Softmax Bottleneck", "Abstract": "Softmax is an output activation function for modeling categorical probability distributions in many applications of deep learning. However, a recent study revealed that softmax can be a bottleneck of representational capacity of neural networks in language modeling (the softmax bottleneck). In this paper, we propose an output activation function for breaking the softmax bottleneck without additional parameters. We re-analyze the softmax bottleneck from the perspective of the output set of log-softmax and identify the cause of the softmax bottleneck. On the basis of this analysis, we propose sigsoftmax, which is composed of a multiplication of an exponential function and sigmoid function. Sigsoftmax can break the softmax bottleneck. The experiments on language modeling demonstrate that sigsoftmax and mixture of sigsoftmax outperform softmax and mixture of softmax, respectively."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DVAE#", "Title": "Discrete Variational Autoencoders with Relaxed Boltzmann Priors", "Abstract": "Boltzmann machines are powerful distributions that have been shown to be an effective prior over binary latent variables in variational autoencoders (VAEs). However, previous methods for training discrete VAEs have used the evidence lower bound and not the tighter importance-weighted bound. We propose two approaches for relaxing Boltzmann machines to continuous distributions that permit training with importance-weighted bounds. These relaxations are based on generalized overlapping transformations and the Gaussian integral trick. Experiments on the MNIST and OMNIGLOT datasets show that these relaxations outperform previous discrete VAEs with Boltzmann priors. An implementation which reproduces these results is available."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GumBolt", "Title": "Extending Gumbel trick to Boltzmann priors", "Abstract": "Boltzmann machines (BMs) are appealing candidates for powerful priors in variational autoencoders (VAEs), as they are capable of capturing nontrivial and multi-modal distributions over discrete variables. However, non-differentiability of the discrete units prohibits using the reparameterization trick, essential for low-noise back propagation. The Gumbel trick resolves this problem in a consistent way by relaxing the variables and distributions, but it is incompatible with BM priors. Here, we propose the GumBolt, a model that extends the Gumbel trick to BM priors in VAEs. GumBolt is significantly simpler than the recently proposed methods with BM prior and outperforms them by a considerable margin. It achieves state-of-the-art performance on permutation invariant MNIST and OMNIGLOT datasets in the scope of models with only discrete latent variables.  Moreover, the performance can be further improved by allowing multi-sampled (importance-weighted) estimation of log-likelihood in training, which was not possible with previous models."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Norm matters", "Title": "efficient and accurate normalization schemes in deep networks", "Abstract": "Over the past few years, Batch-Normalization has been commonly used in deep networks, allowing faster training and high performance for a wide variety of applications. However, the reasons behind its merits remained unanswered, with several shortcomings that hindered its use for certain tasks. In this work, we present a novel view on the purpose and function of normalization methods and weight-decay, as tools to decouple weights' norm from the underlying optimized objective. This property highlights the connection between practices such as normalization, weight decay and learning-rate adjustments. We suggest several alternatives to the widely used $L^2$ batch-norm, using normalization in $L^1$ and $L^\\infty$ spaces that can substantially improve numerical stability in low-precision implementations as well as provide computational and memory benefits. We demonstrate that such methods enable the first batch-norm alternative to work for half-precision implementations. Finally, we suggest a modification to weight-normalization, which improves its performance on large-scale tasks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Co-teaching", "Title": "Robust training of deep neural networks with extremely noisy labels", "Abstract": "Deep learning with noisy labels is practically challenging, as the capacity of deep models is so high that they can totally memorize these noisy labels sooner or later during training. Nonetheless, recent studies on the memorization effects of deep neural networks show that they would first memorize training data of clean labels and then those of noisy labels. Therefore in this paper, we propose a new deep learning paradigm called ''Co-teaching'' for combating with noisy labels. Namely, we train two deep neural networks simultaneously, and let them teach each other given every mini-batch: firstly, each network feeds forward all data and selects some data of possibly clean labels; secondly, two networks communicate with each other what data in this mini-batch should be used for training; finally, each network back propagates the data selected by its peer network and updates itself. Empirical results on noisy versions of MNIST, CIFAR-10 and CIFAR-100 demonstrate that Co-teaching is much superior to the state-of-the-art methods in the robustness of trained deep models."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GroupReduce", "Title": "Block-Wise Low-Rank Approximation for Neural Language Model Shrinking", "Abstract": "Model compression is essential for serving large deep neural nets on devices with limited resources or applications that require real-time responses. For advanced NLP problems, a neural language model usually consists of recurrent layers (e.g., using LSTM cells), an embedding matrix for representing input tokens, and a softmax layer for generating output tokens. For problems with a very large vocabulary size, the embedding and the softmax matrices can account for more than half of the model size. For instance, the bigLSTM model achieves state-of-the-art performance on the One-Billion-Word (OBW) dataset with around 800k vocabulary, and its word embedding and softmax matrices use more than 6GBytes space, and are responsible for over 90\\% of the model parameters. In this paper, we propose GroupReduce, a novel compression method for neural language models, based on vocabulary-partition (block) based low-rank matrix approximation and the inherent frequency distribution of tokens (the power-law distribution of words). We start by grouping words into $c$ blocks based on their frequency, and then refine the clustering iteratively by constructing weighted low-rank approximation for each block, where the weights are based the frequencies of the words in the block. The experimental results show our method can significantly outperform traditional compression methods such as low-rank approximation and pruning. On the OBW dataset, our method achieved 6.6x compression rate for the embedding and softmax matrices, and when combined with quantization, our method can achieve 26x compression rate without losing prediction accuracy."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Clebsch–Gordan Nets", "Title": "a Fully Fourier Space Spherical Convolutional Neural Network", "Abstract": "Recent work by Cohen et al. has achieved state-of-the-art results for learning spherical images in a rotation invariant way by using ideas from group representation theory and noncommutative harmonic analysis. In this paper we propose a generalization of this work that generally exhibits improved performace, but from an implementation point of view is actually simpler. An unusual feature of the proposed architecture is that it uses the Clebsch--Gordan transform as its only source of nonlinearity, thus avoiding repeated forward and backward Fourier transforms. The underlying ideas of the paper generalize to constructing neural networks that are invariant to the action of other compact groups."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Memory Replay GANs", "Title": "Learning to Generate New Categories without Forgetting", "Abstract": "Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepExposure", "Title": "Learning to Expose Photos with Asynchronously Reinforced Adversarial Learning", "Abstract": "The accurate exposure is the key of capturing high-quality photos in computational photography, especially for mobile phones that are limited by sizes of camera modules. Inspired by luminosity masks usually applied by professional photographers, in this paper, we develop a novel algorithm for learning local exposures with deep reinforcement adversarial learning. To be specific, we segment an image into sub-images that can reflect variations of dynamic range exposures according to raw low-level features. Based on these sub-images, a local exposure for each sub-image is automatically learned by virtue of policy network sequentially while the reward of learning is globally designed for striking a balance of overall exposures. The aesthetic evaluation function is approximated by discriminator in generative adversarial networks. The reinforcement learning and the adversarial learning are trained collaboratively by asynchronous deterministic policy gradient and generative loss approximation. To further simply the algorithmic architecture, we also prove the feasibility of leveraging the discriminator as the value function. Further more, we employ each local exposure to retouch the raw input image respectively, thus delivering multiple retouched images under different exposures which are fused with exposure blending. The extensive experiments verify that our algorithms are superior to state-of-the-art methods in terms of quantitative accuracy and visual illustration."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Data Amplification", "Title": "A Unified and Competitive Approach to Property Estimation", "Abstract": "We illustrate the estimator's practical advantages by comparing it to existing estimators for a wide variety of properties and distributions. In most cases, its performance with n samples is even as good as that of the empirical estimator with n\\log n samples, and for essentially all properties, its performance is comparable to that of the best existing estimator designed specifically for that property."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Path-Integral Autoencoders", "Title": "Representation Learning and Planning for Dynamical Systems", "Abstract": "We present a representation learning algorithm that learns a low-dimensional latent dynamical system from high-dimensional sequential raw data, e.g., video. The framework builds upon recent advances in amortized inference methods that use both an inference network and a refinement procedure to output samples from a variational distribution given an observation sequence, and takes advantage of the duality between control and inference to approximately solve the intractable inference problem using the path integral control approach. The learned dynamical model can be used to predict and plan the future states; we also present the efficient planning method that exploits the learned low-dimensional latent dynamics. Numerical experiments show that the proposed path-integral control based variational inference method leads to tighter lower bounds in statistical model learning of sequential data. Supplementary video: https://youtu.be/xCp35crUoLQ"}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FastGRNN", "Title": "A Fast, Accurate, Stable and Tiny Kilobyte Sized Gated Recurrent Neural Network", "Abstract": "This paper develops the FastRNN and FastGRNN algorithms to address the twin RNN limitations of inaccurate training and inefficient prediction. Previous approaches have improved accuracy at the expense of prediction costs making them infeasible for resource-constrained and real-time applications. Unitary RNNs have increased accuracy somewhat by restricting the range of the state transition matrix's singular values but have also increased the model size as they require a larger number of hidden units to make up for the loss in expressive power. Gated RNNs have obtained state-of-the-art accuracies by adding extra parameters thereby resulting in even larger models. FastRNN addresses these limitations by adding a residual connection that does not constrain the range of the singular values explicitly and has only two extra scalar parameters. FastGRNN then extends the residual connection to a gate by reusing the RNN matrices to match state-of-the-art gated RNN accuracies but with a 2-4x smaller model. Enforcing FastGRNN's matrices to be low-rank, sparse and quantized resulted in accurate models that could be up to 35x smaller than leading gated and unitary RNNs. This allowed FastGRNN to accurately recognize the \"Hey Cortana\" wakeword with a 1 KB model and to be deployed on severely resource-constrained IoT microcontrollers too tiny to store other RNN models. FastGRNN's code is available at (https://github.com/Microsoft/EdgeML/)."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Pipelines with Limited Data and Domain Knowledge", "Title": "A Study in Parsing Physics Problems", "Abstract": "As machine learning becomes more widely used in practice, we need new methods to build complex intelligent systems that integrate learning with existing software, and with domain knowledge encoded as rules. As a case study, we present such a system that learns to parse Newtonian physics problems in textbooks. This system, Nuts&Bolts, learns a pipeline process that incorporates existing code, pre-learned machine learning models, and human engineered rules.  It jointly trains the entire pipeline to prevent propagation of errors, using a combination of labelled and unlabelled data.  Our approach achieves a good performance on the parsing task, outperforming the simple pipeline and its variants. Finally, we also show how Nuts&Bolts can be used to achieve improvements on a relation extraction task and on the end task of answering Newtonian physics problems."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Practical Deep Stereo (PDS)", "Title": "Toward applications-friendly deep stereo matching", "Abstract": "We compare PDS to state-of-the-art methods published over the recent months, and demonstrate its superior performance on FlyingThings3D and KITTI sets."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Masking", "Title": "A New Perspective of Noisy Supervision", "Abstract": "It is important to learn various types of classifiers given training data with noisy labels. Noisy labels, in the most popular noise model hitherto, are corrupted from ground-truth labels by an unknown noise transition matrix. Thus, by estimating this matrix, classifiers can escape from overfitting those noisy labels. However, such estimation is practically difficult, due to either the indirect nature of two-step approaches, or not big enough data to afford end-to-end approaches. In this paper, we propose a human-assisted approach called ''Masking'' that conveys human cognition of invalid class transitions and naturally speculates the structure of the noise transition matrix. To this end, we derive a structure-aware probabilistic model incorporating a structure prior, and solve the challenges from structure extraction and structure alignment. Thanks to Masking, we only estimate unmasked noise transition probabilities and the burden of estimation is tremendously reduced. We conduct extensive experiments on CIFAR-10 and CIFAR-100 with three noise structures as well as the industrial-level Clothing1M with agnostic noise structure, and the results show that Masking can improve the robustness of classifiers significantly."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Thwarting Adversarial Examples", "Title": "An $L_0$-Robust Sparse Fourier Transform", "Abstract": "We give a new algorithm for approximating the Discrete Fourier transform of an approximately sparse signal that is robust to worst-case $L_0$ corruptions, namely that some coordinates of the signal can be corrupt arbitrarily. Our techniques generalize to a wide range of linear transformations that are used in data analysis such as the Discrete Cosine and Sine transforms, the Hadamard transform, and their high-dimensional analogs. We use our algorithm to successfully defend against worst-case $L_0$ adversaries in the setting of image classification. We give experimental results on the Jacobian-based Saliency Map Attack (JSMA) and the CW $L_0$ attack on the MNIST and Fashion-MNIST datasets as well as the Adversarial Patch on the ImageNet dataset."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dual Principal Component Pursuit", "Title": "Improved Analysis and Efficient Algorithms", "Abstract": "Recent methods for learning a linear subspace from data corrupted by outliers are based on convex L1 and nuclear norm optimization and require the dimension of the subspace and the number of outliers to be sufficiently small [27]. In sharp contrast, the recently proposed Dual Principal Component Pursuit (DPCP) method [22] can provably handle subspaces of high dimension by solving a non-convex L1 optimization problem on the sphere. However, its geometric analysis is based on quantities that are difficult to interpret and are not amenable to  statistical analysis. In this paper we provide a refined geometric analysis and a new statistical analysis that show that DPCP can tolerate as many outliers as the square of the number of inliers, thus improving upon other provably correct robust PCA methods. We also propose a scalable Projected Sub-Gradient Descent method (DPCP-PSGD) for solving the DPCP problem and show it admits linear convergence even though the underlying optimization problem is non-convex and non-smooth. Experiments on road plane detection from 3D point cloud data demonstrate that DPCP-PSGD can be more efficient than the traditional RANSAC algorithm, which is one of the most popular methods for such computer vision applications."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Lingering of Gradients", "Title": "How to Reuse Gradients Over Time", "Abstract": "Classically, the time complexity of a first-order method is estimated by its number of gradient computations. In this paper, we study a more refined complexity by taking into account the ``lingering'' of gradients: once a gradient is computed at $x_k$, the additional time to compute gradients at $x_{k+1},x_{k+2},\\dots$ may be reduced.\n\nWe show how this improves the running time of gradient descent and SVRG. For instance, if the \"additional time'' scales linearly with respect to the traveled distance, then the \"convergence rate'' of gradient descent can be improved from $1/T$ to $\\exp(-T^{1/3})$. On the empirical side, we solve a hypothetical revenue management problem on the Yahoo! Front Page Today Module application with 4.6m users to $10^{-6}$ error (or $10^{-12}$ dual error) using 6 passes of the dataset."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Submodular Maximization via Gradient Ascent", "Title": "The Case of Deep Submodular   Functions", "Abstract": "We study the problem of maximizing deep submodular functions (DSFs) subject to a matroid constraint. DSFs are an expressive class of submodular functions that include, as strict subfamilies, the facility location, weighted coverage, and sums of concave composed with modular functions. We use a strategy similar to the continuous greedy approach, but we show that the multilinear extension of any DSF has a natural and computationally attainable concave relaxation that we can optimize using gradient ascent. Our results show a guarantee of $\\max_{0<\\delta<1}(1-\\epsilon-\\delta-e^{-\\delta^2\\Omega(k)})$ with a running time of $O(\\nicefrac{n^2}{\\epsilon^2})$ plus time for pipage rounding\nto recover a discrete solution, where $k$ is the rank of the matroid constraint. This bound is often better than the standard $1-1/e$ guarantee of the continuous greedy algorithm, but runs much faster. Our bound also holds even for fully curved ($c=1$) functions where the guarantee of $1-c/e$ degenerates to $1-1/e$ where $c$ is the curvature of $f$.  We perform computational experiments that support our theoretical results."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "REFUEL", "Title": "Exploring Sparse Features in Deep Reinforcement Learning for Fast Disease Diagnosis", "Abstract": "This paper proposes REFUEL, a reinforcement learning method with two techniques: {\\em reward shaping} and {\\em feature rebuilding}, to improve the performance of online symptom checking for disease diagnosis. Reward shaping can guide the search of policy towards better directions. Feature rebuilding can guide the agent to learn correlations between features. Together, they can find symptom queries that can yield positive responses from a patient with high probability. Experimental results justify that the two techniques in REFUEL allows the symptom checker to identify the disease more rapidly and accurately."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Porcupine Neural Networks", "Title": "Approximating Neural Network Landscapes", "Abstract": "Neural networks have been used prominently in several machine learning and statistics applications. In general, the underlying optimization of neural networks is non-convex which makes analyzing their performance challenging. In this paper, we take another approach to this problem by constraining the network such that the corresponding optimization landscape has good theoretical properties without significantly compromising performance. In particular, for two-layer neural networks we introduce Porcupine Neural Networks (PNNs) whose weight vectors are constrained to lie over a finite set of lines. We show that most local optima of PNN optimizations are global while we have a characterization of regions where bad local optimizers may exist. Moreover, our theoretical and empirical results suggest that an unconstrained neural network can be approximated using a polynomially-large PNN."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning without the Phase", "Title": "Regularized PhaseMax Achieves Optimal Sample Complexity", "Abstract": "The problem of estimating an unknown signal, $\\mathbf x_0\\in \\mathbb R^n$, from a vector $\\mathbf y\\in \\mathbb R^m$ consisting of $m$ magnitude-only measurements of the form $y_i=|\\mathbf a_i\\mathbf x_0|$, where  $\\mathbf a_i$'s are the rows of a known measurement matrix $\\mathbf A$ is a classical problem known as phase retrieval. This problem arises when measuring the phase is costly or altogether infeasible. In many applications in machine learning, signal processing, statistics, etc., the underlying signal has certain structure (sparse, low-rank, finite alphabet, etc.), opening of up the possibility of recovering $\\mathbf x_0$ from a number of measurements smaller than the ambient dimension, i.e., $m"}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attacks Meet Interpretability", "Title": "Attribute-steered Detection of Adversarial Samples", "Abstract": "Adversarial sample attacks perturb benign inputs to induce DNN misbehaviors. Recent research has demonstrated the widespread presence and the devastating consequences of such attacks. Existing defense techniques either assume prior knowledge of specific attacks or may not work well on complex models due to their underlying assumptions. We argue that adversarial sample attacks are deeply entangled with interpretability of DNN models: while classification results on benign inputs can be reasoned based on the human perceptible features/attributes, results on adversarial samples can hardly be explained. Therefore, we propose a novel adversarial sample detection technique for face recognition models, based on interpretability. It features a novel bi-directional correspondence inference between attributes and internal neurons to identify neurons critical for individual attributes. The activation values of critical neurons are enhanced to amplify the reasoning part of the computation and the values of other neurons are weakened to suppress the uninterpretable part. The classification results after such transformation are compared with those of the original model to detect adversaries. Results show that our technique can achieve 94% detection accuracy for 7 different kinds of attacks with 9.91% false positives on benign inputs. In contrast, a state-of-the-art feature squeezing technique can only achieve 55% accuracy with 23.3% false positives."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reinforcement Learning with Multiple Experts", "Title": "A Bayesian Model Combination Approach", "Abstract": "Potential based reward shaping is a powerful technique for accelerating convergence of reinforcement learning algorithms. Typically, such information includes an estimate of the optimal value function and is often provided by a human expert or other sources of domain knowledge. However, this information is often biased or inaccurate and can mislead many reinforcement learning algorithms. In this paper, we apply Bayesian Model Combination with multiple experts in a way that learns to trust a good combination of experts as training progresses. This approach is both computationally efficient and general, and is shown numerically to improve convergence across discrete and continuous domains and different reinforcement learning algorithms."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fairness Behind a Veil of Ignorance", "Title": "A Welfare Analysis for Automated Decision Making", "Abstract": "We draw attention to an important, yet largely overlooked aspect of evaluating fairness for automated decision making systems---namely risk and welfare considerations. Our proposed family of measures corresponds to the long-established formulations of cardinal social welfare in economics, and is justified by the Rawlsian conception of fairness behind a veil of ignorance. The convex formulation of our welfare-based measures of fairness allows us to integrate them as a constraint into any convex loss minimization pipeline. Our empirical analysis reveals interesting trade-offs between our proposal and (a) prediction accuracy, (b) group discrimination, and (c) Dwork et al's notion of individual fairness. Furthermore and perhaps most importantly, our work provides both heuristic justification and empirical evidence suggesting that a lower-bound on our measures often leads to bounded inequality in algorithmic outcomes; hence presenting the first computationally feasible mechanism for bounding individual-level inequality."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Understanding the Role of Adaptivity in Machine Teaching", "Title": "The Case of Version Space Learners", "Abstract": "In real-world applications of education, an effective teacher adaptively chooses the next example to teach based on the learner’s current state. However, most existing work in algorithmic machine teaching focuses on the batch setting, where adaptivity plays no role. In this paper, we study the case of teaching consistent, version space learners in an interactive setting. At any time step, the teacher provides an example, the learner performs an update, and the teacher observes the learner’s new state. We highlight that adaptivity does not speed up the teaching process when considering existing models of version space learners, such as the “worst-case” model (the learner picks the next hypothesis randomly from the version space) and the “preference-based” model (the learner picks hypothesis according to some global preference). Inspired by human teaching, we propose a new model where the learner picks hypotheses according to some local preference defined by the current hypothesis. We show that our model exhibits several desirable properties, e.g., adaptivity plays a key role, and the learner’s transitions over hypotheses are smooth/interpretable. We develop adaptive teaching algorithms, and demonstrate our results via simulation and user studies."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structural Causal Bandits", "Title": "Where to Intervene?", "Abstract": "We study the problem of identifying the best action in a sequential decision-making setting when the reward distributions of the arms exhibit a non-trivial dependence structure, which is governed by the underlying causal model of the domain where the agent is deployed. In this setting, playing an arm corresponds to intervening on a set of variables and setting them to specific values. In this paper, we show that whenever the underlying causal model is not taken into account during the decision-making process, the standard strategies of simultaneously intervening on all variables or on all the subsets of the variables may, in general, lead to suboptimal policies, regardless of the number of interventions performed by the agent in the environment. We formally acknowledge this phenomenon and investigate structural properties implied by the underlying causal model, which lead to a complete characterization of the relationships between the arms' distributions. We leverage this characterization to build a new algorithm that takes as input a causal structure and finds a minimal, sound, and complete set of qualified arms that an agent should play to maximize its expected reward. We empirically demonstrate that the new strategy learns an optimal policy and leads to orders of magnitude faster convergence rates when compared with its causal-insensitive counterparts."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DifNet", "Title": "Semantic Segmentation by Diffusion Networks", "Abstract": "Deep Neural Networks (DNNs) have recently shown state of the art performance on semantic segmentation tasks, however, they still suffer from problems of poor boundary localization and spatial fragmented predictions. The difficulties lie in the requirement of making dense predictions from a long path model all at once since details are hard to keep when data goes through deeper layers. Instead, in this work, we decompose this difficult task into two relative simple sub-tasks: seed detection which is required to predict initial predictions without the need of wholeness and preciseness, and similarity estimation which measures the possibility of any two nodes belong to the same class without the need of knowing which class they are. We use one branch network for one sub-task each, and apply a cascade of random walks base on hierarchical semantics to approximate a complex diffusion process which propagates seed information to the whole image according to the estimated similarities. \nThe proposed DifNet consistently produces improvements over the baseline models with the same depth and with the equivalent number of parameters, and also achieves promising performance on Pascal VOC and Pascal Context dataset. OurDifNet is trained end-to-end without complex loss functions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Out of the Box", "Title": "Reasoning with Graph Convolution Nets for Factual Visual Question Answering", "Abstract": "Accurately answering a question about a given image requires combining observations with general knowledge. While this is effortless for humans, reasoning with general knowledge remains an algorithmic challenge. To advance research in this direction a novel fact-based' visual question answering (FVQA) task has been introduced recently along with a large set of curated facts which link two entities, i.e., two possible answers, via a relation. Given a question-image pair, deep network techniques have been employed to successively reduce the large set of facts until one of the two entities of the final remaining fact is predicted as the answer. We observe that a successive process which considers one fact at a time to form a local decision is sub-optimal. Instead, we develop an entity graph and use a graph convolutional network toreason' about the correct answer by jointly considering all entities. We show on the challenging FVQA dataset that this leads to an improvement in accuracy of around 7% compared to the state-of-the-art."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Submodular Field Grammars", "Title": "Representation, Inference, and Application to Image Parsing", "Abstract": "Natural scenes contain many layers of part-subpart structure, and distributions over them are thus naturally represented by stochastic image grammars, with one production per decomposition of a part. Unfortunately, in contrast to language grammars, where the number of possible split points for a production $A \\rightarrow BC$ is linear in the length of $A$, in an image there are an exponential number of ways to split a region into subregions. This makes parsing intractable and requires image grammars to be severely restricted in practice, for example by allowing only rectangular regions. In this paper, we address this problem by associating with each production a submodular Markov random field whose labels are the subparts and whose labeling segments the current object into these subparts. We call the result a submodular field grammar (SFG). Finding the MAP split of a region into subregions is now tractable, and by exploiting this we develop an efficient approximate algorithm for MAP parsing of images with SFGs. Empirically, we present promising improvements in accuracy when using SFGs for scene understanding, and show exponential improvements in inference time compared to traditional methods, while returning comparable minima."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FD-GAN", "Title": "Pose-guided Feature Distilling GAN for Robust Person Re-identification", "Abstract": "Person re-identification (reID) is an important task that requires to retrieve a person's images from an image dataset, given one image of the person of interest. For learning robust person features, the pose variation of person images is one of the key challenges. Existing works targeting the problem either perform human alignment, or learn human-region-based representations. Extra pose information and computational cost is generally required for inference. To solve this issue, a Feature Distilling Generative Adversarial Network (FD-GAN) is proposed for learning identity-related and pose-unrelated representations. It is a novel framework based on a Siamese structure with multiple novel discriminators on human poses and identities. In addition to the discriminators, a novel same-pose loss is also integrated, which requires appearance of a same person's generated images to be similar. After learning pose-unrelated person features with pose guidance, no auxiliary pose information and additional computational cost is required during testing. Our proposed FD-GAN achieves state-of-the-art performance on three person reID datasets, which demonstrates that the effectiveness and robust feature distilling capability of the proposed FD-GAN."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Homogeneous Mixture Models", "Title": "Representation, Separation, and Approximation", "Abstract": "At their core, many unsupervised learning models provide a compact representation of homogeneous density mixtures, but their similarities and differences are not always clearly understood. In this work, we formally establish the relationships among latent tree graphical models (including special cases such as hidden Markov models and tensorial mixture models), hierarchical tensor formats and sum-product networks. Based on this connection, we then give a unified treatment of exponential separation in \\emph{exact} representation size between deep mixture architectures and shallow ones. In contrast, for \\emph{approximate} representation, we show that the conditional gradient algorithm can approximate any homogeneous mixture within $\\epsilon$ accuracy by combining $O(1/\\epsilon^2)$ ``shallow'' architectures, where the hidden constant may decrease (exponentially) with respect to the depth. Our experiments on both synthetic and real datasets confirm the benefits of depth in density estimation."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Explanations based on the Missing", "Title": "Towards Contrastive Explanations with Pertinent Negatives", "Abstract": "In this paper we propose a novel method that provides contrastive explanations justifying the classification of an input by a black box classifier such as a deep neural network. Given an input we find what should be minimally and sufficiently present (viz. important object pixels in an image) to justify its classification and analogously what should be  minimally and necessarily \\emph{absent} (viz. certain background pixels). We argue that such explanations are natural for humans and are used commonly in domains such as health care and criminology. What is minimally but critically \\emph{absent} is an important part of an explanation, which to the best of our knowledge, has not been explicitly identified by current explanation methods that explain predictions of neural networks. We validate our approach on three real datasets obtained from diverse domains; namely, a handwritten digits dataset MNIST, a large procurement fraud dataset and a brain activity strength dataset. In all three cases, we witness the power of our approach in generating precise explanations that are also easy for human experts to understand and evaluate."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Community Exploration", "Title": "From Offline Optimization to Online Learning", "Abstract": "We introduce the community exploration problem that has various real-world applications such as online advertising. In the problem, an explorer allocates limited budget to explore communities so as to maximize the number of members he could meet. We provide a systematic study of the community exploration problem, from offline optimization to online learning. For the offline setting where the sizes of communities are known, we prove that the greedy methods for both of non-adaptive exploration and adaptive exploration are optimal. For the online setting where the sizes of communities are not known and need to be learned from the multi-round explorations, we propose an ``upper confidence'' like algorithm that achieves the logarithmic regret bounds. By combining the feedback from different rounds, we can achieve a constant regret bound."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Log-concavity", "Title": "Provable Guarantees for Sampling Multi-modal Distributions using Simulated Tempering Langevin Monte Carlo", "Abstract": "We address this problem by combining Langevin diffusion with simulated tempering. The result is a Markov chain that mixes more rapidly by transitioning between different temperatures of the distribution. We analyze this Markov chain for a mixture of (strongly) log-concave distributions of the same shape. In particular, our technique applies to the canonical multi-modal distribution: a mixture of gaussians (of equal variance). Our algorithm efficiently samples from these distributions given only access to the gradient of the log-pdf. To the best of our knowledge, this is the first result that proves fast mixing for multimodal distributions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "M-Walk", "Title": "Learning to Walk over Graphs using Monte Carlo Tree Search", "Abstract": "Learning to walk over a graph towards a target node for a given query and a source node is an important problem in applications such as knowledge base completion (KBC). It can be formulated as a reinforcement learning (RL) problem with a known state transition model. To overcome the challenge of sparse rewards, we develop a graph-walking agent called M-Walk, which consists of a deep recurrent neural network (RNN) and Monte Carlo Tree Search (MCTS). The RNN encodes the state (i.e., history of the walked path) and maps it separately to a policy and Q-values. In order to effectively train the agent from sparse rewards, we combine MCTS with the neural policy to generate trajectories yielding more positive rewards. From these trajectories, the network is improved in an off-policy manner using Q-learning, which modifies the RNN policy via parameter sharing. Our proposed RL algorithm repeatedly applies this policy-improvement step to learn the model. At test time, MCTS is combined with the neural policy to predict the target node. Experimental results on several graph-walking benchmarks show that M-Walk is able to learn better policies than other RL-based methods, which are mainly based on policy gradients. M-Walk also outperforms traditional KBC baselines."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Scene Editing", "Title": "Automatic Object Removal from Weak Supervision", "Abstract": "While great progress has been made recently in automatic image manipulation, it has been limited to object centric images like faces or structured scene datasets.\nIn this work, we take a step towards general scene-level image editing by developing an automatic interaction-free object removal model. Our model learns to find and remove objects from general scene images using image-level labels and unpaired data in a generative adversarial network (GAN) framework. We achieve this with two key contributions: a two-stage editor architecture consisting of a mask generator and image in-painter that co-operate to remove objects, and a novel GAN based prior for the mask generator that allows us to flexibly incorporate knowledge about object shapes. We experimentally show on two datasets that our method effectively removes a wide variety of objects using weak supervision only."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Variational Inverse Control with Events", "Title": "A General Framework for Data-Driven Reward Definition", "Abstract": "The design of a reward function often poses a major practical challenge to real-world applications of reinforcement learning. Approaches such as inverse reinforcement learning attempt to overcome this challenge, but require expert demonstrations, which can be difficult or expensive to obtain in practice. We propose inverse event-based control, which generalizes inverse reinforcement learning methods to cases where full demonstrations are not needed, such as when only samples of desired goal states are available. Our method is grounded in an alternative perspective on control and reinforcement learning, where an agent's goal is to maximize the probability that one or more events will happen at some point in the future, rather than maximizing cumulative rewards. We demonstrate the effectiveness of our methods on continuous control tasks, with a focus on high-dimensional observations like images where rewards are hard or even impossible to specify."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MULAN", "Title": "A Blind and Off-Grid Method for Multichannel Echo Retrieval", "Abstract": "This paper addresses the general problem of blind echo retrieval, i.e., given M sensors measuring in the discrete-time domain M mixtures of K delayed and attenuated copies of an unknown source signal, can the echo location and weights be recovered? This problem has broad applications in fields such as sonars, seismology, ultrasounds or room acoustics. It belongs to the broader class of blind channel identification problems, which have been intensively studied in signal processing. All existing methods proceed in two steps: (i) blind estimation of sparse discrete-time filters and (ii) echo information retrieval by peak picking. The precision of these methods is fundamentally limited by the rate at which the signals are sampled: estimated echo locations are necessary on-grid, and since true locations never match the sampling grid, the weight estimation precision is also strongly limited. This is the so-called basis-mismatch problem in compressed sensing. We propose a radically different approach to the problem, building on top of the framework of finite-rate-of-innovation sampling. The approach operates directly in the parameter-space of echo locations and weights, and enables near-exact blind and off-grid echo retrieval from discrete-time measurements. It is shown to outperform conventional methods by several orders of magnitudes in precision."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Topkapi", "Title": "Parallel and Fast Sketches for Finding Top-K Frequent Elements", "Abstract": "Identifying the top-K frequent items is one of the most common and important operations in large data processing systems. As a result, several solutions have been proposed to solve this problem approximately. In this paper, we identify that in modern distributed settings with both multi-node as well as multi-core parallelism, existing algorithms, although theoretically sound, are suboptimal from the performance perspective. In particular, for identifying top-K frequent items, Count-Min Sketch (CMS) has fantastic update time but lack the important property of reducibility which is needed for exploiting available massive data parallelism. On the other end, popular Frequent algorithm (FA) leads to reducible summaries but the update costs are significant. In this paper, we present Topkapi, a fast and parallel algorithm for finding top-K frequent items, which gives the best of both worlds, i.e., it is reducible as well as efficient update time similar to CMS. Topkapi possesses strong theoretical guarantees and leads to significant performance gains due to increased parallelism, relative to past work."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Price of Fair PCA", "Title": "One Extra dimension", "Abstract": "We investigate whether the standard dimensionality reduction technique of PCA inadvertently produces data representations with different fidelity for two different populations. We show on several real-world data sets, PCA has higher reconstruction error on population A than on B (for example, women versus men or lower- versus higher-educated individuals). This can happen even when the data set has a similar number of samples from A and B. This motivates our study of dimensionality reduction techniques which maintain similar fidelity for A and B. We define the notion of Fair PCA and give a polynomial-time algorithm for finding a low dimensional representation of the data which is nearly-optimal with respect to this measure. Finally, we show on real-world data sets that our algorithm can be used to efficiently generate a fair low dimensional representation of the data."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Algorithmic Assurance", "Title": "An Active Approach to Algorithmic Testing using Bayesian Optimisation", "Abstract": "We introduce algorithmic assurance, the problem of testing whether\nmachine learning algorithms are conforming to their intended design\ngoal. We address this problem by proposing an efficient framework\nfor algorithmic testing. To provide assurance, we need to efficiently\ndiscover scenarios where an algorithm decision deviates maximally\nfrom its intended gold standard. We mathematically formulate this\ntask as an optimisation problem of an expensive, black-box function.\nWe use an active learning approach based on Bayesian optimisation\nto solve this optimisation problem. We extend this framework to algorithms\nwith vector-valued outputs by making appropriate modification in Bayesian\noptimisation via the EXP3 algorithm. We theoretically analyse our\nmethods for convergence. Using two real-world applications, we demonstrate\nthe efficiency of our methods. The significance of our problem formulation\nand initial solutions is that it will serve as the foundation in assuring\nhumans about machines making complex decisions."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PG-TS", "Title": "Improved Thompson Sampling for Logistic Contextual Bandits", "Abstract": "We address the problem of regret minimization in logistic contextual bandits, where a learner decides among sequential actions or arms given their respective contexts to maximize binary rewards. Using a fast inference procedure with Polya-Gamma distributed augmentation variables, we propose an improved version of Thompson Sampling, a Bayesian formulation of contextual bandits with near-optimal performance. Our approach, Polya-Gamma augmented Thompson Sampling (PG-TS), achieves state-of-the-art performance on simulated and real data. PG-TS explores the action space efficiently and exploits high-reward arms, quickly converging to solutions of low regret. Its explicit estimation of the posterior distribution of the context feature covariance leads to substantial empirical gains over approximate approaches. PG-TS is the first approach to demonstrate the benefits of Polya-Gamma augmentation in bandits and to propose an efficient Gibbs sampler for approximating the analytically unsolvable integral of logistic contextual bandits."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GradiVeQ", "Title": "Vector Quantization for Bandwidth-Efficient Gradient Aggregation in Distributed CNN Training", "Abstract": "Data parallelism can boost the training speed of convolutional neural networks (CNN), but could suffer from significant communication costs caused by gradient aggregation. To alleviate this problem, several scalar quantization techniques have been developed to compress the gradients. But these techniques could perform poorly when used together with decentralized aggregation protocols like ring all-reduce (RAR), mainly due to their inability to directly aggregate compressed gradients. In this paper, we empirically demonstrate the strong linear correlations between CNN gradients, and propose a gradient vector quantization technique, named GradiVeQ, to exploit these correlations through principal component analysis (PCA) for substantial gradient dimension reduction. GradiveQ enables direct aggregation of compressed gradients, hence allows us to build a distributed learning system that parallelizes GradiveQ gradient compression and RAR communications. Extensive experiments on popular CNNs demonstrate that applying GradiveQ slashes the wall-clock gradient aggregation time of the original RAR by more than 5x without noticeable accuracy loss, and reduce the end-to-end training time by almost 50%. The results also show that \\GradiveQ is compatible with scalar quantization techniques such as QSGD (Quantized SGD), and achieves a much higher speed-up gain under the same compression ratio."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adapted Deep Embeddings", "Title": "A Synthesis of Methods for k-Shot Inductive Transfer Learning", "Abstract": "The focus in machine learning has branched beyond training classifiers on a single task to investigating how previously acquired knowledge in a source domain can be leveraged to facilitate learning in a related target domain, known as inductive transfer learning. Three active lines of research have independently explored transfer learning using neural networks. In weight transfer, a model trained on the source domain is used as an initialization point for a network to be trained on the target domain. In deep metric learning, the source domain is used to construct an embedding that captures class structure in both the source and target domains. In few-shot learning, the focus is on generalizing well in the target domain based on a limited number of labeled examples. We compare state-of-the-art methods from these three paradigms and also explore hybrid adapted-embedding methods that use limited target-domain data to fine tune embeddings constructed from source-domain data. We conduct a systematic comparison of methods in a variety of domains, varying the number of labeled instances available in the target domain (k), as well as the number of target-domain classes. We reach three principal conclusions: (1) Deep embeddings are far superior, compared to weight transfer, as a starting point for inter-domain transfer or model re-use (2) Our hybrid methods robustly outperform every few-shot learning and every deep metric learning method previously proposed, with a mean error reduction of 34% over state-of-the-art. (3) Among loss functions for discovering embeddings, the histogram loss (Ustinova & Lempitsky, 2016) is most robust. We hope our results will motivate a unification of research in weight transfer, deep metric learning, and few-shot learning."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KONG", "Title": "Kernels for ordered-neighborhood graphs", "Abstract": "We present novel graph kernels for graphs with node and edge labels that have ordered neighborhoods, i.e. when neighbor nodes follow an order. Graphs with ordered neighborhoods are a natural data representation for evolving graphs where edges are created over time, which induces an order. Combining convolutional subgraph kernels and string kernels, we design new scalable algorithms for generation of explicit graph feature maps using sketching techniques. We obtain precise bounds for the approximation accuracy and computational complexity of the proposed approaches and demonstrate their applicability on real datasets.  In particular, our experiments demonstrate that neighborhood ordering results in more informative features. For the special case of general graphs, i.e. graphs without ordered neighborhoods, the new graph kernels yield efficient and simple algorithms for the comparison of label distributions between graphs."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Glow", "Title": "Generative Flow with Invertible 1x1 Convolutions", "Abstract": "Flow-based generative models are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood and qualitative sample quality. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient synthesis of large and subjectively realistic-looking images."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Do Less, Get More", "Title": "Streaming Submodular Maximization with Subsampling", "Abstract": "In this paper, we develop the first one-pass streaming algorithm for submodular maximization that does not evaluate the entire stream even once. By carefully subsampling each element of the data stream, our algorithm enjoys the tightest approximation guarantees in various settings while having the smallest memory footprint and requiring the lowest number of function evaluations. More specifically, for a monotone submodular function and a $p$-matchoid constraint, our randomized algorithm achieves a $4p$ approximation ratio (in expectation) with $O(k)$ memory and $O(km/p)$ queries per element ($k$ is the size of the largest feasible solution and $m$ is the number of matroids used to define the constraint). For the non-monotone case, our approximation ratio increases only slightly to $4p+2-o(1)$.  To the best or our knowledge, our algorithm is the first that combines the benefits of streaming and subsampling in a novel way in order to truly scale submodular maximization to massive machine learning problems. To showcase its practicality, we empirically evaluated the performance of our algorithm on a video summarization application and observed that it outperforms the state-of-the-art algorithm by up to fifty-fold while maintaining practically the same utility. We also evaluated the scalability of our algorithm on a large dataset of Uber pick up locations."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SLANG", "Title": "Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient", "Abstract": "Uncertainty estimation in large deep-learning models is a computationally challenging\ntask, where it is difficult to form even a Gaussian approximation to the\nposterior distribution. In such situations, existing methods usually resort to a diagonal\napproximation of the covariance matrix despite the fact that these matrices\nare known to give poor uncertainty estimates. To address this issue, we propose\na new stochastic, low-rank, approximate natural-gradient (SLANG) method for\nvariational inference in large deep models. Our method estimates a “diagonal\nplus low-rank” structure based solely on back-propagated gradients of the network\nlog-likelihood. This requires strictly less gradient computations than methods that\ncompute the gradient of the whole variational objective. Empirical evaluations\non standard benchmarks confirm that SLANG enables faster and more accurate\nestimation of uncertainty than mean-field methods, and performs comparably to\nstate-of-the-art methods."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NEON2", "Title": "Finding Local Minima via First-Order Oracles", "Abstract": "As applications, our reduction turns Natasha2 into a first-order method without hurting its theoretical performance. It also converts SGD, GD, SCSG, and SVRG into algorithms finding approximate local minima, outperforming some best known results."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Lipschitz regularity of deep neural networks", "Title": "analysis and efficient estimation", "Abstract": "Deep neural networks are notorious for being sensitive to small well-chosen perturbations, and estimating the regularity of such architectures is of utmost importance for safe and robust practical applications.  In this paper, we investigate one of the key characteristics to assess the regularity of such methods: the Lipschitz constant of deep learning architectures.  First, we show that, even for two layer neural networks, the exact computation of this quantity is NP-hard and state-of-art methods may significantly overestimate it. Then, we both extend and improve previous estimation methods by providing AutoLip, the first generic algorithm for upper bounding the Lipschitz constant of any automatically differentiable function.  We provide a power method algorithm working with automatic differentiation, allowing efficient computations even on large convolutions. Second, for sequential neural networks, we propose an improved algorithm named SeqLip that takes advantage of the linear computation graph to split the computation per pair of consecutive layers. Third we propose heuristics on SeqLip in order to tackle very large networks.  Our experiments show that SeqLip can significantly improve on the existing upper bounds.  Finally, we provide an implementation of AutoLip in the PyTorch environment that may be used to better estimate the robustness of a given neural network to small perturbations or regularize it using more precise Lipschitz estimations.  These results also hint at the difficulty to estimate the Lipschitz constant of deep networks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accelerated Stochastic Matrix Inversion", "Title": "General Theory and  Speeding up BFGS Rules for Faster Second-Order Optimization", "Abstract": "We present the first accelerated randomized algorithm for solving linear systems in Euclidean spaces. One essential problem of this type is the matrix inversion problem. In particular, our algorithm can be specialized to invert positive definite matrices in such a way that all iterates (approximate solutions) generated by the algorithm are positive definite matrices themselves. This opens the way for many applications in the field of optimization and machine learning.  As an application of our general theory, we develop the first  accelerated (deterministic and stochastic) quasi-Newton updates. Our updates lead to provably more aggressive approximations of the inverse Hessian, and lead to speed-ups over classical non-accelerated rules in numerical experiments. Experiments with empirical risk minimization show that our rules can accelerate training of machine learning models."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dialog-to-Action", "Title": "Conversational Question Answering Over a Large-Scale Knowledge Base", "Abstract": "We present an approach to map utterances in conversation to logical forms, which will be executed on a large-scale knowledge base. To handle enormous ellipsis phenomena in conversation, we introduce dialog memory management to manipulate historical entities, predicates, and logical forms when inferring the logical form of current utterances. Dialog memory management is embodied in a generative model, in which a logical form is interpreted in a top-down manner following a small and flexible grammar. We learn the model from denotations without explicit annotation of logical forms, and evaluate it on a large-scale dataset consisting of 200K dialogs over 12.8M entities. Results verify the benefits of modeling dialog memory, and show that our semantic parsing-based approach outperforms a memory network based encoder-decoder model by a huge margin."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Text-Adaptive Generative Adversarial Networks", "Title": "Manipulating Images with Natural Language", "Abstract": "This paper addresses the problem of manipulating images using natural language description. Our task aims to semantically modify visual attributes of an object in an image according to the text describing the new visual appearance. Although existing methods synthesize images having new attributes, they do not fully preserve text-irrelevant contents of the original image. In this paper, we propose the text-adaptive generative adversarial network (TAGAN) to generate semantically manipulated images while preserving text-irrelevant contents. The key to our method is the text-adaptive discriminator that creates word level local discriminators according to input text to classify fine-grained attributes independently. With this discriminator, the generator learns to generate images where only regions that correspond to the given text is modified. Experimental results show that our method outperforms existing methods on CUB and Oxford-102 datasets, and our results were mostly preferred on a user study. Extensive analysis shows that our method is able to effectively disentangle visual attributes and produce pleasing outputs."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "How to Start Training", "Title": "The Effect of Initialization and Architecture", "Abstract": "We identify and study two common failure modes for early training in deep ReLU nets. For each, we give a rigorous proof of when it occurs and how to avoid it, for fully connected, convolutional, and residual architectures. We show that the first failure mode, exploding or vanishing mean activation length, can be avoided by initializing weights from a symmetric distribution with variance 2/fan-in and, for ResNets, by correctly scaling the residual modules. We prove that the second failure mode, exponentially large variance of activation length, never occurs in residual nets once the first failure mode is avoided. In contrast, for fully connected nets, we prove that this failure mode can happen and is avoided by keeping constant the sum of the reciprocals of layer widths. We demonstrate empirically the effectiveness of our theoretical results in predicting when networks are able to start training. In particular, we note that many popular initializations fail our criteria, whereas correct initialization and architecture allows much deeper networks to be trained."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GIANT", "Title": "Globally Improved Approximate Newton Method for Distributed Optimization", "Abstract": "For distributed computing environment, we consider the empirical risk minimization problem and propose a distributed and communication-efficient Newton-type optimization method. At every iteration, each worker locally finds an Approximate NewTon (ANT) direction, which is sent to the main driver. The main driver, then, averages all the ANT directions received from workers to form a Globally Improved ANT (GIANT) direction. GIANT is highly communication efficient and naturally exploits the trade-offs between local computations and global communications in that more local computations result in fewer overall rounds of communications. Theoretically, we show that GIANT enjoys an improved convergence rate as compared with first-order methods and existing distributed Newton-type methods. Further, and in sharp contrast with many existing distributed Newton-type methods, as well as popular first-order methods, a highly advantageous practical feature of GIANT is that it only involves one tuning parameter. We conduct large-scale experiments on a computer cluster and, empirically, demonstrate the superior performance of GIANT."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mean Field for the Stochastic Blockmodel", "Title": "Optimization Landscape and Convergence Issues", "Abstract": "Variational approximation has been widely used in large-scale Bayesian inference recently, the simplest kind of which involves imposing a mean field assumption to approximate complicated latent structures. Despite the computational scalability of mean field, theoretical studies of its loss function surface and the convergence behavior of iterative updates for optimizing the loss are far from complete. In this paper, we focus on the problem of community detection for a simple two-class Stochastic Blockmodel (SBM). Using batch co-ordinate ascent (BCAVI) for updates, we give a complete characterization of all the critical points and show different convergence behaviors with respect to initializations. When the parameters are known, we show a significant proportion of random initializations will converge to ground truth. On the other hand, when the parameters themselves need to be estimated, a random initialization will converge to an uninformative local optimum."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gather-Excite", "Title": "Exploiting Feature Context in Convolutional Neural Networks", "Abstract": "While the use of bottom-up local operators in convolutional neural networks (CNNs) matches well some of the statistics of natural images, it may also prevent such models from capturing contextual long-range feature interactions. In this work, we propose a simple, lightweight approach for better context exploitation in CNNs. We do so by introducing a pair of operators: gather, which efficiently aggregates feature responses from a large spatial extent, and excite, which redistributes the pooled information to local features. The operators are cheap, both in terms of number of added parameters and computational complexity, and can be integrated directly in existing architectures to improve their performance. Experiments on several datasets show that gather-excite can bring benefits comparable to increasing the depth of a CNN at a fraction of the cost. For example, we find ResNet-50 with gather-excite operators is able to outperform its 101-layer counterpart on ImageNet with no additional learnable parameters. We also propose a parametric gather-excite operator pair which yields further performance gains, relate it to the recently-introduced Squeeze-and-Excitation Networks, and analyse the effects of these changes to the CNN feature activation statistics."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepProbLog", "Title": "Neural Probabilistic Logic Programming", "Abstract": "We introduce DeepProbLog, a probabilistic logic programming language that incorporates deep learning by means of neural predicates. We show how existing inference and learning techniques can be adapted for the new language. Our experiments demonstrate that DeepProbLog supports (i) both symbolic and subsymbolic representations and inference, (ii) program induction, (iii) probabilistic (logic) programming, and (iv) (deep) learning from examples. To the best of our knowledge, this work is the first to propose a framework where general-purpose neural networks and expressive probabilistic-logical modeling and reasoning are integrated in a way that exploits the full expressiveness and strengths of both worlds and can be trained end-to-end based on examples."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Breaking the Curse of Horizon", "Title": "Infinite-Horizon Off-Policy Estimation", "Abstract": "We consider the off-policy estimation problem of estimating the expected reward of a target policy using samples collected by a different behavior policy. Importance sampling (IS) has been a key technique to derive (nearly) unbiased estimators, but is known to suffer from an excessively high variance in long-horizon problems.  In the extreme case of in infinite-horizon problems, the variance of an IS-based estimator may even be unbounded. In this paper, we propose a new off-policy estimation method that applies IS directly on the stationary state-visitation distributions to avoid the exploding variance issue faced by existing estimators.Our key contribution is a novel approach to estimating the density ratio of two stationary distributions, with trajectories sampled from only the behavior distribution. We develop a mini-max loss function for the estimation problem, and derive a closed-form solution for the case of RKHS. We support our method with both theoretical  and empirical analyses."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TopRank", "Title": "A practical algorithm for online stochastic ranking", "Abstract": "Online learning to rank is a sequential decision-making problem where in each round the learning agent chooses a list of items and receives feedback in the form of clicks from the user. Many sample-efficient algorithms have been proposed for this problem that assume a specific click model connecting rankings and user behavior. We propose a generalized click model that encompasses many existing models, including the position-based and cascade models. Our generalization motivates a novel online learning algorithm based on topological sort, which we call TopRank. TopRank is (a) more natural than existing algorithms, (b) has stronger regret guarantees than existing algorithms with comparable generality, (c) has a more insightful proof that leaves the door open to many generalizations, (d) outperforms existing algorithms empirically."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A^2-Nets", "Title": "Double Attention Networks", "Abstract": "Learning to capture long-range relations is fundamental to image/video recognition. Existing CNN models generally rely on increasing depth to model such relations which is highly inefficient. In this work, we propose the “double attention block”, a novel component that aggregates and propagates informative global features from the entire spatio-temporal space of input images/videos, enabling subsequent convolution layers to access features from the entire space efficiently. The component is designed with a double attention mechanism in two steps, where the first step gathers features from the entire space into a compact set through second-order attention pooling and the second step adaptively selects and distributes features to each location via another attention. The proposed double attention block is easy to adopt and can be plugged into existing deep neural networks conveniently. We conduct extensive ablation studies and experiments on both image and video recognition tasks for evaluating its performance. On the image recognition task, a ResNet-50 equipped with our double attention blocks outperforms a much larger ResNet-152 architecture on ImageNet-1k dataset with over 40% less the number of parameters and less FLOPs. On the action recognition task, our proposed model achieves the state-of-the-art results on the Kinetics and UCF-101 datasets with significantly higher efficiency than recent works."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse Attentive Backtracking", "Title": "Temporal Credit Assignment Through Reminding", "Abstract": "Learning long-term dependencies in extended temporal sequences requires credit assignment to events far back in the past. The most common method for training recurrent neural networks, back-propagation through time (BPTT), requires credit information to be propagated backwards through every single step of the forward computation, potentially over thousands or millions of time steps.\nThis becomes computationally expensive or even infeasible when used with long sequences. Importantly, biological brains are unlikely to perform such detailed reverse replay over very long sequences of internal states (consider days, months, or years.) However, humans are often reminded of past memories or mental states which are associated with the current mental state.\nWe consider the hypothesis that such memory associations between past and present could be used for credit assignment through arbitrarily long sequences, propagating the credit assigned to the current state to the associated past state. Based on this principle, we study a novel algorithm which only back-propagates through a few of these temporal skip connections, realized by a learned attention mechanism that associates current states with relevant past states. We demonstrate in experiments that our method matches or outperforms regular BPTT and truncated BPTT in tasks involving particularly long-term dependencies, but without requiring the biologically implausible backward replay through the whole history of states. Additionally, we demonstrate that the proposed method transfers to longer sequences significantly better than LSTMs trained with BPTT and LSTMs trained with full self-attention."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DAGs with NO TEARS", "Title": "Continuous Optimization for Structure Learning", "Abstract": "Estimating the structure of directed acyclic graphs (DAGs, also known as Bayesian networks) is a challenging problem since the search space of DAGs is combinatorial and scales superexponentially with the number of nodes. Existing approaches rely on various local heuristics for enforcing the acyclicity constraint. In this paper, we introduce a fundamentally different strategy: we formulate the structure learning problem as a purely continuous optimization problem over real matrices that avoids this combinatorial constraint entirely. \nThis is achieved by a novel characterization of acyclicity that is not only smooth but also exact. The resulting problem can be efficiently solved by standard numerical algorithms, which also makes implementation effortless. The proposed method outperforms existing ones, without imposing any structural assumptions on the graph such as bounded treewidth or in-degree."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kalman Normalization", "Title": "Normalizing Internal Representations Across Network Layers", "Abstract": "As an indispensable component, Batch Normalization (BN) has successfully improved the training of deep neural networks (DNNs) with mini-batches, by normalizing the distribution of the internal representation for each hidden layer. However, the effectiveness of BN would diminish with the scenario of micro-batch (e.g. less than 4 samples in a mini-batch), since the estimated statistics in a mini-batch are not reliable with insufficient samples. This limits BN's room in training larger models on segmentation, detection, and video-related problems, which require small batches constrained by memory consumption. In this paper, we present a novel normalization method, called Kalman Normalization (KN), for improving and accelerating the training of DNNs, particularly under the context of micro-batches. Specifically, unlike the existing solutions treating each hidden layer as an isolated system, KN treats all the layers in a network as a whole system, and estimates the statistics of a certain layer by considering the distributions of all its preceding layers, mimicking the merits of Kalman Filtering. On ResNet50 trained in ImageNet, KN has 3.4% lower error than its BN counterpart when using a batch size of 4; Even when using typical batch sizes, KN still maintains an advantage over BN while other BN variants suffer a performance degradation. Moreover, KN can be naturally generalized to many existing normalization variants to obtain gains, e.g. equipping Group Normalization with Group Kalman Normalization (GKN). KN can outperform BN and its variants for large scale object detection and segmentation task in COCO 2017."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FRAGE", "Title": "Frequency-Agnostic Word Representation", "Abstract": "Continuous word representation (aka word embedding) is a basic building block in many neural network-based models used in natural language processing tasks. Although it is widely accepted that words with similar semantics should be close to each other in the embedding space, we find that word embeddings learned in several tasks are biased towards word frequency: the embeddings of high-frequency and low-frequency words lie in different subregions of the embedding space, and the embedding of a rare word and a popular word can be far from each other even if they are semantically similar. This makes learned word embeddings ineffective, especially for rare words, and consequently limits the performance of these neural network models. In order to mitigate the issue, in this paper, we propose a neat, simple yet effective adversarial training method to blur the boundary between the embeddings of high-frequency words and low-frequency words. We conducted comprehensive studies on ten datasets across four natural language processing tasks, including word similarity, language modeling, machine translation and text classification. Results show that we achieve higher performance than the baselines in all tasks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HOUDINI", "Title": "Lifelong Learning as Program Synthesis", "Abstract": "We present a neurosymbolic framework for the lifelong learning of algorithmic tasks that mix perception and procedural reasoning. Reusing high-level concepts across domains and learning complex procedures are key challenges in lifelong learning. We show that a program synthesis approach that combines gradient descent with combinatorial search over programs can be a more effective response to these challenges than purely neural methods. Our framework, called HOUDINI, represents neural networks as strongly typed, differentiable functional programs that use symbolic higher-order combinators to compose a library of neural functions. Our learning algorithm consists of: (1) a symbolic program synthesizer that performs a type-directed search over parameterized programs, and decides on the library functions to reuse, and the architectures to combine them, while learning a sequence of tasks; and (2) a neural module that trains these programs using stochastic gradient descent. We evaluate HOUDINI on three benchmarks that combine perception with the algorithmic tasks of counting, summing, and shortest-path computation. Our experiments show that HOUDINI transfers high-level concepts more effectively than traditional transfer learning and progressive neural networks, and that the typed representation of networks signiﬁcantly accelerates the search."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Snap ML", "Title": "A Hierarchical Framework for Machine Learning", "Abstract": "We describe a new software framework for fast training of generalized linear models. The framework, named Snap Machine Learning (Snap ML), combines recent advances in machine learning systems and algorithms in a nested manner to reflect the hierarchical architecture of modern computing systems. We prove theoretically that such a hierarchical system can accelerate training in distributed environments where intra-node communication is cheaper than inter-node communication. Additionally, we provide a review of the implementation of Snap ML in terms of GPU acceleration, pipelining, communication patterns and software architecture, highlighting aspects that were critical for achieving high performance. We evaluate the performance of Snap ML in both single-node and multi-node environments, quantifying the benefit of the hierarchical scheme and the data streaming functionality, and comparing with other widely-used machine learning software frameworks. Finally, we present a logistic regression benchmark on the Criteo Terabyte Click Logs dataset and show that Snap ML achieves the same test loss an order of magnitude faster than any of the previously reported results, including those obtained using TensorFlow and scikit-learn."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BML", "Title": "A High-performance, Low-cost Gradient Synchronization Algorithm for DML Training", "Abstract": "In distributed machine learning (DML), the network performance between machines significantly impacts the speed of iterative training. In this paper we propose BML, a new gradient synchronization algorithm with higher network performance and lower network cost than the current practice. BML runs on BCube network, instead of using the traditional Fat-Tree topology. BML algorithm is designed in such a way that, compared to the parameter server (PS) algorithm on a Fat-Tree network connecting the same number of server machines, BML achieves theoretically 1/k of the gradient synchronization time, with k/5 of switches (the typical number of k is 2∼4). Experiments of LeNet-5 and VGG-19 benchmarks on a testbed with 9 dual-GPU servers show that, BML reduces the job completion time of DML training by up to 56.4%."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BinGAN", "Title": "Learning Compact Binary Descriptors with a Regularized GAN", "Abstract": "In this paper, we propose a novel regularization method for Generative Adversarial Networks that allows the model to learn discriminative yet compact binary representations of image patches (image descriptors). We exploit the dimensionality reduction that takes place in the intermediate layers of the discriminator network and train the binarized penultimate layer's low-dimensional representation to mimic the distribution of the higher-dimensional preceding layers. To achieve this, we introduce two loss terms that aim at: (i) reducing the correlation between the dimensions of the binarized penultimate layer's low-dimensional representation (i.e. maximizing joint entropy)  and (ii) propagating the relations between the dimensions in the high-dimensional space to the low-dimensional space. We evaluate the resulting binary image descriptors on two challenging applications, image matching and retrieval, where they achieve state-of-the-art results."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LF-Net", "Title": "Learning Local Features from Images", "Abstract": "We present a novel deep architecture and a training strategy to learn a local feature pipeline from scratch, using collections of images without the need for human supervision. To do so we exploit depth and relative camera pose cues to create a virtual target that the network should achieve on one image, provided the outputs of the network for the other image. While this process is inherently non-differentiable, we show that we can optimize the network in a two-branch setup by confining it to one branch, while preserving differentiability in the other. We train our method on both indoor and outdoor datasets, with depth data from 3D sensors for the former, and depth estimates from an off-the-shelf Structure-from-Motion solution for the latter. Our models outperform the state of the art on sparse feature matching on both datasets, while running at 60+ fps for QVGA images."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CapProNet", "Title": "Deep Feature Learning via Orthogonal Projections onto Capsule Subspaces", "Abstract": "In this paper, we formalize the idea behind capsule nets of using a capsule vector rather than a neuron activation to predict the label of samples. To this end, we propose to learn a group of capsule subspaces onto which an input feature vector is projected. Then the lengths of resultant capsules are used to score the probability of belonging to different classes.  We train such a Capsule Projection Network (CapProNet) by learning an orthogonal projection matrix for each capsule subspace, and show that each capsule subspace is updated until it contains input feature vectors corresponding to the associated class.  With low dimensionality of capsule subspace as well as an iterative method to estimate the matrix inverse, only a small negligible computing overhead is incurred to train the network. Experiment results on image datasets show the presented network can greatly improve the performance of state-of-the-art Resnet backbones by $10-20\\%$ with almost the same computing cost."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PointCNN", "Title": "Convolution On X-Transformed Points", "Abstract": "We present a simple and general framework for feature learning from point cloud. The key to the success of CNNs is the convolution operator that is capable of leveraging spatially-local correlation in data represented densely in grids (e.g. images). However, point cloud are irregular and unordered, thus a direct convolving of kernels against the features associated with the points will result in deserting the shape information while being variant to the orders. To address these problems, we propose to learn a X-transformation from the input points, which is used for simultaneously weighting the input features associated with the points and permuting them into latent potentially canonical order. Then element-wise product and sum operations of typical convolution operator are applied on the X-transformed features. The proposed method is a generalization of typical CNNs into learning features from point cloud, thus we call it PointCNN. Experiments show that PointCNN achieves on par or better performance than state-of-the-art methods on multiple challenging benchmark datasets and tasks."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SEGA", "Title": "Variance Reduction via Gradient Sketching", "Abstract": "We propose a novel randomized first order optimization method---SEGA (SkEtched GrAdient method)---which progressively throughout its iterations builds a variance-reduced estimate of the gradient from random linear measurements (sketches) of the gradient provided  at each iteration by an oracle. In each iteration, SEGA updates the current estimate of the gradient  through a sketch-and-project operation using the information provided by the latest sketch, and this is subsequently used to compute an unbiased estimate of the true gradient through a random relaxation procedure. This unbiased estimate is then used to perform a gradient step. Unlike standard subspace descent methods, such as coordinate descent, SEGA can be used for optimization problems with  a non-separable proximal term. We provide a general convergence analysis and prove linear convergence for strongly convex objectives. In the special case of  coordinate sketches, SEGA can be enhanced with various techniques such as importance sampling, minibatching and acceleration, and its rate is up to a small constant factor identical to the best-known rate of coordinate descent."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Algorithmic Regularization in Learning Deep Homogeneous Models", "Title": "Layers are Automatically Balanced", "Abstract": "We study the implicit regularization imposed by gradient descent for learning multi-layer homogeneous functions including feed-forward fully connected and convolutional deep neural networks with linear, ReLU or Leaky ReLU activation. We rigorously prove that gradient flow (i.e. gradient descent with infinitesimal step size) effectively enforces the differences between squared norms across different layers to remain invariant without any explicit regularization. This result implies that if the weights are initially small, gradient flow automatically balances the magnitudes of all layers. Using a discretization argument, we analyze gradient descent with positive step size for the non-convex low-rank asymmetric matrix factorization problem without any regularization. Inspired by our findings for gradient flow, we prove that gradient descent with step sizes $\\eta_t=O(t^{−(1/2+\\delta)}) (0<\\delta\\le1/2)$ automatically balances two low-rank factors and converges to a bounded global optimum. Furthermore, for rank-1 asymmetric matrix factorization we give a finer analysis showing gradient descent with constant step size converges to the global minimum at a globally linear rate. We believe that the idea of examining the invariance imposed by first order algorithms in learning homogeneous models could serve as a fundamental building block for studying optimization for learning deep models."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Third-order Smoothness Helps", "Title": "Faster Stochastic Optimization Algorithms for Finding Local Minima", "Abstract": "We propose stochastic optimization algorithms that can find local minima faster than existing algorithms for nonconvex optimization problems, by exploiting the third-order smoothness to escape non-degenerate saddle points more efficiently. More specifically, the proposed algorithm only needs $\\tilde{O}(\\epsilon^{-10/3})$ stochastic gradient evaluations to converge to an approximate local minimum $\\mathbf{x}$, which satisfies $\\|\\nabla f(\\mathbf{x})\\|_2\\leq\\epsilon$ and $\\lambda_{\\min}(\\nabla^2 f(\\mathbf{x}))\\geq -\\sqrt{\\epsilon}$ in unconstrained stochastic optimization, where $\\tilde{O}(\\cdot)$ hides logarithm polynomial terms and constants. This improves upon the $\\tilde{O}(\\epsilon^{-7/2})$ gradient complexity achieved by the state-of-the-art stochastic local minima finding algorithms by a factor of $\\tilde{O}(\\epsilon^{-1/6})$. Experiments on two nonconvex optimization problems demonstrate the effectiveness of our algorithm and corroborate our theory."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robot Learning in Homes", "Title": "Improving Generalization and Reducing Dataset Bias", "Abstract": "Data-driven approaches to solving robotic tasks have gained a lot of traction in recent years. However, most existing policies are trained on large-scale datasets collected in curated lab settings. If we aim to deploy these models in unstructured visual environments like people's homes, they will be unable to cope with the mismatch in data distribution. In such light, we present the first systematic effort in collecting a large dataset for robotic grasping in homes. First, to scale and parallelize data collection, we built a low cost mobile manipulator assembled for under 3K USD. Second, data collected using low cost robots suffer from noisy labels due to imperfect execution and calibration errors. To handle this, we develop a framework which factors out the noise as a latent variable. Our model is trained on 28K grasps collected in several houses under an array of different environmental conditions. We evaluate our models by physically executing grasps on a collection of novel objects in multiple unseen homes. The models trained with our home dataset showed a marked improvement of 43.7% over a baseline model trained with data collected in lab. Our architecture which explicitly models the latent noise in the dataset also performed 10% better than one that did not factor out the noise. We hope this effort inspires the robotics community to look outside the lab and embrace learning based approaches to handle inaccurate cheap robots."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LAG", "Title": "Lazily Aggregated Gradient for Communication-Efficient Distributed Learning", "Abstract": "This paper presents a new class of gradient methods for distributed \nmachine learning that adaptively skip the gradient calculations to \nlearn with reduced communication and computation. Simple rules \nare designed to detect slowly-varying gradients and, therefore, \ntrigger the reuse of outdated gradients. The resultant gradient-based \nalgorithms are termed Lazily Aggregated Gradient --- justifying our \nacronym LAG used henceforth. Theoretically, the merits of \nthis contribution are: i) the convergence rate is the same as batch \ngradient descent in strongly-convex, convex, and nonconvex cases; \nand, ii) if the distributed datasets are heterogeneous (quantified by \ncertain measurable constants), the communication rounds needed \nto achieve a targeted accuracy are reduced thanks to the adaptive \nreuse of lagged gradients. Numerical experiments on both \nsynthetic and real data corroborate a significant communication \nreduction compared to alternatives."}
{"Type": "conference", "Year": "2018", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Equality of Opportunity in Classification", "Title": "A Causal Approach", "Abstract": "The Equalized Odds (for short, EO)  is one of the most popular measures of discrimination used in the supervised learning setting. It ascertains fairness through the balance of the misclassification rates (false positive and negative) across the protected groups -- e.g., in the context of law enforcement, an African-American defendant who would not commit a future crime will have an equal opportunity of being released, compared to a non-recidivating Caucasian defendant. Despite this noble goal, it has been acknowledged in the literature that statistical tests based on the EO are oblivious to the underlying causal mechanisms that generated the disparity in the first place (Hardt et al. 2016). This leads to a critical disconnect between statistical measures readable from the data and the meaning of discrimination in the legal system, where compelling evidence that the observed disparity is tied to a specific causal process deemed unfair by society is required to characterize discrimination. The goal of this paper is to develop a principled approach to connect the statistical disparities characterized by the EO  and the underlying, elusive, and frequently unobserved, causal mechanisms that generated such inequality. We start by introducing a new family of counterfactual measures that allows one to explain the misclassification disparities in terms of the underlying mechanisms in an arbitrary, non-parametric structural causal model. This will, in turn, allow legal and data analysts to interpret currently deployed classifiers through causal lens, linking the statistical disparities found in the data to the corresponding causal processes. Leveraging the new family of counterfactual measures, we develop a learning procedure to construct a classifier that is statistically efficient, interpretable, and compatible with the basic human intuition of fairness. We demonstrate our results through experiments in both real (COMPAS) and synthetic datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "XNAS", "Title": "Neural Architecture Search with Expert Advice", "Abstract": "This paper introduces a novel optimization method for differential neural architecture search, based on the theory of prediction with expert advice. Its optimization criterion is well fitted for an architecture-selection, i.e., it minimizes the regret incurred by a sub-optimal selection of operations. \nUnlike previous search relaxations, that require hard pruning of architectures, our method is designed to dynamically wipe out inferior architectures and enhance superior ones.\nIt achieves an optimal worst-case regret bound and suggests the use of multiple learning-rates, based on the amount of information carried by the backward gradients. \nExperiments show that our algorithm achieves a strong performance over several image classification datasets.\nSpecifically, it obtains an error rate of 1.6% for CIFAR-10, 23.9% for ImageNet under mobile settings, and achieves state-of-the-art results on three additional datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Asymmetric Valleys", "Title": "Beyond Sharp and Flat Local Minima", "Abstract": "Despite the non-convex nature of their loss functions, deep neural networks are known to generalize well when optimized with stochastic gradient descent (SGD). Recent work conjectures that SGD with proper conﬁguration is able to ﬁnd wide and ﬂat local minima, which are correlated with good generalization performance. In this paper, we observe that local minima of modern deep networks are more than being ﬂat or sharp. Instead, at a local minimum there exist many asymmetric directions such that the loss increases abruptly along one side, and slowly along the opposite side – we formally deﬁne such minima as asymmetric valleys. Under mild assumptions, we ﬁrst prove that for asymmetric valleys, a solution biased towards the ﬂat side generalizes better than the exact empirical minimizer. Then, we show that performing weight averaging along the SGD trajectory implicitly induces such biased solutions. This provides theoretical explanations for a series of intriguing phenomena observed in recent work [25, 5, 51]. Finally, extensive empirical experiments on both modern deep networks and simple 2 layer networks are conducted to validate our assumptions and analyze the intriguing properties of asymmetric valleys."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Think out of the \"Box\"", "Title": "Generically-Constrained Asynchronous Composite Optimization and Hedging", "Abstract": "We present two new algorithms, ASYNCADA and HEDGEHOG, for asynchronous sparse online and stochastic optimization. ASYNCADA is, to our knowledge, the first asynchronous stochastic optimization algorithm with finite-time data-dependent convergence guarantees for generic convex constraints. In addition, ASYNCADA: (a) allows for proximal (i.e., composite-objective) updates and adaptive step-sizes; (b) enjoys any-time convergence guarantees without requiring an exact global clock; and (c) when the data is sufficiently sparse, its convergence rate for (non-)smooth, (non-)strongly-convex, and even a limited class of non-convex objectives matches the corresponding serial rate, implying a theoretical “linear speed-up”. The second algorithm, HEDGEHOG, is an asynchronous parallel version of the Exponentiated Gradient (EG) algorithm for optimization over the probability simplex (a.k.a. Hedge in online learning), and, to our knowledge, the first asynchronous algorithm enjoying linear speed-ups under sparsity with non-SGD-style updates. Unlike previous work, ASYNCADA and HEDGEHOG and their convergence and speed-up analyses are not limited to individual coordinate-wise (i.e., “box-shaped”) constraints or smooth and strongly-convex objectives. Underlying both results is a generic analysis framework that is of independent\ninterest, and further applicable to distributed and delayed feedback optimization"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DTWNet", "Title": "a Dynamic Time Warping Network", "Abstract": "Dynamic Time Warping (DTW) is widely used as a similarity measure in various domains. Due to its invariance against warping in the time axis, DTW provides more meaningful discrepancy measurements between two signals than other dis- tance measures. In this paper, we propose a novel component in an artificial neural network. In contrast to the previous successful usage of DTW as a loss function, the proposed framework leverages DTW to obtain a better feature extraction. For the first time, the DTW loss is theoretically analyzed, and a stochastic backpropogation scheme is proposed to improve the accuracy and efficiency of the DTW learning. We also demonstrate that the proposed framework can be used as a data analysis tool to perform data decomposition."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cormorant", "Title": "Covariant Molecular Neural Networks", "Abstract": "We propose Cormorant, a rotationally covariant neural network architecture for learning the behavior and properties of complex many-body physical systems. We apply these networks to molecular systems with two goals: learning atomic potential energy surfaces for use in Molecular Dynamics simulations, and learning ground state properties of molecules calculated by Density Functional Theory. Some of the key features of our network are that (a) each neuron explicitly corresponds to a subset of atoms; (b) the activation of each neuron is covariant to rotations, ensuring that overall the network is fully rotationally invariant. Furthermore, the non-linearity in our network is based upon tensor products and the Clebsch-Gordan decomposition, allowing the network to operate entirely in Fourier space. Cormorant significantly outperforms competing algorithms in learning molecular Potential Energy Surfaces from conformational geometries in the MD-17 dataset, and is competitive with other methods at learning geometric, energetic, electronic, and thermodynamic properties of molecules on the GDB-9 dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SpArSe", "Title": "Sparse Architecture Search for CNNs on Resource-Constrained Microcontrollers", "Abstract": "The vast majority of processors in the world are actually microcontroller units (MCUs), which find widespread use performing simple control tasks in applications ranging from automobiles to medical devices and office equipment. The Internet of Things (IoT) promises to inject machine learning into many of these every-day objects via tiny, cheap MCUs. However, these resource-impoverished hardware platforms severely limit the complexity of machine learning models that can be deployed. For example, although convolutional neural networks (CNNs) achieve state-of-the-art results on many visual recognition tasks, CNN inference on MCUs is challenging due to severe memory limitations. To circumvent the memory challenge associated with CNNs, various alternatives have been proposed that do fit within the memory budget of an MCU, albeit at the cost of prediction accuracy. This paper challenges the idea that CNNs are not suitable for deployment on MCUs. We demonstrate that it is possible to automatically design CNNs which generalize well, while also being small enough to fit onto memory-limited MCUs. Our Sparse Architecture Search method combines neural architecture search with pruning in a single, unified approach, which learns superior models on four popular IoT datasets. The CNNs we find are more accurate and up to 7.4× smaller than previous approaches, while meeting the strict MCU working memory constraint."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LIIR", "Title": "Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning", "Abstract": "A great challenge in cooperative decentralized multi-agent reinforcement learning (MARL) is generating diversified behaviors for each individual agent when receiving only a team reward. Prior studies have paid much effort on reward shaping or designing a centralized critic that can discriminatively credit the agents.\nIn this paper, we propose to merge the two directions and learn each agent an intrinsic reward function which diversely stimulates the agents at each time step. Specifically, the intrinsic reward for a specific agent will be involved in computing a distinct proxy critic for the agent to direct the updating of its individual policy. Meanwhile, the parameterized intrinsic reward function will be updated towards maximizing the expected accumulated team reward from the environment so that the objective is consistent with the original MARL problem. The proposed method is referred to as learning individual intrinsic reward (LIIR) in MARL. We compare LIIR with a number of state-of-the-art MARL methods on battle games in StarCraft II. The results demonstrate the effectiveness of LIIR, and we show LIIR can assign each individual agent an insightful intrinsic reward per time step."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Geometry of Deep Networks", "Title": "Power Diagram Subdivision", "Abstract": "We study the geometry of deep (neural) networks (DNs) with piecewise affine and convex nonlinearities. \nThe layers of such DNs have been shown to be max-affine spline operators (MASOs) that partition their input space and apply a region-dependent affine mapping to their input to produce their output.\nWe demonstrate that each MASO layer's input space partitioning corresponds to a power diagram (an extension of the classical Voronoi tiling) with a number of regions that grows exponentially with respect to the number of units (neurons).\nWe further show that a composition of MASO layers (e.g., the entire DN) produces a progressively subdivided power diagram and provide its analytical form. \nThe subdivision process constrains the affine maps on the potentially exponentially many power diagram regions with respect to the number of neurons to greatly reduce their complexity. \nFor classification problems, we obtain a formula for a MASO DN's decision boundary in the input space plus a measure of its curvature that depends on the DN's nonlinearities, weights, and architecture. \nNumerous numerical experiments support and extend our theoretical results."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Concentration of risk measures", "Title": "A Wasserstein distance approach", "Abstract": "Known finite-sample concentration bounds for the Wasserstein distance between the empirical and true distribution of a random variable are used to derive a two-sided  concentration bound for the error between the true conditional value-at-risk (CVaR) of a (possibly unbounded) random variable and a standard estimate of its CVaR computed from an i.i.d. sample. The bound applies under fairly general assumptions on the random variable, and improves upon previous bounds which were either one sided, or applied only to bounded random variables. Specializations of the bound to sub-Gaussian and sub-exponential random variables are also derived.   A similar procedure is followed to derive concentration bounds for the error between the true and estimated Cumulative Prospect Theory (CPT) value of a random variable, in cases where the random variable is bounded or sub-Gaussian. These bounds are shown to match a known bound in the bounded case, and improve upon the known bound in the sub-Gaussian case. The usefulness of the bounds is illustrated through an algorithm, and corresponding regret bound for a stochastic bandit problem, where the underlying risk measure to be optimized is CVaR."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interior-Point Methods Strike Back", "Title": "Solving the Wasserstein Barycenter Problem", "Abstract": "Computing the Wasserstein barycenter of a set of probability measures under the optimal transport metric can quickly become prohibitive for traditional second-order algorithms, such as interior-point methods, as the support size of the measures increases. In this paper, we overcome the difficulty by developing a new adapted interior-point method that fully exploits the problem's special matrix structure to reduce the iteration complexity and speed up the Newton procedure. Different from regularization approaches, our method achieves a well-balanced tradeoff between accuracy and speed. A numerical comparison on various distributions with existing algorithms exhibits the computational advantages of our approach. Moreover, we demonstrate the practicality of our algorithm on image benchmark problems including MNIST and Fashion-MNIST."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Coda", "Title": "An End-to-End Neural Program Decompiler", "Abstract": "Reverse engineering of binary executables is a critical problem in the computer security domain. On the one hand, malicious parties may recover interpretable source codes from the software products to gain commercial advantages. On the other hand, binary decompilation can be leveraged for code vulnerability analysis and malware detection. However, efficient binary decompilation is challenging. Conventional decompilers have the following major limitations: (i) they are only applicable to specific source-target language pair, hence incurs undesired development cost for new language tasks; (ii) their output high-level code cannot effectively preserve the correct functionality of the input binary; (iii) their output program does not capture the semantics of the input and the reversed program is hard to interpret. To address the above problems, we propose Coda1, the first end-to-end neural-based framework for code decompilation. Coda decomposes the decompilation task into of two key phases: First, Coda employs an instruction type-aware encoder and a tree decoder for generating an abstract syntax tree (AST) with attention feeding during the code sketch generation stage. Second, Coda then updates the code sketch using an iterative error correction machine guided by an ensembled neural error predictor. By finding a good approximate candidate and then fixing it towards perfect, Coda achieves superior with performance compared to baseline approaches. We assess Coda’s performance with extensive experiments on various benchmarks. Evaluation results show that Coda achieves an average of 82% program recovery accuracy on unseen binary samples, where the state-of-the-art decompilers yield 0% accuracy. Furthermore, Coda outperforms the sequence-to-sequence model with attention by a margin of 70% program accuracy. Our work reveals the vulnerability of binary executables and imposes a new threat to the protection of Intellectual Property (IP) for software development."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GPipe", "Title": "Efficient Training of Giant Neural Networks using Pipeline Parallelism", "Abstract": "Scaling up deep neural network capacity has been known as an effective approach to improving model quality for several different machine learning tasks. In many cases, increasing model capacity beyond the memory limit of a single accelerator has required developing special algorithms or infrastructure. These solutions are often architecture-specific and do not transfer to other machine learning tasks. To address the need for efficient and task-independent model parallelism, we introduce TensorPipe, a pipeline parallelism library that allows scaling any network that can be expressed as a sequence of layers.  By pipelining different sub-sequences of layers on separate accelerators, TensorPipe provides the flexibility of scaling a variety of different networks to gigantic sizes efficiently. Moreover, TensorPipe utilizes a novel batch-splitting pipelining algorithm,  resulting in almost linear speedup when a model is partitioned across multiple accelerators. We demonstrate the  advantages  of  TensorPipe  by  training  large-scale  neural  networks  on  two different tasks with distinct network architectures: (i)Image Classification: We train a 557-million-parameter AmoebaNet model and attain a top-1 accuracy of 84.4% on ImageNet-2012, (ii)Multilingual Neural Machine Translation: We train a single 6-billion-parameter, 128-layer Transformer model on a corpus spanning over 100 languages and achieve better quality than all bilingual models."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DiskANN", "Title": "Fast Accurate Billion-point Nearest Neighbor Search on a Single Node", "Abstract": "Current state-of-the-art approximate nearest neighbor search (ANNS) algorithms\ngenerate indices that must be stored in main memory for fast high-recall search.\nThis makes them expensive and limits the size of the dataset. We present a\nnew graph-based indexing and search system called DiskANN that can index,\nstore, and search a billion point database on a single workstation with just 64GB\nRAM and an inexpensive solid-state drive (SSD). Contrary to current wisdom,\nwe demonstrate that the SSD-based indices built by DiskANN can meet all three\ndesiderata for large-scale ANNS: high-recall, low query latency and high density\n(points indexed per node). On the billion point SIFT1B bigann dataset, DiskANN\nserves > 5000 queries a second with < 3ms mean latency and 95%+ 1-recall@1\non a 16 core machine, where state-of-the-art billion-point ANNS algorithms with\nsimilar memory footprint like FAISS and IVFOADC+G+P plateau at\naround 50% 1-recall@1. Alternately, in the high recall regime, DiskANN can\nindex and serve 5 − 10x more points per node compared to state-of-the-art graph-\nbased methods such as HNSW and NSG. Finally, as part of our overall\nDiskANN system, we introduce Vamana, a new graph-based ANNS index that is\nmore versatile than the graph indices even for in-memory indices."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Gamblers", "Title": "Learning to Abstain with Portfolio Theory", "Abstract": "We deal with the selective classification problem (supervised-learning problem with a rejection option), where we want to achieve the best performance at a certain level of coverage of the data. We transform the original $m$-class classification problem to (m+1)-class where the (m+1)-th class represents the model abstaining from making a prediction due to disconfidence. Inspired by portfolio theory, we propose a loss function for the selective classification problem based on the doubling rate of gambling. Minimizing this loss function corresponds naturally to maximizing the return of a horse race, where a player aims to balance between betting on an outcome (making a prediction) when confident and reserving one's winnings (abstaining) when not confident. This loss function allows us to train neural networks and characterize the disconfidence of prediction in an end-to-end fashion. In comparison with previous methods, our method requires almost no modification to the model inference algorithm or model architecture. Experiments show that our method can identify uncertainty in data points, and achieves strong results on SVHN and CIFAR10 at various coverages of the data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DRUM", "Title": "End-To-End Differentiable Rule Mining On Knowledge Graphs", "Abstract": "In this paper, we study the problem of learning probabilistic logical rules for inductive and interpretable link prediction. Despite the importance of inductive link prediction, most previous works focused on transductive link prediction and cannot manage previously unseen entities. Moreover, they are black-box models that are not easily explainable for humans. We propose DRUM, a scalable and differentiable approach for mining first-order logical rules from knowledge graphs that resolves these problems. We motivate our method by making a connection between learning confidence scores for each rule and low-rank tensor approximation. DRUM uses bidirectional RNNs to share useful information across the tasks of learning rules for different relations. We also empirically demonstrate the efficiency of DRUM over existing rule mining methods for inductive link prediction on a variety of benchmark datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Average Individual Fairness", "Title": "Algorithms, Generalization and Experiments", "Abstract": "We propose a new family of fairness definitions for classification problems that combine some of the best properties of both statistical and individual notions of fairness. We posit not only a distribution over individuals, but also a distribution over (or collection of) classification tasks. We then ask that standard statistics (such as error or false positive/negative rates) be (approximately) equalized across individuals, where the rate is defined as an expectation over the classification tasks. Because we are no longer averaging over coarse groups (such as race or gender), this is a semantically meaningful individual-level constraint. Given a sample of individuals and problems, we design an oracle-efficient algorithm (i.e. one that is given access to any standard, fairness-free learning heuristic) for the fair empirical risk minimization task. We also show that given sufficiently many samples, the ERM solution generalizes in two directions: both to new individuals, and to new classification tasks, drawn from their corresponding distributions. Finally we implement our algorithm and empirically verify its effectiveness."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Comparing distributions", "Title": "$\\ell_1$ geometry improves kernel two-sample testing", "Abstract": "Are two sets of observations drawn from the same distribution? This\nproblem is a two-sample test. \nKernel methods lead to many appealing properties. Indeed state-of-the-art\napproaches use the $L^2$ distance between kernel-based\ndistribution representatives to derive their test statistics. Here, we show that\n$L^p$ distances (with $p\\geq 1$) between these\ndistribution representatives give metrics on the space of distributions that are\nwell-behaved to detect differences between distributions as they\nmetrize the weak convergence. Moreover, for analytic kernels,\nwe show that the $L^1$ geometry gives improved testing power for\nscalable computational procedures. Specifically, we derive a finite\ndimensional approximation of the metric given as the $\\ell_1$ norm of a vector which captures differences of expectations of analytic functions evaluated at spatial locations or frequencies (i.e, features). The features can be chosen to\nmaximize the differences of the distributions and give interpretable\nindications of how they differs. Using an $\\ell_1$ norm gives better detection\nbecause differences between representatives are dense\nas we use analytic kernels (non-zero almost everywhere). The tests are consistent, while\nmuch faster than state-of-the-art quadratic-time kernel-based tests. Experiments\non artificial\nand real-world problems demonstrate\nimproved power/time tradeoff than the state of the art, based on\n$\\ell_2$ norms, and in some cases, better outright power than even the most\nexpensive quadratic-time tests. This performance gain is retained even in high dimensions."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deconstructing Lottery Tickets", "Title": "Zeros, Signs, and the Supermask", "Abstract": "The recent \"Lottery Ticket Hypothesis\" paper by Frankle & Carbin showed that a simple approach to creating sparse networks (keep the large weights) results in models that are trainable from scratch, but only when starting from the same initial weights. The performance of these networks often exceeds the performance of the non-sparse base model, but for reasons that were not well understood. In this paper we study the three critical components of the Lottery Ticket (LT) algorithm, showing that each may be varied significantly without impacting the overall results. Ablating these factors leads to new insights for why LT networks perform as well as they do. We show why setting weights to zero is important, how signs are all you need to make the re-initialized network train, and why masking behaves like training. Finally, we discover the existence of Supermasks, or masks that can be applied to an untrained, randomly initialized network to produce a model with performance far better than chance (86% on MNIST, 41% on CIFAR-10)."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CPM-Nets", "Title": "Cross Partial Multi-View Networks", "Abstract": "Despite multi-view learning progressed fast in past decades, it is still challenging due to the difficulty in modeling complex correlation among different views, especially under the context of view missing. To address the challenge, we propose a novel framework termed Cross Partial Multi-View Networks (CPM-Nets). In this framework, we first give a formal definition of completeness and versatility for multi-view representation and then theoretically prove the versatility of the latent representation learned from our algorithm. To achieve the completeness, the task of learning latent multi-view representation is specifically translated to degradation process through mimicking data transmitting, such that the optimal tradeoff between consistence and complementarity across different views could be achieved. In contrast with methods that either complete missing views or group samples according to view-missing patterns, our model fully exploits all samples and all views to produce structured representation for interpretability. Extensive experimental results validate the effectiveness of our algorithm over existing state-of-the-arts."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Finding the Needle in the Haystack with Convolutions", "Title": "on the benefits of architectural bias", "Abstract": "We introduce a method that maps a CNN to its equivalent FCN (denoted as eFCN). Such an embedding enables the comparison of CNN and FCN training dynamics directly in the FCN space.\nWe use this method to test a new training protocol, which consists in training a CNN, embedding it to FCN space at a certain ``relax time'', then resuming the training in FCN space. We observe that for all relax times, the deviation from the CNN subspace is small, and the final performance reached by the eFCN is higher than that reachable by a standard FCN of same architecture. More surprisingly, for some intermediate relax times, the eFCN outperforms the CNN it stemmed, by combining the prior information of the CNN and the expressivity of the FCN in a complementary way. The practical interest of our protocol is limited by the very large size of the highly sparse eFCN. However, it offers interesting insights into the persistence of architectural bias under stochastic gradient dynamics. It shows the existence of some rare basins in the FCN loss landscape associated with very good generalization. These can only be accessed thanks to the CNN prior, which helps navigate the landscape during the early stages of optimization."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Efficiently avoiding saddle points with zero order methods", "Title": "No gradients required", "Abstract": "We consider the case of derivative-free algorithms for non-convex optimization, also known as zero order algorithms, that use only function evaluations rather than gradients. For a wide variety of gradient approximators based on finite differences, we establish asymptotic convergence to second order stationary points using a carefully tailored application of the Stable Manifold Theorem.  Regarding efficiency, we introduce a noisy zero-order method that converges to second order stationary points, i.e avoids saddle points. Our algorithm uses only $\\tilde{\\mathcal{O}}(1 / \\epsilon^2)$ approximate gradient calculations and, thus, it matches the converge rate guarantees of their exact gradient counterparts up to constants. In contrast to previous work, our convergence rate analysis avoids imposing additional dimension dependent slowdowns in the number of iterations required for non-convex zero order optimization."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PasteGAN", "Title": "A Semi-Parametric Method to Generate Image from Scene Graph", "Abstract": "Despite some exciting progress on high-quality image generation from structured (scene graphs) or free-form (sentences) descriptions, most of them only guarantee the image-level semantical consistency, i.e. the generated image matching the semantic meaning of the description. They still lack the investigations on synthesizing the images in a more controllable way, like finely manipulating the visual appearance of every object. Therefore, to generate the images with preferred objects and rich interactions, we propose a semi-parametric method, PasteGAN, for generating the image from the scene graph and the image crops, where spatial arrangements of the objects and their pair-wise relationships are defined by the scene graph and the object appearances are determined by the given object crops. To enhance the interactions of the objects in the output, we design a Crop Refining Network and an Object-Image Fuser to embed the objects as well as their relationships into one map. Multiple losses work collaboratively to guarantee the generated images highly respecting the crops and complying with the scene graphs while maintaining excellent image quality. A crop selector is also proposed to pick the most-compatible crops from our external object tank by encoding the interactions around the objects in the scene graph if the crops are not provided. Evaluated on Visual Genome and COCO-Stuff dataset, our proposed method significantly outperforms the SOTA methods on Inception Score, Diversity Score and Fréchet Inception Distance. Extensive experiments also demonstrate our method’s ability to generate complex and diverse images with given objects. The code is available at https://github.com/yikang-li/PasteGAN."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dying Experts", "Title": "Efficient Algorithms with Optimal Regret Bounds", "Abstract": "We study a variant of decision-theoretic online learning in which the set of experts that are available to Learner can shrink over time. This is a restricted version of the well-studied sleeping experts problem, itself a generalization of the fundamental game of prediction with expert advice. Similar to many works in this direction, our benchmark is the ranking regret. Various results suggest that achieving optimal regret in the fully adversarial sleeping experts problem is computationally hard. This motivates our relaxation where any expert that goes to sleep will never again wake up. We call this setting \"dying experts\" and study it in two different cases: the case where the learner knows the order in which the experts will die and the case where the learner does not. In both cases, we provide matching upper and lower bounds on the ranking regret in the fully adversarial setting. Furthermore, we present new, computationally efficient algorithms that obtain our optimal upper bounds."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayesian Layers", "Title": "A Module for Neural Network Uncertainty", "Abstract": "We describe Bayesian Layers, a module designed for fast experimentation with neural network uncertainty. It extends neural network libraries with drop-in replacements for common layers. This enables composition via a unified abstraction over deterministic and stochastic functions and allows for scalability via the underlying system. These layers capture uncertainty over weights (Bayesian neural nets), pre-activation units (dropout), activations (stochastic output layers''), or the function itself (Gaussian processes). They can also be reversible to propagate uncertainty from input to output. We include code examples for common architectures such as Bayesian LSTMs, deep GPs, and flow-based models. As demonstration, we fit a 5-billion parameterBayesian Transformer'' on 512 TPUv2 cores for uncertainty in machine translation and a Bayesian dynamics model for model-based planning. Finally, we show how Bayesian Layers can be used within the Edward2 language for probabilistic programming with stochastic processes."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Predict Without Looking Ahead", "Title": "World Models Without Forward Prediction", "Abstract": "Much of model-based reinforcement learning involves learning a model of an agent's world, and training an agent to leverage this model to perform a task more efficiently. While these models are demonstrably useful for agents, every naturally occurring model of the world of which we are aware---e.g., a brain---arose as the byproduct of competing evolutionary pressures for survival, not minimization of a supervised forward-predictive loss via gradient descent.  That useful models can arise out of the messy and slow optimization process of evolution suggests that forward-predictive modeling can arise as a side-effect of optimization under the right circumstances. Crucially, this optimization process need not explicitly be a forward-predictive loss. In this work, we introduce a modification to traditional reinforcement learning which we call observational dropout, whereby we limit the agents ability to observe the real environment at each timestep. In doing so, we can coerce an agent into learning a world model to fill in the observation gaps during reinforcement learning. We show that the emerged world model, while not explicitly trained to predict the future, can help the agent learn key skills required to perform well in its environment. Videos of our results available at https://learningtopredict.github.io/"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Copulas as High-Dimensional Generative Models", "Title": "Vine Copula Autoencoders", "Abstract": "We introduce the vine copula autoencoder (VCAE), a flexible generative model for high-dimensional distributions built in a straightforward three-step procedure.\n  First, an autoencoder (AE) compresses the data into a lower dimensional representation.\nSecond, the multivariate distribution of the encoded data is estimated with vine copulas. \nThird, a generative model is obtained by combining the estimated distribution with the decoder part of the AE.\nAs such, the proposed approach can transform any already trained AE into a flexible generative model at a low computational cost.\nThis is an advantage over existing generative models such as adversarial networks and variational AEs which can be difficult to train and can impose strong assumptions on the latent space.\nExperiments on MNIST, Street View House Numbers and Large-Scale CelebFaces Attributes datasets show that VCAEs can achieve competitive results to standard baselines."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "q-means", "Title": "A quantum algorithm for unsupervised machine learning", "Abstract": "Quantum information is a promising new paradigm for fast computations that can provide substantial speedups for many algorithms we use today. Among them, quantum machine learning is one of the most exciting applications of quantum computers. In this paper, we introduce q-means, a new quantum algorithm for clustering. It is a quantum version of a robust k-means algorithm, with similar convergence and precision guarantees. We also design a method to pick the initial centroids equivalent to the classical k-means++ method. Our algorithm provides currently an exponential speedup in the number of points of the dataset, compared to the classical k-means algorithm. We also detail the running time of q-means when applied to well-clusterable datasets. We provide a detailed runtime analysis and numerical simulations for specific datasets. Along with the algorithm, the theorems and tools introduced in this paper can be reused for various applications in quantum machine learning."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RUDDER", "Title": "Return Decomposition for Delayed Rewards", "Abstract": "We propose RUDDER, a novel reinforcement learning approach for delayed rewards in finite Markov decision processes (MDPs). In MDPs the Q-values are equal to the expected immediate reward plus the expected future rewards. The latter are related to bias problems in temporal difference (TD) learning and to high variance problems in Monte Carlo (MC) learning. Both problems are even more severe when rewards are delayed. RUDDER aims at making the expected future rewards zero, which simplifies Q-value estimation to computing the mean of the immediate reward. We propose the following two new concepts to push the expected future rewards toward zero. (i) Reward redistribution that leads to return-equivalent decision processes with the same optimal policies and, when optimal, zero expected future rewards. (ii) Return decomposition via contribution analysis which transforms the reinforcement learning task into a regression task at which deep learning excels. On artificial tasks with delayed rewards, RUDDER is significantly faster than MC and exponentially faster than Monte Carlo Tree Search (MCTS), TD(λ), and reward shaping approaches. At Atari games, RUDDER on top of a Proximal Policy Optimization (PPO) baseline improves the scores, which is most prominent at games with delayed rewards."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Theoretical Analysis of Adversarial Learning", "Title": "A Minimax Approach", "Abstract": "In this paper, we propose a general theoretical method for analyzing the risk bound in the presence of adversaries. Specifically, we try to fit the adversarial learning problem into the minimax framework. We first show that the original adversarial learning problem can be transformed into a minimax statistical learning problem by introducing a transport map between distributions. Then, we prove a new risk bound for this minimax problem in terms of covering numbers under a weak version of Lipschitz condition. Our method can be applied to multi-class classification and popular loss functions including the hinge loss and ramp loss. As some illustrative examples, we derive the adversarial risk bounds for SVMs and deep neural networks, and our bounds have two data-dependent terms, which can be optimized for achieving adversarial robustness."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Successor Uncertainties", "Title": "Exploration and Uncertainty in Temporal Difference Learning", "Abstract": "Posterior sampling for reinforcement learning (PSRL) is an effective method for balancing exploration and exploitation in reinforcement learning. Randomised value functions (RVF) can be viewed as a promising approach to scaling PSRL. However, we show that most contemporary algorithms combining RVF with neural network function approximation do not possess the properties which make PSRL effective, and provably fail in sparse reward problems. Moreover, we find that propagation of uncertainty, a property of PSRL previously thought important for exploration, does not preclude this failure. We use these insights to design Successor Uncertainties (SU), a cheap and easy to implement RVF algorithm that retains key properties of PSRL. SU is highly effective on hard tabular exploration benchmarks. Furthermore, on the Atari 2600 domain, it surpasses human performance on 38 of 49 games tested (achieving a median human normalised score of 2.09), and outperforms its closest RVF competitor, Bootstrapped DQN, on 36 of those."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ouroboros", "Title": "On Accelerating Training of Transformer-Based Language Models", "Abstract": "Language models are essential for natural language processing (NLP) tasks, such as machine translation and text summarization. Remarkable performance has been demonstrated recently across many NLP domains via a Transformer-based language model with over a billion parameters, verifying the benefits of model size. Model parallelism is required if a model is too large to fit in a single computing device. Current methods for model parallelism either suffer from backward locking in backpropagation or are not applicable to language models. We propose the first model-parallel algorithm that speeds the training of Transformer-based language models. We also prove that our proposed algorithm is guaranteed to converge to critical points for non-convex problems. Extensive experiments on Transformer and Transformer-XL language models demonstrate that the proposed algorithm obtains a much faster speedup beyond data parallelism, with comparable or better accuracy. Code to reproduce experiments is to be found at \\url{https://github.com/LaraQianYang/Ouroboros}."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Calibration tests in multi-class classification", "Title": "A unifying framework", "Abstract": "In safety-critical applications a probabilistic model is usually required to be calibrated, i.e., to capture the uncertainty of its predictions accurately. In multi-class classification, calibration of the most confident predictions only is often not sufficient. We propose and study calibration measures for multi-class classification that generalize existing measures such as the expected calibration error, the maximum calibration error, and the maximum mean calibration error. We propose and evaluate empirically different consistent and unbiased estimators for a specific class of measures based on matrix-valued kernels. Importantly, these estimators can be interpreted as test statistics associated with well-defined bounds and approximations of the p-value under the null hypothesis that the model is calibrated, significantly improving the interpretability of calibration measures, which otherwise lack any meaningful unit or scale."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MixMatch", "Title": "A Holistic Approach to Semi-Supervised Learning", "Abstract": "Semi-supervised learning has proven to be a powerful paradigm for leveraging unlabeled data to mitigate the reliance on large labeled datasets.\nIn this work, we unify the current dominant approaches for semi-supervised learning to produce a new algorithm, MixMatch, that\nguesses low-entropy labels for data-augmented unlabeled examples and mixes labeled and unlabeled data using MixUp.\nMixMatch obtains state-of-the-art results by a large margin across many datasets and labeled data amounts. For example,\non CIFAR-10 with 250 labels, we reduce error rate by a factor of 4 (from 38% to 11%) and by a factor of 2 on STL-10.\nWe also demonstrate how MixMatch can help achieve a dramatically better accuracy-privacy trade-off for differential privacy.\nFinally, we perform an ablation study to tease apart which components of MixMatch are most important for its success.\nCode is attached."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Confuse", "Title": "Generating Training Time Adversarial Data with Auto-Encoder", "Abstract": "In this work, we consider one challenging training time attack by modifying training data with bounded perturbation, hoping to manipulate the behavior (both targeted or non-targeted) of any corresponding trained classifier during test time when facing clean samples. To achieve this, we proposed to use an auto-encoder-like network to generate such adversarial perturbations on the training data together with one imaginary victim differentiable classifier. The perturbation generator will learn to update its weights so as to produce the most harmful noise, aiming to cause the lowest performance for the victim classifier during test time. This can be formulated into a non-linear equality constrained optimization problem. Unlike GANs, solving such problem is computationally challenging, we then proposed a simple yet effective procedure to decouple the alternating updates for the two networks for stability. By teaching the perturbation generator to hijacking the training trajectory of the victim classifier, the generator can thus learn to move against the victim classifier step by step. The method proposed in this paper can be easily extended to the label specific setting where the attacker can manipulate the predictions of the victim classifier according to some predefined rules rather than only making wrong predictions. Experiments on various datasets including CIFAR-10 and a reduced version of ImageNet confirmed the effectiveness of the proposed method and empirical results showed that, such bounded perturbations have good transferability across different types of victim classifiers."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ADDIS", "Title": "an adaptive discarding algorithm for online FDR control with conservative nulls", "Abstract": "Major internet companies routinely perform tens of thousands of A/B tests each year. Such large-scale sequential experimentation has resulted in a recent spurt of new algorithms that can provably control the false discovery rate (FDR) in a fully online fashion. However, current state-of-the-art adaptive algorithms can suffer from a significant loss in power if null p-values are conservative (stochastically larger than the uniform distribution), a situation that occurs frequently in practice. In this work, we introduce a new adaptive discarding method called ADDIS that provably controls the FDR and achieves the best of both worlds: it enjoys appreciable power increase over all existing methods if nulls are conservative (the practical case), and rarely loses power if nulls are exactly uniformly distributed (the ideal case). We provide several practical insights on robust choices of tuning parameters, and extend the idea to asynchronous and offline settings as well."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HyperGCN", "Title": "A New Method For Training Graph Convolutional Networks on Hypergraphs", "Abstract": "In many real-world network datasets such as co-authorship, co-citation, email communication, etc., relationships are complex and go beyond pairwise. Hypergraphs provide a flexible and natural modeling tool to model such complex relationships. The obvious existence of such complex relationships in many real-world networks naturaly motivates the problem of learning with hypergraphs. A popular learning paradigm is hypergraph-based semi-supervised learning (SSL) where the goal is to assign labels to initially unlabeled vertices in a hypergraph. Motivated by the fact that a graph convolutional network (GCN) has been effective for graph-based SSL, we propose HyperGCN, a novel GCN for SSL on attributed hypergraphs. Additionally, we show how HyperGCN can be used as a learning-based approach for combinatorial optimisation on NP-hard hypergraph problems. We demonstrate HyperGCN's effectiveness through detailed experimentation on real-world hypergraphs. We have made HyperGCN's source code available to foster reproducible research."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TAB-VCR", "Title": "Tags and Attributes based VCR Baselines", "Abstract": "Reasoning is an important ability that we learn from a very early age. Yet, reasoning is extremely hard for algorithms. Despite impressive recent progress that has been reported on tasks that necessitate reasoning, such as visual question answering and visual dialog, models often exploit biases in datasets.  To develop models with better reasoning abilities, recently, the new visual commonsense reasoning(VCR) task has been introduced. Not only do models have to answer questions, but also do they have to provide a reason for the given answer.  The proposed baseline achieved compelling results, leveraging a meticulously designed model composed of LSTM modules and attention nets. Here we show that a much simpler model obtained by ablating and pruning the existing intricate baseline can perform better with half the number of trainable parameters. By associating visual features with attribute information and better text to image grounding, we obtain further improvements for our simpler & effective baseline, TAB-VCR. We show that this approach results in a 5.3%, 4.4% and 6.5% absolute improvement over the previous state-of-the-art on question answering, answer justification and holistic VCR. Webpage: https://deanplayerljx.github.io/tabvcr/"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MaCow", "Title": "Masked Convolutional Generative Flow", "Abstract": "Flow-based generative models, conceptually attractive due to tractability of both the exact log-likelihood computation and latent-variable inference, and efficiency of both training and sampling, has led to a number of impressive empirical successes and spawned many advanced variants and theoretical investigations.\nDespite their computational efficiency, the density estimation performance of flow-based generative models significantly falls behind those of state-of-the-art autoregressive models. In this work, we introduce masked convolutional generative flow (MaCow), a simple yet effective architecture of generative flow using masked convolution. By restricting the local connectivity in a small kernel, MaCow enjoys the properties of fast and stable training, and efficient sampling, while achieving significant improvements over Glow for density estimation on standard image benchmarks, considerably narrowing the gap to autoregressive models."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization in multitask deep neural classifiers", "Title": "a statistical physics approach", "Abstract": "A proper understanding of the striking generalization abilities of deep neural networks presents an enduring puzzle. Recently, there has been a growing body of numerically-grounded theoretical work that has contributed important insights to the theory of learning in deep neural nets. There has also been a recent interest in extending these analyses to understanding how multitask learning can further improve the generalization capacity of deep neural nets. These studies deal almost exclusively with regression tasks which are amenable to existing analytical techniques. We develop an analytic theory of the nonlinear dynamics of generalization of deep neural networks trained to solve classification tasks using softmax outputs and cross-entropy loss, addressing both single task and multitask settings. We do so by adapting techniques from the statistical physics of disordered systems, accounting for both finite size datasets and correlated outputs induced by the training dynamics. We discuss the validity of our theoretical results in comparison to a comprehensive suite of numerical experiments. Our analysis provides theoretical support for the intuition that the performance of multitask learning is determined by the noisiness of the tasks and how well their input features align with each other. Highly related, clean tasks benefit each other, whereas unrelated, clean tasks can be detrimental to individual task performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Locality-Sensitive Hashing for f-Divergences", "Title": "Mutual Information Loss and Beyond", "Abstract": "Computing approximate nearest neighbors in high dimensional spaces is a central problem in large-scale data mining with a wide range of applications in machine learning and data science. A popular and effective technique in computing nearest neighbors approximately is the locality-sensitive hashing (LSH) scheme. In this paper, we aim to develop LSH schemes for distance functions that measure the distance between two probability distributions, particularly for f-divergences as well as a generalization to capture mutual information loss. First, we provide a general framework to design LHS schemes for f-divergence distance functions and develop LSH schemes for the generalized Jensen-Shannon divergence and triangular discrimination in this framework. We show a two-sided approximation result for approximation of the generalized Jensen-Shannon divergence by the Hellinger distance, which may be of independent interest. Next, we show a general method of reducing the problem of designing an LSH scheme for a Krein kernel (which can be expressed as the difference of two positive definite kernels) to the problem of maximum inner product search. We exemplify this method by applying it to the mutual information loss, due to its several important applications such as model compression."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ANODEV2", "Title": "A Coupled Neural ODE Framework", "Abstract": "It has been observed that residual networks can be viewed as the explicit Euler discretization of an Ordinary Differential Equation (ODE). This observation motivated the introduction of so-called Neural ODEs, in which other discretization schemes and/or adaptive time stepping techniques can be used to improve the performance of residual networks. Here, we propose \\OURS, which extends this approach by introducing a framework that allows ODE-based evolution for both the weights and the activations, in a coupled formulation. Such an approach provides more modeling flexibility, and it can help with generalization performance. We present the formulation of \\OURS, derive optimality conditions, and implement the coupled framework in PyTorch. We present empirical results using several different configurations of \\OURS, testing them on the CIFAR-10 dataset. We report results showing that our coupled ODE-based framework is indeed trainable, and that it achieves higher accuracy, compared to the baseline ResNet network and the recently-proposed Neural ODE approach."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Turbo Autoencoder", "Title": "Deep learning based channel codes for point-to-point communication channels", "Abstract": "Designing codes that combat the noise in a communication medium has remained a significant area of research in information theory as well as wireless communications. Asymptotically optimal channel codes have been developed by mathematicians for communicating under canonical models after over 60 years of research. On the other hand, in many non-canonical channel settings, optimal codes do not exist and the codes designed for canonical models are adapted via heuristics to these channels and are thus not guaranteed to be optimal. In this work, we make significant progress on this problem by designing a fully end-to-end jointly trained neural encoder and decoder, namely, Turbo Autoencoder (TurboAE), with the following contributions: (a) under moderate block lengths, TurboAE approaches state-of-the-art performance under canonical channels; (b) moreover, TurboAE outperforms the state-of-the-art codes under non-canonical settings in terms of reliability. TurboAE shows that the development of channel coding design can be automated via deep learning, with near-optimal performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DetNAS", "Title": "Backbone Search for Object Detection", "Abstract": "Object detectors are usually equipped with backbone networks designed for image classification.  It might be sub-optimal because of the gap between the tasks of image classification and object detection. In this work, we present DetNAS to use Neural Architecture Search (NAS) for the design of better backbones for object detection.  It is non-trivial because detection training typically needs ImageNetpre-training while NAS systems require accuracies on the target detection task as supervisory signals. Based on the technique of one-shot supernet, which contains all possible networks in the search space, we propose a framework for backbone search on object detection. We train the supernet under the typical detector training schedule: ImageNet pre-training and detection fine-tuning. Then, the architecture search is performed on the trained supernet, using the detection task as the guidance. This framework makes NAS on backbones very efficient. In experiments, we show the effectiveness of DetNAS on various detectors, for instance, one-stage RetinaNetand the two-stage FPN. We empirically find that networks searched on object detection shows consistent superiority compared to those searched on ImageNet classification. The resulting architecture achieves superior performance than hand-crafted networks on COCO with much less FLOPs complexity."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Option Keyboard", "Title": "Combining Skills in Reinforcement Learning", "Abstract": "The ability to combine known skills to create new ones may be crucial in the solution of complex reinforcement learning problems that unfold over extended periods. We argue that a robust way of combining skills is to define and manipulate them in the space of pseudo-rewards (or \"cumulants\"). Based on this premise, we propose a framework for combining skills using the formalism of options. We show that every deterministic option can be unambiguously represented as a cumulant defined in an extended domain. Building on this insight and on previous results on transfer learning, we show how to approximate options whose cumulants are linear combinations of the cumulants of known options. This means that, once we have learned options associated with a set of cumulants, we can instantaneously synthesise options induced by any linear combination of them, without any learning involved. We describe how this framework provides a hierarchical interface to the environment whose abstract actions correspond to combinations of basic skills. We demonstrate the practical benefits of our approach in a resource management problem and a navigation task involving a quadrupedal simulated robot."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Learning Over-parameterized Neural Networks", "Title": "A Functional Approximation Perspective", "Abstract": "We consider training over-parameterized two-layer neural networks with Rectified Linear Unit (ReLU) using gradient descent (GD) method. Inspired by a recent line of work, we study the evolutions of network prediction errors across GD iterations, which can be  neatly described in a matrix form. When the network is sufficiently over-parameterized, these matrices individually approximate {\\em an} integral operator which is determined by the feature vector distribution $\\rho$ only. Consequently, GD method can be viewed as {\\em approximately} applying the powers of this integral operator on the underlying/target function $f^*$ that generates the responses/labels. \n \nWe show that if $f^*$ admits a low-rank approximation with respect to the eigenspaces of this integral operator, then the empirical risk decreases to this low rank approximation error at a linear rate which is determined by $f^*$ and $\\rho$ only, i.e., the rate is independent of the sample size $n$. Furthermore, if $f^*$ has zero low-rank approximation error, then, as long as the width of the neural network is $\\Omega(n\\log n)$, the empirical risk decreases to $\\Theta(1/\\sqrt{n})$. To the best of our knowledge, this is the first result showing the sufficiency of nearly-linear network over-parameterization.  We provide an application of our general results to the setting where $\\rho$ is the uniform distribution on the spheres and $f^*$ is a polynomial. Throughout this paper, we consider the scenario where the input dimension $d$ is fixed."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Painless Stochastic Gradient", "Title": "Interpolation, Line-Search, and Convergence Rates", "Abstract": "Recent works have shown that stochastic gradient descent (SGD) achieves the fast convergence rates of full-batch gradient descent for over-parameterized models satisfying certain interpolation conditions. However, the step-size used in these works depends on unknown quantities and SGD's practical performance heavily relies on the choice of this step-size. We propose to use line-search techniques to automatically set the step-size when training models that can interpolate the data. In the interpolation setting, we prove that SGD with a stochastic variant of the classic Armijo line-search attains the deterministic convergence rates for both convex and strongly-convex functions. Under additional assumptions, SGD with Armijo line-search is shown to achieve fast convergence for non-convex functions. Furthermore, we show that stochastic extra-gradient with a Lipschitz line-search attains linear convergence for an important class of non-convex functions and saddle-point problems satisfying interpolation. To improve the proposed methods' practical performance, we give heuristics to use larger step-sizes and acceleration. We compare the proposed algorithms against numerous optimization methods on standard classification tasks using both kernel methods and deep networks. The proposed methods result in competitive performance across all models and datasets, while being robust to the precise choices of hyper-parameters. For multi-class classification using deep networks, SGD with Armijo line-search results in both faster convergence and better generalization."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Random Quadratic Forms with Dependence", "Title": "Applications to Restricted Isometry and Beyond", "Abstract": "Several important families of computational and statistical results in machine learning and randomized algorithms rely on uniform bounds on quadratic forms of random vectors or matrices. Such results include the Johnson-Lindenstrauss (J-L) Lemma, the Restricted Isometry Property (RIP), randomized sketching algorithms, and approximate linear algebra. The existing results critically depend on statistical independence, e.g., independent entries for random vectors, independent rows for random matrices, etc., which prevent their usage in dependent or adaptive modeling settings. In this paper, we show that such independence is in fact not needed for such results which continue to hold under fairly general dependence structures. In particular, we present uniform bounds on random quadratic forms of stochastic processes which are conditionally independent and sub-Gaussian given another (latent) process. Our setup allows general dependencies of the stochastic process on the history of the latent process and the latent process to be influenced by realizations of the stochastic process. The results are thus applicable to adaptive modeling settings and also allows for sequential design of random vectors and matrices. We also discuss stochastic process based forms of  J-L, RIP, and sketching, to illustrate the generality of the results."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Energy-Inspired Models", "Title": "Learning with Sampler-Induced Distributions", "Abstract": "Energy-based models (EBMs) are powerful probabilistic models, but suffer from intractable sampling and density evaluation due to the partition function. As a result, inference in EBMs relies on approximate sampling algorithms, leading to a mismatch between the model and inference. Motivated by this, we consider the sampler-induced distribution as the model of interest and maximize the likelihood of this model. This yields a class of energy-inspired models (EIMs) that incorporate learned energy functions while still providing exact samples and tractable log-likelihood lower bounds. We describe and evaluate three instantiations of such models based on truncated rejection sampling, self-normalized importance sampling, and Hamiltonian importance sampling. These models out-perform or perform comparably to the recently proposed Learned Accept/RejectSampling algorithm and provide new insights on ranking Noise Contrastive Estimation and Contrastive Predictive Coding. Moreover, EIMs allow us to generalize a recent connection between multi-sample variational lower bounds and auxiliary variable variational inference. We show how recent variational bounds can be unified with EIMs as the variational family."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Temporal FiLM", "Title": "Capturing Long-Range Sequence Dependencies with Feature-Wise Modulations.", "Abstract": "Learning representations that accurately capture long-range dependencies in sequential inputs --- including text, audio, and genomic data --- is a key problem in deep learning. Feed-forward convolutional models capture only feature interactions within finite receptive fields while recurrent architectures can be slow and difficult to train due to vanishing gradients. Here, we propose Temporal Feature-Wise Linear Modulation (TFiLM) --- a novel architectural component inspired by adaptive batch normalization and its extensions --- that uses a recurrent neural network to alter the activations of a convolutional model. This approach expands the receptive field of convolutional sequence models with minimal computational overhead. Empirically, we find that TFiLM significantly improves the learning speed and accuracy of feed-forward neural networks on a range of generative and discriminative learning tasks, including text classification and audio super-resolution."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SMILe", "Title": "Scalable Meta Inverse Reinforcement Learning through Context-Conditional Policies", "Abstract": "Imitation Learning (IL) has been successfully applied to complex sequential decision-making problems where standard Reinforcement Learning (RL) algorithms fail. A number of recent methods extend IL to few-shot learning scenarios, where a meta-trained policy learns to quickly master new tasks using limited demonstrations. However, although Inverse Reinforcement Learning (IRL) often outperforms Behavioral Cloning (BC) in terms of imitation quality, most of these approaches build on BC due to its simple optimization objective. In this work, we propose SMILe, a scalable framework for Meta Inverse Reinforcement Learning (Meta-IRL) based on maximum entropy IRL, which can learn high-quality policies from few demonstrations. We examine the efficacy of our method on a variety of high-dimensional simulated continuous control tasks and observe that SMILe significantly outperforms Meta-BC. Furthermore, we observe that SMILe performs comparably or outperforms Meta-DAgger, while being applicable in the state-only setting and not requiring online experts. To our knowledge, our approach is the first efficient method for Meta-IRL that scales to the function approximator setting. For datasets and reproducing results please refer to https://github.com/KamyarGh/rlswiss/blob/master/reproducing/smilepaper.md ."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Model Compression with Adversarial Robustness", "Title": "A Unified Optimization Framework", "Abstract": "Deep model compression has been extensively studied, and state-of-the-art methods can now achieve high compression ratios with minimal accuracy loss. This paper studies model compression through a different lens: could we compress models without hurting their robustness to adversarial attacks, in addition to maintaining accuracy? Previous literature suggested that the goals of robustness and compactness might sometimes contradict. We propose a novel Adversarially Trained Model Compression (ATMC) framework. ATMC constructs a unified constrained optimization formulation, where existing compression means (pruning, factorization, quantization) are all integrated into the constraints. An efficient algorithm is then developed. An extensive group of experiments are presented, demonstrating that ATMC obtains remarkably more favorable trade-off among model size, accuracy and robustness, over currently available alternatives in various settings. The codes are publicly available at: https://github.com/shupenggui/ATMC."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Subspace Attack", "Title": "Exploiting Promising Subspaces for Query-Efficient Black-box Attacks", "Abstract": "Unlike the white-box counterparts that are widely studied and readily accessible, adversarial examples in black-box settings are generally more Herculean on account of the difficulty of estimating gradients. Many methods achieve the task by issuing numerous queries to target classification systems, which makes the whole procedure costly and suspicious to the systems. In this paper, we aim at reducing the query complexity of black-box attacks in this category. We propose to exploit gradients of a few reference models which arguably span some promising search subspaces. Experimental results show that, in comparison with the state-of-the-arts, our method can gain up to 2x and 4x reductions in the requisite mean and medium numbers of queries with much lower failure rates even if the reference models are trained on a small and inadequate dataset disjoint to the one for training the victim model. Code and models for reproducing our results will be made publicly available."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalized Block-Diagonal Structure Pursuit", "Title": "Learning Soft Latent Task Assignment against Negative Transfer", "Abstract": "In multi-task learning, a major challenge springs from a notorious issue known as negative transfer, which refers to the phenomenon that sharing the knowledge with dissimilar and hard tasks often results in a worsened performance. To circumvent this issue, we propose a novel multi-task learning method, which simultaneously learns latent task representations and a block-diagonal Latent Task Assignment Matrix (LTAM). Different from most of the previous work, pursuing the Block-Diagonal structure of LTAM (assigning latent tasks to output tasks) alleviates negative transfer via collaboratively grouping latent tasks and output tasks such that inter-group knowledge transfer and sharing is suppressed. This goal is challenging, since 1) our notion of Block-Diagonal Property extends the traditional notion for square matrices where the $i$-th column and the $i$-th column represents the same concept; 2) marginal constraints on rows and columns are also required for avoiding isolated latent/output tasks. Facing such challenges, we propose  a novel regularizer by means of an equivalent spectral condition realizing this generalized block-diagonal property. Practically, we provide a relaxation scheme which improves the flexibility of the model. With the objective function given, we then propose an alternating optimization method, which not only tells how negative transfer is alleviated in our method but also reveals an interesting connection between our method and the optimal transport problem.  Finally, the method is demonstrated on a simulation dataset, three real-world benchmark datasets and further applied to personalized attribute predictions."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "N-Gram Graph", "Title": "Simple Unsupervised Representation for Graphs, with Applications to Molecules", "Abstract": "Machine learning techniques have recently been adopted in various applications in medicine, biology, chemistry, and material engineering. An important task is to predict the properties of molecules, which serves as the main subroutine in many downstream applications such as virtual screening and drug design. Despite the increasing interest, the key challenge is to construct proper representations of molecules for learning algorithms. This paper introduces the N-gram graph, a simple unsupervised representation for molecules. The method first embeds the vertices in the molecule graph. It then constructs a compact representation for the graph by assembling the vertex embeddings in short walks in the graph, which we show is equivalent to a simple graph neural network that needs no training. The representations can thus be efficiently computed and then used with supervised learning methods for prediction. Experiments on 60 tasks from 10 benchmark datasets demonstrate its advantages over both popular graph neural networks and traditional representation methods. This is complemented by theoretical analysis showing its strong representation and prediction power."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Step Decay Schedule", "Title": "A Near Optimal, Geometrically Decaying Learning Rate Procedure For Least Squares", "Abstract": "Minimax optimal convergence rates for numerous classes of stochastic convex optimization problems are well characterized, where the majority of results utilize iterate averaged stochastic gradient descent (SGD) with polynomially decaying step sizes. In contrast, the behavior of SGD’s final iterate has received much less attention despite the widespread use in practice. Motivated by this observation, this work provides a detailed study of the following question: what rate is achievable using the final iterate of SGD for the streaming least squares regression problem with and without strong convexity? \n\n\nFirst, this work shows that even if the time horizon T (i.e. the number of iterations that SGD is run for) is known in advance, the behavior of SGD’s final iterate with any polynomially decaying learning rate scheme is highly sub-optimal compared to the statistical minimax rate (by a condition number factor in the strongly convex case and a factor of $\\sqrt{T}$ in the non-strongly convex case). In contrast, this paper shows that Step Decay schedules, which cut the learning rate by a constant factor every constant number of epochs (i.e., the learning rate decays geometrically) offer significant improvements over any polynomially decaying step size schedule. In particular, the behavior of the final iterate with step decay schedules is off from the statistical minimax rate by only log factors (in the condition number for the strongly convex case, and in T in the non-strongly convex case). Finally, in stark contrast to the known horizon case, this paper shows that the anytime (i.e. the limiting) behavior of SGD’s final iterate is poor (in that it queries iterates with highly sub-optimal function value infinitely often, i.e. in a limsup sense) irrespective of the step size scheme employed. These results demonstrate the subtlety in establishing optimal learning rate schedules (for the final iterate) for stochastic gradient procedures in fixed time horizon settings."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "R2D2", "Title": "Reliable and Repeatable Detector and Descriptor", "Abstract": "Interest point detection and local feature description are fundamental steps in many computer vision applications. Classical approaches are based on a detect-then-describe paradigm where separate handcrafted methods are used to first identify repeatable keypoints and then represent them with a local descriptor. Neural networks trained with metric learning losses have recently caught up with these techniques, focusing on learning repeatable saliency maps for keypoint detection or learning descriptors at the detected keypoint locations. In this work, we argue that repeatable regions are not necessarily discriminative and can therefore lead to select suboptimal keypoints. Furthermore, we claim that descriptors should be learned only in regions for which matching can be performed with high confidence. \nWe thus propose to jointly learn keypoint detection and description together with a predictor of the local descriptor discriminativeness. This allows to avoid ambiguous areas, thus leading to reliable keypoint detection and description. Our detection-and-description approach simultaneously outputs sparse, repeatable and reliable keypoints that outperforms state-of-the-art detectors and descriptors on the HPatches dataset and on the recent Aachen Day-Night localization benchmark."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "REM", "Title": "From Structural Entropy to Community Structure Deception", "Abstract": "This paper focuses on the privacy risks of disclosing the community structure in an online social network. By exploiting the community affiliations of user accounts, an attacker may infer sensitive user attributes. This raises the problem of community structure deception (CSD), which asks for ways to minimally modify the network so that a given community structure maximally hides itself from community detection algorithms. We investigate CSD through an information-theoretic lens. To this end, we propose a community-based structural entropy to express the amount of information revealed by a community structure. This notion allows us to devise residual entropy minimization (REM) as an efficient procedure to solve CSD. Experimental results over 9 real-world networks and 6 community detection algorithms show that REM is very effective in obfuscating the community structure as compared to other benchmark methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "iSplit LBI", "Title": "Individualized Partial Ranking with Ties via Split LBI", "Abstract": "Due to the inherent uncertainty of data, the problem of predicting partial ranking from pairwise comparison data with ties has attracted increasing interest in recent years. However, in real-world scenarios, different individuals often hold distinct preferences, thus might be misleading to merely look at a global partial ranking while ignoring personal diversity. In this paper, instead of learning a global ranking which is agreed with the consensus, we pursue the tie-aware partial ranking  from an individualized perspective. Particularly, we formulate a unified framework which not only can be used for individualized partial ranking prediction, but can also be helpful for abnormal users selection. This is realized by a variable splitting-based algorithm called iSplit LBI. Specifically, our algorithm  generates a sequence of estimations with a regularization path, where both the hyperparameters and model parameters are updated. At each step of the path, the parameters can be decomposed into three orthogonal parts, namely, abnormal signals, personalized signals and random noise. The abnormal signals can serve the purpose of abnormal user selection, while the  abnormal signals and personalized signals \ntogether are mainly responsible for user partial ranking prediction. Extensive experiments on simulated and real-world datasets demonstrate that our new approach significantly outperforms state-of-the-art alternatives."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PointDAN", "Title": "A Multi-Scale 3D Domain Adaption Network for Point Cloud Representation", "Abstract": "Domain Adaptation (DA) approaches achieved significant improvements in a wide range of machine learning and computer vision tasks (i.e., classification, detection, and segmentation). However, as far as we are aware, there are few methods yet to achieve domain adaptation directly on 3D point cloud data. The unique challenge of point cloud data lies in its abundant spatial geometric information, and the semantics of the whole object is contributed by including regional geometric structures. Specifically, most general-purpose DA methods that struggle for global feature alignment and ignore local geometric information are not suitable for 3D domain alignment. In this paper, we propose a novel 3D Domain Adaptation Network for point cloud data (PointDAN). PointDAN jointly aligns the global and local features in multi-level. For local alignment, we propose Self-Adaptive (SA) node module with an adjusted receptive field to model the discriminative local structures for aligning domains. To represent hierarchically scaled features, node-attention module is further introduced to weight the relationship of SA nodes across objects and domains. For global alignment, an adversarial-training strategy is employed to learn and align global features across domains. Since there is no common evaluation benchmark for 3D point cloud DA scenario, we build a general benchmark (i.e., PointDA-10) extracted from three popular 3D object/scene datasets (i.e., ModelNet, ShapeNet and ScanNet) for cross-domain 3D objects classification fashion. Extensive experiments on PointDA-10 illustrate the superiority of our model over the state-of-the-art general-purpose DA methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GIFT", "Title": "Learning Transformation-Invariant Dense Visual Descriptors via Group CNNs", "Abstract": "Finding local correspondences between images with different viewpoints requires local descriptors that are robust against geometric transformations. An approach for transformation invariance is to integrate out the transformations by pooling the features extracted from transformed versions of an image. However, the feature pooling may sacrifice the distinctiveness of the resulting descriptors. In this paper, we introduce a novel visual descriptor named Group Invariant Feature Transform (GIFT), which is both discriminative and robust to geometric transformations. The key idea is that the features extracted from the transformed versions of an image can be viewed as a function defined on the group of the transformations. Instead of feature pooling, we use group convolutions to exploit underlying structures of the extracted features on the group, resulting in descriptors that are both discriminative and provably invariant to the group of transformations. Extensive experiments show that GIFT outperforms state-of-the-art methods on several benchmark datasets and practically improves the performance of relative pose estimation."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast and Furious Learning in Zero-Sum Games", "Title": "Vanishing Regret with Non-Vanishing Step Sizes", "Abstract": "We show for the first time that it is possible to  reconcile in online learning in zero-sum games two seemingly contradictory objectives: vanishing time-average regret and non-vanishing step sizes. This phenomenon, that we coin   ``fast and furious\" learning in games, sets a new benchmark about what is possible both in  max-min optimization as well as in multi-agent systems. Our analysis does not depend on introducing a carefully tailored  dynamic. Instead we focus on the most well studied online dynamic, gradient descent. Similarly, we focus on the simplest textbook class of games, two-agent two-strategy zero-sum games, such as Matching Pennies. Even for this simplest of benchmarks the best known bound for total regret, prior to our work, was the trivial one of $O(T)$, which is immediately applicable even to a non-learning agent.  Based on a tight understanding of the geometry of the non-equilibrating trajectories in the dual space we prove a regret bound of $\\Theta(\\sqrt{T})$ matching the well known optimal bound for adaptive step sizes in the online setting. This guarantee holds for all fixed step-sizes without having to know the time horizon in advance and adapt the fixed step-size accordingly.As a corollary, we establish that even with fixed learning rates the time-average of mixed strategies, utilities converge to their exact Nash equilibrium values. We also provide experimental evidence suggesting the stronger regret bound holds for all zero-sum games."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Slice-based Learning", "Title": "A Programming Model for Residual Learning in Critical Data Slices", "Abstract": "In real-world machine learning applications, data subsets correspond to especially critical outcomes: vulnerable cyclist detections are safety-critical in an autonomous driving task, and \"question\" sentences might be important to a dialogue agent's language understanding for product purposes.  While machine learning models can achieve quality performance on coarse-grained metrics like F1-score and overall accuracy, they may underperform on these critical subsets---we define these as slices, the key abstraction in our approach. To address slice-level performance, practitioners often train separate \"expert\" models on slice subsets or use multi-task hard parameter sharing.  We propose Slice-based Learning, a new programming model in which the slicing function (SF), a programmer abstraction, is used to specify additional model capacity for each slice.  Any model can leverage SFs to learn slice-specific representations, which are combined with an attention mechanism to make slice-aware predictions.  We show that our approach improves over baselines in terms of computational complexity and slice-specific performance by up to 19.0 points, and overall performance by up to 4.6 F1 points on applications spanning natural language understanding and computer vision benchmarks as well as production-scale industrial systems."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Mixup Training", "Title": "Improved Calibration and Predictive Uncertainty for Deep Neural Networks", "Abstract": "Mixup~\\cite{zhang2017mixup} is  a recently proposed  method for training deep neural networks  where additional samples are generated during training  by convexly combining random pairs of images and their associated labels. While simple to implement, it has shown to be a surprisingly effective method of data augmentation for image classification;  DNNs trained with mixup show noticeable gains in classification performance on a number of  image classification benchmarks. In this work, we discuss a hitherto untouched aspect of mixup training -- the calibration and predictive uncertainty   of models trained with mixup. We find that DNNs trained with mixup  are significantly better calibrated --  i.e the predicted softmax scores  are  much better indicators of the actual likelihood of a correct prediction --  than DNNs trained in the regular fashion. We conduct experiments on a number of image classification architectures and datasets --  including large-scale datasets like ImageNet -- and find this to be the case. \n    Additionally, we find that merely mixing features does not result in the same calibration benefit and that the label smoothing in mixup training plays a significant role in improving calibration.  Finally,  we also observe that mixup-trained DNNs are less prone to over-confident predictions on out-of-distribution and random-noise data.  We conclude that the  typical overconfidence seen in neural networks, even on in-distribution data is likely a consequence of training with hard labels, suggesting that mixup training be employed for classification tasks where predictive uncertainty is a significant concern."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unlocking Fairness", "Title": "a Trade-off Revisited", "Abstract": "The prevailing wisdom is that a model's fairness and its accuracy\n  are in tension with one another.  However, there is a pernicious\n  {\\em modeling-evaluating dualism} bedeviling fair machine learning\n  in which phenomena such as label bias are appropriately acknowledged\n  as a source of unfairness when designing fair models,\n  only to be tacitly abandoned when evaluating them.  We investigate\n  fairness and accuracy, but this time under a variety of controlled\n  conditions in which we vary the amount and type of bias.  We find,\n  under reasonable assumptions, that the tension between fairness and\n  accuracy is illusive, and vanishes as soon as we account for these\n  phenomena during evaluation.  Moreover, our results are consistent\n  with an opposing conclusion: fairness and accuracy are sometimes in\n  accord.  This raises the question, {\\em might there be a way to\n    harness fairness to improve accuracy after all?}  Since most\n  notions of fairness are with respect to the model's predictions and\n  not the ground truth labels, this provides an opportunity to see if\n  we can improve accuracy by harnessing appropriate notions of\n  fairness over large quantities of {\\em unlabeled} data with\n  techniques like posterior regularization and generalized\n  expectation.  Indeed, we find that semi-supervision not only\n  improves fairness, but also accuracy and has advantages over\n  existing in-processing methods that succumb to selection bias on the\n  training set."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Shared Embeddings", "Title": "Data-driven Regularization of Embedding Layers", "Abstract": "In deep neural nets, lower level embedding layers account for a large portion of the total number of parameters. Tikhonov regularization, graph-based regularization, and hard parameter sharing are approaches that introduce explicit biases into training in a hope to reduce statistical complexity. Alternatively, we propose stochastically shared embeddings (SSE), a data-driven approach to regularizing embedding layers, which stochastically transitions between embeddings during stochastic gradient descent (SGD). Because SSE integrates seamlessly with existing SGD algorithms, it can be used with only minor modifications when training large scale neural networks. We develop two versions of SSE: SSE-Graph using knowledge graphs of embeddings; SSE-SE using no prior information. We provide theoretical guarantees for our method and show its empirical effectiveness on 6 distinct tasks, from simple neural networks with one hidden layer in recommender systems, to the transformer and BERT in natural languages. We find that when used along with widely-used regularization methods such as weight decay and dropout, our proposed SSE can further reduce overfitting, which often leads to more favorable generalization results."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Singleshot ", "Title": "a scalable Tucker tensor decomposition", "Abstract": "This paper introduces a new approach for the scalable Tucker decomposition\nproblem. Given a tensor X , the method proposed allows to infer the latent factors\nby processing one subtensor drawn from X at a time. The key principle of our\napproach is based on the recursive computations of gradient and on cyclic update of factors involving only one single step of gradient descent. We further improve the\ncomputational efficiency of this algorithm by proposing an inexact gradient version.\nThese two algorithms are backed with theoretical guarantees of convergence and\nconvergence rate under mild conditions. The scalabilty of the proposed approaches\nwhich can be easily extended to handle some common constraints encountered in\ntensor decomposition (e.g non-negativity), is proven via numerical experiments on\nboth synthetic and real data sets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Mean Field Theory of Quantized Deep Networks", "Title": "The Quantization-Depth Trade-Off", "Abstract": "Reducing the precision of weights and activation functions in neural network training, with minimal impact on performance, is essential for the deployment of these models in resource-constrained environments. We apply mean field techniques to networks with quantized activations in order to evaluate the degree to which quantization degrades signal propagation at initialization. We derive initialization schemes which maximize signal propagation in such networks, and suggest why this is helpful for generalization. Building on these results, we obtain a closed form implicit equation for $L_{\\max}$, the maximal trainable depth (and hence model capacity), given $N$, the number of quantization levels in the activation function. Solving this equation numerically, we obtain asymptotically: $L_{\\max}\\propto N^{1.82}$."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DISN", "Title": "Deep Implicit Surface Network for High-quality Single-view 3D Reconstruction", "Abstract": "Reconstructing 3D shapes from single-view images has been a long-standing\nresearch problem. In this paper, we present DISN, a Deep Implicit Surface Net-\nwork which can generate a high-quality detail-rich 3D mesh from a 2D image by\npredicting the underlying signed distance fields. In addition to utilizing global\nimage features, DISN predicts the projected location for each 3D point on the\n2D image and extracts local features from the image feature maps. Combin-\ning global and local features significantly improves the accuracy of the signed\ndistance field prediction, especially for the detail-rich areas. To the best of our\nknowledge, DISN is the first method that constantly captures details such as\nholes and thin structures present in 3D shapes from single-view images. DISN\nachieves the state-of-the-art single-view reconstruction performance on a variety\nof shape categories reconstructed from both synthetic and real images. Code is\navailable at https://github.com/laughtervv/DISN. The supplemen-\ntary can be found at https://xharlie.github.io/images/neurips_\n2019_supp.pdf"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Supervised Summarization", "Title": "Algorithm and Application to Learning Instructions", "Abstract": "We address the problem of finding representative points of datasets by learning from multiple datasets and their ground-truth summaries. We develop a supervised subset selection framework, based on the facility location utility function, which learns to map datasets to their ground-truth representatives. To do so, we propose to learn representations of data so that the input of transformed data to the facility location recovers their ground-truth representatives. Given the NP-hardness of the utility function, we consider its convex relaxation based on sparse representation and investigate conditions under which the solution of the convex optimization recovers ground-truth representatives of each dataset. We design a loss function whose minimization over the parameters of the data representation network leads to satisfying the theoretical conditions, hence guaranteeing recovering ground-truth summaries. Given the non-convexity of the loss function, we develop an efficient learning scheme that alternates between representation learning by minimizing our proposed loss given the current assignments of points to ground-truth representatives and updating assignments given the current data representation. By experiments on the problem of learning key-steps (subactivities) of instructional videos, we show that our proposed framework improves the state-of-the-art supervised subset selection algorithms."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Think Globally, Act Locally", "Title": "A Deep Neural Network Approach to High-Dimensional Time Series Forecasting", "Abstract": "Forecasting high-dimensional time series plays a crucial role in many applications such as demand forecasting and financial predictions. Modern datasets can have millions of correlated time-series that evolve together, i.e they are extremely high dimensional (one dimension for each individual time-series). There is a need for exploiting global patterns and coupling them with local calibration for better prediction. However, most recent deep learning approaches in the literature are one-dimensional, i.e, even though they are trained on the whole dataset, during prediction, the future forecast for a single dimension mainly depends on past values from the same dimension. In this paper, we seek to correct this deficiency and propose DeepGLO, a deep forecasting model which thinks globally and acts locally. In particular, DeepGLO is a hybrid model that combines a global matrix factorization model regularized by a temporal convolution network, along with another temporal network that can capture local properties of each time-series and associated covariates. Our model can be trained effectively on high-dimensional but diverse time series, where different time series can have vastly different scales, without a priori normalization or rescaling. Empirical results demonstrate that DeepGLO can outperform state-of-the-art approaches; for example, we see more than 25% improvement in WAPE over other methods on a public dataset that contains more than 100K-dimensional time series."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CXPlain", "Title": "Causal Explanations for Model Interpretation under Uncertainty", "Abstract": "Feature importance estimates that inform users about the degree to which given inputs influence the output of a predictive model are crucial for understanding, validating, and interpreting machine-learning models. However, providing fast and accurate estimates of feature importance for high-dimensional data, and quantifying the uncertainty of such estimates remain open challenges. Here, we frame the task of providing explanations for the decisions of machine-learning models as a causal learning task, and train causal explanation (CXPlain) models that learn to estimate to what degree certain inputs cause outputs in another machine-learning model. CXPlain can, once trained, be used to explain the target model in little time, and enables the quantification of the uncertainty associated with its feature importance estimates via bootstrap ensembling. We present experiments that demonstrate that CXPlain is significantly more accurate and faster than existing model-agnostic methods for estimating feature importance. In addition, we confirm that the uncertainty estimates provided by CXPlain ensembles are strongly correlated with their ability to accurately estimate feature importance on held-out data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interaction Hard Thresholding", "Title": "Consistent Sparse Quadratic Regression in Sub-quadratic Time and Space", "Abstract": "Quadratic regression involves modeling the response as a (generalized) linear function of not only the features $x^{j_1}$ but also of quadratic terms $x^{j_1}x^{j_2}$. The inclusion of such higher-order “interaction terms\" in regression often provides an easy way to increase accuracy in already-high-dimensional problems. However, this explodes the problem dimension from linear $O(p)$ to quadratic $O(p^2)$, and it is common to look for sparse interactions (typically via heuristics). In this paper, we provide a new algorithm – Interaction Hard Thresholding (IntHT) which is the first one to provably accurately solve this problem in sub-quadratic time and space. It is a variant of Iterative Hard Thresholding; one that uses the special quadratic structure to devise a new way to (approx.) extract the top elements of a $p^2$ size gradient in sub-$p^2$ time and space. Our main result is to theoretically prove that, in spite of the many speedup-related approximations, IntHT linearly converges to a consistent estimate under standard high-dimensional sparse recovery assumptions. We also demonstrate its value via synthetic experiments. Moreover, we numerically show that IntHT can be extended to higher-order regression problems, and also theoretically analyze an SVRG variant of IntHT."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "More Is Less", "Title": "Learning Efficient Video Representations by Big-Little Network and Depthwise Temporal Aggregation", "Abstract": "Current state-of-the-art models for video action recognition are mostly based on expensive 3D ConvNets. This results in a need for large GPU clusters to train and evaluate such architectures. To address this problem, we present an lightweight and memory-friendly architecture for action recognition that performs on par with or better than current architectures by using only a fraction of resources.\nThe proposed architecture is based on a combination of a deep subnet operating on low-resolution frames with a compact subnet operating on high-resolution frames, allowing for high efficiency and accuracy at the same time. We demonstrate that our approach achieves a reduction by 3~4 times in FLOPs and ~2 times in memory usage compared to the baseline. This enables training deeper models with more input frames under the same computational budget.  To further obviate the need for large-scale 3D convolutions, a temporal aggregation module is proposed to model temporal dependencies in a video at very small additional computational costs. Our models achieve strong performance on several action recognition benchmarks including Kinetics, Something-Something and Moments-in-time. The code and models are available at \\url{https://github.com/IBM/bLVNet-TAM}."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learner-aware Teaching", "Title": "Inverse Reinforcement Learning with Preferences and Constraints", "Abstract": "Inverse reinforcement learning (IRL) enables an agent to learn complex behavior by observing demonstrations from a (near-)optimal policy. The typical assumption is that the learner's goal is to match the teacher’s demonstrated behavior. In this paper, we consider the setting where the learner has its own preferences that it additionally takes into consideration. These preferences can for example capture behavioral biases, mismatched worldviews, or physical constraints. We study two teaching approaches: learner-agnostic teaching, where the teacher provides demonstrations from an optimal policy ignoring the learner's preferences, and learner-aware teaching, where the teacher accounts for the learner’s preferences. We design learner-aware teaching algorithms and show that significant performance improvements can be achieved over learner-agnostic teaching."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisiting the Bethe-Hessian", "Title": "Improved Community Detection in Sparse Heterogeneous Graphs", "Abstract": "Spectral clustering is one of the most popular, yet still incompletely understood, methods for community detection on graphs. This article studies spectral clustering based on the Bethe-Hessian matrix Hr= (r^2−1)In+D−rA for sparse heterogeneous graphs (following the degree-corrected stochastic block model) in a two-class setting. For a specific value r=ζ, clustering is shown to be insensitive to the degree heterogeneity. We then study the behavior of the informative eigenvector of H_ζ and, as a result, predict the clustering accuracy. The article concludes with an overview of the generalization to more than two classes along with extensive simulations on synthetic and real networks corroborating our findings."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Censored Semi-Bandits", "Title": "A Framework for Resource Allocation with Censored Feedback", "Abstract": "In this paper, we study Censored Semi-Bandits, a novel variant of the semi-bandits problem. The learner is assumed to have a fixed amount of resources, which it allocates to the arms at each time step. The loss observed from an arm is random and depends on the amount of resources allocated to it. More specifically, the loss equals zero if the allocation for the arm exceeds a constant (but unknown) threshold that can be dependent on the arm. Our goal is to learn a feasible allocation that minimizes the expected loss. The problem is challenging because the loss distribution and threshold value of each arm are unknown. We study this novel setting by establishing its `equivalence' to Multiple-Play Multi-Armed Bandits (MP-MAB) and Combinatorial Semi-Bandits. Exploiting these equivalences, we derive optimal algorithms for our setting using existing algorithms for MP-MAB and Combinatorial Semi-Bandits. Experiments on synthetically generated data validate performance guarantees of the proposed algorithms."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Average-Case Averages", "Title": "Private Algorithms for Smooth Sensitivity and Mean Estimation", "Abstract": "The simplest and most widely applied method for guaranteeing differential privacy is to add instance-independent noise to a statistic of interest that is scaled to its global sensitivity. However, global sensitivity is a worst-case notion that is often too conservative for realized dataset instances. We provide methods for scaling noise in an instance-dependent way and demonstrate that they provide greater accuracy under average-case distributional assumptions. Specifically, we consider the basic problem of privately estimating the mean of a real distribution from i.i.d. samples. The standard empirical mean estimator can have arbitrarily-high global sensitivity. We propose the trimmed mean estimator, which interpolates between the mean and the median, as a way of attaining much lower sensitivity on average while losing very little in terms of statistical accuracy. To privately estimate the trimmed mean, we revisit the smooth sensitivity framework of Nissim, Raskhodnikova, and Smith (STOC 2007), which provides a framework for using instance-dependent sensitivity. We propose three new additive noise distributions which provide concentrated differential privacy when scaled to smooth sensitivity. We provide theoretical and experimental evidence showing that our noise distributions compare favorably to others in the literature, in particular, when applied to the mean estimation problem."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "First-order methods almost always avoid saddle points", "Title": "The case of vanishing step-sizes", "Abstract": "In a series of papers [Lee et al 2016], [Panageas and Piliouras 2017], [Lee et al 2019], it was established that some of the most commonly used first order methods almost surely (under random initializations) and with step-size being small enough, avoid strict saddle points, as long as the objective function $f$ is $C^2$ and has Lipschitz gradient.  The key observation was that first order methods can be studied from a dynamical systems perspective, in which instantiations of Center-Stable manifold theorem allow for a global analysis. The results of the aforementioned papers were limited to the case where the step-size $\\alpha$ is constant, i.e., does not depend on time (and typically bounded from the inverse of the Lipschitz constant of the gradient of $f$). It remains an open question whether or not the results still hold when the step-size is time dependent and vanishes with time.\n\nIn this paper, we resolve this question on the affirmative for gradient descent, mirror descent, manifold descent and proximal point. The main technical challenge is that the induced (from each first order method) dynamical system is time non-homogeneous and the stable manifold theorem is not applicable in its classic form. By exploiting the dynamical systems structure of the aforementioned first order methods, we are able to prove a stable manifold theorem that is applicable to time non-homogeneous dynamical systems and generalize the results in [Lee et al 2019] for time dependent step-sizes."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Markov Decoding", "Title": "Lower Bounds and Near-Optimal Approximation Algorithms", "Abstract": "We resolve the fundamental problem of online decoding with general nth order ergodic Markov chain models. Specifically, we provide deterministic and randomized algorithms whose performance is close to that of the optimal offline algorithm even when latency is small. Our algorithms admit efficient implementation via dynamic programs, and readily extend to (adversarial) non-stationary or time-varying settings. We also establish lower bounds for online methods under latency constraints in both deterministic and randomized settings, and show that no online algorithm can perform significantly better than our algorithms. To our knowledge, our work is the first to analyze general Markov chain decoding under hard constraints on latency.  We provide strong empirical evidence to illustrate the potential impact of our work in applications such as gene sequencing."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Modelling the Dynamics of Multiagent Q-Learning in Repeated Symmetric Games", "Title": "a Mean Field Theoretic Approach", "Abstract": "Modelling the dynamics of multi-agent learning has long been an important research topic, but all of the previous works focus on 2-agent settings and mostly use evolutionary game theoretic approaches. In this paper, we study an n-agent setting with n tends to infinity, such that agents learn their policies concurrently over repeated symmetric bimatrix games with some other agents. Using mean field theory, we approximate the effects of other agents on a single agent by an averaged effect. A Fokker-Planck equation that describes the evolution of the probability distribution of Q-values in the agent population is derived. To the best of our knowledge, this is the first time to show the Q-learning dynamics under an n-agent setting can be described by a system of only three equations. We validate our model through comparisons with agent-based simulations on typical symmetric bimatrix games and different initial settings of Q-values."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DETOX", "Title": "A Redundancy-based Framework for Faster and More Robust Gradient Aggregation", "Abstract": "To improve the resilience of distributed  training to worst-case, or Byzantine node failures, several recent methods have replaced gradient averaging with robust aggregation methods. Such techniques can have high computational costs, often quadratic in the number of compute nodes, and only have limited robustness guarantees. Other methods have instead used redundancy to guarantee robustness, but can only tolerate limited numbers of Byzantine failures. In this work, we present DETOX, a Byzantine-resilient distributed training framework that combines algorithmic redundancy with robust aggregation. DETOX operates in two steps, a filtering step that uses limited redundancy to significantly reduce the effect of Byzantine nodes, and a hierarchical aggregation step that can be used in tandem with any state-of-the-art robust aggregation method. We show theoretically that this leads to a substantial increase in robustness, and has a per iteration runtime that can be nearly linear in the number of compute nodes. We provide extensive experiments over real distributed setups across a variety of large-scale machine learning tasks, showing that DETOX leads to orders of magnitude accuracy and speedup improvements over many state-of-the-art Byzantine-resilient approaches."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PHYRE", "Title": "A New Benchmark for Physical Reasoning", "Abstract": "Understanding and reasoning about physics is an important ability of intelligent agents. We develop the PHYRE benchmark for physical reasoning that contains a set of simple classical mechanics puzzles in a 2D physical environment. The benchmark is designed to encourage the development of learning algorithms that are sample-efficient and generalize well across puzzles. We test several modern learning algorithms on PHYRE and find that these algorithms fall short in solving the puzzles efficiently. We expect that PHYRE will encourage the development of novel sample-efficient agents that learn efficient but useful models of physics. For code and to play PHYRE for yourself, please visit https://player.phyre.ai."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning-In-The-Loop Optimization", "Title": "End-To-End Control And Co-Design Of Soft Robots Through Learned Deep Latent Representations", "Abstract": "Soft robots have continuum solid bodies that can deform in an infinite number of ways. Controlling soft robots is very challenging as there are no closed form solutions.  We present a learning-in-the-loop co-optimization algorithm in which a latent state representation is learned as the robot figures out how to solve the task. Our solution marries hybrid particle-grid-based simulation with deep, variational convolutional autoencoder architectures that can capture salient features of robot dynamics with high efficacy. We demonstrate our dynamics-aware feature learning algorithm on both 2D and 3D soft robots, and show that it is more robust and faster converging than the dynamics-oblivious baseline.  We validate the behavior of our algorithm with visualizations of the learned representation."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FreeAnchor", "Title": "Learning to Match Anchors for Visual Object Detection", "Abstract": "Modern CNN-based object detectors assign anchors for ground-truth objects under the restriction of object-anchor Intersection-over-Unit (IoU). In this study, we propose a learning-to-match approach to break IoU restriction, allowing objects to match anchors in a flexible manner. Our approach, referred to as FreeAnchor, updates hand-crafted anchor assignment to \"free\" anchor matching by formulating detector training as a maximum likelihood estimation (MLE) procedure. FreeAnchor targets at learning features which best explain a class of objects in terms of both classification and localization. FreeAnchor is implemented by optimizing detection customized likelihood and can be fused with CNN-based detectors in a plug-and-play manner. Experiments on MS-COCO demonstrate that FreeAnchor consistently outperforms the counterparts with significant margins."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SuperGLUE", "Title": "A Stickier Benchmark for General-Purpose Language Understanding Systems", "Abstract": "In the last year, new models and methods for pretraining and transfer learning have driven striking performance improvements across a range of language understanding tasks. The GLUE benchmark, introduced a little over one year ago, offers a single-number metric that summarizes progress on a diverse set of such tasks, but performance on the benchmark has recently surpassed the level of non-expert humans, suggesting limited headroom for further research. In this paper we present SuperGLUE, a new benchmark styled after GLUE with a new set of more difficult language understanding tasks, a software toolkit, and a public leaderboard. SuperGLUE is available at https://super.gluebenchmark.com."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PC-Fairness", "Title": "A Unified Framework for Measuring Causality-based Fairness", "Abstract": "A recent trend of fair machine learning is to define fairness as causality-based notions which concern the causal connection between protected attributes and decisions. However, one common challenge of all causality-based fairness notions is identifiability, i.e., whether they can be uniquely measured from observational data, which is a critical barrier to applying these notions to real-world situations. In this paper, we develop a framework for measuring different causality-based fairness. We propose a unified definition that covers most of previous causality-based fairness notions, namely the path-specific counterfactual fairness (PC fairness). Based on that, we propose a general method in the form of a constrained optimization problem for bounding the path-specific counterfactual fairness under all unidentifiable situations. Experiments on synthetic and real-world datasets show the correctness and effectiveness of our method."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Glyce", "Title": "Glyph-vectors for Chinese Character Representations", "Abstract": "We show that glyph-based models are able to consistently outperform word/char ID-based models  in a wide range of Chinese NLP tasks. When combing with BERT,  we  are able to  set new state-of-the-art results for a variety of Chinese NLP tasks, including  language modeling, tagging (NER, CWS, POS), \nsentence pair classification (BQ, LCQMC,  XNLI, NLPCC-DBQA), \nsingle sentence classification tasks (ChnSentiCorp, the Fudan corpus, iFeng),\ndependency parsing, and semantic role labeling. \nFor example, the proposed model achieves an F1 score of 81.6 on the OntoNotes dataset of NER, +1.5 over BERT; it achieves an almost perfect accuracy of 99.8\\% on the the Fudan corpus for text classification."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GRU-ODE-Bayes", "Title": "Continuous Modeling of Sporadically-Observed Time Series", "Abstract": "Modeling real-world multidimensional time series can be particularly challenging when these are sporadically observed (i.e., sampling is irregular both in time and across dimensions)—such as in the case of clinical patient data. To address these challenges, we propose (1) a continuous-time version of the Gated Recurrent Unit, building upon the recent Neural Ordinary Differential Equations (Chen et al., 2018), and (2) a Bayesian update network that processes the sporadic observations. We bring these two ideas together in our GRU-ODE-Bayes method. We then demonstrate that the proposed method encodes a continuity prior for the latent process and that it can exactly represent the Fokker-Planck dynamics of complex processes driven by a multidimensional stochastic differential equation. Additionally, empirical evaluation shows that our method outperforms the state of the art on both synthetic data and real-world data with applications in healthcare and climate forecast. What is more, the continuity prior is shown to be well suited for low number of samples settings."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Continuous Greedy ++", "Title": "When Upper and Lower Bounds Match", "Abstract": "In this paper, we develop \\scg~(\\text{SCG}{$++$}), the first efficient variant of a conditional gradient method for maximizing a  continuous submodular function subject to a convex constraint. Concretely, for a monotone and continuous DR-submodular function, \\SCGPP achieves a tight  $[(1-1/e)\\OPT -\\epsilon]$ solution while using $O(1/\\epsilon^2)$ stochastic gradients and $O(1/\\epsilon)$ calls to the linear optimization oracle. The best previously known algorithms either achieve a suboptimal $[(1/2)\\OPT -\\epsilon]$ solution with $O(1/\\epsilon^2)$ stochastic gradients or the tight $[(1-1/e)\\OPT -\\epsilon]$ solution  with suboptimal $O(1/\\epsilon^3)$ stochastic gradients. We further provide an information-theoretic lower bound to showcase the necessity of $\\OM({1}/{\\epsilon^2})$ stochastic oracle queries in order to achieve $[(1-1/e)\\OPT -\\epsilon]$ for monotone and DR-submodular functions. This result shows that our proposed \\SCGPP enjoys optimality in terms of both approximation guarantee, i.e., $(1-1/e)$ approximation factor, and stochastic gradient evaluations, i.e., $O(1/\\epsilon^2)$ calls to the stochastic oracle. By using stochastic\ncontinuous optimization as an interface, we also show that it is possible to obtain the $[(1-1/e)\\OPT-\\epsilon]$ tight approximation guarantee for maximizing a monotone\nbut stochastic submodular set function subject to a general matroid constraint after at most \n$\\mathcal{O}(n^2/\\epsilon^2)$ calls to the stochastic function value, where $n$ is the number of elements in the ground set."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "General Proximal Incremental Aggregated Gradient Algorithms", "Title": "Better and Novel Results under General Scheme", "Abstract": "In this paper, we propose a general proximal incremental aggregated gradient algorithm, which contains various existing algorithms including the basic incremental aggregated gradient method. Better and new convergence results are proved even with the general scheme. The novel results presented in this paper, which have not appeared in previous literature, include: a general scheme, nonconvex analysis, the sublinear convergence rates of the function values, much larger stepsizes that guarantee the convergence, the convergence when noise exists, the line search strategy of the proximal incremental aggregated gradient algorithm and its convergence."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Empirically Measuring Concentration", "Title": "Fundamental Limits on Intrinsic Robustness", "Abstract": "Many recent works have shown that adversarial examples that fool classifiers can be found by minimally perturbing a normal input. Recent theoretical results, starting with Gilmer et al. (2018b), show that if the inputs are drawn from a concentrated metric probability space, then adversarial examples with small perturbation are inevitable. A concentrated space has the property that any subset with Ω(1) (e.g.,1/100) measure, according to the imposed distribution, has small distance to almost all (e.g.,  99/100) of the points in the space. It is not clear,  however,  whether these theoretical results apply to actual distributions such as images. This paper presents a method for empirically measuring and bounding the concentration of a concrete dataset which is proven to converge to the actual concentration. We use it to empirically estimate the intrinsic robustness to and L2 and Linfinity perturbations of several image classification benchmarks. Code for our experiments is available at https://github.com/xiaozhanguva/Measure-Concentration."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Drill-down", "Title": "Interactive Retrieval of Complex Scenes using Natural Language Queries", "Abstract": "This paper explores the task of interactive image retrieval using natural language queries, where a user progressively provides input queries to refine a set of retrieval results. Moreover, our work explores this problem in the context of complex image scenes containing multiple objects. We propose Drill-down, an effective framework for encoding multiple queries with an efficient compact state representation that significantly extends current methods for single-round image retrieval.\nWe show that using multiple rounds of natural language queries as input can be surprisingly effective to find arbitrarily specific images of complex scenes. Furthermore, we find that existing image datasets with textual captions can provide a surprisingly effective form of weak supervision for this task. We compare our method with existing sequential encoding and embedding networks, demonstrating superior performance on two proposed benchmarks: automatic image retrieval on a simulated scenario that uses region captions as queries, and interactive image retrieval using real queries from human evaluators."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization in Generative Adversarial Networks", "Title": "A Novel Perspective from Privacy Protection", "Abstract": "In this paper, we aim to understand the generalization properties of generative adversarial networks (GANs) from a new perspective of privacy protection. Theoretically, we prove that a differentially private learning algorithm used for training the GAN does not overfit to a certain degree, i.e., the generalization gap can be bounded. Moreover, some recent works, such as the Bayesian GAN, can be re-interpreted based on our theoretical insight from privacy protection. Quantitatively, to evaluate the information leakage of well-trained GAN models, we perform various membership attacks on these models. The results show that previous Lipschitz regularization techniques are effective in not only reducing the generalization gap but also alleviating the information leakage of the training dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "vGraph", "Title": "A Generative Model for Joint Community Detection and Node Representation Learning", "Abstract": "This paper focuses on two fundamental tasks of graph analysis: community detection and node representation learning, which capture the global and local structures of graphs respectively. In existing literature, these two tasks are usually independently studied while they are actually highly correlated. We propose a probabilistic generative model called vGraph to learn community membership and node representation collaboratively. Specifically, we assume that each node can be represented as a mixture of communities, and each community is defined as a multinomial distribution over nodes. Both the mixing coefficients and the community distribution are parameterized by the low-dimensional representations of the nodes and communities. We designed an effective variational inference algorithm for the optimization through backpropagation, which regularizes the community membership of neighboring nodes to be similar in the latent space. Experimental results on multiple real-world graphs show that vGraph is very effective in both community detection and node representation learning, outperforming many competitive baselines in both tasks. We show that the framework of vGraph is quite flexible and can be easily extended to detect hierarchical communities."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AGEM", "Title": "Solving Linear Inverse Problems via Deep Priors and Sampling", "Abstract": "In this paper we propose to use a denoising autoencoder (DAE) prior to simultaneously solve a linear inverse problem and estimate its noise parameter. Existing DAE-based methods estimate the noise parameter empirically or treat it as a tunable hyper-parameter. We instead propose autoencoder guided EM, a probabilistically sound framework that performs Bayesian inference with intractable deep priors. We show that efficient posterior sampling from the DAE can be achieved via Metropolis-Hastings, which allows the Monte Carlo EM algorithm to be used. We demonstrate competitive results for signal denoising, image deblurring and image devignetting. Our method is an example of combining the representation power of deep learning with uncertainty quantification from Bayesian statistics."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Devign", "Title": "Effective Vulnerability Identification by Learning Comprehensive Program Semantics via Graph Neural Networks", "Abstract": "Vulnerability identification is crucial to protect the software systems from attacks\nfor cyber security. It is especially important to localize the vulnerable functions\namong the source code to facilitate the fix. However, it is a challenging and tedious\nprocess, and also requires specialized security expertise. Inspired by the work\non manually-defined patterns of vulnerabilities from various code representation\ngraphs and the recent advance on graph neural networks, we propose Devign, a\ngeneral graph neural network based model for graph-level classification through\nlearning on a rich set of code semantic representations. It includes a novel Conv\nmodule to efficiently extract useful features in the learned rich node representations for graph-level classification. The model is trained over manually labeled datasets built on 4 diversified large-scale open-source C projects that incorporate high complexity and variety of real source code instead of synthesis code used in previous works. The results of the extensive evaluation on the datasets demonstrate that Devign outperforms the state of the arts significantly with an average of 10.51% higher accuracy and 8.68% F1 score, increases averagely 4.66% accuracy and 6.37% F1 by the Conv module."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probabilistic Watershed", "Title": "Sampling all spanning forests for seeded segmentation and semi-supervised learning", "Abstract": "The seeded Watershed algorithm / minimax semi-supervised learning on a graph computes a minimum spanning forest which connects every pixel / unlabeled node to a seed / labeled node. We propose instead to consider all possible spanning forests and calculate, for every node, the probability  of sampling a forest connecting a certain seed with that node. We dub this approach \"Probabilistic Watershed\". Leo Grady (2006) already noted its equivalence to the Random Walker / Harmonic energy minimization. We here give a simpler proof of this equivalence and establish the computational feasibility of the Probabilistic Watershed with Kirchhoff's matrix tree theorem. Furthermore, we show a new connection between the Random Walker probabilities and the triangle inequality of the effective resistance. Finally, we derive a new and intuitive interpretation of the Power Watershed."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Prior of a Googol Gaussians", "Title": "a Tensor Ring Induced Prior for Generative Models", "Abstract": "Generative models produce realistic objects in many domains, including text, image, video, and audio synthesis. Most popular models—Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs)—usually employ a standard Gaussian distribution as a prior. Previous works show that the richer family of prior distributions may help to avoid the mode collapse problem in GANs and to improve the evidence lower bound in VAEs. We propose a new family of prior distributions—Tensor Ring Induced Prior (TRIP)—that packs an exponential number of Gaussians into a high-dimensional lattice with a relatively small number of parameters. We show that these priors improve Fréchet Inception Distance for GANs and Evidence Lower Bound for VAEs. We also study generative models with TRIP in the conditional generation setup with missing conditions. Altogether, we propose a novel plug-and-play framework for generative models that can be utilized in any GAN and VAE-like architectures."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Preference-Based Batch and Sequential Teaching", "Title": "Towards a Unified View of Models", "Abstract": "Algorithmic machine teaching studies the interaction between a teacher and a learner where the teacher selects labeled examples aiming at teaching a target hypothesis. In a quest to lower teaching complexity and to achieve more natural teacher-learner interactions, several teaching models and complexity measures have been proposed for both the batch settings (e.g., worst-case, recursive, preference-based, and non-clashing models) as well as the sequential settings (e.g., local preference-based model). To better understand the connections between these different batch and sequential models, we develop a novel framework which captures the teaching process via preference functions $\\Sigma$. In our framework, each function $\\sigma \\in \\Sigma$ induces a teacher-learner pair with teaching complexity as $\\TD(\\sigma)$. We show that the above-mentioned teaching models are equivalent to specific types/families of preference functions in our framework. This equivalence, in turn, allows us to study the differences between two important teaching models, namely $\\sigma$ functions inducing the strongest batch (i.e., non-clashing) model and $\\sigma$ functions inducing a weak sequential (i.e., local preference-based) model.  Finally, we identify preference functions inducing a novel family of sequential models with teaching complexity linear in the VC dimension of the hypothesis class: this is in contrast to the best known complexity result for the batch models which is quadratic in the VC dimension."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoPrune", "Title": "Automatic Network Pruning by Regularizing Auxiliary Parameters", "Abstract": "Reducing the model redundancy is an important task to deploy complex deep learning models to resource-limited or time-sensitive devices. Directly regularizing or modifying weight values makes pruning procedure less robust and sensitive to the choice of hyperparameters, and it also requires prior knowledge to tune different hyperparameters for different models. To build a better generalized and easy-to-use pruning method, we propose AutoPrune, which prunes the network through optimizing a set of trainable auxiliary parameters instead of original weights. The instability and noise during training on auxiliary parameters will not directly affect weight values, which makes pruning process more robust to noise and less sensitive to hyperparameters. Moreover, we design gradient update rules for auxiliary parameters to keep them consistent with pruning tasks. Our method can automatically eliminate network redundancy with recoverability, relieving the complicated prior knowledge required to design thresholding functions, and reducing the time for trial and error. We evaluate our method with LeNet and VGG-like on MNIST and CIFAR-10 datasets, and with AlexNet, ResNet and MobileNet on ImageNet to establish the scalability of our work. Results show that our model achieves state-of-the-art sparsity, e.g. 7%, 23% FLOPs and 310x, 75x compression ratio for LeNet5 and VGG-like structure without accuracy drop, and 200M and 100M FLOPs for MobileNet V2 with accuracy 73.32% and 66.83% respectively."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DAC", "Title": "The Double Actor-Critic Architecture for Learning Options", "Abstract": "We reformulate the option framework as two parallel augmented MDPs. Under this novel formulation, all policy optimization algorithms can be used off the shelf to learn intra-option policies, option termination conditions, and a master policy over options. We apply an actor-critic algorithm on each augmented MDP, yielding the Double Actor-Critic (DAC) architecture. Furthermore, we show that, when state-value functions are used as critics, one critic can be expressed in terms of the other, and hence only one critic is necessary. We conduct an empirical study on challenging robot simulation tasks. In a transfer learning setting, DAC outperforms both its hierarchy-free counterpart and previous gradient-based option learning algorithms."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NAOMI", "Title": "Non-Autoregressive Multiresolution Sequence Imputation", "Abstract": "Missing value imputation is a fundamental problem in spatiotemporal modeling, from motion tracking to the dynamics of physical systems. Deep autoregressive models suffer from error propagation which becomes catastrophic for imputing long-range sequences. In this paper, we take a non-autoregressive approach and propose a novel deep generative model: Non-AutOregressive Multiresolution Imputation (NAOMI) to impute long-range sequences given arbitrary missing patterns. NAOMI exploits the multiresolution structure of spatiotemporal data and decodes recursively from coarse to fine-grained resolutions using a divide-and-conquer strategy. We further enhance our model with adversarial training. When evaluated extensively on benchmark datasets from systems of both deterministic and stochastic dynamics. NAOMI demonstrates significant improvement in imputation accuracy (reducing average prediction error by 60% compared to autoregressive counterparts) and generalization for long range sequences."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Write, Execute, Assess", "Title": "Program Synthesis with a REPL", "Abstract": "We present a neural program synthesis approach integrating components which write, execute, and assess code to navigate the search space of possible programs. We equip the search process with an interpreter or a read-eval-print-loop (REPL), which immediately executes partially written programs, exposing their semantics. The REPL addresses a basic challenge of program synthesis: tiny changes in syntax can lead to huge changes in semantics. We train a pair of models, a policy that proposes the new piece of code to write, and a value function that assesses the prospects of the code written so-far. At test time we can combine these models with a Sequential Monte Carlo algorithm. We apply our approach to two domains: synthesizing text editing programs and inferring 2D and 3D graphics programs."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SpiderBoost and Momentum", "Title": "Faster Variance Reduction Algorithms", "Abstract": "SARAH and SPIDER are two recently developed stochastic variance-reduced algorithms, and SPIDER has been shown to achieve a near-optimal first-order oracle complexity in smooth nonconvex optimization. However, SPIDER uses an accuracy-dependent stepsize that slows down the convergence in practice, and cannot handle objective functions that involve nonsmooth regularizers. In this paper, we propose SpiderBoost as an improved scheme, which allows to use a much larger constant-level stepsize while maintaining the same near-optimal oracle complexity, and can be extended with proximal mapping to handle composite optimization (which is nonsmooth and nonconvex) with provable convergence guarantee. In particular, we show that proximal SpiderBoost achieves an oracle complexity of  O(min{n^{1/2}\\epsilon^{-2},\\epsilon^{-3}})  in composite nonconvex optimization, improving the state-of-the-art result by a factor of  O(min{n^{1/6},\\epsilon^{-1/3}}). We further develop a novel momentum scheme to accelerate SpiderBoost for composite optimization, which achieves the near-optimal oracle complexity in theory and substantial improvement in experiments."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mixtape", "Title": "Breaking the Softmax Bottleneck Efficiently", "Abstract": "The softmax bottleneck has been shown to limit the expressiveness of neural lan-\nguage models. Mixture of Softmaxes (MoS) is an effective approach to address such a theoretical limitation, but are expensive compared to softmax in terms of both memory and time. We propose Mixtape, an output layer that breaks the softmax bottleneck more efficiently with three novel techniques—logit space vector gating, sigmoid tree decomposition, and gate sharing. On four benchmarks including language modeling and machine translation, the Mixtape layer substantially improves the efficiency over the MoS layer by 3.5x to 10.5x while obtaining similar performance. A network equipped with Mixtape is only 20% to 34% slower than a\nsoftmax-based network with 10-30K vocabulary sizes, and outperforms softmax in perplexity and translation quality."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MarginGAN", "Title": "Adversarial Training in Semi-Supervised Learning", "Abstract": "A Margin Generative Adversarial Network (MarginGAN) is proposed for semi-supervised learning problems. Like Triple-GAN, the proposed MarginGAN consists of three components---a generator, a discriminator and a classifier, among which two forms of adversarial training arise. The discriminator is trained as usual to distinguish real examples from fake examples produced by the generator. The new feature is that the classifier attempts to increase the margin of real examples and to decrease the margin of fake examples. On the contrary, the purpose of the generator is yielding realistic and large-margin examples in order to fool the discriminator and the classifier simultaneously. Pseudo labels are used for generated and unlabeled examples in training. Our method is motivated by the success of large-margin classifiers and the recent viewpoint that good semi-supervised learning requires a ``bad'' GAN. Experiments on benchmark datasets testify that MarginGAN is orthogonal to several state-of-the-art methods, offering improved error rates and shorter training time as well."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cold Case", "Title": "The Lost MNIST Digits", "Abstract": "Although the popular MNIST dataset \\citep{mnist} is derived from the NIST database \\citep{nist-sd19}, precise processing steps of this derivation have been lost to time. We propose a reconstruction that is accurate enough to serve as a replacement for the MNIST dataset, with insignificant changes in accuracy.  We trace each MNIST digit to its NIST source and its rich metadata such as writer identifier, partition identifier, etc. We also reconstruct the complete MNIST test set with 60,000 samples instead of the usual 10,000. Since the balance 50,000 were never distributed, they enable us to investigate the impact of twenty-five years of MNIST experiments on the reported testing performances. Our results unambiguously confirm the trends observed by \\citet{recht2018cifar,recht2019imagenet}: although the misclassification rates are slightly off, classifier ordering and model selection remain broadly reliable. We attribute this phenomenon to the pairing benefits of comparing classifiers on the same digits."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RUBi", "Title": "Reducing Unimodal Biases for Visual Question Answering", "Abstract": "We propose RUBi, a new learning strategy to reduce biases in any VQA model.\nIt reduces the importance of the most biased examples, i.e. examples that can be correctly classified without looking at the image. \nIt implicitly forces the VQA model to use the two input modalities instead of relying on statistical regularities between the question and the answer.\nWe leverage a question-only model that captures the language biases by identifying when these unwanted regularities are used.\nIt prevents the base VQA model from learning them by influencing its predictions. This leads to dynamically adjusting the loss in order to compensate for biases. \nWe validate our contributions by surpassing the current state-of-the-art results on VQA-CP v2. This dataset is specifically designed to assess the robustness of VQA models when exposed to different question biases at test time than what was seen during training."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bat-G net", "Title": "Bat-inspired High-Resolution 3D Image Reconstruction using Ultrasonic Echoes", "Abstract": "In this paper, a bat-inspired high-resolution ultrasound 3D imaging system is presented. Live bats demonstrate that the properly used ultrasound can be used to perceive 3D space. With this in mind, a neural network referred to as a Bat-G network is implemented to reconstruct the 3D representation of target objects from the hyperbolic FM (HFM) chirped ultrasonic echoes. The Bat-G network consists of an encoder emulating a bat's central auditory pathway, and a 3D graphical visualization decoder. For the acquisition of the ultrasound data, a custom-made Bat-I sensor module is used. The Bat-G network shows the uniform 3D reconstruction results and achieves precision, recall, and F1-score of 0.896, 0.899 and 0.895, respectively. The experimental results demonstrate the implementation feasibility of a high-resolution non-optical sound-based imaging system being used by live bats. The project web page (https://sites.google.com/view/batgnet) contains additional content summarizing our research."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Procrastinating with Confidence", "Title": "Near-Optimal, Anytime, Adaptive Algorithm Configuration", "Abstract": "Algorithm configuration methods optimize the performance of a parameterized heuristic algorithm on a given distribution of problem instances. Recent work introduced an algorithm configuration procedure (Structured Procrastination'') that provably achieves near optimal performance with high probability and with nearly minimal runtime in the worst case. It also offers an anytime property: it keeps tightening its optimality guarantees the longer it is run. Unfortunately, Structured Procrastination is not adaptive to characteristics of the parameterized algorithm: it treats every input like the worst case. Follow-up work (LeapsAndBounds'') achieves adaptivity but trades away the anytime property. This paper introduces a new algorithm, ``Structured Procrastination with Confidence'', that preserves the near-optimality and anytime properties of Structured Procrastination while adding adaptivity. In particular, the new algorithm will perform dramatically faster in settings where many algorithm configurations perform poorly. We show empirically both that such settings arise frequently in practice and that the anytime property is useful for finding good configurations quickly."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepUSPS", "Title": "Deep Robust Unsupervised Saliency Prediction via Self-supervision", "Abstract": "Deep neural network (DNN) based salient object detection in images based on high-quality labels is expensive. Alternative unsupervised approaches rely on careful selection of multiple handcrafted saliency methods to generate noisy pseudo-ground-truth labels. In this work, we propose a two-stage mechanism for robust unsupervised object saliency prediction, where the first stage involves refinement of the noisy pseudo labels generated from different handcrafted methods. Each handcrafted method is substituted by a deep network that learns to generate the pseudo labels. These labels are refined incrementally in multiple iterations via our proposed self-supervision technique. In the second stage, the refined labels produced from multiple networks representing multiple saliency methods are used to train the actual saliency detection network. We show that this self-learning procedure outperforms all the existing unsupervised methods over different datasets. Results are even comparable to those of fully-supervised state-of-the-art approaches."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Disentangling Influence", "Title": "Using disentangled representations to audit model predictions", "Abstract": "Motivated by the need to audit complex and black box models, there has been extensive research on quantifying how data features influence model predictions. Feature influence can be direct (a direct influence on model outcomes) and indirect (model outcomes are influenced via proxy features). Feature influence can also be expressed in aggregate over the training or test data or locally with respect to a single point. Current research has typically focused on one of each of these dimensions. In this paper, we develop disentangled influence audits, a procedure to audit the indirect influence of features. Specifically, we show that disentangled representations provide a mechanism to identify proxy features in the dataset, while allowing an explicit computation of feature influence on either individual outcomes or aggregate-level outcomes. We show through both theory and experiments that disentangled influence audits can both detect proxy features and show, for each individual or in aggregate, which of these proxy features affects the classifier being audited the most. In this respect, our method is more powerful than existing methods for ascertaining feature influence."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SHE", "Title": "A Fast and Accurate Deep Neural Network for Encrypted Data", "Abstract": "In this paper, we propose a Shift-accumulation-based LHE-enabled deep neural network (SHE) for fast and accurate inferences on encrypted data. We use the binary-operation-friendly leveled-TFHE (LTFHE) encryption scheme to implement ReLU activations and max poolings. We also adopt the logarithmic quantization to accelerate inferences by replacing expensive LTFHE multiplications with cheap LTFHE shifts. We propose a mixed bitwidth accumulator to expedite accumulations. Since the LTFHE ReLU activations, max poolings, shifts and accumulations have small multiplicative depth, SHE can implement much deeper network architectures with more convolutional and activation layers. Our experimental results show SHE achieves the state-of-the-art inference accuracy and reduces the inference latency by 76.21% ~ 94.23% over prior LHECNNs on MNIST and CIFAR-10."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Arbicon-Net", "Title": "Arbitrary Continuous Geometric Transformation Networks for Image Registration", "Abstract": "This paper concerns the undetermined problem of estimating geometric transformation between image pairs. Recent methods introduce deep neural networks to predict the controlling parameters of hand-crafted geometric transformation models (e.g. thin-plate spline) for image registration and matching. However, the low-dimension parametric models are incapable of estimating a highly complex geometric transform with limited flexibility to model the actual geometric deformation from image pairs. To address this issue, we present an end-to-end trainable deep neural networks, named Arbitrary Continuous Geometric Transformation Networks (Arbicon-Net), to directly predict the dense displacement field for pairwise image alignment. Arbicon-Net is generalized from training data to predict the desired arbitrary continuous geometric transformation in a data-driven manner for unseen new pair of images. Particularly, without imposing penalization terms, the predicted displacement vector function is proven to be spatially continuous and smooth. To verify the performance of Arbicon-Net, we conducted semantic alignment tests over both synthetic and real image dataset with various experimental settings. The results demonstrate that Arbicon-Net outperforms the previous image alignment techniques in identifying the image correspondences."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast Convergence of Belief Propagation to Global Optima", "Title": "Beyond Correlation Decay", "Abstract": "Belief propagation is a fundamental message-passing algorithm for probabilistic reasoning and inference in graphical models. While it is known to be exact on trees, in most applications belief propagation is run on graphs with cycles. Understanding the behavior of loopy'' belief propagation has been a major challenge for researchers in machine learning, and several positive convergence results for BP are known under strong assumptions which imply the underlying graphical model exhibits decay of correlations. We show that under a natural initialization, BP converges quickly to the global optimum of the Bethe free energy for Ising models on arbitrary graphs, as long as the Ising model is \\emph{ferromagnetic} (i.e. neighbors prefer to be aligned). This holds even though such models can exhibit long range correlations and may have multiple suboptimal BP fixed points. We also show an analogous result for iterating the (naive) mean-field equations; perhaps surprisingly, both results aredimension-free'' in the sense that a constant number of iterations already provides a good estimate to the Bethe/mean-field free energy."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ZO-AdaMM", "Title": "Zeroth-Order Adaptive Momentum Method for Black-Box Optimization", "Abstract": "The adaptive momentum method (AdaMM), which uses past gradients to update descent directions and learning rates simultaneously, has become one of the most popular first-order optimization methods for solving machine learning  problems. However,  AdaMM is not suited for solving black-box optimization problems, where explicit gradient forms are difficult or infeasible to obtain. In this paper, we propose a zeroth-order  AdaMM (ZO-AdaMM) algorithm, that generalizes AdaMM to the gradient-free regime. We show that the convergence rate of ZO-AdaMM for  both  convex and nonconvex optimization is roughly a factor of $O(\\sqrt{d})$ worse than that of the first-order AdaMM algorithm, where $d$ is problem size. In particular, we provide a deep understanding on why  Mahalanobis distance matters in convergence of ZO-AdaMM and other AdaMM-type methods. As a byproduct, our analysis   makes the first step toward understanding adaptive learning rate methods for nonconvex constrained optimization.Furthermore, we demonstrate two applications, designing  per-image and universal adversarial attacks from black-box neural networks, respectively. We perform extensive experiments on ImageNet and empirically show that  ZO-AdaMM converges much faster to a solution of high accuracy compared with  $6$ state-of-the-art ZO optimization methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "U-Time", "Title": "A Fully Convolutional Network for Time Series Segmentation Applied to Sleep Staging", "Abstract": "Neural networks are becoming more and more popular for the analysis of physiological time-series. The most successful deep learning systems in this domain combine convolutional and recurrent layers to extract useful features to model temporal relations. Unfortunately, these recurrent models are difficult to tune and optimize. In our experience, they often require task-specific modifications, which makes them challenging to use for non-experts. We propose U-Time, a fully feed-forward deep learning approach to physiological time series segmentation developed for the analysis of sleep data. U-Time is a temporal fully convolutional network based on the U-Net architecture that was originally proposed for image segmentation. U-Time maps sequential inputs of arbitrary length to sequences of class labels on a freely chosen temporal scale. This is done by implicitly classifying every individual time-point of the input signal and aggregating these classifications over fixed intervals to form the final predictions. We evaluated U-Time for sleep stage classification on a large collection of sleep electroencephalography (EEG) datasets. In all cases, we found that U-Time reaches or outperforms current state-of-the-art deep learning models while being much more robust in the training process and without requiring architecture or hyperparameter adaptation across tasks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VIREL", "Title": "A Variational Inference Framework for Reinforcement Learning", "Abstract": "Applying probabilistic models to reinforcement learning (RL) enables the uses of powerful optimisation tools such as variational inference in RL. However, existing inference frameworks and their algorithms pose significant challenges for learning optimal policies, e.g., the lack of mode capturing behaviour in pseudo-likelihood methods, difficulties learning deterministic policies in maximum entropy RL based approaches, and a lack of analysis when function approximators are used. We propose VIREL, a theoretically grounded probabilistic inference framework for RL that utilises a parametrised action-value function to summarise future dynamics of the underlying MDP, generalising existing approaches. VIREL also benefits from a mode-seeking form of KL divergence, the ability to learn deterministic optimal polices naturally from inference, and the ability to optimise value functions and policies in separate, iterative steps. In applying variational expectation-maximisation to VIREL, we thus show that the actor-critic algorithm can be reduced to expectation-maximisation, with policy improvement equivalent to an E-step and policy evaluation to an M-step. We then derive a family of actor-critic methods fromVIREL, including a scheme for adaptive exploration. Finally, we demonstrate that actor-critic algorithms from this family outperform state-of-the-art methods based on soft value functions in several domains."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Computational Mirrors", "Title": "Blind Inverse Light Transport by Deep Matrix Factorization", "Abstract": "We recover a video of the motion taking place in a hidden scene by observing changes in indirect illumination in a nearby uncalibrated visible region. We solve this problem by factoring the observed video into a matrix product between the unknown hidden scene video and an unknown light transport matrix. This task is extremely ill-posed, as any non-negative factorization will satisfy the data. Inspired by recent work on the Deep Image Prior, we parameterize the factor matrices using randomly initialized convolutional neural networks trained in a one-off manner, and show that this results in decompositions that reflect the true motion in the hidden scene."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Statistical bounds for entropic optimal transport", "Title": "sample complexity and the central limit theorem", "Abstract": "We prove several fundamental statistical bounds for entropic OT with the squared Euclidean cost between subgaussian probability measures in arbitrary dimension.\nFirst, through a new sample complexity result we establish the rate of convergence of entropic OT for empirical measures.\nOur analysis improves exponentially on the bound of Genevay et al.~(2019) and extends their work to unbounded measures.\nSecond, we establish a central limit theorem for entropic OT, based on techniques developed by Del Barrio and Loubes~(2019).\nPreviously, such a result was only known for finite metric spaces.\nAs an application of our results, we develop and analyze a new technique for estimating the entropy of a random variable corrupted by gaussian noise."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Search on the Replay Buffer", "Title": "Bridging Planning and Reinforcement Learning", "Abstract": "The history of learning for control has been an exciting back and forth between two broad classes of algorithms: planning and reinforcement learning. Planning algorithms effectively reason over long horizons, but assume access to a local policy and distance metric over collision-free paths. Reinforcement learning excels at learning policies and relative values of states, but fails to plan over long horizons. Despite the successes of each method on various tasks, long horizon, sparse reward tasks with high-dimensional observations remain exceedingly challenging for both planning and reinforcement learning algorithms. Frustratingly, these sorts of tasks are potentially the most useful, as they are simple to design (a human only need to provide an example goal state) and avoid injecting bias through reward shaping. We introduce a general-purpose control algorithm that combines the strengths of planning and reinforcement learning to effectively solve these tasks. Our main idea is to decompose the task of reaching a distant goal state into a sequence of easier tasks, each of which corresponds to reaching a particular subgoal. We use goal-conditioned RL to learn a policy to reach each waypoint and to learn a distance metric for search. Using graph search over our replay buffer, we can automatically generate this sequence of subgoals, even in image-based environments. Our algorithm, search on the replay buffer (SoRB), enables agents to solve sparse reward tasks over hundreds of steps, and generalizes substantially better than standard RL algorithms."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Differentially Private Bagging", "Title": "Improved utility and cheaper privacy than subsample-and-aggregate", "Abstract": "Differential Privacy is a popular and well-studied notion of privacy. In the era ofbig data that we are in, privacy concerns are becoming ever more prevalent and thusdifferential privacy is being turned to as one such solution. A popular method forensuring differential privacy of a classifier is known as subsample-and-aggregate,in which the dataset is divided into distinct chunks and a model is learned on eachchunk, after which it is aggregated. This approach allows for easy analysis of themodel on the data and thus differential privacy can be easily applied. In this paper,we extend this approach by dividing the data several times (rather than just once)and learning models on each chunk within each division. The first benefit of thisapproach is the natural improvement of utility by aggregating models trained ona more diverse range of subsets of the data (as demonstrated by the well-knownbagging technique). The second benefit is that, through analysis that we provide inthe paper, we can derive tighter differential privacy guarantees when several queriesare made to this mechanism.  In order to derive these guarantees, we introducethe upwards and downwards moments accountants and derive bounds for thesemoments accountants in a data-driven fashion. We demonstrate the improvementsour model makes over standard subsample-and-aggregate in two datasets (HeartFailure (private) and UCI Adult (public))."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "When to Trust Your Model", "Title": "Model-Based Policy Optimization", "Abstract": "Designing effective model-based reinforcement learning algorithms is difficult because the ease of data generation must be weighed against the bias of model-generated data. In this paper, we study the role of model usage in policy optimization both theoretically and empirically. We first formulate and analyze a model-based reinforcement learning algorithm with a guarantee of monotonic improvement at each step. In practice, this analysis is overly pessimistic and suggests that real off-policy data is always preferable to model-generated on-policy data, but we show that an empirical estimate of model generalization can be incorporated into such analysis to justify model usage. Motivated by this analysis, we then demonstrate that a simple procedure of using short model-generated rollouts branched from real data has the benefits of more complicated model-based algorithms without the usual pitfalls. In particular, this approach surpasses the sample efficiency of prior model-based methods, matches the asymptotic performance of the best model-free algorithms, and scales to horizons that cause other model-based methods to fail entirely."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning New Tricks From Old Dogs", "Title": "Multi-Source Transfer Learning From Pre-Trained Networks", "Abstract": "The advent of deep learning algorithms for mobile devices and sensors has led to a dramatic expansion in the availability and number of systems trained on a wide range of machine learning tasks, creating a host of opportunities and challenges in the realm of transfer learning.  Currently, most transfer learning methods require some kind of control over the systems learned, either by enforcing constraints during the source training, or through the use of a joint optimization objective between tasks that requires all data be co-located for training.  However, for practical, privacy, or other reasons, in a variety of applications we may have no control over the individual source task training, nor access to source training samples.  Instead we only have access to features pre-trained on such data as the output of \"black-boxes.''  For such scenarios, we consider the multi-source learning problem of training a classifier using an ensemble of pre-trained neural networks for a set of classes that have not been observed by any of the source networks, and for which we have very few training samples.  We show that by using these distributed networks as feature extractors, we can train an effective classifier in a computationally-efficient manner using tools from (nonlinear) maximal correlation analysis.  In particular, we develop a method we refer to as maximal correlation weighting (MCW) to build the required target classifier from an appropriate weighting of the feature functions from the source networks.  We illustrate the effectiveness of the resulting classifier on datasets derived from the CIFAR-100, Stanford Dogs, and Tiny ImageNet datasets, and, in addition, use the methodology to characterize the relative value of different source tasks in learning a target task."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Correlation in Extensive-Form Games", "Title": "Saddle-Point Formulation and Benchmarks", "Abstract": "While Nash equilibrium in extensive-form games is well understood, very little is known about the properties of extensive-form correlated equilibrium (EFCE), both from a behavioral and from a computational point of view. In this setting, the strategic behavior of players is complemented by an external device that privately recommends moves to agents as the game progresses; players are free to deviate at any time, but will then not receive future recommendations. Our contributions are threefold. First, we show that an EFCE\ncan be formulated as the solution to a bilinear saddle-point problem. To showcase how this novel formulation can inspire new algorithms to compute EFCEs, we propose a simple subgradient descent method which exploits this formulation and structural properties of EFCEs. Our method has better scalability than the prior approach based on linear programming. Second, we propose two benchmark games, which we hope will serve as the basis for future evaluation of EFCE solvers. These games were chosen so as to cover two natural application domains for EFCE: conflict resolution via a mediator, and bargaining and negotiation. Third, we document the qualitative behavior of EFCE in our proposed games. We show that the social-welfare-maximizing equilibria in these games are highly nontrivial and exhibit surprisingly subtle sequential behavior that so far has not received attention in the literature."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Variational Denoising Network", "Title": "Toward Blind Noise Modeling and Removal", "Abstract": "Blind image denoising is an important yet very challenging problem in computer\nvision due to the complicated acquisition process of real images. In this work we\npropose a new variational inference method, which integrates both noise estimation and image denoising into a unique Bayesian framework, for blind image denoising. Specifically, an approximate posterior, parameterized by deep neural networks, is presented by taking the intrinsic clean image and noise variances as latent variables conditioned on the input noisy image. This posterior provides explicit parametric forms for all its involved hyper-parameters, and thus can be easily implemented for blind image denoising with automatic noise estimation for the test noisy image. On one hand, as other data-driven deep learning methods, our method, namely variational denoising network (VDN), can perform denoising efficiently due to its explicit form of posterior expression. On the other hand, VDN inherits the advantages of traditional model-driven approaches, especially the good generalization capability of generative models. VDN has good interpretability and can be flexibly utilized to estimate and remove complicated non-i.i.d. noise collected in real scenarios. Comprehensive experiments are performed to substantiate the superiority of our method in blind image denoising."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Keeping Your Distance", "Title": "Solving Sparse Reward Tasks Using Self-Balancing Shaped Rewards", "Abstract": "While using shaped rewards can be beneficial when solving sparse reward tasks, their successful application often requires careful engineering and is problem specific.  For instance, in tasks where the agent must achieve some goal state, simple distance-to-goal reward shaping often fails, as it renders learning vulnerable to local optima. We introduce a simple and effective model-free method to learn from shaped distance-to-goal rewards on tasks where success depends on reaching a goal state.  Our method introduces an auxiliary distance-based reward based on pairs of rollouts to encourage diverse exploration.  This approach effectively prevents learning dynamics from stabilizing around local optima induced by the naive distance-to-goal reward shaping and enables policies to efficiently solve sparse reward tasks.  Our augmented objective does not require any additional reward engineering or domain expertise to implement and converges to the original sparse objective as the agent learns to solve the task.  We demonstrate that our method successfully solves a variety of hard-exploration tasks (including maze navigation and 3D construction in a Minecraft environment), where naive distance-based reward shaping otherwise fails, and intrinsic curiosity and reward relabeling strategies exhibit poor performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HYPE", "Title": "A Benchmark for Human eYe Perceptual Evaluation of Generative Models", "Abstract": "Generative models often use human evaluations to measure the perceived quality of their outputs. Automated metrics are noisy indirect proxies, because they rely on heuristics or pretrained embeddings. However, up until now, direct human evaluation strategies have been ad-hoc, neither standardized nor validated. Our work establishes a gold standard human benchmark for generative realism. We construct Human eYe Perceptual Evaluation (HYPE) a human benchmark that is (1) grounded in psychophysics research in perception, (2) reliable across different sets of randomly sampled outputs from a model, (3) able to produce separable model performances, and (4) efficient in cost and time. We introduce two variants: one that measures visual perception under adaptive time constraints to determine the threshold at which a model's outputs appear real (e.g. $250$ms), and the other a less expensive variant that measures human error rate on fake and real images sans time constraints. We test HYPE across six state-of-the-art generative adversarial networks and two sampling techniques on conditional and unconditional image generation using four datasets: CelebA, FFHQ, CIFAR-10, and ImageNet. We find that HYPE can track model improvements across training epochs, and we confirm via bootstrap sampling that HYPE rankings are consistent and replicable."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rapid Convergence of the Unadjusted Langevin Algorithm", "Title": "Isoperimetry Suffices", "Abstract": "We study the Unadjusted Langevin Algorithm (ULA) for sampling from a probability distribution $\\nu = e^{-f}$ on $\\R^n$. We prove a convergence guarantee in Kullback-Leibler (KL) divergence assuming $\\nu$ satisfies log-Sobolev inequality and $f$ has bounded Hessian. Notably, we do not assume convexity or bounds on higher derivatives. We also prove convergence guarantees in R\\'enyi divergence of order $q > 1$ assuming the limit of ULA satisfies either log-Sobolev or Poincar\\'e inequality."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "E2-Train", "Title": "Training State-of-the-art CNNs with Over 80% Energy Savings", "Abstract": "Convolutional neural networks (CNNs) have been increasingly deployed to edge devices. Hence, many efforts have been made towards efficient CNN inference on resource-constrained platforms. This paper attempts to explore an orthogonal direction: how to conduct more energy-efficient training of CNNs, so as to enable on-device training? We strive to reduce the energy cost during training, by dropping unnecessary computations, from three complementary levels: stochastic mini-batch dropping on the data level; selective layer update on the model level; and sign prediction for low-cost, low-precision back-propagation, on the algorithm level. Extensive simulations and ablation studies, with real energy measurements from an FPGA board, confirm the superiority of our proposed strategies and demonstrate remarkable energy savings for training. For example, when training ResNet-74 on CIFAR-10, we achieve aggressive energy savings of >90% and >60%, while incurring a top-1 accuracy loss of only about 2% and 1.2%, respectively. When training ResNet-110 on CIFAR-100, an over 84% training energy saving is achieved without degrading inference accuracy."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Graph Neural Tangent Kernel", "Title": "Fusing Graph Neural Networks with Graph Kernels", "Abstract": "While graph kernels (GKs) are easy to train and enjoy provable theoretical guarantees, their practical performances are limited by their expressive power, as the kernel function often depends on hand-crafted combinatorial features of graphs. Compared to graph kernels, graph neural networks (GNNs) usually achieve better practical performance, as GNNs use multi-layer architectures and non-linear activation functions to extract high-order information of graphs as features. However, due to the large number of hyper-parameters and the non-convex nature of the training procedure, GNNs are harder to train. Theoretical guarantees of GNNs are also not well-understood. Furthermore, the expressive power of GNNs scales with the number of parameters, and thus it is hard to exploit the full power of GNNs when computing resources are limited. The current paper presents a new class of graph kernels, Graph Neural Tangent Kernels (GNTKs), which correspond to \\emph{infinitely wide} multi-layer GNNs trained by gradient descent. GNTKs enjoy the full expressive power of GNNs and inherit advantages of GKs. Theoretically, we show GNTKs provably learn a class of smooth functions on graphs. Empirically, we test GNTKs on graph classification datasets and show they achieve strong performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Image Captioning", "Title": "Transforming Objects into Words", "Abstract": "Image captioning models typically follow an encoder-decoder architecture which uses abstract image feature vectors as input to the encoder.\nOne of the most successful algorithms uses feature vectors extracted from the region proposals obtained from an object detector. In this work we introduce the Object Relation Transformer, that builds upon this approach by explicitly incorporating information about the spatial relationship between input detected objects through geometric attention. Quantitative and qualitative results demonstrate the importance of such geometric attention for image captioning, leading to improvements on all common captioning metrics on the MS-COCO dataset. Code is available at https://github.com/yahoo/objectrelationtransformer ."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MelGAN", "Title": "Generative Adversarial Networks for Conditional Waveform Synthesis", "Abstract": "Previous works (Donahue et al., 2018a; Engel et al., 2019a) have found that generating coherent raw audio waveforms with GANs is challenging. In this paper, we show that it is possible to train GANs reliably to generate high quality coherent waveforms by introducing a set of architectural changes and simple training techniques. Subjective evaluation metric (Mean Opinion Score, or MOS) shows the effectiveness of the proposed approach for high quality mel-spectrogram inversion. To establish the generality of the proposed techniques, we show qualitative results of our model in speech synthesis, music domain translation and unconditional music synthesis. We evaluate the various components of the model through ablation studies and suggest a set of guidelines to design general purpose discriminators and generators for conditional sequence synthesis tasks. Our model is non-autoregressive, fully convolutional, with significantly fewer parameters than competing models and generalizes to unseen speakers for mel-spectrogram inversion. Our pytorch implementation runs at more than 100x faster than realtime on GTX 1080Ti GPU and more than 2x faster than real-time on CPU, without any hardware specific optimization tricks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deliberative Explanations", "Title": "visualizing network insecurities", "Abstract": "A new approach to explainable AI, denoted {\\it deliberative explanations,\\/}\n  is proposed. Deliberative explanations are a visualization technique\n  that aims to go beyond the simple visualization of the image regions\n  (or, more generally, input variables) responsible for a network\n  prediction. Instead, they aim to expose the deliberations carried\n  by the network to arrive at that prediction, by uncovering the\n  insecurities of the network about the latter. The\n  explanation consists of a list of insecurities, each composed of\n  1) an image region (more generally, a set of input variables), and 2)\n  an ambiguity formed by the pair of classes responsible for the network\n  uncertainty about the region. Since insecurity detection requires\n  quantifying the difficulty of network predictions, deliberative\n  explanations combine ideas from the literatures on visual explanations and\n  assessment of classification difficulty. More specifically,\n  the proposed implementation\n  combines attributions with respect to both class\n  predictions and a difficulty score.\n  An evaluation protocol that leverages object recognition (CUB200)\n  and scene classification (ADE20K) datasets that combine part and\n  attribute annotations is also introduced to evaluate the accuracy of\n  deliberative explanations. Finally, an experimental evaluation shows that\n  the most accurate explanations are achieved by combining non self-referential\n  difficulty scores and second-order attributions. The resulting\n  insecurities are shown to correlate with regions of attributes that\n  are shared by different classes. Since these regions are also ambiguous\n  for humans, deliberative explanations are intuitive, suggesting that\n  the deliberative process of modern networks correlates with human\n  reasoning."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking Generative Mode Coverage", "Title": "A Pointwise Guaranteed Approach", "Abstract": "Many generative models have to combat missing modes. The conventional wisdom to this end is by reducing through training a statistical distance (such as f -divergence) between the generated distribution and provided data distribution. But this is more of a heuristic than a guarantee. The statistical distance measures a global, but not local, similarity between two distributions. Even if it is small, it does not imply a plausible mode coverage. Rethinking this problem from a game-theoretic perspective, we show that a complete mode coverage is firmly attainable. If a generative model can approximate a data distribution moderately well under a global statistical distance measure, then we will be able to find a mixture of generators that collectively covers every data point and thus every mode, with a lower-bounded generation probability. Constructing the generator mixture has a connection to the multiplicative weights update rule, upon which we propose our algorithm. We prove that our algorithm guarantees complete mode coverage. And our experiments on real and synthetic datasets confirm better mode coverage over recent approaches, ones that also use generator mixtures but rely on global statistical distances."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Extreme Classification in Log Memory using Count-Min Sketch", "Title": "A Case Study of Amazon Search with 50M Products", "Abstract": "In the last decade, it has been shown that many hard AI tasks, especially in NLP, can be naturally modeled as extreme classification problems leading to improved precision. However, such models are prohibitively expensive to train due to the memory bottleneck in the last layer. For example, a reasonable softmax layer for the dataset of interest in this paper can easily reach well beyond 100 billion parameters (> 400 GB memory). To alleviate this problem, we present Merged-Average Classifiers via Hashing (MACH), a generic $K$-classification algorithm where memory provably scales at $O(\\log K)$ without any assumption on the relation between classes. MACH is subtly a count-min sketch structure in disguise, which uses universal hashing to reduce classification with a large number of classes to few embarrassingly parallel and independent classification tasks with a small (constant) number of classes. MACH naturally provides a technique for zero communication model parallelism. We experiment with 6 datasets; some multiclass and some multilabel, and show consistent improvement in precision and recall metrics compared to respective baselines. In particular, we train an end-to -end deep classifier on a private product search dataset sampled from Amazon Search Engine with 70 million queries and 49.46 million documents. MACH outperforms, by a significant margin, the state-of-the-art extreme classification models deployed on commercial search engines: Parabel and dense embedding models. Our largest model has 6.4 billion parameters and trains in less than 35 hrs on a single p3.16x machine. Our training times are 7-10x faster, and our memory footprints are 2-4x smaller than the best baselines. This training time is also significantly lower than the one reported by Google’s mixture of experts (MoE) language model on a comparable model size and hardware."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DM2C", "Title": "Deep Mixed-Modal Clustering", "Abstract": "Data exhibited with multiple modalities are ubiquitous in real-world clustering tasks. Most existing methods, however, pose a strong assumption that the pairing information for modalities is available for all instances. In this paper, we consider a more challenging task where each instance is represented in only one modality, which we call mixed-modal data. Without any extra pairing supervision across modalities, it is difficult to find a universal semantic space for all of them. To tackle this problem, we present an adversarial learning framework for clustering with mixed-modal data. Instead of transforming all the samples into a joint modality-independent space, our framework learns the mappings across individual modal spaces by virtue of cycle-consistency. Through these mappings, we could easily unify all the samples into a single modal space and perform the clustering. Evaluations on several real-world mixed-modal datasets could demonstrate the superiority of our proposed framework."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Proximal Langevin Algorithm", "Title": "Potential Splitting and Nonasymptotic Rates", "Abstract": "We propose a new algorithm---Stochastic Proximal Langevin Algorithm (SPLA)---for sampling from a log concave distribution. Our method is a generalization of the Langevin algorithm to potentials expressed as the sum of one stochastic smooth term and multiple stochastic nonsmooth terms. In each iteration, our splitting technique only requires access to a stochastic gradient of the smooth term and a stochastic proximal operator  for each of the nonsmooth terms. We establish nonasymptotic  sublinear and linear convergence rates under convexity and strong convexity of the smooth term, respectively, expressed in terms of the KL divergence and Wasserstein distance. We illustrate the efficiency of our sampling technique through numerical simulations on a Bayesian learning task."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Optimal Control with Linear Dynamics and Predictions", "Title": "Algorithms and Regret Analysis", "Abstract": "This paper studies the online optimal control problem with time-varying convex stage costs for a time-invariant linear dynamical system, where a finite lookahead window of accurate predictions of the stage costs are available at each time. We design online algorithms, Receding Horizon Gradient-based Control (RHGC), that utilize the predictions through finite steps of gradient computations. We study the algorithm performance measured by dynamic regret: the online performance minus the optimal performance in hindsight. It is shown that the dynamic regret of RHGC decays exponentially with the size of the lookahead window. In addition, we provide a fundamental limit of the dynamic regret for any online algorithms by considering linear quadratic tracking problems. The regret upper bound of one RHGC method almost reaches the fundamental limit, demonstrating the effectiveness of the algorithm. Finally, we numerically test our algorithms for both linear and nonlinear systems to show the effectiveness and generality of our RHGC."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Vector Spaces", "Title": "Compact Data Representation as Differentiable Weighted Graphs", "Abstract": "Learning useful representations is a key ingredient to the success of modern machine learning. Currently, representation learning mostly relies on embedding data into Euclidean space. However, recent work has shown that data in some domains is better modeled by non-euclidean metric spaces, and inappropriate geometry can result in inferior performance. In this paper, we aim to eliminate the inductive bias imposed by the embedding space geometry. Namely, we propose to map data into more general non-vector metric spaces: a weighted graph with a shortest path distance. By design, such graphs can model arbitrary geometry with a proper configuration of edges and weights. Our main contribution is PRODIGE: a method that learns a weighted graph representation of data end-to-end by gradient descent. Greater generality and fewer model assumptions make PRODIGE  more powerful than existing embedding-based approaches. We confirm the superiority of our method via extensive experiments on a wide range of tasks, including classification, compression, and collaborative filtering."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning search spaces for Bayesian optimization", "Title": "Another view of hyperparameter transfer learning", "Abstract": "Bayesian optimization (BO) is a successful methodology to optimize black-box functions that are expensive to evaluate. While traditional methods optimize each black-box function in isolation, there has been recent interest in speeding up BO by transferring knowledge across multiple related black-box functions. In this work, we introduce a method to automatically design the BO search space by relying on evaluations of previous black-box functions. We depart from the common practice of defining a set of arbitrary search ranges a priori by considering search space geometries that are learnt from historical data. This simple, yet effective strategy can be used to endow many existing BO methods with transfer learning properties. Despite its simplicity, we show that our approach considerably boosts BO by reducing the size of the search space, thus accelerating the optimization of a variety of black-box optimization problems. In particular, the proposed approach combined with random search results in a parameter-free, easy-to-implement, robust hyperparameter optimization strategy. We hope it will constitute a natural baseline for further research attempting to warm-start BO."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Loaded DiCE", "Title": "Trading off Bias and Variance in Any-Order Score Function Gradient Estimators for Reinforcement Learning", "Abstract": "Gradient-based methods for optimisation of objectives in stochastic settings with unknown or intractable dynamics require estimators of derivatives. We derive an objective that, under automatic differentiation, produces low-variance unbiased estimators of derivatives at any order. Our objective is compatible with arbitrary advantage estimators, which allows the control of the bias and variance of any-order derivatives when using function approximation. Furthermore, we propose a method to trade off bias and variance of higher order derivatives by discounting the impact of more distant causal dependencies. We demonstrate the correctness and utility of our estimator in analytically tractable MDPs and in meta-reinforcement-learning for continuous control."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Private Learning Implies Online Learning", "Title": "An Efficient Reduction", "Abstract": "In this paper we resolve this open question in the context of pure differential privacy.\nWe derive an efficient black-box reduction from differentially private learning to online learning from expert advice."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MintNet", "Title": "Building Invertible Neural Networks with Masked Convolutions", "Abstract": "We propose a new way of constructing invertible neural networks by combining simple building blocks with a novel set of composition rules. This leads to a rich set of invertible architectures, including those similar to ResNets. Inversion is achieved with a locally convergent iterative procedure that is parallelizable and very fast in practice. Additionally, the determinant of the Jacobian can be computed analytically and efficiently, enabling their generative use as flow models. To demonstrate their flexibility, we show that our invertible neural networks are competitive with ResNets on MNIST and CIFAR-10 classification. When trained as generative models, our invertible networks achieve competitive likelihoods on MNIST, CIFAR-10 and ImageNet 32x32, with bits per dimension of 0.98, 3.32 and 4.06 respectively."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dynamic Incentive-Aware Learning", "Title": "Robust Pricing in Contextual Auctions", "Abstract": "Motivated by pricing in ad exchange markets, we consider the problem  of  robust learning of reserve  prices against strategic  buyers in repeated contextual second-price auctions. Buyers' valuations \\new{for} an item depend on the context  that describes the item.  However, the seller is not aware of  the relationship between the context  and buyers' valuations, i.e., buyers' preferences. The seller's goal is to design a learning policy to set reserve prices via observing the past sales data, and her objective is  to minimize her regret for revenue, where the regret  is computed against   a clairvoyant policy that knows buyers' heterogeneous  preferences. Given the seller's goal,  utility-maximizing buyers  have the incentive to bid untruthfully in order to manipulate the seller's learning policy.  We propose two learning policies that are robust to such strategic behavior. These policies use  the outcomes of the auctions, rather than the submitted bids, to estimate the preferences  while controlling the long-term effect of the outcome of each auction on the future reserve prices. The first policy called Contextual Robust Pricing (CORP) is designed for the setting where the market noise distribution is known to the seller and achieves a T-period regret  of  $O(d\\log(Td) \\log (T))$, where $d$ is the dimension of {the} contextual information.  The second policy, which is a variant of the first policy, is called Stable CORP (SCORP). This policy is tailored to the setting where  the market noise distribution is unknown to the seller and belongs to an ambiguity set.  We show that the SCORP policy has  a T-period regret  of  $O(\\sqrt{d\\log(Td)}\\;T^{2/3})$."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SPoC", "Title": "Search-based Pseudocode to Code", "Abstract": "We consider the task of mapping pseudocode to executable code, assuming a one-to-one correspondence between lines of pseudocode and lines of code. Given test cases as a mechanism to validate programs, we search over the space of possible translations of the pseudocode to find a program that compiles and passes the test cases. While performing a best-first search, compilation errors constitute 88.7% of program failures. To better guide this search, we learn to predict the line of the program responsible for the failure and focus search over alternative translations of the pseudocode for that line.  For evaluation, we collected the SPoC dataset (Search-based Pseudocode to Code) containing 18,356 C++ programs with human-authored pseudocode and test cases. Under a budget of 100 program compilations, performing search improves the synthesis success rate over using the top-one translation of the pseudocode from 25.6% to 44.7%."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributional Policy Optimization", "Title": "An Alternative Approach for Continuous Control", "Abstract": "We identify a fundamental problem in policy gradient-based methods in continuous control. As policy gradient methods require the agent's underlying probability distribution, they limit policy representation to parametric distribution classes. We show that optimizing over such sets results in local movement in the action space and thus convergence to sub-optimal solutions. We suggest a novel distributional framework, able to represent arbitrary distribution functions over the continuous action space. Using this framework, we construct a generative scheme, trained using an off-policy actor-critic paradigm, which we call the Generative Actor Critic (GAC). Compared to policy gradient methods, GAC does not require knowledge of the underlying probability distribution, thereby overcoming these limitations. Empirical evaluation shows that our approach is comparable and often surpasses current state-of-the-art baselines in continuous domains."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Fairness of Risk Scores Beyond Classification", "Title": "Bipartite Ranking and the XAUC Metric", "Abstract": "Where machine-learned predictive risk scores inform high-stakes decisions, such as bail and sentencing in criminal justice, fairness has been a serious concern. Recent work has characterized the disparate impact that such risk scores can have when used for a binary classification task. This may not account, however, for the more diverse downstream uses of risk scores and their non-binary nature. To better account for this, in this paper, we investigate the fairness of predictive risk scores from the point of view of a bipartite ranking task, where one seeks to rank positive examples higher than negative ones. We introduce the xAUC disparity as a metric to assess the disparate impact of risk scores and define it as the difference in the probabilities of ranking a random positive example from one protected group above a negative one from another group and vice versa. We provide a decomposition of bipartite ranking loss into components that involve the discrepancy and components that involve pure predictive ability within each group. We use xAUC analysis to audit predictive risk scores for recidivism prediction, income prediction, and cardiac arrest prediction, where it describes disparities that are not evident from simply comparing within-group predictive performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DATA", "Title": "Differentiable ArchiTecture Approximation", "Abstract": "Neural architecture search (NAS) is inherently subject to the gap of architectures during searching and validating. To bridge this gap, we develop Differentiable ArchiTecture Approximation (DATA) with an Ensemble Gumbel-Softmax (EGS) estimator to automatically approximate architectures during searching and validating in a differentiable manner. Technically, the EGS estimator consists of a group of Gumbel-Softmax estimators, which is capable of converting probability vectors to binary codes and passing gradients from binary codes to probability vectors. Benefiting from such modeling, in searching, architecture parameters and network weights in the NAS model can be jointly optimized with the standard back-propagation, yielding an end-to-end learning mechanism for searching deep models in a large enough search space. Conclusively, during validating, a high-performance architecture that approaches to the learned one during searching is readily built. Extensive experiments on a variety of popular datasets strongly evidence that our method is capable of discovering high-performance architectures for image classification, language modeling and semantic segmentation, while guaranteeing the requisite efficiency during searching."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Near Neighbor", "Title": "Who is the Fairest of Them All?", "Abstract": "In this work we study a \"fair\" variant of the near neighbor problem. Namely, given a set of $n$ points $P$ and a parameter $r$, the goal is to preprocess the points, such that given a query point $q$, any point in the $r$-neighborhood of the query, i.e., $B(q,r)$, have the same probability of being reported as the near neighbor.\n\nWe show that LSH based algorithms can be made fair, without a significant loss in efficiency. Specifically, we show an algorithm that reports a point $p$ in the $r$-neighborhood of a query $q$ with almost uniform probability.  The time to report such a point is proportional to $O(\\dns(q.r) Q(n,c))$, and its space is $O(S(n,c))$, where $Q(n,c)$ and $S(n,c)$ are the query time and space of an LSH algorithm for $c$-approximate near neighbor, and $\\dns(q,r)$ is a function of the local density around $q$.\n\nOur approach works more generally for sampling uniformly from a sub-collection of sets of a given collection and can be used in a few other applications. Finally, we run experiments to show performance of our approach on real data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking Deep Neural Network Ownership Verification", "Title": "Embedding Passports to Defeat Ambiguity Attacks", "Abstract": "With substantial amount of time, resources and human (team) efforts invested to explore and develop successful deep neural networks (DNN), there emerges an urgent need to protect these inventions from being illegally copied, redistributed, or abused without respecting the intellectual properties of legitimate owners. Following recent progresses along this line, we investigate a number of watermark-based DNN ownership verification methods in the face of ambiguity attacks, which aim to cast doubts on the ownership verification by forging counterfeit watermarks. It is shown that ambiguity attacks pose serious threats to existing DNN watermarking methods. As remedies to the above-mentioned loophole, this paper proposes novel passport-based DNN ownership verification schemes which are both robust to network modifications and resilient to ambiguity attacks. The gist of embedding digital passports is to design and train DNN models in a way such that, the DNN inference performance of an original task will be significantly deteriorated due to forged passports. In other words, genuine passports are not only verified by looking for the predefined signatures, but also reasserted by the unyielding DNN model inference performances. Extensive experimental results justify the effectiveness of the proposed passport-based DNN ownership verification schemes. Code and models are available at https://github.com/kamwoh/DeepIPR"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Group Retention when Using Machine Learning in Sequential Decision Making", "Title": "the Interplay between User Dynamics and Fairness", "Abstract": "Machine Learning (ML) models trained on data from multiple demographic groups can inherit representation disparity (Hashimoto et al., 2018) that may exist in the data: the model may be less favorable to groups contributing less to the training process; this in turn can degrade population retention in these groups over time, and exacerbate representation disparity in the long run. In this study, we seek to understand the interplay between ML decisions and the underlying group representation, how they evolve in a sequential framework, and how the use of fairness criteria plays a role in this process. We show that the representation disparity can easily worsen over time under a natural user dynamics (arrival and departure) model when decisions are made based on a commonly used objective and fairness criteria, resulting in some groups diminishing entirely from the sample pool in the long run. It highlights the fact that fairness criteria have to be defined while taking into consideration the impact of decisions on user dynamics. Toward this end, we explain how a proper fairness criterion can be selected based on a general user dynamics model."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shallow RNN", "Title": "Accurate Time-series Classification on Resource Constrained Devices", "Abstract": "Recurrent Neural Networks (RNNs) capture long dependencies and context, and\n2 hence are the key component of typical sequential data based tasks. However, the\nsequential nature of RNNs dictates a large inference cost for long sequences even if\nthe hardware supports parallelization. To induce long-term dependencies, and yet\nadmit parallelization, we introduce novel shallow RNNs. In this architecture, the\nfirst layer splits the input sequence and runs several independent RNNs. The second\nlayer consumes the output of the first layer using a second RNN thus capturing\nlong dependencies. We provide theoretical justification for our architecture under\nweak assumptions that we verify on real-world benchmarks. Furthermore, we show\nthat for time-series classification, our technique leads to substantially improved\ninference time over standard RNNs without compromising accuracy. For example,\nwe can deploy audio-keyword classification on tiny Cortex M4 devices (100MHz\nprocessor, 256KB RAM, no DSP available) which was not possible using standard\nRNN models. Similarly, using SRNN in the popular Listen-Attend-Spell (LAS)\narchitecture for phoneme classification [4], we can reduce the lag inphoneme\nclassification by 10-12x while maintaining state-of-the-art accuracy."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accelerating Rescaled Gradient Descent", "Title": "Fast Optimization of Smooth Functions", "Abstract": "We present a family of algorithms, called descent algorithms, for optimizing convex and non-convex functions. We also introduce a new first-order algorithm, called rescaled gradient descent (RGD), and show that RGD achieves a faster convergence rate than gradient descent provided the function is strongly smooth  - a natural generalization of the standard smoothness assumption on the objective function. When the objective function is convex, we present two frameworks for “accelerating” descent methods, one in the style of Nesterov and the other in the style of Monteiro and Svaiter. Rescaled gradient descent can be accelerated under the same strong smoothness assumption using both frameworks. We provide several examples of strongly smooth loss functions in machine learning and numerical experiments that verify our theoretical findings."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse Variational Inference", "Title": "Bayesian Coresets from Scratch", "Abstract": "The proliferation of automated inference algorithms in Bayesian statistics has provided practitioners newfound access to fast, reproducible data analysis and powerful statistical models.  Designing automated methods that are also both computationally scalable and theoretically sound, however, remains a significant challenge.  Recent work on Bayesian coresets takes the approach of compressing the dataset before running a standard inference algorithm, providing both scalability and guarantees on posterior approximation error.  But the automation of past coreset methods is limited because they depend on the availability of a reasonable coarse posterior approximation, which is difficult to specify in practice.  In the present work we remove this requirement by formulating coreset construction as sparsity-constrained variational inference within an exponential family.  This perspective leads to a novel construction via greedy optimization, and also provides a unifying information-geometric view of present and past methods.  The proposed Riemannian coreset construction algorithm is fully automated, requiring no problem-specific inputs aside from the probabilistic model and dataset.  In addition to being significantly easier to use than past methods, experiments demonstrate that past coreset constructions are fundamentally limited by the fixed coarse posterior approximation; in contrast, the proposed algorithm is able to continually improve the coreset, providing state-of-the-art Bayesian dataset summarization with orders-of-magnitude reduction in KL divergence to the exact posterior."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From voxels to pixels and back", "Title": "Self-supervision in natural-image reconstruction from fMRI", "Abstract": "Reconstructing observed images from fMRI brain recordings is challenging. Unfortunately, acquiring sufficient ''labeled'' pairs of {Image, fMRI} (i.e., images with their corresponding fMRI responses) to span the huge space of natural images is prohibitive for many reasons. We present a novel approach which, in addition to the scarce labeled data (training pairs), allows to train fMRI-to-image reconstruction networks also on \"unlabeled\" data (i.e., images without fMRI recording, and fMRI recording without images). The proposed model utilizes both an Encoder network (image-to-fMRI) and a Decoder network (fMRI-to-image). Concatenating these two networks back-to-back (Encoder-Decoder & Decoder-Encoder) allows augmenting the training data with both types of unlabeled data. Importantly, it allows training on the unlabeled test-fMRI data. This self-supervision adapts the reconstruction network to the new input test-data, despite its deviation from the statistics of the scarce training data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reverse KL-Divergence Training of Prior Networks", "Title": "Improved Uncertainty and Adversarial Robustness", "Abstract": "Ensemble approaches for uncertainty estimation have recently been applied to the tasks of misclassification detection, out-of-distribution input detection and adversarial attack detection. Prior Networks have been proposed as an approach to efficiently emulate an ensemble of models for classification by parameterising a Dirichlet prior distribution over output distributions. These models have been shown to outperform alternative ensemble approaches, such as Monte-Carlo Dropout, on the task of out-of-distribution input detection. However, scaling Prior Networks to complex datasets with many classes is difficult using the training criteria originally proposed. This paper makes two contributions. First, we show that the appropriate training criterion for Prior Networks is the reverse KL-divergence between Dirichlet distributions. This addresses issues in the nature of the training data target distributions, enabling prior networks to be successfully trained on classification tasks with arbitrarily many classes, as well as improving out-of-distribution detection performance. Second, taking advantage of this new training criterion, this paper investigates using Prior Networks to detect adversarial attacks and proposes a generalized form of adversarial training. It is shown that the construction of successful adaptive whitebox attacks, which affect the prediction and evade detection, against Prior Networks trained on CIFAR-10 and CIFAR-100 using the proposed approach requires a greater amount of computational effort than against networks defended using standard adversarial training or MC-dropout."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel-Based Approaches for Sequence Modeling", "Title": "Connections to Neural Methods", "Abstract": "We investigate time-dependent data analysis from the perspective of recurrent kernel machines, from which models with hidden units and gated memory cells arise naturally. By considering dynamic gating of the memory cell, a model closely related to the long short-term memory (LSTM) recurrent neural network is derived. Extending this setup to $n$-gram filters, the convolutional neural network (CNN), Gated CNN, and recurrent additive network (RAN) are also recovered as special cases. Our analysis provides a new perspective on the LSTM, while also extending it to $n$-gram convolutional filters. Experiments are performed on natural language processing tasks and on analysis of local field potentials (neuroscience). We demonstrate that the variants we derive from kernels perform on par or even better than traditional neural methods. For the neuroscience application, the new models demonstrate significant improvements relative to the prior state of the art."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dichotomize and Generalize", "Title": "PAC-Bayesian Binary Activated Deep Neural Networks", "Abstract": "We present a comprehensive study of multilayer neural networks with binary activation, relying on the PAC-Bayesian theory. Our contributions are twofold: (i) we develop an end-to-end framework to train a binary activated deep neural network, (ii) we provide nonvacuous PAC-Bayesian generalization bounds for binary activated deep neural networks. Our results are obtained by minimizing the expected loss of an architecture-dependent aggregation of binary activated deep neural networks. Our analysis inherently overcomes the fact that binary activation function is non-differentiable. The performance of our approach is assessed on a thorough numerical experiment protocol on real-life datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "You Only Propagate Once", "Title": "Accelerating Adversarial Training via Maximal Principle", "Abstract": "Deep learning achieves state-of-the-art results in many tasks in computer vision and natural language processing. However, recent works have shown that deep networks can be vulnerable to adversarial perturbations which raised a serious robustness issue of deep networks. Adversarial training, typically formulated as a robust optimization problem, is an effective way of improving the robustness of deep networks. A major drawback of existing adversarial training algorithms is the computational overhead of the generation of adversarial examples, typically far greater than that of the network training. This leads to unbearable overall computational cost of adversarial training. In this paper, we show that adversarial training can be cast as a discrete time differential game. Through analyzing the Pontryagin’s Maximum Principle (PMP) of the problem, we observe that the adversary update is only coupled with the parameters of the first layer of the network. This inspires us to restrict most of the forward and back propagation within the first layer of the network during adversary updates. This effectively reduces the total number of full forward and backward propagation to only one for each group of adversary updates. Therefore, we refer to this algorithm YOPO (\\textbf{Y}ou \\textbf{O}nly \\textbf{P}ropagate  \\textbf{O}nce). Numerical experiments demonstrate that YOPO can achieve comparable defense accuracy with \\textbf{approximately 1/5 $\\sim$ 1/4 GPU time} of the projected gradient descent (PGD) algorithm~\\cite{kurakin2016adversarial}."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Chasing Ghosts", "Title": "Instruction Following as Bayesian State Tracking", "Abstract": "A visually-grounded navigation instruction can be interpreted as a sequence of expected observations and actions an agent following the correct trajectory would encounter and perform. Based on this intuition, we formulate the problem of finding the goal location in Vision-and-Language Navigation (VLN) within the framework of Bayesian state tracking - learning observation and motion models conditioned on these expectable events. Together with a mapper that constructs a semantic spatial map on-the-fly during navigation, we formulate an end-to-end differentiable Bayes filter and train it to identify the goal by predicting the most likely trajectory through the map according to the instructions. The resulting navigation policy constitutes a new approach to instruction following that explicitly models a probability distribution over states, encoding strong geometric and algorithmic priors while enabling greater explainability. Our experiments show that our approach outperforms a strong LingUNet baseline when predicting the goal location on the map. On the full VLN task, i.e. navigating to the goal location, our approach achieves promising results with less reliance on navigation constraints."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Divide and Couple", "Title": "Using Monte Carlo Variational Objectives for Posterior Approximation", "Abstract": "Recent work in variational inference (VI) has used ideas from Monte Carlo estimation to obtain tighter lower bounds on the log-likelihood to be used as objectives for VI. However, there is not a systematic understanding of how optimizing different objectives relates to approximating the posterior distribution. Developing such a connection is important if the ideas are to be applied to inference—i.e., applications that require an approximate posterior and not just an approximation of the log-likelihood. Given a VI objective defined by a Monte Carlo estimator of the likelihood, we use a \"divide and couple\" procedure to identify augmented proposal and target distributions so that the gap between the VI objective and the log-likelihood is equal to the divergence between these distributions. Thus, after maximizing the VI objective, the augmented variational distribution may be used to approximate the posterior distribution."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Failing Loudly", "Title": "An Empirical Study of Methods for Detecting Dataset Shift", "Abstract": "We might hope that when faced with unexpected inputs, well-designed software systems would fire off warnings. Machine learning (ML) systems, however, which depend strongly on properties of their inputs (e.g. the i.i.d. assumption), tend to fail silently. This paper explores the problem of building ML systems that fail loudly, investigating methods for detecting dataset shift, identifying exemplars that most typify the shift, and quantifying shift malignancy. We focus on several datasets and various perturbations to both covariates and label distributions with varying magnitudes and fractions of data affected. Interestingly, we show that across the dataset shifts that we explore, a two-sample-testing-based approach, using pre-trained classifiers for dimensionality reduction, performs best. Moreover, we demonstrate that domain-discriminating approaches tend to be helpful for characterizing shifts qualitatively and determining if they are harmful."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "No-Press Diplomacy", "Title": "Modeling Multi-Agent Gameplay", "Abstract": "Diplomacy is a seven-player non-stochastic, non-cooperative game, where agents acquire resources through a mix of teamwork and betrayal. Reliance on trust and coordination makes Diplomacy the first non-cooperative multi-agent benchmark for complex sequential social dilemmas in a rich environment. In this work, we focus on training an agent that learns to play the No Press version of Diplomacy where there is no dedicated communication channel between players. We present DipNet, a neural-network-based policy model for No Press Diplomacy. The model was trained on a new dataset of more than 150,000 human games. Our model is trained by supervised learning (SL) from expert trajectories, which is then used to initialize a reinforcement learning (RL) agent trained through self-play. Both the SL and the RL agent demonstrate state-of-the-art No Press performance by beating popular rule-based bots."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Putting An End to End-to-End", "Title": "Gradient-Isolated Learning of Representations", "Abstract": "We propose a novel deep learning method for local self-supervised representation learning that does not require labels nor end-to-end backpropagation but exploits the natural order in data instead. Inspired by the observation that biological neural networks appear to learn without backpropagating a global error signal, we split a deep neural network into a stack of gradient-isolated modules. Each module is trained to maximally preserve the information of its inputs using the InfoNCE bound from Oord et al [2018]. Despite this greedy training, we demonstrate that each module improves upon the output of its predecessor, and that the representations created by the top module yield highly competitive results on downstream classification tasks in the audio and visual domain. The proposal enables optimizing modules asynchronously, allowing large-scale distributed training of very deep neural networks on unlabelled datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Modular Universal Reparameterization", "Title": "Deep Multi-task Learning Across Diverse Domains", "Abstract": "As deep learning applications continue to become more diverse, an interesting question arises: Can general problem solving arise from jointly learning several such diverse tasks? To approach this question, deep multi-task learning is extended in this paper to the setting where there is no obvious overlap between task architectures. The idea is that any set of (architecture,task) pairs can be decomposed into a set of potentially related subproblems, whose sharing is optimized by an efficient stochastic algorithm. The approach is first validated in a classic synthetic multi-task learning benchmark, and then applied to sharing across disparate architectures for vision, NLP, and genomics tasks. It discovers regularities across these domains, encodes them into sharable modules, and combines these modules systematically to improve performance in the individual tasks. The results confirm that sharing learned functionality across diverse domains and architectures is indeed beneficial, thus establishing a key ingredient for general problem solving in the future."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularization Matters", "Title": "Generalization and Optimization of Neural Nets v.s. their Induced Kernel", "Abstract": "Recent works have shown that on sufficiently over-parametrized neural nets, gradient descent with relatively large initialization optimizes a prediction function in the RKHS of the Neural Tangent Kernel (NTK). This analysis leads to global convergence results but does not work when there is a standard $\\ell_2$ regularizer, which is useful to have in practice. We show that sample efficiency can indeed depend on the presence of the regularizer: we construct a simple distribution in $d$ dimensions which the optimal regularized neural net learns with $O(d)$ samples but the NTK requires $\\Omega(d^2)$ samples to learn. To prove this, we establish two analysis tools: i) for multi-layer feedforward ReLU nets, we show that the global minimizer of a weakly-regularized cross-entropy loss is the max normalized margin solution among all neural nets, which generalizes well; ii) we develop a new technique for proving lower bounds for kernel methods, which relies on showing that the kernel cannot focus on informative features. Motivated by our generalization results, we study whether the regularized global optimum is attainable. We prove that for infinite-width two-layer nets, noisy gradient descent optimizes the regularized neural net loss to a global minimum in polynomial iterations."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaInit", "Title": "Initializing learning by learning to initialize", "Abstract": "Deep learning models frequently trade handcrafted features for deep features learned with much less human intervention using gradient descent. While this paradigm has been enormously successful, deep networks are often difficult to train and performance can depend crucially on the initial choice of parameters. In this work, we introduce an algorithm called MetaInit as a step towards automating the search for good initializations using meta-learning. Our approach is based on a hypothesis that good initializations make gradient descent easier by starting in regions that look locally linear with minimal second order effects. We formalize this notion via a quantity that we call the gradient quotient, which can be computed with any architecture or dataset. MetaInit minimizes this quantity efficiently by using gradient descent to tune the norms of the initial weight matrices. We conduct experiments on plain and residual networks and show that the algorithm can automatically recover from a class of bad initializations. MetaInit allows us to train networks and achieve performance competitive with the state-of-the-art without batch normalization or residual connections. In particular, we find that this approach outperforms normalization for networks without skip connections on CIFAR-10 and can scale to Resnet-50 models on Imagenet."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Time Matters in Regularizing Deep Networks", "Title": "Weight Decay and Data Augmentation Affect Early Learning Dynamics, Matter Little Near Convergence", "Abstract": "Regularization is typically understood as improving generalization by altering the landscape of local extrema to which the model eventually converges. Deep neural networks (DNNs), however, challenge this view: We show that removing regularization after an initial transient period has little effect on generalization, even if the final loss landscape is the same as if there had been no regularization. In some cases, generalization even improves after interrupting regularization. Conversely, if regularization is applied only after the initial transient, it has no effect on the final solution, whose generalization gap is as bad as if regularization never happened. This suggests that what matters for training deep networks is not just whether or how, but when to regularize. The phenomena we observe are manifest in different datasets (CIFAR-10, CIFAR-100, SVHN, ImageNet), different architectures (ResNet-18, All-CNN), different regularization methods (weight decay, data augmentation, mixup), different learning rate schedules (exponential, piece-wise constant). They collectively suggest that there is a \"critical period'' for regularizing deep networks that is decisive of the final performance. More analysis should, therefore, focus on the transient rather than asymptotic behavior of learning."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UniXGrad", "Title": "A Universal, Adaptive Algorithm with Optimal Guarantees for Constrained Optimization", "Abstract": "We propose a novel adaptive, accelerated algorithm for the stochastic constrained convex optimization setting.Our method, which is inspired by the Mirror-Prox method,  \\emph{simultaneously} achieves the optimal rates for smooth/non-smooth problems with either deterministic/stochastic first-order oracles. This is done without any prior knowledge of the smoothness nor the noise properties of the problem. To the best of our knowledge, this is the first adaptive, unified algorithm that achieves the optimal rates in the constrained setting. We demonstrate the practical performance of our framework through extensive numerical experiments."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Complexity to Simplicity", "Title": "Adaptive ES-Active Subspaces for Blackbox Optimization", "Abstract": "We present a new algorithm (ASEBO) for optimizing high-dimensional blackbox functions. ASEBO adapts to the geometry of the function and learns optimal sets of sensing directions, which are used to probe it, on-the-fly. It addresses the exploration-exploitation trade-off of blackbox optimization with expensive blackbox queries by continuously learning the bias of the lower-dimensional model used to approximate gradients of smoothings of the function via compressed sensing and contextual bandits methods. To obtain this model, it leverages techniques from the emerging theory of active subspaces in a novel ES blackbox optimization context. As a result, ASEBO learns the dynamically changing intrinsic dimensionality of the gradient space and adapts to the hardness of different stages of the optimization without external supervision. Consequently, it leads to more sample-efficient blackbox optimization than state-of-the-art algorithms. We provide theoretical results and test ASEBO advantages over other methods empirically by evaluating it on the set of reinforcement learning policy optimization tasks as well as functions from the recently open-sourced Nevergrad library."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "L_DMI", "Title": "A Novel Information-theoretic Loss Function for Training Deep Nets Robust to Label Noise", "Abstract": "Accurately annotating large scale dataset is notoriously expensive both in time and in money. Although acquiring low-quality-annotated dataset can be much cheaper, it often badly damages the performance of trained models when using such dataset without particular treatment. Various methods have been proposed for learning with noisy labels. However, most methods only handle limited kinds of noise patterns, require auxiliary information or steps (e.g., knowing or estimating the noise transition matrix), or lack theoretical justification. In this paper, we propose a novel information-theoretic loss function, LDMI, for training deep neural networks robust to label noise. The core of LDMI is a generalized version of mutual information, termed Determinant based Mutual Information (DMI), which is not only information-monotone but also relatively invariant. To the best of our knowledge, LDMI is the first loss function that is provably robust to instance-independent label noise, regardless of noise pattern, and it can be applied to any existing classification neural networks straightforwardly without any auxiliary information. In addition to theoretical justification, we also empirically show that using LDMI outperforms all other counterparts in the classification task on both image dataset and natural language dataset include Fashion-MNIST, CIFAR-10, Dogs vs. Cats, MR with a variety of synthesized noise patterns and noise amounts, as well as a real-world dataset Clothing1M."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PerspectiveNet", "Title": "A Scene-consistent Image Generator for New View Synthesis in Real Indoor Environments", "Abstract": "Given a set of a reference RGBD views of an indoor environment, and a new viewpoint, our goal is to predict the view from that location. Prior work on new-view generation has predominantly focused on significantly constrained scenarios, typically involving artificially rendered views of isolated CAD models. Here we tackle a much more challenging version of the problem. We devise an approach that exploits known geometric properties of the scene (per-frame camera extrinsics and depth) in order to warp reference views into the new ones. The defects in the generated views are handled by a novel RGBD inpainting network, PerspectiveNet, that is fine-tuned for a given scene in order to obtain images that are geometrically consistent with all the views in the scene camera system. Experiments conducted on the ScanNet and SceneNet datasets reveal performance superior to strong baselines."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond temperature scaling", "Title": "Obtaining well-calibrated multi-class probabilities with Dirichlet calibration", "Abstract": "Class probabilities predicted by most multiclass classifiers are uncalibrated, often tending towards over-confidence. With neural networks, calibration can be improved by temperature scaling, a method to learn a single corrective multiplicative factor for inputs to the last softmax layer. On non-neural models the existing methods apply binary calibration in a pairwise or one-vs-rest fashion. We propose a natively multiclass calibration method applicable to classifiers from any model class, derived from Dirichlet distributions and generalising the beta calibration method from binary classification. It is easily implemented with neural nets since it is equivalent to log-transforming the uncalibrated probabilities, followed by one linear layer and softmax. Experiments demonstrate improved probabilistic predictions according to multiple measures (confidence-ECE, classwise-ECE, log-loss, Brier score) across a wide range of datasets and classifiers. Parameters of the learned Dirichlet calibration map \nprovide insights to the biases in the uncalibrated model."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SySCD", "Title": "A System-Aware Parallel Coordinate Descent Algorithm", "Abstract": "In this paper we propose a novel parallel stochastic coordinate descent (SCD) algorithm with convergence guarantees that exhibits strong scalability. We start by studying a state-of-the-art parallel implementation of SCD and identify scalability as well as system-level performance bottlenecks of the respective implementation. We then take a principled approach to develop a new SCD variant which is designed to avoid the identified system bottlenecks, such as limited scaling due to coherence traffic of model sharing across threads, and inefficient CPU cache accesses. Our proposed system-aware parallel coordinate descent algorithm (SySCD) scales to many cores and across numa nodes, and offers a consistent bottom line speedup in training time of up to x12 compared to an optimized asynchronous parallel SCD algorithm and up to x42, compared to state-of-the-art GLM solvers (scikit-learn, Vowpal Wabbit, and H2O) on a range of datasets and multi-core CPU architectures."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Saccader", "Title": "Improving Accuracy of Hard Attention Models for Vision", "Abstract": "Although deep convolutional neural networks achieve state-of-the-art performance across nearly all image classification tasks, their decisions are difficult to interpret. One approach that offers some level of interpretability by design is \\textit{hard attention}, which uses only relevant portions of the image. However, training hard attention models with only class label supervision is challenging, and hard attention has proved difficult to scale to complex datasets. Here, we propose a novel hard attention model, which we term Saccader. \nKey to Saccader is a pretraining step that requires only class labels and provides initial attention locations for policy gradient optimization. Our best models narrow the gap to common ImageNet baselines, achieving $75\\%$  top-1 and $91\\%$ top-5 while attending to less than one-third of the image."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeurVPS", "Title": "Neural Vanishing Point Scanning via Conic Convolution", "Abstract": "We present a simple yet effective end-to-end trainable deep network with geometry-inspired convolutional operators for detecting vanishing points in images. Traditional convolutional neural networks rely on aggregating edge features and do not have mechanisms to directly exploit the geometric properties of vanishing points as the intersections of parallel lines. In this work, we identify a canonical conic space in which the neural network can effectively compute the global geometric information of vanishing points locally, and we propose a novel operator named conic convolution that can be implemented as regular convolutions in this space. This new operator explicitly enforces feature extractions and aggregations along the structural lines and yet has the same number of parameters as the regular 2D convolution. Our extensive experiments on both synthetic and real-world datasets show that the proposed operator significantly improves the performance of vanishing point detection over traditional methods. The code and dataset have been made publicly available at https://github.com/zhou13/neurvps."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Lookahead Optimizer", "Title": "k steps forward, 1 step back", "Abstract": "The vast majority of successful deep neural networks are trained using variants of stochastic gradient descent (SGD) algorithms. Recent attempts to improve SGD can be broadly categorized into two approaches: (1) adaptive learning rate schemes, such as AdaGrad and Adam and (2) accelerated schemes, such as heavy-ball and Nesterov momentum. In this paper, we propose a new optimization algorithm, Lookahead, that is orthogonal to these previous approaches and iteratively updates two sets of weights. Intuitively, the algorithm chooses a search direction by looking ahead at the sequence of ``fast weights\" generated by another optimizer. We show that Lookahead improves the learning stability and lowers the variance of its inner optimizer with negligible computation and memory cost. We empirically demonstrate Lookahead can significantly improve the performance of SGD and Adam, even with their default hyperparameter settings on ImageNet, CIFAR-10/100, neural machine translation, and Penn Treebank."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Data Parameters", "Title": "A New Family of Parameters for Learning a Differentiable Curriculum", "Abstract": "Recent works have shown that learning from easier instances first can help deep neural networks (DNNs) generalize better. However, knowing which data to present during different stages of training is a challenging problem. In this work, we address\nthis problem by introducing data parameters. More specifically, we equip each sample and class in a dataset with a learnable parameter (data parameters), which governs their importance in the learning process. During training, at each iteration,\nas we update the model parameters, we also update the data parameters. These updates are done by gradient descent and do not require hand-crafted rules or design. When applied to image classification task on CIFAR10, CIFAR100,WebVision and ImageNet datasets, and object detection task on KITTI dataset, learning a dynamic curriculum via data parameters leads to consistent gains, without any increase in model complexity or training time. When applied to a noisy dataset, the proposed method learns to learn from clean images and improves over the state-of-the-art methods by 14%. To the best of our knowledge, our work is the first curriculum learning method to show gains on large scale image classification and detection tasks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SCAN", "Title": "A Scalable Neural Networks Framework Towards Compact and Efficient Models", "Abstract": "Remarkable achievements have been attained by deep neural networks in various applications. However, the increasing depth and width of such models also lead to explosive growth in both storage and computation, which has restricted the deployment of deep neural networks on resource-limited edge devices. To address this problem, we propose the so-called SCAN framework for networks training and inference, which is orthogonal and complementary to existing acceleration and compression methods. The proposed SCAN firstly divides neural networks into multiple sections according to their depth and constructs shallow classifiers upon the intermediate features of different sections. Moreover, attention modules and knowledge distillation are utilized to enhance the accuracy of shallow classifiers. Based on this architecture, we further propose a threshold controlled scalable inference mechanism to approach human-like sample-specific inference. Experimental results show that SCAN can be easily equipped on various neural networks without any adjustment on hyper-parameters or neural networks architectures, yielding significant performance gain on CIFAR100 and ImageNet. Codes will be released on github soon."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Blow", "Title": "a single-scale hyperconditioned flow for non-parallel raw-audio voice conversion", "Abstract": "End-to-end models for raw audio generation are a challenge, specially if they have to work with non-parallel data, which is a desirable setup in many situations. Voice conversion, in which a model has to impersonate a speaker in a recording, is one of those situations. In this paper, we propose Blow, a single-scale normalizing flow using hypernetwork conditioning to perform many-to-many voice conversion between raw audio. Blow is trained end-to-end, with non-parallel data, on a frame-by-frame basis using a single speaker identifier. We show that Blow compares favorably to existing flow-based architectures and other competitive baselines, obtaining equal or better performance in both objective and subjective evaluations. We further assess the impact of its main components with an ablation study, and quantify a number of properties such as the necessary amount of training data or the preference for source or target speakers."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dimensionality reduction", "Title": "theoretical perspective on practical measures", "Abstract": "Dimensionality reduction plays a central role in real-world applications for Machine Learning, among many fields. In particular,  metric dimensionality reduction where data from a general metric is mapped into low dimensional space, is often used as a first step before applying machine learning algorithms. In almost all these applications the quality of the embedding is measured by various average case criteria. Metric dimensionality reduction has also been studied in Math and TCS, within the extremely fruitful and influential field of metric embedding. Yet, the vast majority of theoretical research has been devoted to analyzing the worst case behavior of embeddings and therefore has little relevance to practical settings. The goal of this paper is to bridge the gap between theory and practice view-points of metric dimensionality reduction, laying the foundation for a theoretical study of more practically oriented analysis. This paper can be viewed as providing a comprehensive theoretical framework addressing a line of research initiated by VL [NeuroIPS' 18] who have set the goal of analyzing different distortion measurement criteria, with the lens of Machine Learning applicability, from both theoretical and practical perspectives.\nWe complement their work by considering some important and vastly used average case criteria, some of which originated within the well-known Multi-Dimensional Scaling framework.  While often studied in practice, no theoretical studies have thus far attempted at providing rigorous analysis of these criteria. In this paper we provide the first analysis of these, as well as the new distortion measure developed by [VL18] designed to possess Machine Learning desired properties. Moreover, we show that all measures considered can be adapted to possess similar qualities. The main consequences of our work are nearly tight bounds on the absolute values of all distortion criteria, as well as first approximation algorithms with provable guarantees."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MCP", "Title": "Learning Composable Hierarchical Control with Multiplicative Compositional Policies", "Abstract": "Humans are able to perform a myriad of sophisticated tasks by drawing upon skills acquired through prior experience. For autonomous agents to have this capability, they must be able to extract reusable skills from past experience that can be recombined in new ways for subsequent tasks. Furthermore, when controlling complex high-dimensional morphologies, such as humanoid bodies, tasks often require coordination of multiple skills simultaneously. Learning discrete primitives for every combination of skills quickly becomes prohibitive. Composable primitives that can be recombined to create a large variety of behaviors can be more suitable for modeling this combinatorial explosion. In this work, we propose multiplicative compositional policies (MCP), a method for learning reusable motor skills that can be composed to produce a range of complex behaviors. Our method factorizes an agent's skills into a collection of primitives, where multiple primitives can be activated simultaneously via multiplicative composition. This flexibility allows the primitives to be transferred and recombined to elicit new behaviors as necessary for novel tasks. We demonstrate that MCP is able to extract composable skills for highly complex simulated characters from pre-training tasks, such as motion imitation, and then reuse these skills to solve challenging continuous control tasks, such as dribbling a soccer ball to a goal, and picking up an object and transporting it to a target location."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Legendre Memory Units", "Title": "Continuous-Time Representation in Recurrent Neural Networks", "Abstract": "We propose a novel memory cell for recurrent neural networks that dynamically maintains information across long windows of time using relatively few resources. The Legendre Memory Unit~(LMU) is mathematically derived to orthogonalize its continuous-time history -- doing so by solving $d$ coupled ordinary differential equations~(ODEs), whose phase space linearly maps onto sliding windows of time via the Legendre polynomials up to degree $d - 1$. Backpropagation across LMUs outperforms equivalently-sized LSTMs on a chaotic time-series prediction task, improves memory capacity by two orders of magnitude, and significantly reduces training and inference times. LMUs can efficiently handle temporal dependencies spanning $100\\text{,}000$ time-steps, converge rapidly, and use few internal state-variables to learn complex functions spanning long windows of time -- exceeding state-of-the-art performance among RNNs on permuted sequential MNIST. These results are due to the network's disposition to learn scale-invariant features independently of step size. Backpropagation through the ODE solver allows each layer to adapt its internal time-step, enabling the network to learn task-relevant time-scales. We demonstrate that LMU memory cells can be implemented using $m$ recurrently-connected Poisson spiking neurons, $\\mathcal{O}( m )$ time and memory, with error scaling as $\\mathcal{O}( d / \\sqrt{m} )$. We discuss implementations of LMUs on analog and digital neuromorphic hardware."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BatchBALD", "Title": "Efficient and Diverse Batch Acquisition for Deep Bayesian Active Learning", "Abstract": "We develop BatchBALD, a tractable approximation to the mutual information between a batch of points and model parameters, which we use as an acquisition function to select multiple informative points jointly for the task of deep Bayesian active learning. BatchBALD is a greedy linear-time $1 - \\nicefrac{1}{e}$-approximate algorithm amenable to dynamic programming and efficient caching. We compare BatchBALD to the commonly used approach for batch data acquisition and find that the current approach acquires similar and redundant points, sometimes performing worse than randomly acquiring data. We finish by showing that, using BatchBALD to consider dependencies within an acquisition batch, we achieve new state of the art performance on standard benchmarks, providing substantial data efficiency improvements in batch acquisition."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mo' States Mo' Problems", "Title": "Emergency Stop Mechanisms from Observation", "Abstract": "In many environments, only a relatively small subset of the complete state space is necessary in order to accomplish a given task. We develop a simple technique using emergency stops (e-stops) to exploit this phenomenon. Using e-stops significantly improves sample complexity by reducing the amount of required exploration, while retaining a performance bound that efficiently trades off the rate of convergence with a small asymptotic sub-optimality gap. We analyze the regret behavior of e-stops and present empirical results in discrete and continuous settings demonstrating that our reset mechanism can provide order-of-magnitude speedups on top of existing reinforcement learning methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Provably Global Convergence of Actor-Critic", "Title": "A Case for Linear Quadratic Regulator with Ergodic Cost", "Abstract": "Despite the empirical success of the actor-critic algorithm, its theoretical understanding lags behind. In a broader context, actor-critic can be viewed as an online alternating update algorithm for bilevel optimization, whose convergence is known to be fragile. To understand the instability of actor-critic, we focus on its application to linear quadratic regulators, a simple yet fundamental setting of reinforcement learning. We establish a nonasymptotic convergence analysis of actor- critic in this setting. In particular, we prove that actor-critic finds a globally optimal pair of actor (policy) and critic (action-value function) at a linear rate of convergence. Our analysis may serve as a preliminary step towards a complete theoretical understanding of bilevel optimization with nonconvex subproblems, which is NP-hard in the worst case and is often solved using heuristics."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DINGO", "Title": "Distributed Newton-Type Method for Gradient-Norm Optimization", "Abstract": "For optimization of a large sum of functions in a distributed computing environment, we present a novel communication efficient Newton-type algorithm that enjoys a variety of advantages over similar existing methods. Our algorithm, DINGO, is derived by optimization of the gradient's norm as a surrogate function. DINGO does not impose any specific form on the underlying functions and its application range extends far beyond convexity and smoothness. The underlying sub-problems of DINGO are simple linear least-squares, for which a plethora of efficient algorithms exist. DINGO involves a few hyper-parameters that are easy to tune and we theoretically show that a strict reduction in the surrogate objective is guaranteed, regardless of the selected hyper-parameters."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ObjectNet", "Title": "A large-scale bias-controlled dataset for pushing the limits of object recognition models", "Abstract": "We collect a large real-world test set, ObjectNet, for object recognition with controls where object backgrounds, rotations, and imaging viewpoints are random. Most scientific experiments have controls, confounds which are removed from the data, to ensure that subjects cannot perform a task by exploiting trivial correlations in the data. Historically, large machine learning and computer vision datasets have lacked such controls. This has resulted in models that must be fine-tuned for new datasets and perform better on datasets than in real-world applications. When tested on ObjectNet, object detectors show a 40-45% drop in performance, with respect to their performance on other benchmarks, due to the controls for biases. Controls make ObjectNet robust to fine-tuning showing only small performance increases. We develop a highly automated platform that enables gathering datasets with controls by crowdsourcing image capturing and annotation. ObjectNet is the same size as the ImageNet test set (50,000 images), and by design does not come paired with a training set in order to encourage generalization. The dataset is both easier than ImageNet (objects are largely centered and unoccluded) and harder (due to the controls). Although we focus on object recognition here, data with controls can be gathered at scale using automated tools throughout machine learning to generate datasets that exercise models in new ways thus providing valuable feedback to researchers. This work opens up new avenues for research in generalizable, robust, and more human-like computer vision and in creating datasets where results are predictive of real-world performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Point Where Reality Meets Fantasy", "Title": "Mixed Adversarial Generators for Image Splice Detection", "Abstract": "Modern photo editing tools allow creating realistic manipulated images easily. While fake images can be quickly generated, learning models for their detection is challenging due to the high variety of tampering artifacts and the lack of large labeled datasets of manipulated images. In this paper, we propose a new framework for training of discriminative segmentation model via an adversarial process. We simultaneously train four models: a generative retouching model GR that translates manipulated image to the real image domain, a generative annotation model GA that estimates the pixel-wise probability of image patch being either real or fake, and two discriminators DR and DA that qualify the output of GR and GA. The aim of model GR is to maximize the probability of model GA making a mistake. Our method extends the generative adversarial networks framework with two main contributions: (1) training of a generative model GR against a deep semantic segmentation network GA that learns rich scene semantics for manipulated region detection, (2) proposing per class semantic loss that facilitates semantically consistent image retouching by the G_R. We collected large-scale manipulated image dataset to train our model. The dataset includes 16k real and fake images with pixel-level annotations of manipulated areas. The dataset also provides ground truth pixel-level object annotations. We validate our approach on several modern manipulated image datasets, where quantitative results and ablations demonstrate that our method achieves and surpasses the state-of-the-art in manipulated image detection. We made our code and dataset publicly available."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ODE2VAE", "Title": "Deep generative second order ODEs with Bayesian neural networks", "Abstract": "We present Ordinary Differential Equation Variational Auto-Encoder (ODE2VAE), a latent second order ODE model for high-dimensional sequential data. Leveraging the advances in deep generative models, ODE2VAE can simultaneously learn the embedding of high dimensional trajectories and infer arbitrarily complex continuous-time latent dynamics. Our model explicitly decomposes the latent space into momentum and position components and solves a second order ODE system, which is in contrast to recurrent neural network (RNN) based time series models and recently proposed black-box ODE techniques. In order to account for uncertainty, we propose probabilistic latent ODE dynamics parameterized by deep Bayesian neural networks. We demonstrate our approach on motion capture, image rotation, and bouncing balls datasets. We achieve state-of-the-art performance in long term motion prediction and imputation tasks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MaxGap Bandit", "Title": "Adaptive Algorithms for Approximate Ranking", "Abstract": "This paper studies the problem of adaptively sampling from K distributions (arms) in order to identify the largest gap between any two adjacent means. We call this the MaxGap-bandit problem. This problem arises naturally in approximate ranking, noisy sorting, outlier detection, and top-arm identification in bandits.  The key novelty of the MaxGap bandit problem is that it aims to adaptively determine the natural partitioning of the distributions into a subset with larger means and a subset with smaller means, where the split is determined by the largest gap rather than a pre-specified rank or threshold. Estimating an arm’s gap requires sampling its neighboring arms in addition to itself, and this dependence results in a novel hardness parameter that characterizes the sample complexity of the problem. We propose elimination and UCB-style algorithms and show that they are minimax optimal. Our experiments show that the UCB-style algorithms require 6-8x fewer samples than non-adaptive sampling to achieve the same error."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoAssist", "Title": "A Framework to Accelerate Training of Deep Neural Networks", "Abstract": "Deep neural networks have yielded superior performance in many contemporary\napplications. However, the gradient computation in a deep model with millions of\ninstances leads to a lengthy training process even with modern\nGPU/TPU hardware acceleration.  In this paper, we propose AutoAssist, a\nsimple framework to accelerate training of a deep neural network.\nTypically, as the training procedure evolves, the amount of improvement by a\nstochastic gradient update varies dynamically with the choice of instances in the mini-batch.\nIn AutoAssist, we utilize this fact and design an instance shrinking operation that is\nused to filter out instances with relatively low marginal improvement to the\ncurrent model; thus the computationally intensive gradient computations are\nperformed on informative instances as much as possible.\nSpecifically, we train\na very lightweight Assistant model jointly with the original deep network, which we refer to as Boss.\nThe Assistant model is designed to gauge the importance of a given\ninstance with respect to the current Boss such that the shrinking operation can\nbe applied in the batch generator. With careful design, we train the Boss and\nAssistant in a nonblocking and asynchronous fashion such that\noverhead is minimal.\nTo demonstrate the effectiveness of AutoAssist, we conduct experiments on two\ncontemporary applications: image classification using ResNets with varied number\nof layers, and neural machine translation using LSTMs, ConvS2S and\nTransformer models. For each application, we verify that AutoAssist leads to\nsignificant reduction in training time; in particular, 30% to 40% of the total operation count can be reduced which leads to\nfaster convergence and a corresponding decrease in training time."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BIVA", "Title": "A Very Deep Hierarchy of Latent Variables for Generative Modeling", "Abstract": "With the introduction of the variational autoencoder (VAE), probabilistic latent variable models have received renewed attention as powerful generative models. However, their performance in terms of test likelihood and quality of generated samples has been surpassed by autoregressive models without stochastic units. Furthermore, flow-based models have recently been shown to be an attractive alternative that scales well to high-dimensional data. In this paper we close the performance gap by constructing VAE models that can effectively utilize a deep hierarchy of stochastic variables and model complex covariance structures. We introduce the Bidirectional-Inference Variational Autoencoder (BIVA), characterized by a skip-connected generative model and an inference network formed by a bidirectional stochastic inference path. We show that BIVA reaches state-of-the-art test likelihoods, generates sharp and coherent natural images, and uses the hierarchy of latent variables to capture different aspects of the data distribution. We observe that BIVA, in contrast to recent results, can be used for anomaly detection. We attribute this to the hierarchy of latent variables which is able to extract high-level semantic features. Finally, we extend BIVA to semi-supervised classification tasks and show that it performs comparably to state-of-the-art results by generative adversarial networks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Latent Weights Do Not Exist", "Title": "Rethinking Binarized Neural Network Optimization", "Abstract": "Optimization of Binarized Neural Networks (BNNs) currently relies on real-valued latent weights to accumulate small update steps. In this paper, we argue that these latent weights cannot be treated analogously to weights in real-valued networks. Instead their main role is to provide inertia during training. We interpret current methods in terms of inertia and provide novel insights into the optimization of BNNs. We subsequently introduce the first optimizer specifically designed for BNNs, Binary Optimizer (Bop), and demonstrate its performance on CIFAR-10 and ImageNet. Together, the redefinition of latent weights as inertia and the introduction of Bop enable a better understanding of BNN optimization and open up the way for further improvements in training methodologies for BNNs."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Non-normal Recurrent Neural Network (nnRNN)", "Title": "learning long time dependencies while improving expressivity with transient dynamics", "Abstract": "A recent strategy to circumvent the exploding and vanishing gradient problem in RNNs, and to allow the stable propagation of signals over long time scales, is to constrain recurrent connectivity matrices to be orthogonal or unitary. This ensures eigenvalues with unit norm and thus stable dynamics and training. However this comes at the cost of reduced expressivity due to the limited variety of orthogonal transformations. We propose a novel connectivity structure based on the Schur decomposition and a splitting of the Schur form into normal and non-normal parts. \nThis allows to parametrize matrices with unit-norm eigenspectra without orthogonality constraints on eigenbases. The resulting architecture ensures access to a larger space of spectrally constrained matrices, of which orthogonal matrices are a subset. \nThis crucial difference retains the stability advantages and training speed of orthogonal RNNs while enhancing expressivity, especially on tasks that require computations over ongoing input sequences."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AttentionXML", "Title": "Label Tree-based Attention-Aware Deep Model for High-Performance Extreme Multi-Label Text Classification", "Abstract": "Extreme multi-label text classification (XMTC) is an important problem in the \nera of {\\it big data}, for tagging a given text with the most relevant multiple \nlabels from an extremely large-scale label set. XMTC can be found in many \napplications, such as item categorization, web page tagging, and news \nannotation.\nTraditionally most methods used bag-of-words (BOW) as inputs, ignoring word \ncontext as well as deep semantic information. Recent attempts to overcome the \nproblems of BOW by deep learning still suffer from 1) failing to capture the \nimportant subtext for each label and 2) lack of scalability against the huge \nnumber of labels.\nWe propose a new label tree-based deep learning model for XMTC, called \nAttentionXML, with two unique features: 1) a multi-label attention mechanism \nwith raw text as input, which allows to capture the most relevant part of text \nto each label; and 2) a shallow and wide probabilistic label tree (PLT), which \nallows to handle millions of labels, especially for \"tail labels\".\nWe empirically compared the performance of AttentionXML with those of eight \nstate-of-the-art methods over six benchmark datasets, including Amazon-3M with \naround 3 million labels. AttentionXML outperformed all competing methods \nunder all experimental settings.\nExperimental results also show that AttentionXML achieved the best performance \nagainst tail labels among label tree-based methods. The code and datasets are \navailable at \\url{http://github.com/yourh/AttentionXML} ."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Online Balanced Descent", "Title": "An Optimal Algorithm for Smoothed Online Optimization", "Abstract": "We study online convex optimization in a setting where the learner seeks to minimize the sum of a per-round hitting cost and a movement cost which is incurred when changing decisions between rounds.  We prove a new lower bound on the competitive ratio of any online algorithm in the setting where the costs are $m$-strongly convex and the movement costs are the squared $\\ell_2$ norm. This lower bound shows that no algorithm can achieve a competitive ratio that is  $o(m^{-1/2})$ as $m$ tends to zero.  No existing algorithms have competitive ratios matching this bound, and we show that the state-of-the-art algorithm, Online Balanced Decent (OBD), has a competitive ratio that is $\\Omega(m^{-2/3})$. We additionally propose two new algorithms, Greedy OBD (G-OBD) and Regularized OBD (R-OBD) and prove that both algorithms have an $O(m^{-1/2})$ competitive ratio. The result for G-OBD holds when the hitting costs are quasiconvex and the movement costs are the squared $\\ell_2$ norm, while the result for R-OBD holds when the hitting costs are $m$-strongly convex and the movement costs are Bregman Divergences.  Further, we show that R-OBD simultaneously achieves constant, dimension-free competitive ratio and sublinear regret when hitting costs are strongly convex."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BehaveNet", "Title": "nonlinear embedding and Bayesian neural decoding of behavioral videos", "Abstract": "A fundamental goal of systems neuroscience is to understand the relationship between neural activity and behavior. Behavior has traditionally been characterized by low-dimensional, task-related variables such as movement speed or response times. More recently, there has been a growing interest in automated analysis of high-dimensional video data collected during experiments. Here we introduce a probabilistic framework for the analysis of behavioral video and neural activity. This framework provides tools for compression, segmentation, generation, and decoding of behavioral videos. Compression is performed using a convolutional autoencoder (CAE), which yields a low-dimensional continuous representation of behavior. We then use an autoregressive hidden Markov model (ARHMM) to segment the CAE representation into discrete \"behavioral syllables.\" The resulting generative model can be used to simulate behavioral video data. Finally, based on this generative model, we develop a novel Bayesian decoding approach that takes in neural activity and outputs probabilistic estimates of the full-resolution behavioral video. We demonstrate this framework on two different experimental paradigms using distinct behavioral and neural recording technologies."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One ticket to win them all", "Title": "generalizing lottery ticket initializations across datasets and optimizers", "Abstract": "The success of lottery ticket initializations (Frankle and Carbin, 2019) suggests that small, sparsified networks can be trained so long as the network is initialized appropriately. Unfortunately, finding these \"winning ticket'' initializations is computationally expensive. One potential solution is to reuse the same winning tickets across a variety of datasets and optimizers. However, the generality of winning ticket initializations remains unclear. Here, we attempt to answer this question by generating winning tickets for one training configuration (optimizer and dataset) and evaluating their performance on another configuration. Perhaps surprisingly, we found that, within the natural images domain, winning ticket initializations generalized across a variety of datasets, including Fashion MNIST, SVHN, CIFAR-10/100, ImageNet, and Places365, often achieving performance close to that of winning tickets generated on the same dataset. Moreover, winning tickets generated using larger datasets consistently transferred better than those generated using smaller datasets. We also found that winning ticket initializations generalize across optimizers with high performance. These results suggest that winning ticket initializations generated by sufficiently large datasets contain inductive biases generic to neural networks more broadly which improve training across many settings and provide hope for the development of better initialization methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tensor Monte Carlo", "Title": "Particle Methods for the GPU era", "Abstract": "Multi-sample, importance-weighted variational autoencoders (IWAE) give tighter bounds and more accurate uncertainty estimates than variational autoencoders (VAEs) trained with a standard single-sample objective.  However, IWAEs scale poorly: as the latent dimensionality grows, they require exponentially many samples to retain the benefits of importance weighting.  While sequential Monte-Carlo (SMC) can address this problem, it is prohibitively slow because the resampling step imposes sequential structure which cannot be parallelised, and moreover, resampling is non-differentiable which is problematic when learning approximate posteriors.  To address these issues, we developed tensor Monte-Carlo (TMC) which gives exponentially many importance samples by separately drawing $K$ samples for each of the $n$ latent variables, then averaging over all $K^n$ possible combinations.  While the sum over exponentially many terms might seem to be intractable, in many cases it can be computed efficiently as a series of tensor inner-products.  We show that TMC is superior to IWAE on a generative model with multiple stochastic layers trained on the MNIST handwritten digit database, and we show that TMC can be combined with standard variance reduction techniques."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Seeing the Wind", "Title": "Visual Wind Speed Prediction with a Coupled Convolutional and Recurrent Neural Network", "Abstract": "Wind energy resource quantification, air pollution monitoring, and weather forecasting all rely on rapid, accurate measurement of local wind conditions. Visual observations of the effects of wind---the swaying of trees and flapping of flags, for example---encode information regarding local wind conditions that can potentially be leveraged for visual anemometry that is inexpensive and ubiquitous. Here, we demonstrate a coupled convolutional neural network and recurrent neural network architecture that extracts the wind speed encoded in visually recorded flow-structure interactions of a flag and tree in naturally occurring wind. Predictions for wind speeds ranging from 0.75-11 m/s showed agreement with measurements from a cup anemometer on site, with a root-mean-squared error approaching the natural wind speed variability due to atmospheric turbulence. Generalizability of the network was demonstrated by successful prediction of wind speed based on recordings of other flags in the field and in a controlled wind tunnel test. Furthermore, physics-based scaling of the flapping dynamics accurately predicts the dependence of the network performance on the video frame rate and duration."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SSRGD", "Title": "Simple Stochastic Recursive Gradient Descent for Escaping Saddle Points", "Abstract": "We analyze stochastic gradient algorithms for optimizing nonconvex problems.\nIn particular, our goal is to find local minima (second-order stationary points) instead of just finding first-order stationary points which may be some bad unstable saddle points.\nWe show that a simple perturbed version of stochastic recursive gradient descent algorithm (called SSRGD) can find an $(\\epsilon,\\delta)$-second-order stationary point with $\\widetilde{O}(\\sqrt{n}/\\epsilon^2 + \\sqrt{n}/\\delta^4 + n/\\delta^3)$ stochastic gradient complexity for nonconvex finite-sum problems.\nAs a by-product, SSRGD finds an $\\epsilon$-first-order stationary point with $O(n+\\sqrt{n}/\\epsilon^2)$ stochastic gradients. These results are almost optimal since Fang et al. [2018] provided a lower bound $\\Omega(\\sqrt{n}/\\epsilon^2)$ for finding even just an $\\epsilon$-first-order stationary point.\nWe emphasize that SSRGD algorithm for finding second-order stationary points is as simple as for finding first-order stationary points just by adding a uniform perturbation sometimes, while all other algorithms for finding second-order stationary points with similar gradient complexity need to combine with a negative-curvature search subroutine (e.g., Neon2 [Allen-Zhu and Li, 2018]).\nMoreover, the simple SSRGD algorithm gets a simpler analysis.\nBesides, we also extend our results from nonconvex finite-sum problems to nonconvex online (expectation) problems, and prove the corresponding convergence results."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "This Looks Like That", "Title": "Deep Learning for Interpretable Image Recognition", "Abstract": "When we are faced with challenging image classification tasks, we often explain our reasoning by dissecting the image, and pointing out prototypical aspects of one class or another. The mounting evidence for each of the classes helps us make our final decision. In this work, we introduce a deep network architecture -- prototypical part network (ProtoPNet), that reasons in a similar way: the network dissects the image by finding prototypical parts, and combines evidence from the prototypes to make a final classification. The model thus reasons in a way that is qualitatively similar to the way ornithologists, physicians, and others would explain to people on how to solve challenging image classification tasks. The network uses only image-level labels for training without any annotations for parts of images. We demonstrate our method on the CUB-200-2011 dataset and the Stanford Cars dataset. Our experiments show that ProtoPNet can achieve comparable accuracy with its analogous non-interpretable counterpart, and when several ProtoPNets are combined into a larger network, it can achieve an accuracy that is on par with some of the best-performing deep models. Moreover, ProtoPNet provides a level of interpretability that is absent in other interpretable deep models."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Dynamics of Attention", "Title": "Human Prior for Interpretable Machine Reasoning", "Abstract": "Without relevant human priors, neural networks may learn uninterpretable features. We propose Dynamics of Attention for Focus Transition (DAFT) as a human prior for machine reasoning. DAFT is a novel method that regularizes attention-based reasoning by modelling it as a continuous dynamical system using neural ordinary differential equations. As a proof of concept, we augment a state-of-the-art visual reasoning model with DAFT. Our experiments reveal that applying DAFT yields similar performance to the original model while using fewer reasoning steps, showing that it implicitly learns to skip unnecessary steps. We also propose a new metric, Total Length of Transition (TLT), which represents the effective reasoning step size by quantifying how much a given model's focus drifts while reasoning about a question. We show that adding DAFT results in lower TLT, demonstrating that our method indeed obeys the human prior towards shorter reasoning paths in addition to producing more interpretable attention maps."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Provable Certificates for Adversarial Examples", "Title": "Fitting a Ball in the Union of Polytopes", "Abstract": "We propose a novel method for computing exact pointwise robustness of deep\n neural networks for all convex lp norms. Our algorithm, GeoCert, finds the largest\n lp ball centered at an input point x0, within which the output class of a given neural\n network with ReLU nonlinearities remains unchanged. We relate the problem\n of computing pointwise robustness of these networks to that of computing the\n maximum norm ball with a fixed center that can be contained in a non-convex\npolytope. This is a challenging problem in general, however we show that there\n exists an efficient algorithm to compute this for polyhedral complices. Further\nwe show that piecewise linear neural networks partition the input space into a polyhedral complex. Our algorithm has the ability to almost immediately output a\nnontrivial lower bound to the pointwise robustness which is iteratively improved until it ultimately becomes tight. We empirically show that our approach generates\na distance lower bounds that are tighter compared to prior work, under moderate\ntime constraints."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Two Generator Game", "Title": "Learning to Sample via Linear Goodness-of-Fit Test", "Abstract": "Learning the probability distribution of high-dimensional data is a challenging problem. To solve this problem, we formulate a deep energy adversarial network (DEAN), which casts the energy model learned from real data into an optimization of a goodness-of-fit (GOF) test statistic. DEAN can be interpreted as a GOF game between two generative networks, where one explicit generative network learns an energy-based distribution that fits the real data, and the other implicit generative network is trained by minimizing a GOF test statistic between the energy-based distribution and the generated data, such that the underlying distribution of the generated data is close to the energy-based distribution. We design a two-level alternative optimization procedure to train the explicit and implicit generative networks, such that the hyper-parameters can also be automatically learned. Experimental results show that DEAN achieves high quality generations compared to the state-of-the-art approaches."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fixing Implicit Derivatives", "Title": "Trust-Region Based Learning of Continuous Energy Functions", "Abstract": "We present a new technique for the learning of continuous energy functions that\nwe refer to as Wibergian Learning. One common approach to inverse problems\nis to cast them as an energy minimisation problem, where the minimum cost\nsolution found is used as an estimator of hidden parameters. Our new approach\nformally characterises the dependency between weights that control the shape of\nthe energy function, and the location of minima, by describing minima as fixed\npoints of optimisation methods. This allows for the use of gradient-based end-to-\nend training to integrate deep-learning and the classical inverse problem methods.\nWe show how our approach can be applied to obtain state-of-the-art results in the\ndiverse applications of tracker fusion and multiview 3D reconstruction."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "muSSP", "Title": "Efficient Min-cost Flow Algorithm for Multi-object Tracking", "Abstract": "Min-cost flow has been a widely used paradigm for solving data association problems in multi-object tracking (MOT). However, most existing methods of solving min-cost flow problems in MOT are either direct adoption or slight modifications of generic min-cost flow algorithms, yielding sub-optimal computation efficiency and holding the applications back from larger scale of problems. In this paper, by exploiting the special structures and properties of the graphs formulated in MOT problems, we develop an efficient min-cost flow algorithm, namely, minimum-update Successive Shortest Path (muSSP). muSSP is proved to provide exact optimal solution and we demonstrated its efficiency through 40 experiments on five MOT datasets with various object detection results and a number of graph designs. muSSP is always the most efficient in each experiment compared to the three peer solvers, improving the efficiency by 5 to 337 folds relative to the best competing algorithm and averagely 109 to 4089 folds to each of the three peer methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Continuous Submodular Maximization", "Title": "From Full-Information to Bandit Feedback", "Abstract": "In this paper, we propose three online algorithms for submodular maximization. The first one, Mono-Frank-Wolfe, reduces the number of per-function gradient evaluations from $T^{1/2}$  [Chen2018Online] and $T^{3/2}$ [chen2018projection] to 1, and achieves a $(1-1/e)$-regret bound of $O(T^{4/5})$. The second one, Bandit-Frank-Wolfe, is the first bandit algorithm for continuous DR-submodular maximization, which achieves a $(1-1/e)$-regret bound of $O(T^{8/9})$. Finally, we extend Bandit-Frank-Wolfe to a bandit algorithm for discrete submodular maximization, Responsive-Frank-Wolfe, which attains a $(1-1/e)$-regret bound of $O(T^{8/9})$ in the responsive bandit setting."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Don't take it lightly", "Title": "Phasing optical random projections with unknown operators", "Abstract": "In this paper we tackle the problem of recovering the phase of complex linear measurements when only magnitude information is available and we control the input. We are motivated by the recent development of dedicated optics-based hardware for rapid random projections which leverages the propagation of light in random media. A signal of interest $\\mathbf{\\xi} \\in \\mathbb{R}^N$ is mixed by a random scattering medium to compute the projection $\\mathbf{y} = \\mathbf{A} \\mathbf{\\xi}$, with $\\mathbf{A} \\in \\mathbb{C}^{M \\times N}$ being a realization of a standard complex Gaussian iid random matrix. Such optics-based matrix multiplications can be much faster and energy-efficient than their CPU or GPU counterparts, yet two difficulties must be resolved: only the intensity ${|\\mathbf{y}|}^2$ can be recorded by the camera, and the transmission matrix $\\mathbf{A}$ is unknown. We show that even without knowing $\\mathbf{A}$, we can recover the unknown phase of $\\mathbf{y}$ for some equivalent transmission matrix with the same distribution as $\\mathbf{A}$. Our method is based on two observations: first, conjugating or changing the phase of any row of $\\mathbf{A}$ does not change its distribution; and second, since we control the input we can interfere $\\mathbf{\\xi}$ with arbitrary reference signals. We show how to leverage these observations to cast the measurement phase retrieval problem as a Euclidean distance geometry problem. We demonstrate appealing properties of the proposed algorithm in both numerical simulations and real hardware experiments. Not only does our algorithm accurately recover the missing phase, but it mitigates the effects of quantization and the sensitivity threshold, thus improving the measured magnitudes."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gate Decorator", "Title": "Global Filter Pruning Method for Accelerating Deep Convolutional Neural Networks", "Abstract": "Filter pruning is one of the most effective ways to accelerate and compress convolutional neural networks (CNNs). In this work, we propose a global filter pruning algorithm called Gate Decorator, which transforms a vanilla CNN module by multiplying its output by the channel-wise scaling factors (i.e. gate). When the scaling factor is set to zero, it is equivalent to removing the corresponding filter. We use Taylor expansion to estimate the change in the loss function caused by setting the scaling factor to zero and use the estimation for the global filter importance ranking. Then we prune the network by removing those unimportant filters. After pruning, we merge all the scaling factors into its original module, so no special operations or structures are introduced. Moreover, we propose an iterative pruning framework called Tick-Tock to improve pruning accuracy. The extensive experiments demonstrate the effectiveness of our approaches. For example, we achieve the state-of-the-art pruning ratio on ResNet-56 by reducing 70% FLOPs without noticeable loss in accuracy. For ResNet-50 on ImageNet, our pruned model with 40% FLOPs reduction outperforms the baseline model by 0.31% in top-1 accuracy. Various datasets are used, including CIFAR-10, CIFAR-100, CUB-200, ImageNet ILSVRC-12 and PASCAL VOC 2011."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kalman Filter, Sensor Fusion, and Constrained Regression", "Title": "Equivalences and Insights", "Abstract": "The Kalman filter (KF) is one of the most widely used tools for data assimilation and sequential estimation. In this work, we show that the state estimates from the KF in a standard linear dynamical system setting are equivalent to those given by the KF in a transformed system, with infinite process noise (i.e., a ``flat prior'') and an augmented measurement space. This reformulation---which we refer to as augmented measurement sensor fusion (SF)---is conceptually interesting, because the transformed system here is seemingly static (as there is effectively no process model), but we can still capture the state dynamics inherent to the KF by folding the process model into the measurement space. Further, this reformulation of the KF turns out to be useful in settings in which past states are observed eventually (at some lag). Here, when the measurement noise covariance is estimated by the empirical covariance, we show that the state predictions from SF are equivalent to those from a regression of past states on past measurements, subject to particular linear constraints (reflecting the relationships encoded in the measurement map). This allows us to port standard ideas (say, regularization methods) in regression over to dynamical systems. For example, we can posit multiple candidate process models, fold all of them into the measurement model, transform to the regression perspective, and apply $\\ell_1$ penalization to perform process model selection. We give various empirical demonstrations, and focus on an application to nowcasting the weekly incidence of influenza in the US."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scene Representation Networks", "Title": "Continuous 3D-Structure-Aware Neural Scene Representations", "Abstract": "Unsupervised learning with generative models has the potential of discovering rich representations of 3D scenes. While geometric deep learning has explored 3D-structure-aware representations of scene geometry, these models typically require explicit 3D supervision. Emerging neural scene representations can be trained only with posed 2D images, but existing methods ignore the three-dimensional structure of scenes. We propose Scene Representation Networks (SRNs), a continuous, 3D-structure-aware scene representation that encodes both geometry and appearance. SRNs represent scenes as continuous functions that map world coordinates to a feature representation of local scene properties. By formulating the image formation as a differentiable ray-marching algorithm, SRNs can be trained end-to-end from only 2D images and their camera poses, without access to depth or shape. This formulation naturally generalizes across scenes, learning powerful geometry and appearance priors in the process. We demonstrate the potential of SRNs by evaluating them for novel view synthesis, few-shot reconstruction, joint shape and appearance interpolation, and unsupervised discovery of a non-rigid face model."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Control What You Can", "Title": "Intrinsically Motivated Task-Planning Agent", "Abstract": "We present a novel intrinsically motivated agent that learns how to control the\nenvironment in a sample efficient manner, that is with as few environment interactions as possible, by optimizing learning progress. It learns what can be controlled, how to allocate time and attention as well as the relations between objects using surprise-based motivation. The effectiveness of our method is demonstrated in a synthetic and robotic manipulation environment yielding considerably improved performance and smaller sample complexity compared to an intrinsically motivated, non-hierarchical and state-of-the-art hierarchical baseline. In a nutshell, our work combines several task-level planning agent structures (backtracking search on task-graph, probabilistic road-maps, allocation of search efforts) with intrinsic motivation to achieve learning from scratch."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PerspectiveNet", "Title": "3D Object Detection from a Single RGB Image via Perspective Points", "Abstract": "Detecting 3D objects from a single RGB image is intrinsically ambiguous, thus requiring appropriate prior knowledge and intermediate representations as constraints to reduce the uncertainties and improve the consistencies between the 2D image plane and the 3D world coordinate. To address this challenge, we propose to adopt perspective points as a new intermediate representation for 3D object detection, defined as the 2D projections of local Manhattan 3D keypoints to locate an object; these perspective points satisfy geometric constraints imposed by the perspective projection. We further devise PerspectiveNet, an end-to-end trainable model that simultaneously detects the 2D bounding box, 2D perspective points, and 3D object bounding box for each object from a single RGB image. PerspectiveNet yields three unique advantages: (i) 3D object bounding boxes are estimated based on perspective points, bridging the gap between 2D and 3D bounding boxes without the need of category-specific 3D shape priors. (ii) It predicts the perspective points by a template-based method, and a perspective loss is formulated to maintain the perspective constraints. (iii) It maintains the consistency between the 2D perspective points and 3D bounding boxes via a differentiable projective function. Experiments on SUN RGB-D dataset show that the proposed method significantly outperforms existing RGB-based approaches for 3D object detection."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Confidence Regions", "Title": "Tight Bayesian Ambiguity Sets for Robust MDPs", "Abstract": "Robust MDPs (RMDPs) can be used to compute policies with provable worst-case guarantees in reinforcement learning. The quality and robustness of an RMDP solution are determined by the ambiguity set---the set of plausible transition probabilities---which is usually constructed as a multi-dimensional confidence region. Existing methods construct ambiguity sets as confidence regions using concentration inequalities which leads to overly conservative solutions. This paper proposes a new paradigm that can achieve better solutions with the same robustness guarantees without using confidence regions as ambiguity sets. To incorporate prior knowledge, our algorithms optimize the size and position of ambiguity sets using Bayesian inference. Our theoretical analysis shows the safety of the proposed method, and the empirical results demonstrate its practical promise."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RSN", "Title": "Randomized Subspace Newton", "Abstract": "We develop a randomized Newton method capable of solving learning problems with huge dimensional feature spaces,  which is a common setting in applications such as medical imaging, genomics and seismology. Our method leverages  randomized sketching in a new way, by finding the Newton direction constrained to the space spanned by a random sketch. We develop a simple global linear convergence theory that holds for practically all sketching techniques, which gives the practitioners the freedom to design custom sketching approaches suitable for particular applications. We perform numerical experiments which demonstrate the efficiency of our method as compared to accelerated gradient descent and the full Newton method. Our method can be seen as a refinement and a randomized extension of the results of Karimireddy, Stich, and Jaggi (2019)."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LiteEval", "Title": "A Coarse-to-Fine Framework for Resource Efficient Video Recognition", "Abstract": "This paper presents LiteEval, a simple yet effective coarse-to-fine framework for resource efficient video recognition, suitable for both online and offline scenarios. Exploiting decent yet computationally efficient features derived at a coarse scale with a lightweight CNN model, LiteEval dynamically decides on-the-fly whether to compute more powerful features for incoming video frames at a finer scale to obtain more details. This is achieved by a coarse LSTM and a fine LSTM operating cooperatively, as well as a conditional gating module to learn when to allocate more computation. Extensive experiments are conducted on two large-scale video benchmarks, FCVID and ActivityNet, and the results demonstrate LiteEval requires substantially less computation while offering excellent classification accuracy for both online and offline predictions."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PyTorch", "Title": "An Imperative Style, High-Performance Deep Learning Library", "Abstract": "Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.\nIn this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance.\nWe demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NAT", "Title": "Neural Architecture Transformer for Accurate and Compact Architectures", "Abstract": "Designing effective architectures is one of the key factors behind the success of deep neural networks. Existing deep architectures are either manually designed or automatically searched by some Neural Architecture Search (NAS) methods. However, even a well-searched architecture may still contain many non-significant or redundant modules or operations (e.g., convolution or pooling), which may not only incur substantial memory consumption and computation cost but also deteriorate the performance. Thus, it is necessary to optimize the operations inside an architecture to improve the performance without introducing extra computation cost. Unfortunately, such a constrained optimization problem is NP-hard. To make the problem feasible, we cast the optimization problem into a Markov decision process (MDP) and seek to learn a Neural Architecture Transformer (NAT) to replace the redundant operations with the more computationally efficient ones (e.g., skip connection or directly removing the connection). Based on MDP, we learn NAT by exploiting reinforcement learning to obtain the optimization policies w.r.t. different architectures. To verify the effectiveness of the proposed strategies, we apply NAT on both hand-crafted architectures and NAS based architectures. Extensive experiments on two benchmark datasets, i.e., CIFAR-10 and ImageNet, demonstrate that the transformed architecture by NAT significantly outperforms both its original form and those architectures optimized by existing methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ETNet", "Title": "Error Transition Network for Arbitrary Style Transfer", "Abstract": "Numerous valuable efforts have been devoted to achieving arbitrary style transfer since the seminal work of Gatys et al. However, existing state-of-the-art approaches often generate insufficiently stylized results under challenging cases. We believe a fundamental reason is that these approaches try to generate the stylized result in a single shot and hence fail to fully satisfy the constraints on semantic structures in the content images and style patterns in the style images. Inspired by the works on error-correction, instead, we propose a self-correcting model to predict what is wrong with the current stylization and refine it accordingly in an iterative manner. For each refinement, we transit the error features across both the spatial and scale domain and invert the processed features into a residual image, with a network we call Error Transition Network (ETNet). The proposed model improves over the state-of-the-art methods with better semantic structures and more adaptive style pattern details. Various qualitative and quantitative experiments show that the key concept of both progressive strategy and error-correction leads to better results. Code and models are available at https://github.com/zhijieW94/ETNet."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Icebreaker", "Title": "Element-wise Efficient Information Acquisition with a Bayesian Deep Latent Gaussian Model", "Abstract": "In this paper, we address the ice-start problem, i.e., the challenge of deploying machine learning models when only a little or no training data is initially available, and acquiring each feature element of data is associated with costs. This setting is representative of the real-world machine learning applications. For instance, in the health care domain, obtaining every single measurement comes with a cost. We propose Icebreaker, a principled framework for elementwise training data acquisition. Icebreaker introduces a full Bayesian Deep Latent Gaussian Model (BELGAM) with a novel inference method, which combines recent advances in amortized inference and stochastic gradient MCMC to enable fast and accurate posterior inference. By utilizing BELGAM’s ability to fully quantify model uncertainty, we also propose two information acquisition functions for imputation and active prediction problems. We demonstrate that BELGAM performs significantly better than previous variational autoencoder (VAE) based models, when the data set size is small, using both machine learning benchmarks and real world recommender systems and health-care applications. Moreover, Icebreaker not only demonstrates improved performance compared to baselines, but it is also capable of achieving better test performance with less training data available."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Crowdsourcing via Pairwise Co-occurrences", "Title": "Identifiability and Algorithms", "Abstract": "The data deluge comes with high demands for data labeling. Crowdsourcing (or, more generally, ensemble learning) techniques aim to produce accurate labels via integrating noisy, non-expert labeling from annotators. The classic Dawid-Skene estimator and its accompanying expectation maximization (EM) algorithm have been widely used, but the theoretical properties are not fully understood. Tensor methods were proposed to guarantee identification of the Dawid-Skene model, but the sample complexity is a hurdle for applying such approaches---since the tensor methods hinge on the availability of third-order statistics that are hard to reliably estimate given limited data. In this paper, we propose a framework using pairwise co-occurrences of the annotator responses, which naturally admits lower sample complexity. We show that the approach can identify the Dawid-Skene model under realistic conditions. We propose an algebraic algorithm reminiscent of convex geometry-based structured matrix factorization to solve the model identification problem efficiently, and an identifiability-enhanced algorithm for handling more challenging and critical scenarios. Experiments show that the proposed algorithms outperform the state-of-art algorithms under a variety of scenarios."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Local SGD with  Periodic Averaging", "Title": "Tighter Analysis  and Adaptive Synchronization", "Abstract": "Communication overhead is one of the key challenges that hinders the scalability of distributed optimization algorithms. In this paper, we study local distributed SGD, where data is partitioned among computation nodes, and the computation nodes perform local updates with periodically exchanging the model among the workers to perform averaging. While local SGD is empirically shown to provide promising results, a theoretical understanding of its performance remains open. In this paper, we strengthen convergence analysis for local SGD, and show that local SGD can be far less expensive and applied far more generally than current theory suggests. Specifically, we show that for loss functions that satisfy the Polyak-Kojasiewicz condition, $O((pT)^{1/3})$ rounds of communication suffice to achieve a linear speed up, that is, an error of $O(1/pT)$, where $T$ is the total number of model updates at each worker. This is in contrast with previous work which required higher number of communication rounds, as well as was limited to strongly convex loss functions, for a similar asymptotic performance. We also develop an adaptive synchronization scheme that provides a general condition for linear speed up. Finally, we validate the theory with experimental results, running over AWS EC2 clouds and an internal GPUs cluster."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning by Abstraction", "Title": "The Neural State Machine", "Abstract": "We introduce the Neural State Machine, seeking to bridge the gap between the neural and symbolic views of AI and integrate their complementary strengths for the task of visual reasoning. Given an image, we first predict a probabilistic graph that represents its underlying semantics and serves as a structured world model. Then, we perform sequential reasoning over the graph, iteratively traversing its nodes to answer a given question or draw a new inference. In contrast to most neural architectures that are designed to closely interact with the raw sensory data, our model operates instead in an abstract latent space, by transforming both the visual and linguistic modalities into semantic concept-based representations, thereby achieving enhanced transparency and modularity. We evaluate our model on VQA-CP and GQA, two recent VQA datasets that involve compositionality, multi-step inference and diverse reasoning skills, achieving state-of-the-art results in both cases. We provide further experiments that illustrate the model's strong generalization capacity across multiple dimensions, including novel compositions of concepts, changes in the answer distribution, and unseen linguistic structures, demonstrating the qualities and efficacy of our approach."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Control Self-Assembling Morphologies", "Title": "A Study of Generalization via Modularity", "Abstract": "Contemporary sensorimotor learning approaches typically start with an existing complex agent (e.g., a robotic arm), which they learn to control. In contrast, this paper investigates a modular co-evolution strategy: a collection of primitive agents learns to dynamically self-assemble into composite bodies while also learning to coordinate their behavior to control these bodies. Each primitive agent consists of a limb with a motor attached at one end. Limbs may choose to link up to form collectives. When a limb initiates a link-up action and there is another limb nearby, the latter is magnetically connected to the 'parent' limb's motor. This forms a new single agent, which may further link with other agents. In this way, complex morphologies can emerge, controlled by a policy whose architecture is in explicit correspondence with the morphology. We evaluate the performance of these dynamic and modular agents in simulated environments. We demonstrate better generalization to test-time changes both in the environment, as well as in the structure of the agent, compared to static and monolithic baselines. Project videos and source code are provided in the supplementary material."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Domes to Drones", "Title": "Self-Supervised Active Triangulation for 3D Human Pose Reconstruction", "Abstract": "Existing state-of-the-art estimation systems can detect 2d poses of multiple people in images quite reliably. In contrast, 3d pose estimation from a single image is ill-posed due to occlusion and depth ambiguities. Assuming access to multiple cameras, or given an active system able to position itself to observe the scene from multiple viewpoints, reconstructing 3d pose from 2d measurements becomes well-posed within the framework of standard multi-view geometry. Less clear is what is an informative set of viewpoints for accurate 3d reconstruction, particularly in complex scenes, where people are occluded by others or by scene objects. In order to address the view selection problem in a principled way, we here introduce ACTOR, an active triangulation agent for 3d human pose reconstruction. Our fully trainable agent consists of a 2d pose estimation network (any of which would work) and a deep reinforcement learning-based policy for camera viewpoint selection. The policy predicts observation viewpoints, the number of which varies adaptively depending on scene content, and the associated images are fed to an underlying pose estimator. Importantly, training the policy requires no annotations - given a 2d pose estimator, ACTOR is trained in a self-supervised manner. In extensive evaluations on complex multi-people scenes filmed in a Panoptic dome, under multiple viewpoints, we compare our active triangulation agent to strong multi-view baselines, and show that ACTOR produces significantly more accurate 3d pose reconstructions. We also provide a proof-of-concept experiment indicating the potential of connecting our view selection policy to a physical drone observer."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SIC-MMAB", "Title": "Synchronisation Involves Communication in Multiplayer Multi-Armed Bandits", "Abstract": "Motivated by cognitive radio networks, we consider the stochastic multiplayer multi-armed bandit problem, where several players pull arms simultaneously and collisions occur if one of them is pulled by several players at the same stage.  We present a decentralized algorithm that achieves the same performance as a centralized one,  contradicting the existing lower bounds for that problem. This is possible by ``hacking'' the standard model by constructing a communication protocol between players that deliberately enforces collisions, allowing them to share their information at a negligible cost. \nThis motivates the introduction of a more appropriate dynamic setting without sensing, where similar communication protocols are no longer possible. However, we show that the logarithmic growth of the regret is still achievable for this model with a new algorithm."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Surround Modulation", "Title": "A Bio-inspired Connectivity Structure for Convolutional Neural Networks", "Abstract": "Numerous neurophysiological studies have revealed that a large number of the primary visual cortex neurons operate in a regime called surround modulation. Surround modulation has a substantial effect on various perceptual tasks, and it also plays a crucial role in the efficient neural coding of the visual cortex. Inspired by the notion of surround modulation, we designed new excitatory-inhibitory connections between a unit and its surrounding units in the convolutional neural network (CNN) to achieve a more biologically plausible network. Our experiments show that this simple mechanism can considerably improve both the performance and training speed of traditional CNNs in visual tasks. We further explore additional outcomes of the proposed structure. We first evaluate the model under several visual challenges, such as the presence of clutter or change in lighting conditions and show its superior generalization capability in handling these challenging situations. We then study possible changes in the statistics of neural activities such as sparsity and decorrelation and provide further insight into the underlying efficiencies of surround modulation. Experimental results show that importing surround modulation into the convolutional layers ensues various effects analogous to those derived by surround modulation in the visual cortex."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Catastrophic Forgetting Meets Negative Transfer", "Title": "Batch Spectral Shrinkage for Safe Transfer Learning", "Abstract": "Before sufficient training data is available, fine-tuning neural networks pre-trained on large-scale datasets substantially outperforms training from random initialization. However, fine-tuning methods suffer from two dilemmas, catastrophic forgetting and negative transfer. While several methods with explicit attempts to overcome catastrophic forgetting have been proposed, negative transfer is rarely delved into. In this paper, we launch an in-depth empirical investigation into negative transfer in fine-tuning and find that, for the weight parameters and feature representations, transferability of their spectral components is diverse. For safe transfer learning, we present Batch Spectral Shrinkage (BSS), a novel regularization approach to penalizing smaller singular values so that untransferable spectral components are suppressed. BSS is orthogonal to existing fine-tuning methods and is readily pluggable to them. Experimental results show that BSS can significantly enhance the performance of representative methods, especially with limited training data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ViLBERT", "Title": "Pretraining Task-Agnostic Visiolinguistic Representations for Vision-and-Language Tasks", "Abstract": "We present ViLBERT (short for Vision-and-Language BERT), a model for learning task-agnostic joint representations of image content and natural language. We extend the popular BERT architecture to a multi-modal two-stream model, processing both visual and textual inputs in separate streams that interact through co-attentional transformer layers. We pretrain our model through two proxy tasks on the large, automatically collected Conceptual Captions dataset and then transfer it to multiple established vision-and-language tasks -- visual question answering, visual commonsense reasoning, referring expressions, and caption-based image retrieval -- by making only minor additions to the base architecture. We observe significant improvements across tasks compared to existing task-specific models -- achieving state-of-the-art on all four tasks. Our work represents a shift away from learning groundings between vision and language only as part of task training and towards treating visual grounding as a pretrainable and transferable capability."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Making AI Forget You", "Title": "Data Deletion in Machine Learning", "Abstract": "Intense recent discussions have focused on how to provide individuals with control over when their data can and cannot be used --- the EU’s Right To Be Forgotten regulation is an example of this effort. In this paper we initiate a framework studying what to do when it is no longer permissible to deploy models derivative from specific user data. In particular, we formulate the problem of efficiently deleting individual data points from trained machine learning models. For many standard ML models, the only way to completely remove an individual's data is to retrain the whole model from scratch on the remaining data, which is often not computationally practical.  We investigate algorithmic principles that enable efficient data deletion in ML. For the specific setting of $k$-means clustering, we propose two provably deletion efficient algorithms which achieve an average of over $100\\times$ improvement in deletion efficiency across 6 datasets, while producing clusters of comparable statistical quality to a canonical $k$-means++ baseline."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A New Defense Against Adversarial Images", "Title": "Turning a Weakness into a Strength", "Abstract": "Natural images are virtually surrounded by low-density misclassified regions that can be efficiently discovered by gradient-guided search --- enabling the generation of adversarial images. While many techniques for detecting these attacks have been proposed, they are easily bypassed when the adversary has full knowledge of the detection mechanism and adapts the attack strategy accordingly. In this paper, we adopt a novel perspective and regard the omnipresence of adversarial perturbations as a strength rather than a weakness. We postulate that if an image has been tampered with, these adversarial directions either become harder to find with gradient methods or have substantially higher density than for natural images. We develop a practical test for this signature characteristic to successfully detect adversarial attacks, achieving unprecedented accuracy under the white-box setting where the adversary is given full knowledge of our detection mechanism."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Band-Limited Gaussian Processes", "Title": "The Sinc Kernel", "Abstract": "We propose a novel class of Gaussian processes (GPs) whose spectra have compact support, meaning that their sample trajectories are almost-surely band limited. As a complement to the growing literature on spectral design of covariance kernels, the core of our proposal is to model power spectral densities through a rectangular function, which results in a kernel based on the sinc function with straightforward extensions to non-centred (around zero frequency) and frequency-varying cases. In addition to its use in regression, the relationship between the sinc kernel and the classic theory is illuminated, in particular, the Shannon-Nyquist theorem is interpreted as posterior reconstruction under the proposed kernel. Additionally, we show that the sinc kernel is instrumental in two fundamental signal processing applications: first, in stereo amplitude modulation, where the non-centred sinc kernel arises naturally. Second, for band-pass filtering, where the proposed kernel allows for a Bayesian treatment that is robust to observation noise and missing data. The developed theory is complemented with illustrative graphic examples and validated experimentally using real-world data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Break the Ceiling", "Title": "Stronger Multi-scale Deep Graph Convolutional Networks", "Abstract": "Recently, neural network based approaches have achieved significant progress for solving large, complex, graph-structured problems. Nevertheless, the advantages of multi-scale information and deep architectures have not been sufficiently exploited. In this paper, we first analyze key factors constraining the expressive power of existing Graph Convolutional Networks (GCNs), including the activation function and shallow learning mechanisms. Then, we generalize spectral graph convolution and deep GCN in block Krylov subspace forms, upon which we devise two architectures, both scalable in depth however making use of multi-scale information differently. On several node classification tasks, the proposed architectures achieve state-of-the-art performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KerGM", "Title": "Kernelized Graph Matching", "Abstract": "Graph matching plays a central role in such fields as computer vision, pattern recognition, and bioinformatics. Graph matching problems can be cast as two types of quadratic assignment problems (QAPs): Koopmans-Beckmann's QAP or Lawler's QAP. In our paper, we provide a unifying view for these two problems by introducing new rules for array operations in Hilbert spaces. Consequently, Lawler's QAP can be considered as the Koopmans-Beckmann's alignment between two arrays in reproducing kernel Hilbert spaces (RKHS), making it possible to efficiently solve the problem without computing a huge affinity matrix. Furthermore, we develop the entropy-regularized Frank-Wolfe (EnFW) algorithm for optimizing QAPs, which has the same convergence rate as the original FW algorithm while dramatically reducing the computational burden for each outer iteration. We conduct extensive experiments to evaluate our approach, and show that our algorithm significantly outperforms the state-of-the-art in both matching accuracy and scalability."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STAR-Caps", "Title": "Capsule Networks with Straight-Through Attentive Routing", "Abstract": "Capsule networks have been shown to be powerful models for image classification, thanks to their ability to represent and capture viewpoint variations of an object. However, the high computational complexity of capsule networks that stems from the recurrent dynamic routing poses a major drawback making their use for large-scale image classification challenging. In this work, we propose Star-Caps a capsule-based network that exploits a straight-through attentive routing to address the drawbacks of capsule networks. By utilizing attention modules augmented by differentiable binary routers, the proposed mechanism estimates the routing coefficients between capsules without recurrence, as opposed to prior related work. Subsequently, the routers utilize straight-through estimators to make binary decisions to either connect or disconnect the route between capsules, allowing stable and faster performance. The experiments conducted on several image classification datasets, including MNIST, SmallNorb, CIFAR-10, CIFAR-100, and ImageNet show that Star-Caps outperforms the baseline capsule networks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DualDICE", "Title": "Behavior-Agnostic Estimation of Discounted Stationary Distribution Corrections", "Abstract": "In many real-world reinforcement learning applications, access to the environment is limited to a fixed dataset, instead of direct (online) interaction with the environment.  When using this data for either evaluation or training of a new policy, accurate estimates of discounted stationary distribution ratios -- correction terms which quantify the likelihood that the new policy will experience a certain state-action pair normalized by the probability with which the state-action pair appears in the dataset -- can improve accuracy and performance. In this work, we propose an algorithm, DualDICE, for estimating these quantities. In contrast to previous approaches, our algorithm is agnostic to knowledge of the behavior policy (or policies) used to generate the dataset. Furthermore, our algorithm eschews any direct use of importance weights, thus avoiding potential optimization instabilities endemic of previous methods. In addition to providing theoretical guarantees, we present an empirical study of our algorithm applied to off-policy policy evaluation and find that our algorithm significantly improves accuracy compared to existing techniques."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Self-supervised GAN", "Title": "Analysis and Improvement with Multi-class Minimax Game", "Abstract": "Self-supervised (SS) learning is a powerful approach for representation learning using unlabeled data. Recently, it has been applied to Generative Adversarial Networks (GAN) training. Specifically, SS tasks were proposed to address the catastrophic forgetting issue in the GAN discriminator. In this work, we perform an in-depth analysis to understand how SS tasks interact with learning of generator. From the analysis, we identify issues of SS tasks which allow a severely mode-collapsed generator to excel the SS tasks. To address the issues, we propose new SS tasks based on a multi-class minimax game. The competition between our proposed SS tasks in the game encourages the generator to learn the data distribution and generate diverse samples. We provide both theoretical and empirical analysis to support that our proposed SS tasks have better convergence property. We conduct experiments to incorporate our proposed SS tasks into two different GAN baseline models. Our approach establishes state-of-the-art FID scores on CIFAR-10, CIFAR-100, STL-10, CelebA, Imagenet $32\\times32$ and Stacked-MNIST datasets, outperforming existing works by considerable margins in some cases. Our unconditional GAN model approaches performance of conditional GAN without using labeled data.  Our code:  \\url{https://github.com/tntrung/msgan}"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Social-BiGAT", "Title": "Multimodal Trajectory Forecasting using Bicycle-GAN and Graph Attention Networks", "Abstract": "Predicting the future trajectories of multiple interacting pedestrians in a scene has become an increasingly important problem for many different applications ranging from control of autonomous vehicles and social robots to security and surveillance. This problem is compounded by the presence of social interactions between humans and their physical interactions with the scene. While the existing literature has explored some of these cues, they mainly ignored the multimodal nature of each human's future trajectory which is noticeably influenced by the intricate social interactions. In this paper, we present Social-BiGAT, a graph-based generative adversarial network that generates realistic, multimodal trajectory predictions for multiple pedestrians in a scene. Our method is based on a graph attention network (GAT) that learns feature representations that encode the social interactions between humans in the scene, and a recurrent encoder-decoder architecture that is trained adversarially to predict, based on the features, the humans' paths. We explicitly account for the multimodal nature of the prediction problem by forming a reversible transformation between each scene and its latent noise vector, as in Bicycle-GAN. We show that our framework achieves state-of-the-art performance comparing it to several baselines on existing trajectory forecasting benchmarks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel Truncated Randomized Ridge Regression", "Title": "Optimal Rates and Low Noise Acceleration", "Abstract": "In this paper we consider the nonparametric least square regression in a Reproducing Kernel Hilbert Space (RKHS). We propose a new randomized algorithm that has optimal generalization error bounds with respect to the square loss, closing a long-standing gap between upper and lower bounds. Moreover, we show that our algorithm has faster finite-time and asymptotic rates on problems where the Bayes risk with respect to the square loss is small. We state our results using standard tools from the theory of least square regression in RKHSs, namely, the decay of the eigenvalues of the associated integral operator and the complexity of the optimal predictor measured through the integral operator."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learn, Imagine and Create", "Title": "Text-to-Image Generation from Prior Knowledge", "Abstract": "Text-to-image generation, i.e. generating an image given a text description, is a very challenging task due to the significant semantic gap between the two domains. Humans, however, tackle this problem intelligently. We learn from diverse objects to form a solid prior about semantics, textures, colors, shapes, and layouts. Given a text description, we immediately imagine an overall visual impression using this prior and, based on this, we draw a picture by progressively adding more and more details. In this paper, and inspired by this process, we propose a novel text-to-image method called LeicaGAN to combine the above three phases in a unified framework. First, we formulate the multiple priors learning phase as a textual-visual co-embedding (TVE) comprising a text-image encoder for learning semantic, texture, and color priors and a text-mask encoder for learning shape and layout priors. Then, we formulate the imagination phase as multiple priors aggregation (MPA) by combining these complementary priors and adding noise for diversity. Lastly, we formulate the creation phase by using a cascaded attentive generator (CAG) to progressively draw a picture from coarse to fine. We leverage adversarial learning for LeicaGAN to enforce semantic consistency and visual realism. Thorough experiments on two public benchmark datasets demonstrate LeicaGAN's superiority over the baseline method. Code has been made available at https://github.com/qiaott/LeicaGAN."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Qsparse-local-SGD", "Title": "Distributed SGD with Quantization, Sparsification and Local Computations", "Abstract": "Communication bottleneck has been identified as a significant issue in distributed optimization of large-scale learning models. Recently, several approaches to mitigate this problem have been proposed, including different forms of gradient compression or computing local models and mixing them iteratively. In this paper we propose Qsparse-local-SGD algorithm, which combines aggressive sparsification with quantization and local computation along with error compensation, by keeping track of the difference between the true and compressed gradients. We propose both synchronous and asynchronous implementations of Qsparse-local-SGD. We analyze convergence for Qsparse-local-SGD in the distributed case, for smooth non-convex and convex objective functions. We demonstrate that Qsparse-local-SGD converges at the same rate as vanilla distributed SGD for many important classes of sparsifiers and quantizers. We use Qsparse-local-SGD to train ResNet-50 on ImageNet, and show that it results in significant savings over the state-of-the-art, in the number of bits transmitted to reach target accuracy."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Making the Cut", "Title": "A Bandit-based Approach to Tiered Interviewing", "Abstract": "Given a huge set of applicants, how should a firm allocate sequential resume screenings, phone interviews, and in-person site visits?  In a tiered interview process, later stages (e.g., in-person visits) are more informative, but also more expensive than earlier stages (e.g., resume screenings).  Using accepted hiring models and the concept of structured interviews, a best practice in human resources, we cast tiered hiring as a combinatorial pure exploration (CPE) problem in the stochastic multi-armed bandit setting. The goal is to select a subset of arms (in our case, applicants) with some combinatorial structure.  We present new algorithms in both the probably approximately correct (PAC) and fixed-budget settings that select a near-optimal cohort with provable guarantees.  We show via simulations on real data from one of the largest US-based computer science graduate programs that our algorithms make better hiring decisions or use less budget than the status quo."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sim2real transfer learning for 3D human pose estimation", "Title": "motion to the rescue", "Abstract": "Synthetic visual data can provide practicically infinite diversity and rich labels,\nwhile avoiding ethical issues with privacy and bias. However, for many tasks,\ncurrent models trained on synthetic data generalize poorly to real data. The task of\n3D human pose estimation is a particularly interesting example of this sim2real\nproblem, because learning-based approaches perform reasonably well given real\ntraining data, yet labeled 3D poses are extremely difficult to obtain in the wild,\nlimiting scalability. In this paper, we show that standard neural-network approaches,\nwhich perform poorly when trained on synthetic RGB images, can perform well\nwhen the data is pre-processed to extract cues about the person’s motion, notably\nas optical flow and the motion of 2D keypoints. Therefore, our results suggest\nthat motion can be a simple way to bridge a sim2real gap when video is available.\nWe evaluate on the 3D Poses in the Wild dataset, the most challenging modern\nbenchmark for 3D pose estimation, where we show full 3D mesh recovery that is\non par with state-of-the-art methods trained on real 3D sequences, despite training\nonly on synthetic humans from the SURREAL dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Assessing Disparate Impact of Personalized Interventions", "Title": "Identifiability and Bounds", "Abstract": "Personalized interventions in social services, education, and healthcare leverage individual-level causal effect predictions in order to give the best treatment to each individual or to prioritize program interventions for the individuals most likely to benefit. While the sensitivity of these domains compels us to evaluate the fairness of such policies, we show that actually auditing their disparate impacts per standard observational metrics, such as true positive rates, is impossible since ground truths are unknown. Whether our data is experimental or observational, an individual's actual outcome under an intervention different than that received can never be known, only predicted based on features. We prove how we can nonetheless point-identify these quantities under the additional assumption of monotone treatment response, which may be reasonable in many applications. We further provide a sensitivity analysis for this assumption via sharp partial-identification bounds under violations of monotonicity of varying strengths. We show how to use our results to audit personalized interventions using partially-identified ROC and xROC curves and demonstrate this in a case study of a French job training dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cascade RPN", "Title": "Delving into High-Quality Region Proposal Network with Adaptive Convolution", "Abstract": "This paper considers an architecture referred to as Cascade Region Proposal Network (Cascade RPN) for improving the region-proposal quality and detection performance by systematically addressing the limitation of the conventional RPN that heuristically defines the anchors and aligns the features to the anchors. First, instead of using multiple anchors with predefined scales and aspect ratios, Cascade RPN relies on a single anchor per location and performs multi-stage refinement. Each stage is progressively more stringent in defining positive samples by starting out with an anchor-free metric followed by anchor-based metrics in the ensuing stages. Second, to attain alignment between the features and the anchors throughout the stages, adaptive convolution is proposed that takes the anchors in addition to the image features as its input and learns the sampled features guided by the anchors. A simple implementation of a two-stage Cascade RPN achieves 13.4 point AR higher than that of the conventional RPN, surpassing any existing region proposal methods. When adopting to Fast R-CNN and Faster R-CNN, Cascade RPN can improve the detection mAP by 3.1 and 3.5 points, respectively.  The code will be made publicly available at https://github.com/thangvubk/Cascade-RPN."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ask not what AI can do, but what AI should do", "Title": "Towards a framework of task delegability", "Abstract": "While artificial intelligence (AI) holds promise for addressing societal challenges, issues of exactly which tasks to automate and to what extent to do so remain understudied. We approach this problem of task delegability from a human-centered perspective by developing a framework on human perception of task delegation to AI. We consider four high-level factors that can contribute to a delegation decision: motivation, difficulty, risk, and trust. To obtain an empirical understanding of human preferences in different tasks, we build a dataset of 100 tasks from academic papers, popular media portrayal of AI, and everyday life, and administer a survey based on our proposed framework. We find little preference for full AI control and a strong preference for machine-in-the-loop designs, in which humans play the leading role. Among the four factors, trust is the most correlated with human preferences of optimal human-machine delegation. This framework represents a first step towards characterizing human preferences of AI automation across tasks. We hope this work encourages future efforts towards understanding such individual attitudes; our goal is to inform the public and the AI research community rather than dictating any direction in technology development."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LCA", "Title": "Loss Change Allocation for Neural Network Training", "Abstract": "Neural networks enjoy widespread use, but many aspects of their training, representation, and operation are poorly understood. In particular, our view into the training process is limited, with a single scalar loss being the most common viewport into this high-dimensional, dynamic process. We propose a new window into training called Loss Change Allocation (LCA), in which credit for changes to the network loss is conservatively partitioned to the parameters. This measurement is accomplished by decomposing the components of an approximate path integral along the training trajectory using a Runge-Kutta integrator. This rich view shows which parameters are responsible for decreasing or increasing the loss during training, or which parameters \"help\" or \"hurt\" the network's learning, respectively. LCA may be summed over training iterations and/or over neurons, channels, or layers for increasingly coarse views. This new measurement device produces several insights into training. (1) We find that barely over 50% of parameters help during any given iteration. (2) Some entire layers hurt overall, moving on average against the training gradient, a phenomenon we hypothesize may be due to phase lag in an oscillatory training process. (3) Finally, increments in learning proceed in a synchronized manner across layers, often peaking on identical iterations."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GNNExplainer", "Title": "Generating Explanations for Graph Neural Networks", "Abstract": "Graph Neural Networks (GNNs) are a powerful tool for machine learning on graphs.GNNs combine node feature information with the graph structure by \nrecursively passing neural messages along edges of the input graph. However, incorporating both graph structure and feature information leads to complex models,\nand explaining predictions made by GNNs remains unsolved. Here\nwe propose GNNExplainer, the first general, model-agnostic approach for providing interpretable explanations for predictions of any GNN-based model on any graph-based machine learning task. Given an instance, GNNExplainer identifies a compact subgraph structure and a small subset of node features that have a crucial role in GNN's prediction. \nFurther, GNNExplainer  can generate consistent and concise explanations for an entire class of instances.\nWe formulate GNNExplainer as an optimization task that maximizes the mutual information between a GNN's prediction and distribution of possible subgraph structures. Experiments on synthetic and real-world graphs show that our approach can identify important graph structures as well as node features, and outperforms baselines by 17.1% on average. GNNExplainer  provides a variety of benefits, from the ability to visualize semantically relevant structures to interpretability, to giving insights into errors of faulty GNNs."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Missing Not at Random in Matrix Completion", "Title": "The Effectiveness of Estimating Missingness Probabilities Under a Low Nuclear Norm Assumption", "Abstract": "Matrix completion is often applied to data with entries missing not at random (MNAR). For example, consider a recommendation system where users tend to only reveal ratings for items they like. In this case, a matrix completion method that relies on entries being revealed at uniformly sampled row and column indices can yield overly optimistic predictions of unseen user ratings. Recently, various papers have shown that we can reduce this bias in MNAR matrix completion if we know the probabilities of different matrix entries being missing. These probabilities are typically modeled using logistic regression or naive Bayes, which make strong assumptions and lack guarantees on the accuracy of the estimated probabilities. In this paper, we suggest a simple approach to estimating these probabilities that avoids these shortcomings. Our approach follows from the observation that missingness patterns in real data often exhibit low nuclear norm structure. We can then estimate the missingness probabilities by feeding the (always fully-observed) binary matrix specifying which entries are revealed to an existing nuclear-norm-constrained matrix completion algorithm by Davenport et al. [2014]. Thus, we tackle MNAR matrix completion by solving a different matrix completion problem first that recovers missingness probabilities. We establish finite-sample error bounds for how accurate these probability estimates are and how well these estimates debias standard matrix completion losses for the original matrix to be completed. Our experiments show that the proposed debiasing strategy can improve a variety of existing matrix completion algorithms, and achieves downstream matrix completion accuracy at least as good as logistic regression and naive Bayes debiasing baselines that require additional auxiliary information."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Transfer of Inductive Bias from Simulation to the Real World", "Title": "a New Disentanglement Dataset", "Abstract": "Learning meaningful and compact representations with disentangled semantic aspects is considered to be of key importance in representation learning. Since real-world data is notoriously costly to collect, many recent state-of-the-art disentanglement models have heavily relied on synthetic toy data-sets. In this paper, we propose a novel data-set which consists of over 1 million images of physical 3D objects with seven factors of variation, such as object color, shape, size and position. In order to be able to control all the factors of variation precisely, we built an experimental platform where the objects are being moved by a robotic arm. In addition, we provide two more datasets which consist of simulations of the experimental setup. These datasets provide for the first time the possibility to systematically investigate how well different disentanglement methods perform on real data in comparison to simulation, and how simulated data can be leveraged to build better representations of the real world. We provide a first experimental study of these questions and our results indicate that learned models transfer poorly, but that model and hyperparameter selection is an effective means of transferring information to the real world."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PowerSGD", "Title": "Practical Low-Rank Gradient Compression for Distributed Optimization", "Abstract": "We study gradient compression methods to alleviate the communication bottleneck in data-parallel distributed optimization. Despite the significant attention received, current compression schemes either do not scale well, or fail to achieve the target test accuracy. We propose a low-rank gradient compressor that can i) compress gradients rapidly, ii) efficiently aggregate the compressed gradients using all-reduce, and iii) achieve test performance on par with SGD. The proposed algorithm is the only method evaluated that achieves consistent wall-clock speedups when benchmarked against regular SGD with an optimized communication backend. We demonstrate reduced training times for convolutional networks as well as LSTMs on common datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multilabel reductions", "Title": "what is my loss optimising?", "Abstract": "Multilabel classification is a challenging problem arising in applications ranging from information retrieval to image tagging. A popular approach to this problem is to employ a reduction to a suitable series of binary or multiclass problems (e.g., computing a softmax based cross-entropy over the relevant labels). While such methods have seen empirical success, less is understood about how well they approximate two fundamental performance measures: precision@$k$ and recall@$k$. In this paper, we study five commonly used reductions, including the one-versus-all reduction, a reduction to multiclass classification, and normalised versions of the same, wherein the contribution of each instance is normalised by the number of relevant labels. Our main result is a formal justification of each reduction: we explicate their underlying risks, and show they are each consistent with respect to either precision or recall. Further, we show that in general no reduction can be optimal for both measures. We empirically validate our results, demonstrating scenarios where normalised reductions yield recall gains over unnormalised counterparts."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CNN^{2}", "Title": "Viewpoint Generalization via a Binocular Vision", "Abstract": "The Convolutional Neural Networks (CNNs) have laid the foundation for many techniques in various applications. Despite achieving remarkable performance in some tasks, the 3D viewpoint generalizability of CNNs is still far behind humans visual capabilities. Although recent efforts, such as the Capsule Networks, have been made to address this issue, these new models are either hard to train and/or incompatible with existing CNN-based techniques specialized for different applications. Observing that humans use binocular vision to understand the world, we study in this paper whether the 3D viewpoint generalizability of CNNs can be achieved via a binocular vision. We propose CNN^{2}, a CNN that takes two images as input, which resembles the process of an object being viewed from the left eye and the right eye. CNN^{2} uses novel augmentation, pooling, and convolutional layers to learn a sense of three-dimensionality in a recursive manner. Empirical evaluation shows that CNN^{2} has improved viewpoint generalizability compared to vanilla CNNs. Furthermore, CNN^{2} is easy to implement and train, and is compatible with existing CNN-based specialized techniques for different applications."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "G2SAT", "Title": "Learning to Generate SAT Formulas", "Abstract": "The Boolean Satisfiability (SAT) problem is the canonical NP-complete problem and is fundamental to computer science, with a wide array of applications in planning, verification, and theorem proving. Developing and evaluating practical SAT solvers relies on extensive empirical testing on a set of real-world benchmark formulas. However, the availability of such real-world SAT formulas is limited. While these benchmark formulas can be augmented with synthetically generated ones, existing approaches for doing so are heavily hand-crafted and fail to simultaneously capture a wide range of characteristics exhibited by real-world SAT instances. In this work, we present G2SAT, the first deep generative framework that learns to generate SAT formulas from a given set of input formulas. Our key insight is that SAT formulas can be transformed into latent bipartite graph representations which we model using a specialized deep generative neural network. We show that G2SAT can generate SAT formulas that closely resemble given real-world SAT instances, as measured by both graph metrics and SAT solver behavior. Further, we show that our synthetic SAT formulas could be used to improve SAT solver performance on real-world benchmarks, which opens up new opportunities for the continued development of SAT solvers and a deeper understanding of their performance."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Small ReLU networks are powerful memorizers", "Title": "a tight analysis of memorization capacity", "Abstract": "We study finite sample expressivity, i.e., memorization power of ReLU networks. Recent results require $N$ hidden nodes to memorize/interpolate arbitrary $N$ data points. In contrast, by exploiting depth, we show that 3-layer ReLU networks with $\\Omega(\\sqrt{N})$ hidden nodes can perfectly memorize most datasets with $N$ points. We also prove that width $\\Theta(\\sqrt{N})$ is necessary and sufficient for memorizing $N$ data points, proving tight bounds on memorization capacity. The sufficiency result can be extended to deeper networks; we show that an $L$-layer network with $W$ parameters in the hidden layers can memorize $N$ data points if $W = \\Omega(N)$. Combined with a recent upper bound $O(WL\\log W)$ on VC dimension, our construction is nearly tight for any fixed $L$. Subsequently, we analyze memorization capacity of residual networks under a general position assumption; we prove results that substantially reduce the known requirement of $N$ hidden nodes. Finally, we study the dynamics of stochastic gradient descent (SGD), and show that when initialized near a memorizing global minimum of the empirical risk, SGD quickly finds a nearby point with much smaller empirical risk."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Control Batch Size and Learning Rate to Generalize Well", "Title": "Theoretical and Empirical Evidence", "Abstract": "Deep neural networks have received dramatic success based on the optimization method of stochastic gradient descent (SGD). However, it is still not clear how to tune hyper-parameters, especially batch size and learning rate, to ensure good generalization. This paper reports both theoretical and empirical evidence of a training strategy that we should control the ratio of batch size to learning rate not too large to achieve a good generalization ability. Specifically, we prove a PAC-Bayes generalization bound for neural networks trained by SGD, which has a positive correlation with the ratio of batch size to learning rate. This correlation builds the theoretical foundation of the training strategy. Furthermore, we conduct a large-scale experiment to verify the correlation and training strategy. We trained 1,600 models based on architectures ResNet-110, and VGG-19 with datasets CIFAR-10 and CIFAR-100 while strictly control unrelated variables. Accuracies on the test sets are collected for the evaluation. Spearman's rank-order correlation coefficients and the corresponding $p$ values on 164 groups of the collected data demonstrate that the correlation is statistically significant, which fully supports the training strategy."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "XLNet", "Title": "Generalized Autoregressive Pretraining for Language Understanding", "Abstract": "With the capability of modeling bidirectional contexts, denoising autoencoding based pretraining like BERT achieves better performance than pretraining approaches based on autoregressive language modeling.\nHowever, relying on corrupting the input with masks, BERT neglects dependency between the masked positions and suffers from a pretrain-finetune discrepancy.\nIn light of these pros and cons, we propose XLNet, a generalized autoregressive pretraining method that (1) enables learning bidirectional contexts by maximizing the expected likelihood over all permutations of the factorization order and (2) overcomes the limitations of BERT thanks to its autoregressive formulation.\nFurthermore, XLNet integrates ideas from Transformer-XL, the state-of-the-art autoregressive model, into pretraining.\nEmpirically, under comparable experiment setting, XLNet outperforms BERT on 20 tasks, often by a large margin, including question answering, natural language inference, sentiment analysis, and document ranking."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Classification-by-Components", "Title": "Probabilistic Modeling of Reasoning over a Set of Components", "Abstract": "Abstract Neural networks are state-of-the-art classification approaches but are generally difficult to interpret. This issue can be partly alleviated by constructing a precise decision process within the neural network. In this work, a network architecture, denoted as Classification-By-Components network (CBC), is proposed. It is restricted to follow an intuitive reasoning based decision process inspired by Biederman's recognition-by-components theory from cognitive psychology. The network is trained to learn and detect generic components that characterize objects. In parallel, a class-wise reasoning strategy based on these components is learned to solve the classification problem. In contrast to other work on reasoning, we propose three different types of reasoning: positive, negative, and indefinite. These three types together form a probability space to provide a probabilistic classifier. The decomposition of objects into generic components combined with the probabilistic reasoning provides by design a clear interpretation of the classification decision process. The evaluation of the approach on MNIST shows that CBCs are viable classifiers. Additionally, we demonstrate that the inherent interpretability offers a profound understanding of the classification behavior such that we can explain the success of an adversarial attack. The method's scalability is successfully tested using the ImageNet dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Discrimination in Online Markets", "Title": "Effects of Social Bias on Learning from Reviews and Policy Design", "Abstract": "The increasing popularity of online two-sided markets such as ride-sharing, accommodation and freelance labor platforms, goes hand in hand with new socioeconomic challenges.  One major issue remains the existence of bias and discrimination against certain social groups. We study this problem using  a two-sided large market model with  employers and workers mediated by a platform. Employers who seek to hire  workers face uncertainty about a candidate worker's  skill level. Therefore, they base their hiring decision  on learning from past reviews about an individual worker as well as on their (possibly misspecified)  prior beliefs about the ability level of the social group the worker belongs to. Drawing upon the  social learning literature with bounded rationality and limited information, uncertainty combined with social bias leads to  unequal hiring opportunities between workers of different social groups. Although the effect of social bias decreases as the number of reviews increases (consistent with empirical findings), minority workers still receive lower expected  payoffs. Finally, we  consider a simple directed matching policy (DM), which combines learning and matching to make better matching decisions for minority workers. Under this policy, there exists a steady-state equilibrium, in which  DM reduces the discrimination gap."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structure Learning with Side Information", "Title": "Sample Complexity", "Abstract": "Graphical models encode the stochastic dependencies among random variables (RVs). The vertices represent the  RVs, and the edges signify the conditional dependencies among the RVs. Structure learning is the process of inferring the edges by observing realizations of the RVs, and it has applications in a wide range of technological, social, and biological networks. Learning the structure of graphs when the vertices are treated in isolation from inferential information known about them is well-investigated. In a wide range of domains, however, often there exist additional inferred knowledge about the structure, which can serve as valuable side information. For instance, the gene networks that represent different subtypes of the same cancer share similar edges across all subtypes and also have exclusive edges corresponding to each subtype, rendering partially similar graphical models for gene expression in different cancer subtypes. Hence, an inferential decision regarding a gene network can serve as side information for inferring other related gene networks.  When such side information is leveraged judiciously, it can translate to significant improvement in structure learning. Leveraging such side information can be abstracted as inferring structures of distinct graphical models that are {\\sl partially} similar. This paper focuses on Ising graphical models, and considers the problem of simultaneously learning the structures of two {\\sl partially} similar graphs, where any inference about the structure of one graph offers side information for the other graph. The bounded edge subclass of Ising models is considered, and necessary conditions (information-theoretic ), as well as sufficient conditions (algorithmic) for the sample complexity for achieving a bounded probability of error, are established. Furthermore, specific regimes are identified in which the necessary and sufficient conditions coincide, rendering the optimal sample complexity."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Discrete Flows", "Title": "Invertible Generative Models of Discrete Data", "Abstract": "While normalizing flows have led to significant advances in modeling high-dimensional continuous distributions, their applicability to discrete distributions remains unknown. In this paper, we show that flows can in fact be extended to discrete events---and under a simple change-of-variables formula not requiring log-determinant-Jacobian computations. Discrete flows have numerous applications. We consider two flow architectures: discrete autoregressive flows that enable bidirectionality, allowing, for example, tokens in text to depend on both left-to-right and right-to-left contexts in an exact language model; and discrete bipartite flows that enable efficient non-autoregressive generation as in RealNVP. Empirically, we find that discrete autoregressive flows outperform autoregressive baselines on synthetic discrete distributions, an addition task, and Potts models; and bipartite flows can obtain competitive performance with autoregressive baselines on character-level language modeling for Penn Tree Bank and text8."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "D-VAE", "Title": "A Variational Autoencoder for Directed Acyclic Graphs", "Abstract": "Graph structured data are abundant in the real world. Among different graph types, directed acyclic graphs (DAGs) are of particular interest to machine learning researchers, as many machine learning models are realized as computations on DAGs, including neural networks and Bayesian networks. In this paper, we study deep generative models for DAGs, and propose a novel DAG variational autoencoder (D-VAE). To encode DAGs into the latent space, we leverage graph neural networks. We propose an asynchronous message passing scheme that allows encoding the computations on DAGs, rather than using existing simultaneous message passing schemes to encode local graph structures. We demonstrate the effectiveness of our proposed DVAE through two tasks: neural architecture search and Bayesian network structure learning. Experiments show that our model not only generates novel and valid DAGs, but also produces a smooth latent space that facilitates searching for DAGs with better performance through Bayesian optimization."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Graph-based Discriminators", "Title": "Sample Complexity and Expressiveness", "Abstract": "A basic question in learning theory is to identify if two\ndistributions are identical when we have access only to examples sampled from the distributions.\nThis basic task is considered, for example, in the context of\nGenerative Adversarial Networks (GANs), where a discriminator is trained to distinguish between a real-life distribution and a synthetic distribution.\nClassically, we use a hypothesis class $H$ and claim that the two\ndistributions are distinct if for some $h\\in H$ the expected value\non the two distributions is (significantly) different.\n\nOur starting point is the following fundamental problem: \"is having\nthe hypothesis dependent on more than a single random example\nbeneficial\". To address this challenge we define $k$-ary based\ndiscriminators, which have a family of Boolean $k$-ary functions\n$\\G$. Each function $g\\in \\G$ naturally defines a hyper-graph,\nindicating whether a given hyper-edge exists. A function $g\\in \\G$\ndistinguishes between two distributions, if the expected value of\n$g$, on a $k$-tuple of i.i.d examples, on the two distributions is\n(significantly) different.\n\nWe study the expressiveness of families of $k$-ary functions,\ncompared to the classical hypothesis class $H$, which is $k=1$. We\nshow a separation in expressiveness of $k+1$-ary versus $k$-ary\nfunctions. This demonstrate the great benefit of having $k\\geq 2$ as\ndistinguishers.\n\nFor $k\\geq 2$ we introduce a notion similar to the VC-dimension, and\nshow that it controls the sample complexity. We proceed and provide upper and\nlower bounds as a function of our extended notion of VC-dimension."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Surfing", "Title": "Iterative Optimization Over Incrementally Trained Deep Networks", "Abstract": "We investigate a sequential optimization procedure to minimize the empirical risk functional $f_{\\hat\\theta}(x) = \\frac{1}{2}\\|G_{\\hat\\theta}(x) - y\\|^2$ for certain families of deep networks $G_{\\theta}(x)$. The approach is to optimize a sequence of objective functions that use network parameters obtained during different stages of the training process.  When initialized with random parameters $\\theta_0$, we show that the objective  $f_{\\theta_0}(x)$ is ``nice'' and easy to optimize with gradient descent. As learning is carried out, we obtain a sequence of generative networks $x \\mapsto G_{\\theta_t}(x)$ and associated risk functions $f_{\\theta_t}(x)$, where $t$ indicates a stage of stochastic gradient descent during training.  Since the parameters of the network do not change by very much in each step, the surface evolves slowly and can be incrementally optimized. The algorithm is formalized and analyzed for a family of expansive networks. We call the procedure {\\it surfing} since it rides along the peak of the evolving (negative) empirical risk function, starting from a smooth surface at the beginning of learning and ending with a wavy nonconvex surface after learning is complete.  Experiments show how surfing can be used to find the global optimum and for compressed sensing even when direct gradient descent on the final learned network fails."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Meta-Weight-Net", "Title": "Learning an Explicit Mapping For Sample Weighting", "Abstract": "Current deep neural networks(DNNs) can easily overfit to biased training data with corrupted labels or class imbalance. Sample re-weighting strategy is commonly used to alleviate this issue by designing a weighting function mapping from training loss to sample weight, and then iterating between weight recalculating and classifier updating. Current approaches, however, need manually pre-specify the weighting function as well as its additional hyper-parameters. It makes them fairly hard to be generally applied in practice due to the significant variation of proper weighting schemes relying on the investigated problem and training data. To address this issue, we propose a method capable of adaptively learning an explicit weighting function directly from data. The weighting function is an MLP with one hidden layer, constituting a universal approximator to almost any continuous functions, making the method able to fit a wide range of weighting function forms including those assumed in conventional research. Guided by a small amount of unbiased meta-data, the parameters of the weighting function can be finely updated simultaneously with the learning process of the classifiers. Synthetic and real experiments substantiate the capability of our method for achieving proper weighting functions in class imbalance and noisy label cases, fully complying with the common settings in traditional methods, and more complicated scenarios beyond conventional cases. This naturally leads to its better accuracy than other state-of-the-art methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Two Time-scale Off-Policy TD Learning", "Title": "Non-asymptotic Analysis over Markovian Samples", "Abstract": "Gradient-based temporal difference (GTD) algorithms are widely used in off-policy learning scenarios. Among them, the two time-scale TD with gradient correction (TDC) algorithm has been shown to have superior performance. In contrast to previous studies that characterized the non-asymptotic convergence rate of TDC only under identical and independently distributed (i.i.d.) data samples, we provide the first non-asymptotic convergence analysis for two time-scale TDC under a non-i.i.d.\\ Markovian sample path and linear function approximation. We show that the two time-scale TDC can converge as fast as O(log t/t^(2/3)) under diminishing stepsize, and can converge exponentially fast under constant stepsize, but at the cost of a non-vanishing error. We further propose a TDC algorithm with blockwisely diminishing stepsize, and show that it asymptotically converges with an arbitrarily small error at a blockwisely linear convergence rate. Our experiments demonstrate that such an algorithm converges as fast as TDC under constant stepsize, and still enjoys comparable accuracy as TDC under diminishing stepsize."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepWave", "Title": "A Recurrent Neural-Network for Real-Time Acoustic Imaging", "Abstract": "We propose a recurrent neural-network for real-time reconstruction of acoustic camera spherical maps. The network, dubbed DeepWave, is both physically and algorithmically motivated: its recurrent architecture mimics iterative solvers from convex optimisation, and its parsimonious parametrisation is based on the natural structure of acoustic imaging problems.\nEach network layer applies successive filtering, biasing and activation steps to its input, which can be interpreted as generalised deblurring and sparsification steps. To comply with the irregular geometry of spherical maps, filtering operations are implemented efficiently by means of graph signal processing techniques.\nUnlike commonly-used imaging network architectures, DeepWave is moreover capable of directly processing the complex-valued raw microphone correlations, learning how to optimally back-project these into a spherical map. We propose moreover a smart physically-inspired initialisation scheme that attains much faster training and higher performance than random initialisation.\nOur real-data experiments show DeepWave has similar computational speed to the state-of-the-art delay-and-sum imager with vastly superior resolution. While developed primarily for acoustic cameras, DeepWave could easily be adapted to neighbouring  signal processing fields, such as radio astronomy, radar and sonar."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Transfusion", "Title": "Understanding Transfer Learning for Medical Imaging", "Abstract": "Transfer learning from natural image datasets, particularly ImageNet, using standard large models and corresponding pretrained weights has become a de-facto method for deep learning applications to medical imaging. \nHowever, there are fundamental differences in data sizes, features and task specifications between natural image classification and the target medical tasks, and there is little understanding of the effects of transfer. In this paper, we explore properties of transfer learning for medical imaging. A performance evaluation on two large scale medical imaging tasks shows that surprisingly, transfer offers little benefit to performance, and simple, lightweight models can perform comparably to ImageNet architectures. Investigating the learned representations and features, we find that some of the differences from transfer learning are due to the over-parametrization of standard models rather than sophisticated feature reuse. We isolate where useful feature reuse occurs, and outline the implications for more efficient model exploration. We also explore feature independent benefits of transfer arising from weight scalings."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PIDForest", "Title": "Anomaly Detection via Partial Identification", "Abstract": "We consider the problem of detecting anomalies in a large dataset. We propose a framework called Partial Identification which captures the intuition that anomalies are easy to distinguish from the overwhelming majority of points by relatively few attribute values. Formalizing this intuition, we propose a geometric anomaly measure for a point that we call PIDScore, which measures the minimum density of data points over all subcubes containing the point. We present PIDForest: a random forest based algorithm that finds anomalies based on this definition. We show that it performs favorably in comparison to several popular anomaly detection methods, across a broad range of benchmarks. PIDForest also provides a succinct explanation for why a point is labelled anomalous, by providing a set of features and ranges for them which are relatively uncommon in the dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PRNet", "Title": "Self-Supervised Learning for Partial-to-Partial Registration", "Abstract": "We present a simple, flexible, and general framework titled Partial Registration Network (PRNet), for partial-to-partial point cloud registration. Inspired by recently-proposed learning-based methods for registration, we use deep networks to tackle non-convexity of the alignment and partial correspondence problem. While previous learning-based methods assume the entire shape is visible, PRNet is suitable for partial-to-partial registration, outperforming PointNetLK, DCP, and non-learning methods on synthetic data. PRNet is self-supervised, jointly learning an appropriate geometric representation,  a keypoint detector that finds points in common between partial views, and keypoint-to-keypoint correspondences. We show PRNet predicts keypoints and correspondences consistently across views and objects. Furthermore, the learned representation is transferable to classification."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Music", "Title": "Real world Audio Adversary against Wake-word Detection System", "Abstract": "Voice Assistants (VAs) such as Amazon Alexa or Google Assistant rely on wake-word detection to respond to people's commands, which could potentially be vulnerable to audio adversarial examples. In this work, we target our attack on the wake-word detection system. Our goal is to jam the model with some inconspicuous background music to deactivate the VAs while our audio adversary is present. We implemented an emulated wake-word detection system of Amazon Alexa based on recent publications. We validated our models against the real Alexa in terms of wake-word detection accuracy. Then we computed our audio adversaries with consideration of expectation over transform and we implemented our audio adversary with a differentiable synthesizer. Next we verified our audio adversaries digitally on hundreds of samples of utterances collected from the real world. Our experiments show that we can effectively reduce the recognition F1 score of our emulated model from 93.4% to 11.0%. Finally, we tested our audio adversary over the air, and verified it works effectively against Alexa, reducing its F1 score from 92.5% to 11.0%. To the best of our knowledge, this is the first real-world adversarial attack against a commercial grade VA wake-word detection system. Our demo video is included in the supplementary material."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Little Is Enough", "Title": "Circumventing Defenses For Distributed Learning", "Abstract": "Distributed learning is central for large-scale training of deep-learning models. However, it is exposed to a security threat in which Byzantine participants can interrupt or control the learning process. Previous attack models assume that the rogue participants (a) are omniscient (know the data of all other participants), and (b) introduce large changes to the parameters. \nAccordingly, most defense mechanisms make a similar assumption and attempt to use statistically robust methods to identify and discard values whose reported gradients are far from the population mean. We observe that if the empirical variance between the gradients of workers is high enough, an attacker could take advantage of this and launch a non-omniscient attack that operates within the population variance. We show that the variance is indeed high enough even for simple datasets such as MNIST, allowing an attack that is not only undetected by existing defenses, but also uses their power against them, causing those defense mechanisms to consistently select the byzantine workers while discarding legitimate ones. We demonstrate our attack method works not only for preventing convergence but also for repurposing of the model behavior (``backdooring''). We show that less than 25\\% of colluding workers are sufficient to degrade the accuracy of  models trained on MNIST, CIFAR10 and CIFAR100 by 50\\%, as well as to introduce backdoors without hurting the accuracy for MNIST and CIFAR10 datasets, but with a degradation for CIFAR100."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Prediction of Spatial Point Processes", "Title": "Regularized Method with Out-of-Sample Guarantees", "Abstract": "A spatial point process can be characterized by an intensity function which predicts the number of events that occur across space. In this paper, we develop a method to infer predictive intensity intervals by learning a spatial model using a regularized criterion. We prove that the proposed method exhibits out-of-sample prediction performance guarantees which, unlike standard estimators, are valid even when the spatial model is misspecified. The method is demonstrated using synthetic as well as real spatial data."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STREETS", "Title": "A Novel Camera Network Dataset for Traffic Flow", "Abstract": "In this paper, we introduce STREETS, a novel traffic flow dataset from publicly available web cameras in the suburbs of Chicago, IL. We seek to address the limitations of existing datasets in this area. Many such datasets lack a coherent traffic network graph to describe the relationship between sensors. The datasets that do provide a graph depict traffic flow in urban population centers or highway systems and use costly sensors like induction loops. These contexts differ from that of a suburban traffic body. Our dataset provides over 4 million still images across 2.5 months and one hundred web cameras in suburban Lake County, IL. We divide the cameras into two distinct communities described by directed graphs and count vehicles to track traffic statistics. Our goal is to give researchers a benchmark dataset for exploring the capabilities of inexpensive and non-invasive sensors like web cameras to understand complex traffic bodies in communities of any size. We present benchmarking tasks and baseline results for one such task to guide how future work may use our dataset."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Projected Stein Variational Newton", "Title": "A Fast and Scalable Bayesian Inference Method in High Dimensions", "Abstract": "We propose a projected Stein variational Newton (pSVN) method for high-dimensional Bayesian inference. To address the curse of dimensionality, we exploit the intrinsic low-dimensional geometric structure of the posterior distribution in the high-dimensional parameter space via its Hessian (of the log posterior) operator and perform a parallel update of the parameter samples projected into a low-dimensional subspace by an SVN method. The subspace is adaptively constructed using the eigenvectors of the averaged Hessian at the current samples. We demonstrate fast convergence of the proposed method, complexity independent of the parameter and sample dimensions, and parallel scalability."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From deep learning to mechanistic understanding in neuroscience", "Title": "the structure of retinal prediction", "Abstract": "Recently, deep feedforward neural networks have achieved considerable success in modeling biological sensory processing, in terms of reproducing the input-output map of sensory neurons. However, such models raise profound questions about the very nature of explanation in neuroscience. Are we simply replacing one complex system (a biological circuit) with another (a deep network), without understanding either? Moreover, beyond neural representations, are the deep network's computational mechanisms for generating neural responses the same as those in the brain? Without a systematic approach to extracting and understanding computational mechanisms from deep neural network models, it can be difficult both to assess the degree of utility of deep learning approaches in neuroscience, and to extract experimentally testable hypotheses from deep networks. We develop such a systematic approach by combining dimensionality reduction and modern attribution methods for determining the relative importance of interneurons for specific visual computations. We apply this approach to deep network models of the retina, revealing a conceptual understanding of how the retina acts as a predictive feature extractor that signals deviations from expectations for diverse spatiotemporal stimuli. For each stimulus, our extracted computational mechanisms are consistent with prior scientific literature, and in one case yields a new mechanistic hypothesis. Thus overall, this work not only yields insights into the computational mechanisms underlying the striking predictive capabilities of the retina, but also places the framework of deep networks as neuroscientific models on firmer theoretical foundations, by providing a new roadmap to go beyond comparing neural representations to extracting and understand computational mechanisms."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Scale-spaces", "Title": "Equivariance Over Scale", "Abstract": "We introduce deep scale-spaces, a generalization of convolutional neural networks, exploiting the scale symmetry structure of conventional image recognition tasks. Put plainly, the class of an image is invariant to the scale at which it is viewed. We construct scale equivariant cross-correlations based on a principled extension of convolutions, grounded in the theory of scale-spaces and semigroups. As a very basic operation, these cross-correlations can be used in almost any modern deep learning architecture in a plug-and-play manner. We demonstrate our networks on the Patch Camelyon and Cityscapes datasets, to prove their utility and perform introspective studies to further understand their properties."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CondConv", "Title": "Conditionally Parameterized Convolutions for Efficient Inference", "Abstract": "Convolutional layers are one of the basic building blocks of modern deep neural networks. One fundamental assumption is that convolutional kernels should\nbe shared for all examples in a dataset. We propose conditionally parameterized convolutions (CondConv), which learn specialized convolutional kernels\nfor each example. Replacing normal convolutions with CondConv enables us to increase the size and capacity of a network, while maintaining efficient inference. We demonstrate that scaling networks with CondConv improves the performance and inference cost trade-off of several existing convolutional neural\nnetwork architectures on both classification and detection tasks. On ImageNet classification, our CondConv approach applied to EfficientNet-B0 achieves state-ofthe-art performance of 78.3% accuracy with only 413M multiply-adds. Code and checkpoints for the CondConv Tensorflow layer and CondConv-EfficientNet models are available at: https://github.com/tensorflow/tpu/tree/master/ models/official/efficientnet/condconv."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DppNet", "Title": "Approximating Determinantal Point Processes with Deep Networks", "Abstract": "Determinantal point processes (DPPs) provide an elegant and versatile way to sample sets of items that balance the point-wise quality with the set-wise diversity of selected items. For this reason, they have gained prominence in many machine learning applications that rely on subset selection. However, sampling from a DPP over a ground set of size N is a costly operation, requiring in general an O(N^3) preprocessing cost and an O(Nk^3) sampling cost for subsets of size k. We approach this problem by introducing DppNets: generative deep models that produce DPP-like samples for arbitrary ground sets.  We develop an inhibitive attention mechanism based on transformer networks that captures a notion of dissimilarity between feature vectors.  We show theoretically that such an approximation is sensible as it maintains the guarantees of inhibition or dissimilarity that makes DPPs so powerful and unique. Empirically, we show across multiple datasets that DPPNET is orders of magnitude faster than competing approaches for DPP sampling, while generating high-likelihood samples and performing as well as DPPs on downstream tasks."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Taskonomy", "Title": "Inferring the Similarity of Task-Derived Representations from Brain Activity", "Abstract": "Convolutional neural networks (CNNs) trained for object classification have been widely used to account for visually-driven neural responses in both human and primate brains. However, because of the generality and complexity of object classification, despite the effectiveness of CNNs in predicting brain activity, it is difficult to draw specific inferences about neural information processing using CNN-derived representations. To address this problem, we used learned representations drawn from 21 computer vision tasks to construct encoding models for predicting brain responses from BOLD5000---a large-scale dataset comprised of fMRI scans collected while observers viewed over 5000 naturalistic scene and object images. Encoding models based on task features predict activity in different regions across the whole brain. Features from 3D tasks such as keypoint/edge detection explain greater variance compared to 2D tasks---a pattern observed across the whole brain. Using results across all 21 task representations, we constructed a ``task graph’’ based on the spatial layout of well-predicted brain areas from each task. A comparison of this brain-derived task structure to the task structure derived from transfer learning accuracy demonstrate that tasks with higher transferability make similar predictions for brain responses from different regions. These results---arising out of state-of-the-art computer vision methods---help reveal the task-specific architecture of the human visual system."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FastSpeech", "Title": "Fast, Robust and Controllable Text to Speech", "Abstract": "Neural network based end-to-end text to speech (TTS) has significantly improved the quality of synthesized speech. Prominent methods (e.g., Tacotron 2) usually first generate mel-spectrogram from text, and then synthesize speech from the mel-spectrogram using vocoder such as WaveNet. Compared with traditional concatenative and statistical parametric approaches, neural network based end-to-end models suffer from slow inference speed, and the synthesized speech is usually not robust (i.e., some words are skipped or repeated) and lack of controllability (voice speed or prosody control). In this work, we propose a novel feed-forward network based on Transformer to generate mel-spectrogram in parallel for TTS. Specifically, we extract attention alignments from an encoder-decoder based teacher model for phoneme duration prediction, which is used by a length regulator to expand the source phoneme sequence to match the length of the target mel-spectrogram sequence for parallel mel-spectrogram generation. Experiments on the LJSpeech dataset show that our parallel model matches autoregressive models in terms of speech quality, nearly eliminates the problem of word skipping and repeating in particularly hard cases, and can adjust voice speed smoothly. Most importantly, compared with autoregressive Transformer TTS, our model speeds up mel-spectrogram generation by 270x and the end-to-end speech synthesis by 38x. Therefore, we call our model FastSpeech."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Park", "Title": "An Open Platform for Learning-Augmented Computer Systems", "Abstract": "We present Park, a platform for researchers to experiment with Reinforcement Learning (RL)  for computer systems. Using RL for improving the performance of systems has a lot of potential, but  is also in many ways very different from, for example, using RL for games. Thus, in this work we first discuss the unique challenges RL for systems has, and then  propose Park an open extensible platform, which makes it easier for ML researchers to work on systems problems. Currently, Park consists of 12 real world  system-centric optimization problems with one common easy to use interface. Finally, we present the performance of existing RL approaches over those 12 problems and outline potential areas of future work."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MAVEN", "Title": "Multi-Agent Variational Exploration", "Abstract": "Centralised training with decentralised execution is an important setting for cooperative deep multi-agent reinforcement learning due to communication constraints during execution and computational tractability in training. In this paper, we analyse value-based methods that are known to have superior performance in complex environments. We specifically focus on QMIX, the current state-of-the-art in this domain. We show that the representation constraints on the joint action-values introduced by QMIX and similar methods lead to provably poor exploration and suboptimality. Furthermore, we propose a novel approach called MAVEN that hybridises value and policy-based methods by introducing a latent space for hierarchical control. The value-based agents condition their behaviour on the shared latent variable controlled by a hierarchical policy. This allows MAVEN to achieve committed, temporally extended exploration, which is key to solving complex multi-agent tasks. Our experimental results show that MAVEN achieves significant performance improvements on the challenging SMAC domain."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The continuous Bernoulli", "Title": "fixing a pervasive error in variational autoencoders", "Abstract": "Variational autoencoders (VAE) have quickly become a central tool in machine learning, applicable to a broad range of data types and latent variable models.  By far the most common first step, taken by seminal papers and by core software libraries alike, is to model MNIST data using a deep network parameterizing a Bernoulli likelihood.  This practice contains what appears to be and what is often set aside as a minor inconvenience: the pixel data is [0,1] valued, not {0,1} as supported by the Bernoulli likelihood.  Here we show that, far from being a triviality or nuisance that is convenient to ignore, this error has profound importance to VAE, both qualitative and quantitative.  We introduce and fully characterize a new [0,1]-supported, single parameter distribution: the continuous Bernoulli, which patches this pervasive bug in VAE.  This distribution is not nitpicking; it produces meaningful performance improvements across a range of metrics and datasets, including sharper image samples, and suggests a broader class of performant VAE."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DFNets", "Title": "Spectral CNNs for Graphs with Feedback-Looped Filters", "Abstract": "We propose a novel spectral convolutional neural network (CNN) model on graph structured data, namely Distributed Feedback-Looped Networks (DFNets). This model is incorporated with a robust class of spectral graph filters, called feedback-looped filters, to provide better localization on vertices, while still attaining fast convergence and linear memory requirements. Theoretically, feedback-looped filters can guarantee convergence w.r.t. a specified error bound, and be applied universally to any graph without knowing its structure. Furthermore, the propagation rule of this model can diversify features from the preceding layers to produce strong gradient flows. We have evaluated our model using two benchmark tasks: semi-supervised document classification on citation networks and semi-supervised entity classification on a knowledge graph. The experimental results show that our model considerably outperforms the state-of-the-art methods in both benchmark tasks over all datasets."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaQuant", "Title": "Learning to Quantize by Learning to Penetrate Non-differentiable Quantization", "Abstract": "Tremendous amount of parameters make deep neural networks impractical to be deployed for edge-device-based real-world applications due to the limit of computational power and storage space. Existing studies have made progress on learning quantized deep models to reduce model size and energy consumption, i.e. converting full-precision weights ($r$'s) into discrete values ($q$'s) in a supervised training manner. However, the training process for quantization is non-differentiable, which leads to either infinite or zero gradients ($g_r$) w.r.t. $r$. To address this problem, most training-based quantization methods use the gradient w.r.t. $q$ ($g_q$) with clipping to approximate $g_r$ by Straight-Through-Estimator (STE) or manually design their computation. However, these methods only heuristically make training-based quantization applicable, without further analysis on how the approximated gradients can assist training of a quantized network. In this paper, we propose to learn $g_r$ by a neural network. Specifically, a meta network is trained using $g_q$ and $r$ as inputs, and outputs $g_r$ for subsequent weight updates. The meta network is updated together with the original quantized network. Our proposed method alleviates the problem of non-differentiability, and can be trained in an end-to-end manner. Extensive experiments are conducted with CIFAR10/100 and ImageNet on various deep networks to demonstrate the advantage of our proposed method in terms of a faster convergence rate and better performance. Codes are released at: \\texttt{https://github.com/csyhhu/MetaQuant}"}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Subspace Detours", "Title": "Building Transport Plans that are Optimal on Subspace Projections", "Abstract": "Computing optimal transport (OT) between measures in high dimensions is doomed by the curse of dimensionality. A popular approach to avoid this curse is to project input measures on lower-dimensional subspaces (1D lines in the case of sliced Wasserstein distances), solve the OT problem between these reduced measures, and settle for the Wasserstein distance between these reductions, rather than that between the original measures. This approach is however difficult to extend to the case in which one wants to compute an OT map (a Monge map) between the original measures. Since computations are carried out on lower-dimensional projections, classical map estimation techniques can only produce maps operating in these reduced dimensions. We propose in this work two methods to extrapolate, from an transport map that is optimal on a subspace, one that is nearly optimal in the entire space. We prove that the best optimal transport plan that takes such \"subspace detours\" is a generalization of the Knothe-Rosenblatt transport. We show that these plans can be explicitly formulated when comparing Gaussian measures (between which the Wasserstein distance is commonly referred to as the Bures or Fréchet distance). We provide an algorithm to select optimal subspaces given pairs of Gaussian measures, and study scenarios in which that mediating subspace can be selected using prior information. We consider applications to semantic mediation between elliptic word embeddings and domain adaptation with Gaussian mixture models."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KNG", "Title": "The K-Norm Gradient Mechanism", "Abstract": "This paper presents a new mechanism for producing sanitized statistical summaries that achieve {\\it differential privacy}, called the {\\it K-Norm Gradient} Mechanism, or KNG. This new approach maintains the strong flexibility of the exponential mechanism, while achieving the powerful utility performance of objective perturbation. KNG starts with an inherent objective function (often an empirical risk), and promotes summaries that are close to minimizing the objective by weighting according to how far the gradient of the objective function is from zero.  Working with the gradient instead of the original objective function allows for additional flexibility as one can penalize using different norms.  We show that, unlike the exponential mechanism, the noise added by KNG is asymptotically negligible compared to the statistical error for many problems. In addition to theoretical guarantees on privacy and utility, we confirm the utility of KNG empirically in the settings of linear and quantile regression through simulations."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Transferable Normalization", "Title": "Towards Improving Transferability of Deep Neural Networks", "Abstract": "Deep neural networks (DNNs) excel at learning representations when trained on large-scale datasets. Pre-trained DNNs also show strong transferability when fine-tuned to other labeled datasets. However, such transferability becomes weak when the target dataset is fully unlabeled as in Unsupervised Domain Adaptation (UDA). We envision that the loss of transferability may stem from the intrinsic limitation of the architecture design of DNNs. In this paper, we delve into the components of DNN architectures and propose Transferable Normalization (TransNorm) in place of existing normalization techniques. TransNorm is an end-to-end trainable layer to make DNNs more transferable across domains. As a general method, TransNorm can be easily applied to various deep neural networks and domain adaption methods, without introducing any extra hyper-parameters or learnable parameters. Empirical results justify that TransNorm not only improves classification accuracies but also accelerates convergence for mainstream DNN-based domain adaptation methods."}
{"Type": "conference", "Year": "2019", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GOT", "Title": "An Optimal Transport framework for Graph comparison", "Abstract": "We present a novel framework based on optimal transport for the challenging problem of comparing graphs. Specifically, we exploit the probabilistic distribution of smooth graph signals defined with respect to the graph topology. This allows us to derive an explicit expression of the Wasserstein distance between graph signal distributions in terms of the graph Laplacian matrices. This leads to a structurally meaningful measure for comparing graphs, which is able to take into account the global structure of graphs, while most other measures merely observe local changes independently. Our measure is then used for formulating a new graph alignment problem, whose objective is to estimate the permutation that minimizes the distance between two graphs. We further propose an efficient stochastic algorithm based on Bayesian exploration to accommodate for the non-convexity of the graph alignment problem. We finally demonstrate the performance of our novel framework on different tasks like graph alignment, graph classification and graph signal prediction, and we show that our method leads to significant improvement with respect to the-state-of-art algorithms."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PyGlove", "Title": "Symbolic Programming for Automated Machine Learning", "Abstract": "In this paper, we introduce a new way of programming AutoML based on symbolic programming. Under this paradigm, ML programs are mutable, thus can be manipulated easily by another program. As a result, AutoML can be reformulated as an automated process of symbolic manipulation. With this formulation, we decouple the triangle of the search algorithm, the search space and the child program. This decoupling makes it easy to change the search space and search algorithm (without and with weight sharing), as well as to add search capabilities to existing code and implement complex search flows. We then introduce PyGlove, a new Python library that implements this paradigm. Through case studies on ImageNet and NAS-Bench-101, we show that with PyGlove users can easily convert a static program into a search space, quickly iterate on the search spaces and search algorithms, and craft complex search flows to achieve better results."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Synbols", "Title": "Probing Learning Algorithms with Synthetic Datasets", "Abstract": "Progress in the field of machine learning has been fueled by the introduction of benchmark datasets pushing the limits of existing algorithms. \nEnabling the design of datasets to test specific properties and failure modes of learning algorithms is thus a problem of high interest, as it has a direct impact on innovation in the field. In this sense, we introduce Synbols — Synthetic Symbols — a tool for rapidly generating new datasets with a rich composition of latent features rendered in low resolution images. Synbols leverages the large amount of symbols available in the Unicode standard and the wide range of artistic font provided by the open font community. Our tool's high-level interface provides a language for rapidly generating new distributions on the latent features, including various types of textures and occlusions. To showcase the versatility of Synbols, we use it to dissect the limitations and flaws in standard learning algorithms in various learning setups including supervised learning, active learning, out of distribution generalization, unsupervised representation learning, and object counting."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Trading Personalization for Accuracy", "Title": "Data Debugging in Collaborative Filtering", "Abstract": "Collaborative filtering has been widely used in recommender systems. Existing work has primarily focused on improving the prediction accuracy mainly via either building refined models or incorporating additional side information, yet has largely ignored the inherent distribution of the input rating data. \nIn this paper, we propose a data debugging framework to identify overly personalized ratings whose existence degrades the performance of a given collaborative filtering model. The key idea of the proposed approach is to search for a small set of ratings whose editing (e.g., modification or deletion) would near-optimally improve the recommendation accuracy of a validation set. Experimental results demonstrate that the proposed approach can significantly improve the recommendation accuracy. Furthermore, we observe that the identified ratings significantly deviate from the average ratings of the corresponding items, and the proposed approach tends to modify them towards the average. This result sheds light on the design of future recommender systems in terms of balancing between the overall accuracy and personalization."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Permute-and-Flip", "Title": "A new mechanism for differentially private selection", "Abstract": "We consider the problem of differentially private selection.  Given a finite set of candidate items, and a quality score for each item, our goal is to design a differentially private mechanism that returns an item with a score that is as high as possible.  The most commonly used mechanism for this task is the exponential mechanism.  In this work, we propose a new mechanism for this task based on a careful analysis of the privacy constraints. The expected score of our mechanism is always at least as large as the exponential mechanism, and can offer improvements up to a factor of two.  Our mechanism is simple to implement and runs  in linear time."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stein Self-Repulsive Dynamics", "Title": "Benefits From Past Samples", "Abstract": "We propose a new Stein self-repulsive dynamics for obtaining diversified samples from intractable un-normalized distributions. Our idea is to introduce Stein variational gradient as a repulsive force to push the samples of Langevin dynamics away from the past trajectories. This simple idea allows us to significantly decrease the auto-correlation in Langevin dynamics and hence increase the effective sample size. Importantly, as we establish in our theoretical analysis, the asymptotic stationary distribution remains correct even with the addition of the repulsive force, \nthanks to the special properties of the Stein variational gradient. We perform extensive empirical studies of our new algorithm, showing that our method yields much higher sample efficiency and better uncertainty estimation than vanilla Langevin dynamics."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Algorithmic recourse under imperfect causal knowledge", "Title": "a probabilistic approach", "Abstract": "Recent work has discussed the limitations of counterfactual explanations to recommend actions for algorithmic recourse, and argued for the need of taking causal relationships between features into consideration. Unfortunately, in practice, the true underlying structural causal model is generally unknown. In this work, we first show that it is impossible to guarantee recourse without access to the true structural equations. To address this limitation, we propose two probabilistic approaches to select optimal actions that achieve recourse with high probability given limited causal knowledge (e.g., only the causal graph). The first captures uncertainty over structural equations under additive Gaussian noise, and uses Bayesian model averaging to estimate the counterfactual distribution. The second removes any assumptions on the structural equations by instead computing the average effect of recourse actions on individuals similar to the person who seeks recourse, leading to a novel subpopulation-based interventional notion of recourse. We then derive a gradient-based procedure for selecting optimal recourse actions, and empirically show that the proposed approaches lead to more reliable recommendations under imperfect causal knowledge than non-probabilistic baselines."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Value of Out-of-Distribution Testing", "Title": "An Example of Goodhart's Law", "Abstract": "Out-of-distribution (OOD) testing is increasingly popular for evaluating a machine learning system's ability to generalize beyond the biases of a training set. OOD benchmarks are designed to present a different joint distribution of data and labels between training and test time. VQA-CP has become the standard OOD benchmark for visual question answering, but we discovered three troubling practices in its current use. First, most published methods rely on explicit knowledge of the construction of the OOD splits. They often rely on inverting'' the distribution of labels, e.g. answering mostlyyes'' when the common training answer was ``no''. Second, the OOD test set is used for model selection. Third, a model's in-domain performance is assessed after retraining it on in-domain splits (VQA v2) that exhibit a more balanced distribution of labels. These three practices defeat the objective of evaluating generalization, and put into question the value of methods specifically designed for this dataset. We show that embarrassingly-simple methods, including one that generates answers at random, surpass the state of the art on some question types. We provide short- and long-term solutions to avoid these pitfalls and realize the benefits of OOD evaluation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Extrapolate Knowledge", "Title": "Transductive Few-shot Out-of-Graph Link Prediction", "Abstract": "Many practical graph problems, such as knowledge graph construction and drug-drug interaction prediction, require to handle multi-relational graphs. However, handling real-world multi-relational graphs with Graph Neural Networks (GNNs) is often challenging due to their evolving nature, as new entities (nodes) can emerge over time. Moreover, newly emerged entities often have few links, which makes the learning even more difficult. Motivated by this challenge, we introduce a realistic problem of few-shot out-of-graph link prediction, where we not only predict the links between the seen and unseen nodes as in a conventional out-of-knowledge link prediction task but also between the unseen nodes, with only few edges per node. We tackle this problem with a novel transductive meta-learning framework which we refer to as Graph Extrapolation Networks (GEN). GEN meta-learns both the node embedding network for inductive inference (seen-to-unseen) and the link prediction network for transductive inference (unseen-to-unseen). For transductive link prediction, we further propose a stochastic embedding layer to model uncertainty in the link prediction between unseen entities. We validate our model on multiple benchmark datasets for knowledge graph completion and drug-drug interaction prediction. The results show that our model significantly outperforms relevant baselines for out-of-graph link prediction tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neuron Merging", "Title": "Compensating for Pruned Neurons", "Abstract": "Network pruning is widely used to lighten and accelerate neural network models. Structured network pruning discards the whole neuron or filter, leading to accuracy loss. In this work, we propose a novel concept of neuron merging applicable to both fully connected layers and convolution layers, which compensates for the information loss due to the pruned neurons/filters. Neuron merging starts with decomposing the original weights into two matrices/tensors. One of them becomes the new weights for the current layer, and the other is what we name a scaling matrix, guiding the combination of neurons. If the activation function is ReLU, the scaling matrix can be absorbed into the next layer under certain conditions, compensating for the removed neurons. We also propose a data-free and inexpensive method to decompose the weights by utilizing the cosine similarity between neurons. Compared to the pruned model with the same topology, our merged model better preserves the output feature map of the original model; thus, it maintains the accuracy after pruning without fine-tuning. We demonstrate the effectiveness of our approach over network pruning for various model architectures and datasets. As an example, for VGG-16 on CIFAR-10, we achieve an accuracy of 93.16% while reducing 64% of total parameters, without any fine-tuning. The code can be found here: https://github.com/friendshipkim/neuron-merging"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FixMatch", "Title": "Simplifying Semi-Supervised Learning with Consistency and Confidence", "Abstract": "Semi-supervised learning (SSL) provides an effective means of leveraging unlabeled data to improve a model’s performance. This domain has seen fast progress recently, at the cost of requiring more complex methods. In this paper we propose FixMatch, an algorithm that is a significant simplification of existing SSL methods. FixMatch first generates pseudo-labels using the model’s predictions on weakly-augmented unlabeled images. For a given image, the pseudo-label is only retained if the model produces a high-confidence prediction. The model is then trained to predict the pseudo-label when fed a strongly-augmented version of the same image. Despite its simplicity, we show that FixMatch achieves state-of-the-art performance across a variety of standard semi-supervised learning benchmarks, including 94.93% accuracy on CIFAR-10 with 250 labels and 88.61% accuracy with 40 – just 4 labels per class. We carry out an extensive ablation study to tease apart the experimental factors that are most important to FixMatch’s success. The code is available at https://github.com/google-research/fixmatch."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reinforcement Learning with Combinatorial Actions", "Title": "An Application to Vehicle Routing", "Abstract": "Value-function-based methods have long played an important role in reinforcement learning. However, finding the best next action given a value function of arbitrary complexity is nontrivial when the action space is too large for enumeration. We develop a framework for value-function-based deep reinforcement learning with a combinatorial action space, in which the action selection problem is explicitly formulated as a mixed-integer optimization problem. As a motivating example, we present an application of this framework to the capacitated vehicle routing problem (CVRP), a combinatorial optimization problem in which a set of locations must be covered by a single vehicle with limited capacity. On each instance, we model an action as the construction of a single route, and consider a deterministic policy which is improved through a simple policy iteration algorithm.  Our approach is competitive with other reinforcement learning methods and achieves an average gap of 1.7% with state-of-the-art OR methods on standard library instances of medium size."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rankmax", "Title": "An Adaptive Projection Alternative to the Softmax Function", "Abstract": "Several machine learning models involve mapping a score vector to a probability vector. Usually, this is done by projecting the score vector onto a probability simplex, and such projections are often characterized as Lipschitz continuous approximations of the argmax function, whose Lipschitz constant is controlled by a parameter that is similar to a softmax temperature. The aforementioned parameter has been observed to affect the quality of these models and is typically either treated as a constant or decayed over time. In this work, we propose a method that adapts this parameter to individual training examples. The resulting method exhibits desirable properties, such as sparsity of its support and numerically efficient implementation, and we find that it significantly outperforms competing non-adaptive projection methods. In our analysis, we also derive the general solution of (Bregman) projections onto the (n, k)-simplex, a result which may be of independent interest."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Over-parameterized Adversarial Training", "Title": "An Analysis Overcoming the Curse of Dimensionality", "Abstract": "Adversarial training is a popular method to give neural nets robustness against adversarial perturbations. In practice adversarial training leads to low robust training loss. However, a rigorous explanation for why this happens under natural conditions is still missing. Recently a convergence theory of standard (non-adversarial) supervised training was developed by various groups for {\\em very overparametrized} nets. It is unclear how to extend these results to adversarial training because of the min-max objective. Recently, a first step towards this direction was made by Gao et al. using tools from online learning, but they require the width of the net to be \\emph{exponential} in input dimension $d$, and with an unnatural activation function. Our work proves convergence to low robust training loss for \\emph{polynomial} width instead of exponential, under natural assumptions and with ReLU activations. A key element of our proof is showing that ReLU networks near initialization can approximate the step function, which may be of independent interest."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Latent Actor-Critic", "Title": "Deep Reinforcement Learning with a Latent Variable Model", "Abstract": "Deep reinforcement learning (RL) algorithms can use high-capacity deep networks to learn directly from image observations. However, these high-dimensional observation spaces present a number of  challenges in practice, since the policy must now solve two problems: representation learning and task learning. In this work, we tackle these two problems separately, by explicitly learning latent representations that can accelerate reinforcement learning from images. We propose the stochastic latent actor-critic (SLAC) algorithm: a sample-efficient and high-performing RL algorithm for learning policies for complex continuous control tasks directly from high-dimensional image inputs. SLAC provides a novel and principled approach for unifying stochastic sequential models and RL into a single method, by learning a compact latent representation and then performing RL in the model's learned latent space. Our experimental evaluation demonstrates that our method outperforms both model-free and model-based alternatives in terms of final performance and sample efficiency, on a range of difficult image-based control tasks. Our code and videos of our results are available at our website."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ridge Rider", "Title": "Finding Diverse Solutions by Following Eigenvectors of the Hessian", "Abstract": "Over the last decade, a single algorithm has changed many facets of our lives - Stochastic Gradient Descent (SGD). In the era of ever decreasing loss functions, SGD and its various offspring have become the go-to optimization tool in machine learning and are a key component of the success of deep neural networks (DNNs). While SGD is guaranteed to converge to a local optimum (under loose assumptions), in some cases it may matter which local optimum is found, and this is often context-dependent. Examples frequently arise in machine learning, from shape-versus-texture-features to ensemble methods and zero-shot coordination.  In these settings, there are desired solutions which SGD on standard' loss functions will not find, since it instead converges to theeasy' solutions.  In this paper, we present a different approach. Rather than following the gradient, which corresponds to a locally greedy direction, we instead follow the eigenvectors of the Hessian. By iteratively following and branching amongst the ridges, we effectively span the loss surface to find qualitatively different solutions. We show both theoretically and experimentally that our method, called Ridge Rider (RR), offers a promising direction for a variety of challenging problems."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The route to chaos in routing games", "Title": "When is price of anarchy too optimistic?", "Abstract": "Routing games are amongst the most studied classes of games in game theory. Their most well-known property is that learning dynamics typically converge to equilibria implying approximately optimal performance (low Price of Anarchy). We perform a stress test for these classic results by studying the ubiquitous learning dynamics, Multiplicative Weights Update (MWU), in different classes of congestion games, uncovering intricate non-equilibrium phenomena. We study MWU using the actual game costs without applying cost normalization to $[0,1]$. Although this non-standard assumption leads to large regret, it captures realistic agents' behaviors. Namely, as the total demand increases, agents respond more aggressively to unbearably large costs.\n\nWe start with the illustrative case of non-atomic routing games with two paths of linear cost, and show that every system has a carrying capacity, above which it becomes unstable. If the equilibrium flow is a symmetric $50-50\\%$ split, the system exhibits one period-doubling bifurcation. Although the Price of Anarchy is equal to one,  in the large population limit  the time-average social cost for all but a zero measure set of initial conditions converges to its worst possible value. For asymmetric equilibrium flows, increasing the demand  eventually forces the system into Li-Yorke chaos with positive topological entropy and periodic orbits of all possible periods. Remarkably, in all non-equilibrating regimes, the time-average flows on the paths converge {\\it exactly} to the equilibrium flows, a property akin to no-regret learning in zero-sum games. We extend our results to games with arbitrarily many strategies, polynomial cost functions, non-atomic as well as atomic routing games, and heterogenous users."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoSync", "Title": "Learning to Synchronize for Data-Parallel Distributed Deep Learning", "Abstract": "Synchronization is a key step in data-parallel distributed machine learning (ML). Different synchronization systems and strategies perform differently, and to achieve optimal parallel training throughput requires synchronization strategies that adapt to model structures and cluster configurations. Existing synchronization systems often only consider a single or a few synchronization aspects, and the burden of deciding the right synchronization strategy is then placed on the ML practitioners, who may lack the required expertise. In this paper, we develop a model- and resource-dependent representation for synchronization, which unifies multiple synchronization aspects ranging from architecture, message partitioning, placement scheme, to communication topology. Based on this representation, we build an end-to-end pipeline, AutoSync, to automatically optimize synchronization strategies given model structures and resource specifications, lowering the bar for data-parallel distributed ML. By learning from low-shot data collected in only 200 trial runs, AutoSync can discover synchronization strategies up to 1.6x better than manually optimized ones. We develop transfer-learning mechanisms to further reduce the auto-optimization cost --  the simulators can transfer among similar model architectures, among similar cluster configurations, or both. We also present a dataset that contains over 10000 synchronization strategies and run-time pairs on a diverse set of models and cluster specifications."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Wiener Deconvolution", "Title": "Wiener Meets Deep Learning for Image Deblurring", "Abstract": "We present a simple and effective approach for non-blind image deblurring, combining classical techniques and deep learning. In contrast to existing methods that deblur the image directly in the standard image space, we propose to perform an explicit deconvolution process in a feature space by integrating a classical Wiener deconvolution framework with learned deep features. A multi-scale feature refinement module then predicts the deblurred image from the deconvolved deep features, progressively recovering detail and small-scale structures. The proposed model is trained in an end-to-end manner and evaluated on scenarios with both simulated and real-world image blur. Our extensive experimental results show that the proposed deep Wiener deconvolution network facilitates deblurred results with visibly fewer artifacts. Moreover, our approach quantitatively outperforms state-of-the-art non-blind image deblurring methods by a wide margin."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Asymmetric Shapley values", "Title": "incorporating causal knowledge into model-agnostic explainability", "Abstract": "Explaining AI systems is fundamental both to the development of high performing models and to the trust placed in them by their users. The Shapley framework for explainability has strength in its general applicability combined with its precise, rigorous foundation: it provides a common, model-agnostic language for AI explainability and uniquely satisfies a set of intuitive mathematical axioms. However, Shapley values are too restrictive in one significant regard: they ignore all causal structure in the data. We introduce a less restrictive framework, Asymmetric Shapley values (ASVs), which are rigorously founded on a set of axioms, applicable to any AI system, and can flexibly incorporate any causal structure known to be respected by the data. We demonstrate that ASVs can (i) improve model explanations by incorporating causal information, (ii) provide an unambiguous test for unfair discrimination in model predictions, (iii) enable sequentially incremental explanations in time-series models, and (iv) support feature-selection studies without the need for model retraining."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Detection as Regression", "Title": "Certified Object Detection with Median Smoothing", "Abstract": "Despite the vulnerability of object detectors to adversarial attacks, very few defenses are known to date. While adversarial training can improve the empirical robustness of image classifiers, a direct extension to object detection is very expensive. This work is motivated by recent progress on certified classification by randomized smoothing. We start by presenting a reduction from object detection to a regression problem. Then, to enable certified regression, where standard mean smoothing fails, we propose median smoothing, which is of independent interest. We obtain the first model-agnostic, training-free, and certified defense for object detection against $\\ell_2$-bounded attacks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ExpandNets", "Title": "Linear Over-parameterization to Train Compact Convolutional Networks", "Abstract": "We introduce an approach to training a given compact network. To this end, we leverage over-parameterization, which typically improves both neural network optimization and generalization. Specifically, we propose to expand each linear layer of the compact network into multiple consecutive linear layers, without adding any nonlinearity. As such, the resulting expanded network, or ExpandNet, can be contracted back to the compact one algebraically at inference. In particular, we introduce two convolutional expansion strategies and demonstrate their benefits on several tasks, including image classification, object detection, and semantic segmentation. As evidenced by our experiments, our approach outperforms both training the compact network from scratch and performing knowledge distillation from a teacher. Furthermore, our linear over-parameterization empirically reduces gradient confusion during training and improves the network generalization."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FleXOR", "Title": "Trainable Fractional Quantization", "Abstract": "Quantization based on the binary codes is gaining attention because each quantized bit can be directly utilized for computations without dequantization using look-up tables. Previous attempts, however, only allow for integer numbers of quantization bits, which ends up restricting the search space for compression ratio and accuracy. In this paper, we propose an encryption algorithm/architecture to compress quantized weights so as to achieve fractional numbers of bits per weight. Decryption during inference is implemented by digital XOR-gate networks added into the neural network model while XOR gates are described by utilizing $\\tanh(x)$ for backward propagation to enable gradient calculations. We perform experiments using MNIST, CIFAR-10, and ImageNet to show that inserting XOR gates learns quantization/encrypted bit decisions through training and obtains high accuracy even for fractional sub 1-bit weights. As a result, our proposed method yields smaller size and higher model accuracy compared to binary neural networks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Posterior Network", "Title": "Uncertainty Estimation without OOD Samples via Density-Based Pseudo-Counts", "Abstract": "In this work we propose the Posterior Network (PostNet), which uses Normalizing Flows to predict an individual closed-form posterior distribution over predicted probabilites for any input sample. The posterior distributions learned by PostNet accurately reflect uncertainty for in- and out-of-distribution data -- without requiring access to OOD data at training time. PostNet achieves state-of-the art results in OOD detection and in uncertainty calibration under dataset shifts."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "No-Regret Learning and Mixed Nash Equilibria", "Title": "They Do Not Mix", "Abstract": "Understanding the behavior of no-regret dynamics in general N-player games is\na fundamental question in online learning and game theory. A folk result in the\nfield states that, in finite games, the empirical frequency of play under no-regret\nlearning converges to the game’s set of coarse correlated equilibria. By contrast,\nour understanding of how the day-to-day behavior of the dynamics correlates to the game’s Nash equilibria is much more limited, and only partial results are known\nfor certain classes of games (such as zero-sum or congestion games). In this paper, we study the dynamics of follow the regularized leader (FTRL), arguably the most well-studied class of no-regret dynamics, and we establish a sweeping negative result showing that the notion of mixed Nash equilibrium is antithetical to no-regret learning. Specifically, we show that any Nash equilibrium which is not strict (in that every player has a unique best response) cannot be stable and attracting under the dynamics of FTRL. This result has significant implications for predicting the outcome of a learning process as it shows unequivocally that only strict (and hence, pure) Nash equilibria can emerge as stable limit points thereof."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Continuous Submodular Maximization", "Title": "Beyond DR-Submodularity", "Abstract": "In this paper, we propose the first continuous optimization algorithms that achieve a constant factor approximation guarantee for the problem of monotone continuous submodular maximization subject to a linear constraint. We first prove that a simple variant of the vanilla coordinate ascent, called \\COORDINATE-ASCENT+, achieves a $(\\frac{e-1}{2e-1}-\\eps)$-approximation guarantee while performing $O(n/\\epsilon)$ iterations, where the computational complexity of each iteration is roughly $O(n/\\sqrt{\\epsilon}+n\\log n)$ (here, $n$ denotes the dimension of the optimization problem). We then propose \\COORDINATE-ASCENT++, that achieves the tight $(1-1/e-\\eps)$-approximation guarantee while performing the same number of iterations, but at a higher computational complexity of roughly $O(n^3/\\eps^{2.5} + n^3 \\log n / \\eps^2)$ per iteration. However,   the computation of each round of \\COORDINATE-ASCENT++ can be easily parallelized so that the computational cost per machine scales as $O(n/\\sqrt{\\epsilon}+n\\log n)$."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HiPPO", "Title": "Recurrent Memory with Optimal Polynomial Projections", "Abstract": "A central problem in learning from sequential data is representing cumulative\nhistory in an incremental fashion as more data is processed. We introduce a general framework (HiPPO) for the online compression of continuous signals and discrete time series by projection onto polynomial bases. Given a measure that specifies the importance of each time step in the past, HiPPO produces an optimal solution to a natural online function approximation problem. As special cases, our framework yields a short derivation of the recent Legendre Memory Unit (LMU) from first principles, and generalizes the ubiquitous gating mechanism of recurrent neural networks such as GRUs. This formal framework yields a new memory update mechanism (HiPPO-LegS) that scales through time to remember all history, avoiding priors on the timescale. HiPPO-LegS enjoys the theoretical benefits of timescale robustness, fast updates, and bounded gradients. By incorporating the memory dynamics into recurrent neural networks, HiPPO RNNs can empirically capture complex temporal dependencies. On the benchmark permuted MNIST dataset, HiPPO-LegS sets a new state-of-the-art accuracy of 98.3%. Finally, on a novel trajectory classification task testing robustness to out-of-distribution timescales and missing data, HiPPO-LegS outperforms RNN and neural ODE baselines by 25-40% accuracy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CASTLE", "Title": "Regularization via Auxiliary Causal Graph Discovery", "Abstract": "Regularization improves generalization of supervised models to out-of-sample data. Prior works have shown that prediction in the causal direction (effect from cause) results in lower testing error than the anti-causal direction. However, existing regularization methods are agnostic of causality. We introduce Causal Structure Learning (CASTLE) regularization and propose to regularize a neural network by jointly learning the causal relationships between variables. CASTLE learns the causal directed acyclical graph (DAG) as an adjacency matrix embedded in the neural network's input layers, thereby facilitating the discovery of optimal predictors. Furthermore, CASTLE efficiently reconstructs only the features in the causal DAG that have a causal neighbor, whereas reconstruction-based regularizers suboptimally reconstruct all input features. We provide a theoretical generalization bound for our approach and conduct experiments on a plethora of synthetic and real publicly available datasets demonstrating that CASTLE consistently leads to better out-of-sample predictions as compared to other popular benchmark regularizers."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UnModNet", "Title": "Learning to Unwrap a Modulo Image for High Dynamic Range Imaging", "Abstract": "A conventional camera often suffers from over- or under-exposure when recording a real-world scene with a very high dynamic range (HDR). In contrast, a modulo camera with a Markov random field (MRF) based unwrapping algorithm can theoretically accomplish unbounded dynamic range but shows degenerate performances when there are modulus-intensity ambiguity, strong local contrast, and color misalignment. In this paper, we reformulate the modulo image unwrapping problem into a series of binary labeling problems and propose a modulo edge-aware model, named as UnModNet, to iteratively estimate the binary rollover masks of the modulo image for unwrapping. Experimental results show that our approach can generate 12-bit HDR images from 8-bit modulo images reliably, and runs much faster than the previous MRF-based algorithm thanks to the GPU acceleration."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Thunder", "Title": "a Fast Coordinate Selection Solver for  Sparse Learning", "Abstract": "L1 regularization has been broadly employed to pursue model sparsity. Despite the non-smoothness, people have developed efficient algorithms by leveraging the sparsity and convexity of the problems. In this paper, we propose a novel active incremental approach to further improve the efficiency of the solvers. We show that our method performs well even when the existing methods fail due to the low sparseness or high solution accuracy request. Theoretical analysis and experimental results on synthetic and real-world data sets validate the advantages of the method."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Sinkhorn", "Title": "Optimal Transport distances from sample streams", "Abstract": "Optimal Transport (OT) distances are now routinely used as loss functions in ML tasks. Yet, computing OT distances between arbitrary (i.e. not necessarily discrete) probability distributions remains an open problem. This paper introduces a new online estimator of entropy-regularized OT distances between two such arbitrary distributions. It uses streams of samples from both distributions to iteratively enrich a non-parametric representation of the transportation plan. Compared to the classic Sinkhorn algorithm, our method leverages new samples at each iteration, which enables a consistent estimation of the true regularized OT distance. We provide a theoretical analysis of the convergence of the online Sinkhorn algorithm, showing a nearly-1/n asymptotic sample complexity for the iterate sequence. We validate our method on synthetic 1-d to 10-d data and on real 3-d shape data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gamma-Models", "Title": "Generative Temporal Difference Learning for Infinite-Horizon Prediction", "Abstract": "We introduce the gamma-model, a predictive model of environment dynamics with an infinite, probabilistic horizon. Replacing standard single-step models with gamma-models leads to generalizations of the procedures that form the foundation of model-based control, including the model rollout and model-based value estimation. The gamma-model, trained with a generative reinterpretation of temporal difference learning, is a natural continuous analogue of the successor representation and a hybrid between model-free and model-based mechanisms. Like a value function, it contains information about the long-term future; like a standard predictive model, it is independent of task reward. We instantiate the gamma-model as both a generative adversarial network and normalizing flow, discuss how its training reflects an inescapable tradeoff between training-time and testing-time compounding errors, and empirically investigate its utility for prediction and control."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Mesh Flow", "Title": "3D Manifold Mesh Generation via Diffeomorphic  Flows", "Abstract": "Meshes are important representations of physical 3D entities in the virtual world. Applications like rendering, simulations and 3D printing require meshes to be manifold so that they can interact with the world like the real objects they represent.  Prior methods generate meshes with great geometric accuracy but poor manifoldness. In this work, we propose NeuralMeshFlow (NMF) to generate two-manifold meshes for genus-0 shapes. Specifically, NMF is a shape auto-encoder consisting of several Neural Ordinary Differential Equation (NODE)(1) blocks that learn accurate mesh geometry by progressively deforming a spherical mesh. Training NMF is simpler compared to state-of-the-art methods since it does not require any explicit mesh-based regularization. Our experiments demonstrate that NMF facilitates several applications such as single-view mesh reconstruction, global shape parameterization, texture mapping, shape deformation and correspondence. Importantly, we demonstrate that manifold meshes generated using NMF are better-suited for physically-based rendering and simulation compared to prior works."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Prophet Attention", "Title": "Predicting Attention with Future Attention", "Abstract": "Recently, attention based models have been used extensively in many sequence-to-sequence learning systems. Especially for image captioning, the attention based models are expected to ground correct image regions with proper generated words. However, for each time step in the decoding process, the attention based models usually use the hidden state of the current input to attend to the image regions. Under this setting, these attention models have a deviated focus'' problem that they calculate the attention weights based on previous words instead of the one to be generated, impairing the performance of both grounding and captioning. In this paper, we propose the Prophet Attention, similar to the form of self-supervision. In the training stage, this module utilizes the future information to calculate theideal'' attention weights towards image regions. These calculated ideal'' weights are further used to regularize thedeviated'' attention. In this manner, image regions are grounded with the correct words. The proposed Prophet Attention can be easily incorporated into existing image captioning models to improve their performance of both grounding and captioning. The experiments on the Flickr30k Entities and the MSCOCO datasets show that the proposed Prophet Attention consistently outperforms baselines in both automatic metrics and human evaluations. It is worth noticing that we set new state-of-the-arts on the two benchmark datasets and achieve the 1st place on the leaderboard of the online MSCOCO benchmark in terms of the default ranking score, i.e., CIDEr-c40."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MomentumRNN", "Title": "Integrating Momentum into Recurrent Neural Networks", "Abstract": "Designing deep neural networks is an art that often involves an expensive search over candidate architectures. To overcome this for recurrent neural nets (RNNs), we establish a connection between the hidden state dynamics in an RNN and gradient descent (GD). We then integrate momentum into this framework and propose a new family of RNNs, called {\\em MomentumRNNs}. We theoretically prove and numerically demonstrate that MomentumRNNs alleviate the vanishing gradient issue in training RNNs. We study the momentum long-short term memory (MomentumLSTM) and verify its advantages in convergence speed and accuracy over its LSTM counterpart across a variety of benchmarks. We also demonstrate that MomentumRNN is applicable to many types of recurrent cells, including those in the state-of-the-art orthogonal RNNs. Finally, we show that other advanced momentum-based optimization methods, such as Adam and Nesterov accelerated gradients with a restart, can be easily incorporated into the MomentumRNN framework for designing new recurrent cells with even better performance."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SE(3)-Transformers", "Title": "3D Roto-Translation Equivariant Attention Networks", "Abstract": "We introduce the SE(3)-Transformer, a variant of the self-attention module for 3D point-clouds, which is equivariant under continuous 3D roto-translations. Equivariance is important to ensure stable and predictable performance in the presence of nuisance transformations of the data input. A positive corollary of equivariance is increased weight-tying within the model. The SE(3)-Transformer leverages the benefits of self-attention to operate on large point clouds with varying number of points, while guaranteeing SE(3)-equivariance for robustness. We evaluate our model on a toy N-body particle simulation dataset, showcasing the robustness of the predictions under rotations of the input. We further achieve competitive performance on two real-world datasets, ScanObjectNN and QM9. In all cases, our model outperforms a strong, non-equivariant attention baseline and an equivariant model without attention."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Just Pick a Sign", "Title": "Optimizing Deep Multitask Models with Gradient Sign Dropout", "Abstract": "The vast majority of deep models use multiple gradient signals, typically corresponding to a sum of multiple loss terms, to update a shared set of trainable weights. However, these multiple updates can impede optimal training by pulling the model in conflicting directions. We present Gradient Sign Dropout (GradDrop), a probabilistic masking procedure which samples gradients at an activation layer based on their level of consistency. GradDrop is implemented as a simple deep layer that can be used in any deep net and synergizes with other gradient balancing approaches. We show that GradDrop outperforms the state-of-the-art multiloss methods within traditional multitask and transfer learning settings, and we discuss how GradDrop reveals links between optimal multiloss training and gradient stochasticity."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Black-Box Certification with Randomized Smoothing", "Title": "A Functional Optimization Based Framework", "Abstract": "Randomized classifiers have been shown to provide a promising approach for achieving certified robustness against adversarial attacks in deep learning. However, most existing methods only leverage Gaussian smoothing noise and only work for $\\ell_2$ perturbation. We propose a general framework of adversarial certification with non-Gaussian noise and for more general types of attacks, from a unified \\functional optimization perspective. Our new framework allows us to identify a key trade-off between accuracy and robustness via designing smoothing distributions, helping to design new families of non-Gaussian smoothing distributions that work more efficiently for different $\\ell_p$ settings, including $\\ell_1$, $\\ell_2$ and $\\ell_\\infty$ attacks. Our proposed methods achieve better certification results than previous works and provide a new perspective on randomized smoothing certification."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Falcon", "Title": "Fast Spectral Inference on Encrypted Data", "Abstract": "Homomorphic Encryption (HE) based secure Neural Networks(NNs) inference is one of the most promising security solutions to emerging Machine Learning as a Service (MLaaS). In the HE-based MLaaS setting, a client encrypts the sensitive data, and uploads the encrypted data to the server that directly processes the encrypted data without decryption, and returns the encrypted result to the client. The clients' data privacy is preserved since only the client has the private key. Existing HE-enabled Neural Networks (HENNs), however, suffer from heavy computational overheads. The state-of-the-art HENNs adopt ciphertext packing techniques to reduce homomorphic multiplications by  packing multiple messages into one single ciphertext. Nevertheless, rotations are required in these HENNs to implement the sum of the elements within the same ciphertext. We observed that HENNs have to pay significant computing overhead on rotations, and each of rotations is $\\sim 10\\times$ more expensive than homomorphic multiplications between ciphertext and plaintext. So the massive rotations have become a primary obstacle of efficient HENNs.\n\nIn this paper, we propose a fast, frequency-domain deep neural network called Falcon, for fast inferences on encrypted data. Falcon includes a fast Homomorphic Discrete Fourier Transform (HDFT) using block-circulant matrices to homomorphically support spectral operations. We also propose several efficient methods to reduce inference latency, including Homomorphic Spectral Convolution  and Homomorphic Spectral Fully Connected operations by combing the batched HE and block-circulant matrices. Our experimental results show Falcon achieves the state-of-the-art inference accuracy and reduces the inference latency by $45.45\\%\\sim 85.34\\%$ over prior HENNs on MNIST and CIFAR-10."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Glance and Focus", "Title": "a Dynamic Approach to Reducing Spatial Redundancy in Image Classification", "Abstract": "The accuracy of deep convolutional neural networks (CNNs) generally improves when fueled with high resolution images. However, this often comes at a high computational cost and high memory footprint. Inspired by the fact that not all regions in an image are task-relevant, we propose a novel framework that performs efficient image classification by processing a sequence of relatively small inputs, which are strategically selected from the original image with reinforcement learning. Such a dynamic decision process naturally facilitates adaptive inference at test time, i.e., it can be terminated once the model is sufficiently confident about its prediction and thus avoids further redundant computation. Notably, our framework is general and flexible as it is compatible with most of the state-of-the-art light-weighted CNNs (such as MobileNets, EfficientNets and RegNets), which can be conveniently deployed as the backbone feature extractor. Experiments on ImageNet show that our method consistently improves the computational efficiency of a wide variety of deep models. For example, it further reduces the average latency of the highly efficient MobileNet-V3 on an iPhone XS Max by 20% without sacrificing accuracy. Code and pre-trained models are available at https://github.com/blackfeather-wang/GFNet-Pytorch."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attention-Gated Brain Propagation", "Title": "How the brain can implement reward-based error backpropagation", "Abstract": "Much recent work has focused on biologically plausible variants of supervised learning algorithms. However, there is no teacher in the motor cortex that instructs the motor neurons and learning in the brain depends on reward and punishment. We demonstrate a biologically plausible reinforcement learning scheme for deep networks with an arbitrary number of layers. The network chooses an action by selecting a unit in the output layer and uses feedback connections to assign credit to the units in successively lower layers that are responsible for this action. After the choice, the network receives reinforcement and there is no teacher correcting the errors. We show how the new learning scheme – Attention-Gated Brain Propagation (BrainProp) – is mathematically equivalent to error backpropagation, for one output unit at a time. We demonstrate successful learning of deep fully connected, convolutional and locally connected networks on classical and hard image-classification benchmarks; MNIST, CIFAR10, CIFAR100 and Tiny ImageNet. BrainProp achieves an accuracy that is equivalent to that of standard error-backpropagation, and better than state-of-the-art biologically inspired learning schemes. The trial-and-error nature of learning is associated with limited additional training time so that BrainProp is a factor of 1-3.5 times slower. Our results thereby provide new insights into how deep learning may be implemented in the brain."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PRANK", "Title": "motion Prediction based on RANKing", "Abstract": "Predicting the motion of agents such as pedestrians or human-driven vehicles is one of the most critical problems in the autonomous driving domain. The overall safety of driving and the comfort of a passenger directly depend on its successful solution. The motion prediction problem also remains one of the most challenging problems in autonomous driving engineering, mainly due to high variance of the possible agent’s future behavior given a situation. The two phenomena responsible for the said variance are the multimodality caused by the uncertainty of the agent’s intent (e.g., turn right or move forward) and uncertainty in the realization of a given intent (e.g., which lane to turn into). To be useful within a real-time autonomous driving pipeline, a motion prediction system must provide efficient ways to describe and quantify this uncertainty, such as computing posterior modes and their probabilities or estimating density at the point corresponding to a given trajectory. It also should not put substantial density on physically impossible trajectories, as they can confuse the system processing the predictions. In this paper, we introduce the PRANK method, which satisfies these requirements. PRANK takes rasterized bird-eye images of agent’s surroundings as an input and extracts features of the scene with a convolutional neural network. It then produces the conditional distribution of agent’s trajectories plausible in the given scene. The key contribution of PRANK is a way to represent that distribution using nearest-neighbor methods in latent trajectory space, which allows for efficient inference in real time. We evaluate PRANK on the in-house and Argoverse datasets, where it shows competitive results."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimal Lottery Tickets via Subset Sum", "Title": "Logarithmic Over-Parameterization is Sufficient", "Abstract": "The strong lottery ticket hypothesis (LTH) postulates that one can approximate any target neural network by only pruning the weights of a sufficiently over-parameterized random network.  A recent work by Malach et al. [MYSS20] establishes the first theoretical analysis for the strong LTH: one can provably approximate a neural network of width $d$ and depth $l$, by pruning a random one that is a factor $O(d^4 l^2)$ wider and twice as deep. This polynomial over-parameterization requirement is at odds with recent experimental research that achieves good approximation with networks that are a small factor wider than the target. In this work, we close the gap and offer an exponential improvement to the over-parameterization requirement for the existence of lottery tickets. We show that any target network of width $d$ and depth $l$ can be approximated by pruning a random network that is a factor $O(log(dl))$ wider and twice as deep.  Our analysis heavily relies on connecting pruning random ReLU networks to random instances of the Subset Sum problem. We then show that this logarithmic over-parameterization is essentially optimal for constant depth networks. Finally, we verify several of our theoretical insights with experiments."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Hateful Memes Challenge", "Title": "Detecting Hate Speech in Multimodal Memes", "Abstract": "This work proposes a new challenge set for multimodal classification, focusing on\ndetecting hate speech in multimodal memes. It is constructed such that unimodal\nmodels struggle and only multimodal models can succeed: difficult examples\n(“benign confounders”) are added to the dataset to make it hard to rely on unimodal\nsignals. The task requires subtle reasoning, yet is straightforward to evaluate\nas a binary classification problem. We provide baseline performance numbers\nfor unimodal models, as well as for multimodal models with various degrees of\nsophistication. We find that state-of-the-art methods perform poorly compared to\nhumans, illustrating the difficulty of the task and highlighting the challenge that this important problem poses to the community."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochasticity of Deterministic Gradient Descent", "Title": "Large Learning Rate for Multiscale Objective Function", "Abstract": "This article suggests that deterministic Gradient Descent, which does not use any stochastic gradient approximation, can still exhibit stochastic behaviors. In particular, it shows that if the objective function exhibit multiscale behaviors, then in a large learning rate regime which only resolves the macroscopic but not the microscopic details of the objective, the deterministic GD dynamics can become chaotic and convergent not to a local minimizer but to a statistical distribution. In this sense, deterministic GD resembles stochastic GD even though no stochasticity is injected. A sufficient condition is also established for approximating this long-time statistical limit by a rescaled Gibbs distribution, which for example allows escapes from local minima to be quantified. Both theoretical and numerical demonstrations are provided, and the theoretical part relies on the construction of a stochastic map that uses bounded noise (as opposed to Gaussian noise)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Gradient Descent in Correlated Settings", "Title": "A Study on Gaussian Processes", "Abstract": "Stochastic gradient descent (SGD) and its variants have established themselves as the go-to algorithms for large-scale machine learning problems with independent samples due to their generalization performance and intrinsic computational advantage. However, the fact that the stochastic gradient is a biased estimator of the full gradient with correlated samples has led to the lack of theoretical understanding of how SGD behaves under correlated settings and hindered its use in such cases. In this paper, we focus on the Gaussian process (GP) and take a step forward towards breaking the barrier by proving minibatch SGD converges to a critical point of the full loss function, and recovers model hyperparameters with rate $O(\\frac{1}{K})$ up to a statistical error term depending on the minibatch size. Numerical studies on both simulated and real datasets demonstrate that minibatch SGD has better generalization over state-of-the-art GP methods while reducing the computational burden and opening a new, previously unexplored, data size regime for GPs."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ShiftAddNet", "Title": "A Hardware-Inspired Deep Network", "Abstract": "Multiplication (e.g., convolution) is arguably a cornerstone of modern deep neural networks (DNNs). However, intensive multiplications cause expensive resource costs that challenge DNNs' deployment on resource-constrained edge devices, driving several attempts for multiplication-less deep networks. This paper presented ShiftAddNet, whose main inspiration is drawn from a common practice in energy-efficient hardware implementation, that is,  multiplication can be instead performed with additions and logical bit-shifts. We leverage this idea to explicitly parameterize deep networks in this way, yielding a new type of deep network that involves only bit-shift and additive weight layers. This hardware-inspired ShiftAddNet immediately leads to both energy-efficient inference and training, without compromising the expressive capacity compared to standard DNNs. The two complementary operation types (bit-shift and add) additionally enable finer-grained control of the model's learning capacity, leading to more flexible trade-off between accuracy and (training) efficiency, as well as improved robustness to quantization and pruning. We conduct extensive experiments and ablation studies, all backed up by our FPGA-based ShiftAddNet implementation and energy measurements. Compared to existing DNNs or other multiplication-less models, ShiftAddNet aggressively reduces over 80% hardware-quantified energy cost of DNNs training and inference, while offering comparable or better accuracies. Codes and pre-trained models are available at https://github.com/RICE-EIC/ShiftAddNet."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A/B Testing in Dense Large-Scale Networks", "Title": "Design and Inference", "Abstract": "Design of experiments and estimation of treatment effects in large-scale networks, in the presence of strong interference, is a challenging and important problem. Most existing methods' performance deteriorates as the density of the network increases. In this paper, we present a novel strategy for accurately estimating the causal effects of a class of treatments in a dense large-scale network. First, we design an approximate randomized controlled experiment by solving an optimization problem to allocate treatments in the presence of competition among neighboring nodes. Then we apply an importance sampling adjustment to correct for any leftover bias (from the approximation) in estimating average treatment effects. We provide theoretical guarantees, verify robustness in a simulation study, and validate the scalability and usefulness of our procedure in a real-world experiment on a large social network."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "What Neural Networks Memorize and Why", "Title": "Discovering the Long Tail via Influence Estimation", "Abstract": "In this work we design experiments to test the key ideas in this theory. The experiments require\nestimation of the influence of each training example on the accuracy at each test example as well as memorization values of training examples. Estimating these quantities directly is computationally prohibitive but we show that closely-related subsampled influence and memorization values can be estimated much more efficiently. Our experiments demonstrate the significant benefits of memorization for generalization on several standard benchmarks. They also provide quantitative and visually compelling evidence for the theory put forth in Feldman (2019)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Triple descent and the two kinds of overfitting", "Title": "where & why do they appear?", "Abstract": "A recent line of research has highlighted the existence of a ``double descent'' phenomenon in deep learning, whereby increasing the number of training examples N causes the generalization error of neural networks to peak when N is of the same order as the number of parameters P. In earlier works, a similar phenomenon was shown to exist in simpler models such as linear regression, where the peak instead occurs when N is equal to the input dimension D. Since both peaks coincide with the interpolation threshold, they are often conflated in the litterature. In this paper, we show that despite their apparent similarity, these two scenarios are inherently different. In fact, both peaks can co-exist when neural networks are applied to noisy regression tasks. The relative size of the peaks is then governed by the degree of nonlinearity of the activation function. Building on recent developments in the analysis of random feature models, we provide a theoretical ground for this sample-wise triple descent. As shown previously, the nonlinear peak at N=P is a true divergence caused by the extreme sensitivity of the output function to both the noise corrupting the labels and the initialization of the random features (or the weights in neural networks). This peak survives in the absence of noise, but can be suppressed by regularization. In contrast, the linear peak at N=D is solely due to overfitting the noise in the labels, and forms earlier during training. We show that this peak is implicitly regularized by the nonlinearity, which is why it only becomes salient at high noise and is weakly affected by explicit regularization.\nThroughout the paper, we compare the analytical results obtained in the random feature model with the outcomes of numerical experiments involving realistic neural networks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-label classification", "Title": "do Hamming loss and subset accuracy really conflict with each other?", "Abstract": "Various evaluation measures have been developed for multi-label classification, including Hamming Loss (HL), Subset Accuracy (SA) and Ranking Loss (RL). However, there is a gap between empirical results and the existing theories: 1) an algorithm often empirically performs well on some measure(s) while poorly on others, while a formal theoretical analysis is lacking; and 2) in small label space cases, the algorithms optimizing HL often have comparable or even better performance on the SA measure than those optimizing SA directly, while existing theoretical results show that SA and HL are conflicting measures. This paper provides an attempt to fill up this gap by analyzing the learning guarantees of the corresponding learning algorithms on both SA and HL measures. We show that when a learning algorithm optimizes HL with its surrogate loss, it enjoys an error bound for the HL measure independent of $c$ (the number of labels), while the bound for the SA measure depends on at most $O(c)$. On the other hand, when directly optimizing SA with its surrogate loss, it has learning guarantees that depend on $O(\\sqrt{c})$ for both HL and SA measures. This explains the observation that when the label space is not large, optimizing HL with its surrogate loss can have promising performance for SA. We further show that our techniques are applicable to analyze the learning guarantees of algorithms on other measures, such as RL. Finally, the theoretical analyses are supported by experimental results."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Removing Bias in Multi-modal Classifiers", "Title": "Regularization by Maximizing Functional Entropies", "Abstract": "Many recent datasets contain a variety of different data modalities, for instance, image, question, and answer data in visual question answering (VQA). When training deep net classifiers on those multi-modal datasets, the modalities get exploited at different scales, i.e., some modalities can more easily contribute to the classification results than others. This is suboptimal because the classifier is inherently biased towards a subset of the modalities. To alleviate this shortcoming, we propose a novel regularization term based on the functional entropy. Intuitively, this term encourages to balance the contribution of each modality to the classification result. However, regularization with the functional entropy is challenging. To address this, we develop a method based on the log-Sobolev inequality, which bounds the functional entropy with the functional-Fisher-information. Intuitively, this maximizes the amount of information that the modalities contribute. On the two challenging multi-modal datasets VQA-CPv2, and SocialIQ, we obtain state-of-the-art results while more uniformly exploiting the modalities. In addition, we demonstrate the efficacy of our method on Colored MNIST."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust-Adaptive Control of Linear Systems", "Title": "beyond Quadratic Costs", "Abstract": "We consider the problem of robust and adaptive model predictive control (MPC) of a linear system, with unknown parameters that are learned along the way (adaptive), in a critical setting where failures must be prevented (robust). This problem has been studied from different perspectives by different communities. However, the existing theory deals only with the case of quadratic costs (the LQ problem), which limits applications to stabilisation and tracking tasks only. In order to handle more general (non-convex) costs that naturally arise in many practical problems, we carefully select and bring together several tools from different communities, namely non-asymptotic linear regression, recent results in interval prediction, and tree-based planning. Combining and adapting the theoretical guarantees at each layer is non trivial, and we provide the first end-to-end suboptimality analysis for this setting. Interestingly, our analysis naturally adapts to handle many models and combines with a data-driven robust model selection strategy, which enables to relax the modelling assumptions. Last, we strive to preserve tractability at any stage of the method, that we illustrate on two challenging simulated environments."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UCLID-Net", "Title": "Single View Reconstruction in Object Space", "Abstract": "We demonstrate both on ShapeNet synthetic images, which are often used for benchmarking purposes, and on real-world images that our approach outperforms state-of-the-art ones. Furthermore, the single-view pipeline naturally extends to multi-view reconstruction, which we also show."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Complex Dynamics in Simple Neural Networks", "Title": "Understanding Gradient Flow in Phase Retrieval", "Abstract": "Despite the widespread use of gradient-based algorithms for optimising high-dimensional non-convex functions, understanding their ability of finding good minima instead of being trapped in spurious ones remains to a large extent an open problem. Here we focus on gradient flow dynamics for phase retrieval from random measurements. When the ratio of the number of measurements over the input dimension is small the dynamics remains trapped in spurious minima with large basins of attraction. We find analytically that above a critical ratio those critical points become unstable developing a negative direction toward the signal. By numerical experiments we show that in this regime the gradient flow algorithm is not trapped; it drifts away from the spurious critical points along the unstable direction and succeeds in finding the global minimum. Using tools from statistical physics we characterise this phenomenon, which is related to a BBP-type transition in the Hessian of the spurious minima."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Audeo", "Title": "Audio Generation for a Silent Performance Video", "Abstract": "We present a novel system that gets as an input, video frames of a musician playing the piano, and generates the music for that video. The generation of music from visual cues is a challenging problem and it is not clear whether it is an attainable goal at all. Our main aim in this work is to explore the plausibility of such a transformation and to identify cues and components able to carry the association of sounds with visual events. To achieve the transformation we built a full pipeline named 'Audeo' containing three components. We first translate the video frames of the keyboard and the musician hand movements into raw mechanical musical symbolic representation Piano-Roll (Roll) for each video frame which represents the keys pressed at each time step. We then adapt the Roll to be amenable for audio synthesis by including temporal correlations. This step turns out to be critical for meaningful audio generation. In the last step, we implement Midi synthesizers to generate realistic music. Audeo converts video to audio smoothly and clearly with only a few setup constraints. We evaluate Audeo on piano performance videos collected from Youtube and obtain that their generated music is of reasonable audio quality and can be successfully recognized with high precision by popular music identification software."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Demystifying Contrastive Self-Supervised Learning", "Title": "Invariances, Augmentations and Dataset Biases", "Abstract": "Self-supervised representation learning approaches have recently surpassed their supervised learning counterparts on downstream tasks like object detection and image classification. Somewhat mysteriously the recent gains in performance come from training instance classification models, treating each image and it's augmented versions as samples of a single class. In this work, we first present quantitative experiments to demystify these gains. We demonstrate that approaches  like MOCO and PIRL learn occlusion-invariant representations. However, they fail to capture viewpoint and category instance invariance which are crucial components for object recognition. Second, we demonstrate that these approaches obtain further gains from access to a clean object-centric training dataset like Imagenet. Finally, we propose an approach to leverage unstructured videos to learn representations that possess higher viewpoint invariance. Our results show that the learned representations outperform MOCOv2 trained on the same data in terms of invariances encoded and the performance on downstream image classification and semantic segmentation tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Minimax Regret of Switching-Constrained Online Convex Optimization", "Title": "No Phase Transition", "Abstract": "We study the problem of switching-constrained online convex optimization (OCO), where the player has a limited number of opportunities to change her action. While the discrete analog of this online learning task has been studied extensively, previous work in the continuous setting has neither established the minimax rate nor algorithmically achieved it. In this paper, we show that $ T $-round switching-constrained OCO with fewer than $ K $ switches has a minimax regret of $ \\Theta(\\frac{T}{\\sqrt{K}}) $. In particular, it is at least $ \\frac{T}{\\sqrt{2K}} $ for one dimension and at least $ \\frac{T}{\\sqrt{K}} $ for higher dimensions. The lower bound in higher dimensions is attained by an orthogonal subspace argument. In one dimension, a novel adversarial strategy yields the lower bound of $O(\\frac{T}{\\sqrt{K}})$, but a precise minimax analysis including constants is more involved. To establish the tighter one-dimensional result, we introduce the \\emph{fugal game} relaxation, whose minimax regret lower bounds that of switching-constrained OCO. We show that the minimax regret of the fugal game is at least $ \\frac{T}{\\sqrt{2K}} $ and thereby establish the optimal minimax lower bound in one dimension. To establish the dimension-independent upper bound, we next show that a mini-batching algorithm provides an $ O(\\frac{T}{\\sqrt{K}}) $ upper bound, and therefore conclude that the minimax regret of switching-constrained OCO is $ \\Theta(\\frac{T}{\\sqrt{K}}) $ for any $K$. This is in sharp contrast to its discrete counterpart, the switching-constrained prediction-from-experts problem, which exhibits a phase transition in minimax regret between the low-switching and high-switching regimes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dual Manifold Adversarial Robustness", "Title": "Defense against Lp and non-Lp Adversarial Attacks", "Abstract": "Adversarial training is a popular defense strategy against attack threat models with bounded Lp norms. However, it often degrades the model performance on normal images and more importantly, the defense does not generalize well to novel attacks. Given the success of deep generative models such as GANs and VAEs in characterizing the underlying manifold of images, we investigate whether or not the aforementioned deficiencies of adversarial training can be remedied by exploiting the underlying manifold information. To partially answer this question, we consider the scenario when the manifold information of the underlying data is available. We use a subset of ImageNet natural images where an approximate underlying manifold is learned using StyleGAN. We also construct an ``On-Manifold ImageNet'' (OM-ImageNet) dataset by projecting the ImageNet samples onto the learned manifold. For OM-ImageNet, the underlying manifold information is exact. Using OM-ImageNet, we first show that on-manifold adversarial training improves both standard accuracy and robustness to on-manifold attacks. However, since no out-of-manifold perturbations are realized, the defense can be broken by Lp adversarial attacks. We further propose Dual Manifold Adversarial Training (DMAT) where adversarial perturbations in both latent and image spaces are used in robustifying the model. Our DMAT improves performance on normal images, and achieves comparable robustness to the standard adversarial training against Lp attacks. In addition, we observe that models defended by DMAT achieve improved robustness against novel attacks which manipulate images by global color shifts or various types of image filtering. Interestingly, similar improvements are also achieved when the defended models are tested on (out-of-manifold) natural images. These results demonstrate the potential benefits of using manifold information in enhancing robustness of deep learning models against various types of novel adversarial attacks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Personalized Federated Learning with Theoretical Guarantees", "Title": "A Model-Agnostic Meta-Learning Approach", "Abstract": "In Federated Learning, we aim to train models across multiple computing units (users), while users can only communicate with a common central server, without exchanging their data samples. This mechanism exploits the computational power of all users and allows users to obtain a richer model as their models are trained over a larger set of data points. However, this scheme only develops a common output for all the users, and, therefore, it does not adapt the model to each user. This is an important missing feature, especially given the heterogeneity of the underlying data distribution for various users. In this paper, we study a personalized variant of the federated learning in which our goal is to find an initial shared model that current or new users can easily adapt to their local dataset by performing one or a few steps of gradient descent with respect to their own data. This approach keeps all the benefits of the federated learning architecture, and, by structure, leads to a more personalized model for each user. We show this problem can be studied within the Model-Agnostic Meta-Learning (MAML) framework. Inspired by this connection, we study a personalized variant of the well-known Federated Averaging algorithm and evaluate its performance in terms of gradient norm for non-convex loss functions. Further, we characterize how this performance is affected by the closeness of underlying distributions of user data, measured in terms of distribution distances such as Total Variation and 1-Wasserstein metric."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pixel-Level Cycle Association", "Title": "A New Perspective for Domain Adaptive Semantic Segmentation", "Abstract": "Domain adaptive semantic segmentation aims to train a model performing satisfactory pixel-level predictions on the target with only out-of-domain (source) annotations. The conventional solution to this task is to minimize the discrepancy between source and target to enable effective knowledge transfer. Previous domain discrepancy minimization methods are mainly based on the adversarial training. They tend to consider the domain discrepancy globally, which ignore the pixel-wise relationships and are less discriminative. In this paper, we propose to build the pixel-level cycle association between source and target pixel pairs and contrastively strengthen their connections to diminish the domain gap and make the features more discriminative. To the best of our knowledge, this is a new perspective for tackling such a challenging task. Experiment results on two representative domain adaptation benchmarks, i.e. GTAV $\\rightarrow$ Cityscapes and SYNTHIA $\\rightarrow$ Cityscapes, verify the effectiveness of our proposed method and demonstrate that our method performs favorably against previous state-of-the-arts. Our method can be trained end-to-end in one stage and introduce no additional parameters, which is expected to serve as a general framework and help ease future research in domain adaptive semantic segmentation. Code is available at https://github.com/kgl-prml/Pixel-Level-Cycle-Association."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distribution-free binary classification", "Title": "prediction sets, confidence intervals and calibration", "Abstract": "We study three notions of uncertainty quantification---calibration, confidence intervals and prediction sets---for binary classification in the distribution-free setting, that is without making any distributional assumptions on the data. With a focus towards calibration, we establish a 'tripod' of theorems that connect these three notions for score-based classifiers. A direct implication is that distribution-free calibration is only possible, even asymptotically, using a scoring function whose level sets partition the feature space into at most countably many sets. Parametric calibration schemes such as variants of Platt scaling do not satisfy this requirement, while nonparametric schemes based on binning do. To close the loop, we derive distribution-free confidence intervals for binned probabilities for both fixed-width and uniform-mass binning. As a consequence of our 'tripod' theorems, these confidence intervals for binned probabilities lead to distribution-free calibration. We also derive extensions to settings with streaming data and covariate shift."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Closing the Dequantization Gap", "Title": "PixelCNN as a Single-Layer Flow", "Abstract": "Flow models have recently made great progress at modeling ordinal discrete data such as images and audio. Due to the continuous nature of flow models, dequantization is typically applied when using them for such discrete data, resulting in lower bound estimates of the likelihood. In this paper, we introduce subset flows, a class of flows that can tractably transform finite volumes and thus allow exact computation of likelihoods for discrete data. Based on subset flows, we identify ordinal discrete autoregressive models, including WaveNets, PixelCNNs and Transformers, as single-layer flows. We use the flow formulation to compare models trained and evaluated with either the exact likelihood or its dequantization lower bound. Finally, we study multilayer flows composed of PixelCNNs and non-autoregressive coupling layers and demonstrate state-of-the-art results on CIFAR-10 for flow models trained with dequantization."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CodeCMR", "Title": "Cross-Modal Retrieval For Function-Level Binary Source Code Matching", "Abstract": "Binary source code matching, especially on function-level, has a critical role in the field of computer security. Given binary code only, finding the corresponding source code improves the accuracy and efficiency in reverse engineering. Given source code only, related binary code retrieval contributes to known vulnerabilities confirmation. However, due to the vast difference between source and binary code, few studies have investigated binary source code matching. Previously published studies focus on code literals extraction such as strings and integers, then utilize traditional matching algorithms such as the Hungarian algorithm for code matching. Nevertheless, these methods have limitations on function-level, because they ignore the potential semantic features of code and a lot of code lacks sufficient code literals. Also, these methods indicate a need for expert experience for useful feature identification and feature engineering, which is timeconsuming. This paper proposes an end-to-end cross-modal retrieval network for binary source code matching, which achieves higher accuracy and requires less expert experience. We adopt Deep Pyramid Convolutional Neural Network (DPCNN) for source code feature extraction and Graph Neural Network (GNN) for binary code feature extraction. We also exploit neural network-based models to capture code literals, including strings and integers. Furthermore, we implement \"norm weighted sampling\" for negative sampling. We evaluate our model on two datasets, where it outperforms other methods significantly."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DAGs with No Fears", "Title": "A Closer Look at Continuous Optimization for Learning Bayesian Networks", "Abstract": "This paper re-examines a continuous optimization framework dubbed NOTEARS for learning Bayesian networks. We first generalize existing algebraic characterizations of acyclicity to a class of matrix polynomials. Next, focusing on a one-parameter-per-edge setting, it is shown that the Karush-Kuhn-Tucker (KKT) optimality conditions for the NOTEARS formulation cannot be satisfied except in a trivial case, which explains a behavior of the associated algorithm. We then derive the KKT conditions for an equivalent reformulation, show that they are indeed necessary, and relate them to explicit constraints that certain edges be absent from the graph. If the score function is convex, these KKT conditions are also sufficient for local minimality despite the non-convexity of the constraint. Informed by the KKT conditions, a local search post-processing algorithm is proposed and shown to substantially and universally improve the structural Hamming distance of all tested algorithms, typically by a factor of 2 or more. Some combinations with local search are both more accurate and more efficient than the original NOTEARS."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OOD-MAML", "Title": "Meta-Learning for Few-Shot Out-of-Distribution Detection and Classification", "Abstract": "We propose a few-shot learning method for detecting out-of-distribution (OOD) samples from classes that are unseen during training while classifying samples from seen classes using only a few labeled examples. For detecting unseen classes while generalizing to new samples of known classes, we synthesize fake samples, i.e., OOD samples, but that resemble in-distribution samples, and use them along with real samples. Our approach is based on an extension of model-agnostic meta learning (MAML) and is denoted as OOD-MAML, which not only learns a model initialization but also the initial fake samples across tasks. The learned initial fake samples can be used to quickly adapt to new tasks to form task-specific fake samples with only one or a few gradient update steps using MAML. For testing, OOD-MAML converts a K-shot N-way classification\ntask into N sub-tasks of K-shot OOD detection with respect to each class. The joint analysis of N sub-tasks facilitates simultaneous classification and OOD detection and, furthermore, offers an advantage, in that it does not require re-training when the number of classes for a test task differs from that for training tasks; it is sufficient to simply assume as many sub-tasks as the number of classes for the test task. We also demonstrate the effective performance of OOD-MAML over benchmark datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Differentially Private Clustering", "Title": "Tight Approximation Ratios", "Abstract": "Our results also imply an improved algorithm for the Sample and Aggregate privacy framework. Furthermore, we show that one of the tools used in our 1-Cluster algorithm can be employed to get a faster quantum algorithm for ClosestPair in a moderate number of dimensions."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AttendLight", "Title": "Universal Attention-Based Reinforcement Learning Model for Traffic Signal Control", "Abstract": "We propose AttendLight, an end-to-end Reinforcement Learning (RL) algorithm for the problem of traffic signal control. Previous approaches for this problem have the shortcoming that they require training for each new intersection with a different structure or traffic flow distribution. AttendLight solves this issue by training a single, universal model for intersections with any number of roads, lanes, phases (possible signals), and traffic flow. To this end, we propose a deep RL model which incorporates two attention models. The first attention model is introduced to  handle different numbers of roads-lanes; and the second attention model is intended for enabling decision-making with any number of phases in an intersection. As a result, our proposed model works for any intersection configuration, as long as a similar configuration is represented in the training set. \nExperiments were conducted with both synthetic and real-world standard benchmark datasets. Our numerical experiment covers intersections with three or four approaching roads; one-directional/bi-directional roads with one, two, and three lanes; different number of phases; and different traffic flows. We consider two regimes: (i) single-environment training, single-deployment, and (ii) multi-environment training, multi-deployment. AttendLight outperforms both classical and other RL-based approaches on all cases in both regimes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Predictions to Decisions", "Title": "Using Lookahead Regularization", "Abstract": "Machine learning is a powerful tool for predicting human-related outcomes, from creditworthiness to heart attack risks. But when deployed transparently,  learned models also affect how users act in order to improve outcomes.  The standard approach to learning predictive models is agnostic to induced user actions and provides no guarantees as to the effect of actions.  We provide a framework for learning predictors that are accurate, while also considering interactions between the learned model and user decisions. For this, we introduce look-ahead regularization which, by anticipating user actions, encourages predictive models to also induce actions that improve outcomes. This regularization carefully tailors the uncertainty estimates that govern confidence in this improvement to the distribution of model-induced actions. We report the results of experiments on real and synthetic data that show the effectiveness of this approach."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MDP Homomorphic Networks", "Title": "Group Symmetries in Reinforcement Learning", "Abstract": "This paper introduces MDP homomorphic networks for deep reinforcement learning. MDP homomorphic networks are neural networks that are equivariant under symmetries in the joint state-action space of an MDP. Current approaches to deep reinforcement learning do not usually exploit knowledge about such structure. By building this prior knowledge into policy and value networks using an equivariance constraint, we can reduce the size of the solution space. We specifically focus on group-structured symmetries (invertible transformations). Additionally, we introduce an easy method for constructing equivariant network layers numerically, so the system designer need not solve the constraints by hand, as is typically done. We construct MDP homomorphic MLPs and CNNs that are equivariant under either a group of reflections or rotations. We show that such networks converge faster than unstructured baselines on CartPole, a grid world and Pong."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Funnel-Transformer", "Title": "Filtering out Sequential Redundancy for Efficient Language Processing", "Abstract": "With the success of language pretraining, it is highly desirable to develop more efficient architectures of good scalability that can exploit the abundant unlabeled data at a lower cost.\nTo improve the efficiency, we examine the much-overlooked redundancy in maintaining a full-length token-level presentation, especially for tasks that only require a single-vector presentation of the sequence.\nWith this intuition, we propose Funnel-Transformer which gradually compresses the sequence of hidden states to a shorter one and hence reduces the computation cost.\nMore importantly, by re-investing the saved FLOPs from length reduction in constructing a deeper or wider model, we further improve the model capacity.\nIn addition, to perform token-level predictions as required by common pretraining objectives, Funnel-Transformer is able to recover a deep representation for each token from the reduced hidden sequence via a decoder.\nEmpirically, with comparable or fewer FLOPs, Funnel-Transformer outperforms the standard Transformer on a wide variety of sequence-level prediction tasks, including text classification, language understanding, and reading comprehension."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SuperLoss", "Title": "A Generic Loss for Robust Curriculum Learning", "Abstract": "Curriculum learning is a technique to improve a model performance and generalization based on the idea that easy samples should be presented before difficult ones during training. While it is generally complex to estimate a priori the difficulty of a given sample, recent works have shown that curriculum learning can be formulated dynamically in a self-supervised manner. The key idea is to somehow estimate the importance (or weight) of each sample directly during training based on the observation that easy and hard samples behave differently and can therefore be separated. However, these approaches are usually limited to a specific task (e.g., classification) and require extra data annotations, layers or parameters as well as a dedicated training procedure. We propose instead a simple and generic method that can be applied to a variety of losses and tasks without any change in the learning procedure. It consists in appending a novel loss function on top of any existing task loss, hence its name: the SuperLoss. Its main effect is to automatically downweight the contribution of samples with a large loss, i.e. hard samples, effectively mimicking the core principle of curriculum learning. As a side effect, we show that our loss prevents the memorization of noisy samples, making it possible to train from noisy data even with non-robust loss functions. Experimental results on image classification, regression, object detection and image retrieval demonstrate consistent gain, particularly in the presence of noise."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CogMol", "Title": "Target-Specific and Selective Drug Design for COVID-19 Using Deep Generative Models", "Abstract": "The novel nature of SARS-CoV-2 calls for the development of efficient de novo drug design approaches. In this study, we propose an end-to-end framework, named CogMol (Controlled Generation of Molecules), for designing new drug-like small molecules targeting novel viral proteins with high affinity and off-target selectivity. CogMol combines adaptive pre-training of a molecular SMILES Variational Autoencoder (VAE) and an efficient multi-attribute controlled sampling scheme that uses guidance from attribute predictors trained on latent features. To generate novel and optimal drug-like molecules for unseen viral targets, CogMol leverages a protein-molecule binding affinity predictor that is trained using SMILES VAE embeddings and protein sequence embeddings learned unsupervised from a large corpus.\nWe applied the CogMol framework to three SARS-CoV-2 target proteins: main protease, receptor-binding domain of the spike protein, and non-structural protein 9 replicase. The generated candidates are novel at both the molecular and chemical scaffold levels when compared to the training data. CogMol also includes insilico screening for assessing  toxicity of parent molecules and their metabolites with a multi-task toxicity classifier, synthetic feasibility with a chemical retrosynthesis predictor, and target structure binding with docking simulations.\nDocking reveals favorable binding of generated molecules to the target protein structure, where 87--95\\% of high affinity molecules showed docking free energy $<$ -6 kcal/mol. When compared to approved drugs, the majority of designed compounds show low predicted parent molecule and metabolite toxicity and high predicted synthetic feasibility. In summary, CogMol can handle multi-constraint design of synthesizable, low-toxic, drug-like molecules with high target specificity and selectivity, even to novel protein target sequences, and does not need target-dependent fine-tuning of the framework or target structure information."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Liberty or Depth", "Title": "Deep Bayesian Neural Nets Do Not Need Complex Weight Posterior Approximations", "Abstract": "We challenge the longstanding assumption that the mean-field approximation for variational inference in Bayesian neural networks is severely restrictive, and show this is not the case in deep networks.  We prove several results indicating that deep mean-field variational weight posteriors can induce similar distributions in function-space to those induced by shallower networks with complex weight posteriors.  We validate our theoretical contributions empirically, both through examination of the weight posterior using Hamiltonian Monte Carlo in small models and by comparing diagonal- to structured-covariance in large settings.  Since complex variational posteriors are often expensive and cumbersome to implement, our results suggest that using mean-field variational inference in a deeper model is both a practical and theoretically justified alternative to structured approximations."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reward-rational (implicit) choice", "Title": "A unifying formalism for reward learning", "Abstract": "It is often difficult to hand-specify what the correct reward function is for a task, so researchers have instead aimed to learn reward functions from human behavior or feedback. The types of behavior interpreted as evidence of the reward function have expanded greatly in recent years. We've gone from demonstrations, to comparisons, to reading into the information leaked when the human is pushing the robot away or turning it off. And surely, there is more to come. How will a robot make sense of all these diverse types of behavior? Our key observation is that different types of behavior can be interpreted in a single unifying formalism - as a reward-rational choice that the human is making, often implicitly. We use this formalism to survey prior work through a unifying lens, and discuss its potential use as a recipe for interpreting new sources of information that are yet to be uncovered."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distance Encoding", "Title": "Design Provably More Powerful Neural Networks for Graph Representation Learning", "Abstract": "Learning representations of sets of nodes in a graph is crucial for applications ranging from node-role discovery to link prediction and molecule classification. Graph Neural Networks (GNNs) have achieved great success in graph representation learning. However, expressive power of GNNs is limited by the 1-Weisfeiler-Lehman (WL) test and thus GNNs generate identical representations for graph substructures that may in fact be very different. More powerful GNNs, proposed recently by mimicking higher-order-WL tests, only focus on representing entire graphs and they are computationally inefficient as they cannot utilize sparsity of the underlying graph. Here we propose and mathematically analyze a general class of structure-related features, termed Distance Encoding (DE). DE assists GNNs in representing any set of nodes, while providing strictly more expressive power than the 1-WL test. DE captures the distance between the node set whose representation is to be learned and each node in the graph. To capture the distance DE can apply various graph-distance measures such as shortest path distance or generalized PageRank scores. We propose two ways for GNNs to use DEs (1) as extra node features, and (2) as controllers of message aggregation in GNNs. Both approaches can utilize the sparse structure of the underlying graph, which leads to computational efficiency and scalability. We also prove that DE can distinguish node sets embedded in almost all regular graphs where traditional GNNs always fail. We evaluate DE on three tasks over six real networks: structural role prediction, link prediction, and triangle prediction. Results show that our models outperform GNNs without DE by up-to 15\\% in accuracy and AUROC. Furthermore, our models also significantly outperform other state-of-the-art methods especially designed for the above tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Structured Distributions From Untrusted Batches", "Title": "Faster and Simpler", "Abstract": "In this paper, we find an appealing way to synthesize the techniques of [JO19] and [CLM19] to give the best of both worlds: an algorithm which runs in polynomial time and can exploit structure in the underlying distribution to achieve sublinear sample complexity. Along the way, we simplify the approach of [JO19] by avoiding the need for SDP rounding and giving a more direct interpretation of it through the lens of soft filtering, a powerful recent technique in high-dimensional robust estimation. We validate the usefulness of our algorithms in preliminary experimental evaluations."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Diversity can be Transferred", "Title": "Output Diversification for White- and Black-box Attacks", "Abstract": "Adversarial attacks often involve random perturbations of the inputs drawn from uniform or Gaussian distributions, e.g. to initialize optimization-based white-box attacks or generate update directions in black-box attacks. These simple perturbations, however, could be sub-optimal as they are agnostic to the model being attacked. To improve the efficiency of these attacks, we propose Output Diversified Sampling (ODS), a novel sampling strategy that attempts to maximize diversity in the target model's outputs among the generated samples. While ODS is a gradient-based strategy, the diversity offered by ODS is transferable and can be helpful for both white-box and black-box attacks via surrogate models. Empirically, we demonstrate that ODS significantly improves the performance of existing white-box and black-box attacks. In particular, ODS reduces the number of queries needed for state-of-the-art black-box attacks on ImageNet by a factor of two."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "POLY-HOOT", "Title": "Monte-Carlo Planning in Continuous Space MDPs with Non-Asymptotic Analysis", "Abstract": "Monte-Carlo planning, as exemplified by Monte-Carlo Tree Search (MCTS), has demonstrated remarkable performance in applications with finite spaces. In this paper, we consider Monte-Carlo planning in an environment with continuous state-action spaces, a much less understood problem with important applications in control and robotics. We introduce POLY-HOOT, an algorithm that augments MCTS with a continuous armed bandit strategy named Hierarchical Optimistic Optimization (HOO) (Bubeck et al., 2011). Specifically, we enhance HOO by using an appropriate polynomial, rather than logarithmic, bonus term in the upper confidence bounds. Such a polynomial bonus is motivated by its empirical successes in AlphaGo Zero (Silver et al., 2017b), as well as its significant role in achieving theoretical guarantees of finite space MCTS (Shah et al., 2019). We investigate, for the first time, the regret of the enhanced HOO algorithm in non-stationary bandit problems. Using this result as a building block, we establish non-asymptotic convergence guarantees for POLY-HOOT: the value estimate converges to an arbitrarily small neighborhood of the optimal value function at a polynomial rate. We further provide experimental results that corroborate our theoretical findings."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AvE", "Title": "Assistance via Empowerment", "Abstract": "One difficulty in using artificial agents for human-assistive applications lies in the challenge of accurately assisting with a person's goal(s).  Existing methods tend to rely on inferring the human's goal, which is challenging when there are many potential goals or when the set of candidate goals is difficult to identify. We propose a new paradigm for assistance by instead increasing the human's ability to control their environment, and formalize this approach by augmenting reinforcement learning with human empowerment. This task-agnostic objective increases the person's autonomy and ability to achieve any eventual state. We test our approach against assistance based on goal inference, highlighting scenarios where our method overcomes failure modes stemming from goal ambiguity or misspecification. As existing methods for estimating empowerment in continuous domains are computationally hard, precluding its use in real time learned assistance, we also propose an efficient empowerment-inspired proxy metric. Using this, we are able to successfully demonstrate our method in a shared autonomy user study for a challenging simulated teleoperation task with human-in-the-loop training."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Randomized tests for high-dimensional regression", "Title": "A more efficient and powerful solution", "Abstract": "We investigate the problem of testing the global null in the high-dimensional regression models when the feature dimension $p$ grows proportionally to the number of observations $n$. Despite a number of prior work studying this problem, whether there exists a test that is model-agnostic, efficient to compute and enjoys a high power, still remains unsettled. In this paper, we answer this question in the affirmative by leveraging the random projection techniques, and propose a testing procedure that blends the classical $F$-test with a random projection step. When combined with a systematic choice of the projection dimension, the proposed procedure is proved to be minimax optimal and, meanwhile, reduces the computation and data storage requirements. We illustrate our results in various scenarios when the underlying feature matrix exhibits an intrinsic lower dimensional structure (such as approximate low-rank or has exponential/polynomial eigen-decay), and it turns out that the proposed test achieves sharp adaptive rates. Our theoretical findings are further validated by comparisons to other state-of-the-art tests on synthetic data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generative View Synthesis", "Title": "From Single-view Semantics to Novel-view Images", "Abstract": "Content creation, central to applications such as virtual reality, can be tedious and time-consuming. Recent image synthesis methods simplify this task by offering tools to generate new views from as little as a single input image, or by converting a semantic map into a photorealistic image.  We propose to push the envelope further, and  introduce Generative View Synthesis (GVS) that can synthesize multiple photorealistic views of a scene given a single semantic map.\nWe show that the sequential application of existing techniques, e.g., semantics-to-image translation followed by monocular view synthesis, fail at capturing the scene's structure. In contrast, we solve the semantics-to-image translation in concert with the estimation of the 3D layout of the scene, thus producing geometrically consistent novel views that preserve semantic structures. We first lift the input 2D semantic map onto a 3D layered representation of the scene in feature space, thereby preserving the semantic labels of 3D geometric structures.  We then project the layered features onto the target views to generate the final novel-view images. We verify the strengths of our method and compare it with several advanced baselines on three different datasets. Our approach also allows for style manipulation and image editing operations, such as the addition or removal of objects, with simple manipulations of the input style images and semantic maps respectively. For code and additional results, visit the project page at https://gvsnet.github.io"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Causal Shapley Values", "Title": "Exploiting Causal Knowledge to Explain Individual Predictions of Complex Models", "Abstract": "In this paper, we propose a novel framework for computing Shapley values that generalizes recent work that aims to circumvent the independence assumption. By employing Pearl's do-calculus, we show how these `causal' Shapley values can be derived for general causal graphs without sacrificing any of their desirable properties. Moreover, causal Shapley values enable us to separate the contribution of direct and indirect effects. We provide a practical implementation for computing causal Shapley values based on causal chain graphs when only partial information is available and illustrate their utility on a real-world example."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AI Feynman 2.0", "Title": "Pareto-optimal symbolic regression exploiting graph modularity", "Abstract": "We present an improved method for symbolic regression that seeks to fit data to formulas that are Pareto-optimal, in the sense of having the best accuracy for a given complexity. It improves on the previous state-of-the-art by typically being orders of magnitude more robust toward noise and bad data, and also by discovering many formulas that stumped previous methods. We develop a method for discovering generalized symmetries (arbitrary modularity in the computational graph of a formula) from gradient properties of a neural network fit. We use normalizing flows to generalize our symbolic regression method to probability distributions from which we only have samples, and employ statistical hypothesis testing to accelerate robust brute-force search."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Continual Learning of Control Primitives ", "Title": "Skill Discovery via Reset-Games", "Abstract": "Reinforcement learning has the potential to automate the acquisition of behavior in complex settings, but in order for it to be successfully deployed, a number of practical challenges must be addressed. First, in real world settings, when an agent attempts a tasks and fails, the environment must somehow \"reset\" so that the agent can attempt the task again. While easy in simulation, this could require considerable human effort in the real world, especially if the number of trials is very large. Second, real world learning is often limited by challenges in exploration, as complex, temporally extended behavior is often times difficult to acquire with random exploration. In this work, we show how a single method can allow an agent to acquire skills with minimal supervision while removing the need for resets. We do this by exploiting the insight that the need to reset\" an agent to a broad set of initial states for a learning task provides a natural setting to learn a diverse set ofreset-skills.\" We propose a general-sum game formulation that naturally balances the objective of resetting and learning skills, and demonstrate that this approach improves performance on reset-free tasks, and additionally show that the skills we obtain can be used to significantly accelerate downstream learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HOI Analysis", "Title": "Integrating and Decomposing Human-Object Interaction", "Abstract": "Human-Object Interaction (HOI) consists of human, object and implicit interaction/verb. Different from previous methods that directly map pixels to HOI semantics, we propose a novel perspective for HOI learning in an analytical manner. In analogy to Harmonic Analysis, whose goal is to study how to represent the signals with the superposition of basic waves, we propose the HOI Analysis. We argue that coherent HOI can be decomposed into isolated human and object. Meanwhile, isolated human and object can also be integrated into coherent HOI again. Moreover, transformations between human-object pairs with the same HOI can also be easier approached with integration and decomposition. As a result, the implicit verb will be represented in the transformation function space. In light of this, we propose an Integration-Decomposition Network (IDN) to implement the above transformations and achieve state-of-the-art performance on widely-used HOI detection benchmarks. Code is available at https://github.com/DirtyHarryLYL/HAKE-Action-Torch/tree/IDN-(Integrating-Decomposing-Network)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Path Features and Neural Path Kernel ", "Title": "Understanding the role of gates in deep learning", "Abstract": "In this paper, we analytically characterise the role of gates and active sub-networks in deep learning. To this end, we encode the on/off state of the gates for a given input in a novel 'neural path feature' (NPF), and the weights of the DNN are encoded in a novel 'neural path value' (NPV). Further, we show that the output of network is indeed the inner product of NPF and NPV.  The main result of the paper shows that the 'neural path kernel' associated with the NPF is a fundamental quantity that characterises the information stored in the gates of a DNN. We show via experiments (on MNIST and CIFAR-10) that in standard DNNs with ReLU activations NPFs are learnt during training and such learning is key for generalisation. Furthermore, NPFs and NPVs can be learnt in two separate networks and such learning also generalises well in experiments. In our experiments, we observe that almost all the information learnt by a DNN with ReLU activations is stored in the gates - a novel observation that underscores the need to investigate the role of the gates in DNNs."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Counterfactual Vision-and-Language Navigation", "Title": "Unravelling the Unseen", "Abstract": "The task of vision-and-language navigation (VLN) requires an agent to follow text instructions to find its way through simulated household environments. A prominent challenge is to train an agent capable of generalising to new environments at test time, rather than one that simply memorises trajectories and visual details observed during training. We propose a new learning strategy that learns both from observations and generated counterfactual environments. We describe an effective algorithm to generate counterfactual observations on the fly for VLN, as linear combinations of existing environments. Simultaneously, we encourage the agent's actions to remain stable between original and counterfactual environments through our novel training objective-effectively removing the spurious features that otherwise bias the agent. Our experiments show that this technique provides significant improvements in generalisation on benchmarks for Room-to-Room navigation and Embodied Question Answering."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust Quantization", "Title": "One Model to Rule Them All", "Abstract": "Neural network quantization methods often involve simulating the quantization process during training, making the trained model highly dependent on the target bit-width and precise way quantization is performed.  Robust quantization offers an alternative approach with improved tolerance to different classes of data-types and quantization policies. It opens up new exciting applications where the quantization process is not static and can vary to meet different circumstances and implementations. To address this issue, we propose a method that provides intrinsic robustness to the model against a broad range of quantization processes.  Our method is motivated by theoretical arguments and enables us to store a single generic model capable of operating at various bit-widths and quantization policies. We validate our method's effectiveness on different ImageNet Models. A reference implementation accompanies the paper."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fixed-Support Wasserstein Barycenters", "Title": "Computational Hardness and Fast Algorithm", "Abstract": "We study the fixed-support Wasserstein barycenter problem (FS-WBP), which consists in computing the Wasserstein barycenter of $m$ discrete probability measures supported on a finite metric space of size $n$. We show first that the constraint matrix arising from the standard linear programming (LP) representation of the FS-WBP is \\textit{not totally unimodular} when $m \\geq 3$ and $n \\geq 3$. This result resolves an open question pertaining to the relationship between the FS-WBP and the minimum-cost flow (MCF) problem since it proves that the FS-WBP in the standard LP form is not an MCF problem when $m \\geq 3$ and $n \\geq 3$. We also develop a provably fast \\textit{deterministic} variant of the celebrated iterative Bregman projection (IBP) algorithm, named \\textsc{FastIBP}, with a complexity bound of $\\tilde{O}(mn^{7/3}\\varepsilon^{-4/3})$, where $\\varepsilon \\in (0, 1)$ is the desired tolerance. This complexity bound is better than the best known complexity bound of $\\tilde{O}(mn^2\\varepsilon^{-2})$ for the IBP algorithm in terms of $\\varepsilon$, and that of $\\tilde{O}(mn^{5/2}\\varepsilon^{-1})$ from accelerated alternating minimization algorithm or accelerated primal-dual adaptive gradient algorithm in terms of $n$. Finally, we conduct extensive experiments with both synthetic data and real images and demonstrate the favorable performance of the \\textsc{FastIBP} algorithm in practice."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analytic Characterization of the Hessian in Shallow ReLU Models", "Title": "A Tale of Symmetry", "Abstract": "We consider the optimization problem associated with fitting two-layers ReLU networks with respect to the squared loss, where labels are generated by a target network. We leverage the rich symmetry structure to analytically characterize the Hessian at various families of spurious minima in the natural regime where the number of inputs $d$ and the number of hidden neurons $k$ is finite. In particular, we prove that for $d\\ge k$ standard Gaussian inputs: (a) of the $dk$ eigenvalues of the Hessian, $dk - O(d)$ concentrate near zero, (b) $\\Omega(d)$ of the eigenvalues grow linearly with $k$. Although this phenomenon of extremely skewed spectrum has been observed many times before, to our knowledge, this is \nthe first time it has been established {rigorously}. Our analytic approach uses techniques, new to the field, from symmetry breaking and representation theory, and carries important implications for our ability to argue about statistical \ngeneralization through local curvature."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning under Model Misspecification", "Title": "Applications to Variational and Ensemble methods", "Abstract": "Virtually any model we use in machine learning to make predictions does not perfectly represent reality. So, most of the learning happens under model misspecification. In this work, we present a novel analysis of the generalization performance of Bayesian model averaging under model misspecification and i.i.d. data using a new family of second-order PAC-Bayes bounds. This analysis shows, in simple and intuitive terms, that Bayesian model averaging provides suboptimal generalization performance when the model is misspecified. In consequence, we provide strong theoretical arguments showing that Bayesian methods are not optimal for learning predictive models, unless the model class is perfectly specified. Using novel second-order PAC-Bayes bounds, we derive a new family of Bayesian-like algorithms, which can be implemented as variational and ensemble methods. The output of these algorithms is a new posterior distribution, different from the Bayesian posterior, which induces a posterior predictive distribution with better generalization performance. Experiments with Bayesian neural networks illustrate these findings."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Language Through a Prism", "Title": "A Spectral Approach for Multiscale Language Representations", "Abstract": "Language exhibits structure at a wide range of scales, from subwords to words, sentences, paragraphs, and documents. We propose building models that isolate scale-specific information in deep representations, and develop methods for encouraging models during training to learn more about particular scales of interest. Our method for creating scale-specific neurons in deep NLP models constrains how the activation of a neuron can change across the tokens of an input by interpreting those activations as a digital signal and filtering out parts of its frequency spectrum. This technique enables us to extract scale-specific information from BERT representations: by filtering out different frequencies we can produce new representations that perform well on part of speech tagging (word-level), dialog speech acts classification (utterance-level), or topic classification (document-level), while performing poorly on the other tasks. We also present a prism layer for use during training, which constrains different neurons of a BERT model to different parts of the frequency spectrum. Our proposed BERT + Prism model is better able to predict masked tokens using long-range context, and produces individual multiscale representations that perform with comparable or improved performance across all three tasks. Our methods are general and readily applicable to other domains besides language, such as images, audio, and video."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DVERGE", "Title": "Diversifying Vulnerabilities for Enhanced Robust Generation of Ensembles", "Abstract": "Recent research finds CNN models for image classification demonstrate overlapped adversarial vulnerabilities: adversarial attacks can mislead CNN models with small perturbations, which can effectively transfer between different models trained on the same dataset. Adversarial training, as a general robustness improvement technique, eliminates the vulnerability in a single model by forcing it to learn robust features. The process is hard, often requires models with large capacity, and suffers from significant loss on clean data accuracy. Alternatively, ensemble methods are proposed to induce sub-models with diverse outputs against a transfer adversarial example, making the ensemble robust against transfer attacks even if each sub-model is individually non-robust. Only small clean accuracy drop is observed in the process. However, previous ensemble training methods are not efficacious in inducing such diversity and thus ineffective on reaching robust ensemble. We propose DVERGE, which isolates the adversarial vulnerability in each sub-model by distilling non-robust features, and diversifies the adversarial vulnerability to induce diverse outputs against a transfer attack. The novel diversity metric and training procedure enables DVERGE to achieve higher robustness against transfer attacks comparing to previous ensemble methods, and enables the improved robustness when more sub-models are added to the ensemble. The code of this work is available at https://github.com/zjysteven/DVERGE."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RepPoints v2", "Title": "Verification Meets Regression for Object Detection", "Abstract": "Verification and regression are two general methodologies for prediction in neural networks. Each has its own strengths: verification can be easier to infer accurately, and regression is more efficient and applicable to continuous target variables. Hence, it is often beneficial to carefully combine them to take advantage of their benefits. In this paper, we take this philosophy to improve state-of-the-art object detection, specifically by RepPoints. Though RepPoints provides high performance, we find that its heavy reliance on regression for object localization leaves room for improvement. We introduce verification tasks into the localization prediction of RepPoints, producing RepPoints v2, which proves consistent improvements of about 2.0 mAP over the original RepPoints on COCO object detection benchmark using different backbones and training methods. RepPoints v2 also achieves 52.1 mAP on the COCO \\texttt{test-dev} by a single model. Moreover, we show that the proposed approach can more generally elevate other object detection frameworks as well as applications such as instance segmentation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SLIP", "Title": "Learning to predict in unknown dynamical systems with long-term memory", "Abstract": "We present an efficient and practical (polynomial time) algorithm for online prediction in unknown and partially observed linear dynamical systems (LDS) under stochastic noise. When the system parameters are known, the optimal linear predictor is the Kalman filter. However, in unknown systems, the performance of existing predictive models is poor in important classes of LDS that are only marginally stable and exhibit long-term forecast memory. We tackle this problem by bounding the generalized Kolmogorov width of the Kalman filter coefficient set. This motivates the design of an algorithm, which we call spectral LDS improper predictor (SLIP), based on conducting a tight convex relaxation of the Kalman predictive model via spectral methods. We provide a finite-sample analysis, showing that our algorithm competes with the Kalman filter in hindsight with only logarithmic regret. Our regret analysis relies on Mendelson’s small-ball method, providing sharp error bounds without concentration, boundedness, or exponential forgetting assumptions. Empirical evaluations demonstrate that SLIP outperforms state-of-the-art methods in LDS prediction. Our theoretical and experimental results shed light on the conditions required for efficient probably approximately correct (PAC) learning of the Kalman filter from partially observed data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayesian Bits", "Title": "Unifying Quantization and Pruning", "Abstract": "We introduce Bayesian Bits, a practical method for joint mixed precision quantization and pruning through gradient based optimization. Bayesian Bits employs a novel decomposition of the quantization operation, which sequentially considers doubling the bit width. At each new bit width, the residual error between the full precision value and the previously rounded value is quantized.  We then decide whether or not to add this quantized residual error for a higher effective bit width and lower quantization noise.  By starting with a power-of-two bit width, this decomposition will always produce hardware-friendly configurations, and through an additional 0-bit option, serves as a unified view of pruning and quantization. Bayesian Bits then introduces learnable stochastic gates, which collectively control the bit width of the given tensor. As a result, we can obtain low bit solutions by performing approximate inference over the gates, with prior distributions that encourage most of them to be switched off. We experimentally validate our proposed method on several benchmark datasets and show that we can learn pruned, mixed precision networks that provide a better trade-off between accuracy and efficiency than their static bit width equivalents."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MiniLM", "Title": "Deep Self-Attention Distillation for Task-Agnostic Compression of Pre-Trained Transformers", "Abstract": "Pre-trained language models (e.g., BERT (Devlin et al., 2018) and its variants) have achieved remarkable success in varieties of NLP tasks. However, these models usually consist of hundreds of millions of parameters which brings challenges for fine-tuning and online serving in real-life applications due to latency and capacity constraints. In this work, we present a simple and effective approach to compress large Transformer (Vaswani et al., 2017) based pre-trained models, termed as deep self-attention distillation. The small model (student) is trained by deeply mimicking the self-attention module, which plays a vital role in Transformer networks, of the large model (teacher). Specifically, we propose distilling the self-attention module of the last Transformer layer of the teacher, which is effective and flexible for the student. Furthermore, we introduce the scaled dot-product between values in the self-attention module as the new deep self-attention knowledge, in addition to the attention distributions (i.e., the scaled dot-product of queries and keys) that have been used in existing works. Moreover, we show that introducing a teacher assistant (Mirzadeh et al., 2019) also helps the distillation of large pre-trained Transformer models. Experimental results demonstrate that our monolingual model outperforms state-of-the-art baselines in different parameter size of student models. In particular, it retains more than 99% accuracy on SQuAD 2.0 and several GLUE benchmark tasks using 50% of the Transformer parameters and computations of the teacher model. We also obtain competitive results in applying deep self-attention distillation to multilingual pre-trained models."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep learning versus kernel learning", "Title": "an empirical study of loss landscape geometry and the time evolution of the Neural Tangent Kernel", "Abstract": "In suitably initialized wide networks, small learning rates transform deep neural networks (DNNs) into neural tangent kernel (NTK) machines, whose training dynamics is well-approximated by a linear weight expansion of the network at initialization.  Standard training, however, diverges from its linearization in ways that are poorly understood. We study the relationship between the training dynamics of nonlinear deep networks, the geometry of the loss landscape, and the time evolution of a data-dependent NTK. We do so through a large-scale phenomenological analysis of training, synthesizing diverse measures characterizing loss landscape geometry and NTK dynamics. In multiple neural architectures and datasets, we find these diverse measures evolve in a highly correlated manner, revealing a universal picture of the deep learning process.  In this picture, deep network training exhibits a highly chaotic rapid initial transient that within 2 to 3 epochs determines the final linearly connected basin of low loss containing the end point of training. During this chaotic transient, the NTK changes rapidly, learning useful features from the training data that enables it to outperform the standard initial NTK by a factor of 3 in less than 3 to 4 epochs. After this rapid chaotic transient, the NTK changes at constant velocity, and its performance matches that of full network training in 15\\% to 45\\% of training time. Overall, our analysis reveals a striking correlation between a diverse set of metrics over training time, governed by a rapid chaotic to stable transition in the first few epochs, that together poses challenges and opportunities for the development of more accurate theories of deep learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neuron Shapley", "Title": "Discovering the Responsible Neurons", "Abstract": "We develop Neuron Shapley as a new framework to quantify the contribution of individual neurons to the prediction and performance of a deep network. By accounting for interactions across neurons, Neuron Shapley is more effective in identifying important filters compared to common approaches based on activation patterns. Interestingly, removing just 30 filters with the highest Shapley scores effectively destroys the prediction accuracy of Inception-v3 on ImageNet. Visualization of these few critical filters provides insights into how the network functions. Neuron Shapley is a flexible framework and can be applied to identify responsible neurons in many tasks. We illustrate additional applications of identifying filters that are responsible for biased prediction in facial recognition and filters that are vulnerable to adversarial attacks. Removing these filters is a quick way to repair models. Computing exact Shapley values is computationally infeasible and therefore sampling-based approximations are used in practice. We introduce a new multi-armed bandit algorithm that is able to efficiently  detect neurons with the largest Shapley value orders of magnitude faster than existing Shapley value approximation methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeuMiss networks", "Title": "differentiable programming for supervised learning with missing values.", "Abstract": "The presence of missing values makes supervised learning much more challenging. Indeed, previous work has shown that even when the response is a linear function of the complete data, the optimal predictor is a complex function of the observed entries and the missingness indicator. As a result, the computational or sample complexities of consistent approaches depend on the number of missing patterns, which can be exponential in the number of dimensions. In this work, we derive the analytical form of the optimal predictor under a linearity assumption and various missing data mechanisms including Missing at Random (MAR) and self-masking (Missing Not At Random). Based on a Neumann-series approximation of the optimal predictor, we propose a new principled architecture, named NeuMiss networks. Their originality and strength come from the use of a new type of non-linearity: the multiplication by the missingness indicator. We provide an upper bound on the Bayes risk of NeuMiss networks, and show that they have good predictive accuracy with both a number of parameters and a computational complexity independent of the number of missing data patterns. As a result they scale well to problems with many features, and remain statistically efficient for medium-sized samples. Moreover, we show that, contrary to procedures using EM or imputation, they are robust to the missing data mechanism, including difficult MNAR settings such as self-masking."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Graph Pose", "Title": "a semi-supervised deep graphical model for improved animal pose tracking", "Abstract": "Noninvasive behavioral tracking of animals is crucial for many scientific investigations. Recent transfer learning approaches for behavioral tracking have considerably advanced the state of the art. Typically these methods treat each video frame and each object to be tracked independently. In this work, we improve on these methods (particularly in the regime of few training labels) by leveraging  the rich spatiotemporal structures pervasive in behavioral video --- specifically, the spatial statistics imposed by physical constraints (e.g., paw to elbow distance), and the temporal statistics imposed by smoothness from frame to frame. We propose a probabilistic graphical model built on top of deep neural networks, Deep Graph Pose (DGP), to leverage these useful spatial and temporal constraints, and develop an efficient structured variational approach to perform inference in this model.  The resulting semi-supervised model exploits both labeled and unlabeled frames to achieve significantly more accurate and robust tracking while requiring users to label fewer training frames.  In turn, these tracking improvements enhance performance on downstream applications, including robust unsupervised segmentation of behavioral syllables,'' and estimation of interpretabledisentangled''  low-dimensional representations of the full behavioral video. Open source code is available at  \\href{\\CodeLink}{https://github.com/paninski-lab/deepgraphpose}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Continuous Object Representation Networks", "Title": "Novel View Synthesis without Target View Supervision", "Abstract": "Novel View Synthesis (NVS) is concerned with synthesizing views under camera viewpoint transformations from one or multiple input images. NVS requires explicit reasoning about 3D object structure and unseen parts of the scene to synthesize convincing results. As a result, current approaches typically rely on supervised training with either ground truth 3D models or multiple target images. We propose Continuous Object Representation Networks (CORN), a conditional architecture that encodes an input image's geometry and appearance that map to a 3D consistent scene representation. We can train CORN with only two source images per object by combining our model with a neural renderer. A key feature of CORN is that it requires no ground truth 3D models or target view supervision. Regardless, CORN performs well on challenging tasks such as novel view synthesis and single-view 3D reconstruction and achieves performance comparable to state-of-the-art approaches that use direct supervision. For up-to-date information, data, and code, please see our project page: https://nicolaihaeni.github.io/corn/."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Solver-in-the-Loop", "Title": "Learning from Differentiable Physics to Interact with Iterative PDE-Solvers", "Abstract": "Finding accurate solutions to partial differential equations (PDEs) is a crucial task in all scientific and engineering disciplines. It has recently been shown that machine learning methods can improve the solution accuracy by correcting for effects not captured by the discretized PDE. We target the problem of reducing numerical errors of iterative PDE solvers and compare different learning approaches for finding complex correction functions. We find that previously used learning approaches are significantly outperformed by methods that integrate the solver into the training loop and thereby allow the model to interact with the PDE during training. This provides the model with realistic input distributions that take previous corrections into account, yielding improvements in accuracy with stable rollouts of several hundred recurrent evaluation steps and surpassing even tailored supervised variants. We highlight the performance of the differentiable physics networks for a wide variety of PDEs, from non-linear advection-diffusion systems to three-dimensional Navier-Stokes flows."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reinforcement Learning with General Value Function Approximation", "Title": "Provably Efficient Approach via Bounded Eluder Dimension", "Abstract": "Value function approximation has demonstrated phenomenal empirical success in reinforcement learning (RL). Nevertheless, despite a handful of recent progress on developing theory for RL with linear function approximation, the understanding of \\emph{general} function approximation schemes largely remains missing. In this paper, we establish the first provably efficient RL algorithm with general value function approximation. We show that if the value functions admit an approximation with a function class $\\mathcal{F}$, our algorithm achieves a regret bound of $\\widetilde{O}(\\mathrm{poly}(dH)\\sqrt{T})$ where $d$ is a complexity measure of $\\mathcal{F}$ that depends on the eluder dimension~[Russo and Van Roy, 2013] and log-covering numbers, $H$ is the planning horizon, and $T$ is the number interactions with the environment. Our theory generalizes the linear MDP assumption to general function classes. Moreover, our algorithm is model-free and provides a framework to justify the effectiveness of algorithms used in practice."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Wavelet Flow", "Title": "Fast Training of High Resolution Normalizing Flows", "Abstract": "Normalizing flows are a class of probabilistic generative models which allow for both fast density computation and efficient sampling and are effective at modelling complex distributions like images. A drawback among current methods is their significant training cost, sometimes requiring months of GPU training time to achieve state-of-the-art results. This paper introduces Wavelet Flow, a multi-scale, normalizing flow architecture based on wavelets. A Wavelet Flow has an explicit representation of signal scale that inherently includes models of lower resolution signals and conditional generation of higher resolution signals, i.e., super resolution. A major advantage of Wavelet Flow is the ability to construct generative models for high resolution data (e.g., 1024 × 1024 images) that are impractical with previous models. Furthermore, Wavelet Flow is competitive with previous normalizing flows in terms of bits per dimension on standard (low resolution) benchmarks while being up to 15× faster to train."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Crush Optimism with Pessimism", "Title": "Structured Bandits Beyond Asymptotic Optimality", "Abstract": "We study stochastic structured bandits for minimizing regret.  The fact that the popular optimistic algorithms do not achieve the asymptotic instance-dependent regret optimality (asymptotic optimality for short) has recently alluded researchers.  On the other hand, it is known that one can achieve bounded regret (i.e., does not grow indefinitely with $n$) in certain instances.  Unfortunately, existing asymptotically optimal algorithms rely on forced sampling that introduces an $\\omega(1)$ term w.r.t. the time horizon $n$ in their regret, failing to adapt to the ``easiness'' of the instance.  In this paper, we focus on the finite hypothesis case and ask if one can achieve the asymptotic optimality while enjoying bounded regret whenever possible.  We provide a positive answer by introducing a new algorithm called CRush Optimism with Pessimism (CROP) that eliminates optimistic hypotheses by pulling the informative arms indicated by a pessimistic hypothesis.  Our finite-time analysis shows that CROP $(i)$ achieves a constant-factor asymptotic optimality and, thanks to the forced-exploration-free design, $(ii)$ adapts to bounded regret, and $(iii)$ its regret bound scales not with $K$ but with an effective number of arms $K_\\psi$ that we introduce.  We also discuss a problem class where CROP can be exponentially better than existing algorithms in \\textit{nonasymptotic} regimes.  This problem class also reveals a surprising fact that even a clairvoyant oracle who plays according to the asymptotically optimal arm pull scheme may suffer a linear worst-case regret."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interpretable and Personalized Apprenticeship Scheduling", "Title": "Learning Interpretable Scheduling Policies from Heterogeneous User Demonstrations", "Abstract": "Resource scheduling and coordination is an NP-hard optimization requiring an efficient allocation of agents to a set of tasks with upper- and lower bound temporal and resource constraints. Due to the large-scale and dynamic nature of resource coordination in hospitals and factories, human domain experts manually plan and adjust schedules on the fly. To perform this job, domain experts leverage heterogeneous strategies and rules-of-thumb honed over years of apprenticeship. What is critically needed is the ability to extract this domain knowledge in a heterogeneous and interpretable apprenticeship learning framework to scale beyond the power of a single human expert, a necessity in safety-critical domains. We propose a personalized and interpretable apprenticeship scheduling algorithm that infers an interpretable representation of all human task demonstrators by extracting decision-making criteria via an inferred, personalized embedding non-parametric in the number of demonstrator types. We achieve near-perfect LfD accuracy in synthetic domains and 88.22\\% accuracy on a planning domain with real-world data, outperforming baselines. Finally, our user study showed our methodology produces more interpretable and easier-to-use models than neural networks ($p < 0.05$)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The LoCA Regret", "Title": "A Consistent Metric to Evaluate Model-Based Behavior in Reinforcement Learning", "Abstract": "Deep model-based Reinforcement Learning (RL) has the potential to substantially improve the sample-efficiency of deep RL. While various challenges have long held it back, a number of papers have recently come out reporting success with deep model-based methods. This is a great development, but the lack of a consistent metric to evaluate such methods makes it difficult to compare various approaches. For example, the common single-task sample-efficiency metric conflates improvements due to model-based learning with various other aspects, such as representation learning, making it difficult to assess true progress on model-based RL. To address this, we introduce an experimental setup to evaluate model-based behavior of RL methods, inspired by work from neuroscience on detecting model-based behavior in humans and animals. Our metric based on this setup, the Local Change Adaptation (LoCA) regret, measures how quickly an RL method adapts to a local change in the environment. Our metric can identify model-based behavior, even if the method uses a poor representation and provides insight in how close a method's behavior is from optimal model-based behavior. We use our setup to evaluate the model-based behavior of MuZero on a variation of the classic Mountain Car task."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Erdos Goes Neural", "Title": "an Unsupervised Learning Framework for Combinatorial Optimization on Graphs", "Abstract": "Combinatorial optimization (CO) problems are notoriously challenging for neural networks, especially in the absence of labeled instances. This work proposes an unsupervised learning framework for CO problems on graphs that can provide integral solutions of certified quality. \nInspired by Erdos' probabilistic method, we use a neural network to parametrize a probability distribution over sets. Crucially, we show that when the network is optimized w.r.t. a suitably chosen loss, the learned distribution contains, with controlled probability, a low-cost integral solution that obeys the constraints of the combinatorial problem. \nThe probabilistic proof of existence is then derandomized to\ndecode the desired solutions. We demonstrate the efficacy of this approach to obtain valid \nsolutions to the maximum clique problem and to perform local graph clustering. Our method achieves competitive results on both real datasets and synthetic hard instances."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BlockGAN", "Title": "Learning 3D Object-aware Scene Representations from Unlabelled Images", "Abstract": "We present BlockGAN, an image generative model that learns object-aware 3D scene representations directly from unlabelled 2D images. Current work on scene representation learning either ignores scene background or treats the whole scene as one object. Meanwhile, work that considers scene compositionality treats scene objects only as image patches or 2D layers with alpha maps. Inspired by the computer graphics pipeline, we design BlockGAN to learn to first generate 3D features of background and foreground objects, then combine them into 3D features for the whole scene, and finally render them into realistic images. This allows BlockGAN to reason over occlusion and interaction between objects’ appearance, such as shadow and lighting, and provides control over each object’s 3D pose and identity, while maintaining image realism. BlockGAN is trained end-to-end, using only unlabelled single images, without the need for 3D geometry, pose labels, object masks, or multiple views of the same scene. Our experiments show that using explicit 3D features to represent objects allows BlockGAN to learn disentangled representations both in terms of objects (foreground and background) and their properties (pose and identity)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Barking up the right tree", "Title": "an approach to search over molecule synthesis DAGs", "Abstract": "When designing new molecules with particular properties, it is not only important what to make but crucially how to make it. These instructions form a synthesis directed acyclic graph (DAG), describing how a large vocabulary of simple building blocks can be recursively combined through chemical reactions to create more complicated molecules of interest. In contrast, many current deep generative models for molecules ignore synthesizability. We therefore propose a deep generative model that better represents the real world process, by directly outputting molecule synthesis DAGs. We argue that this provides sensible inductive biases, ensuring that our model searches over the same chemical space that chemists would also have access to, as well as interoperability. We show that our approach is able to model chemical space well, producing a wide range of diverse molecules, and allows for unconstrained optimization of an inherently constrained problem: maximize certain chemical properties such that discovered molecules are synthesizable."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Profile Entropy", "Title": "A Fundamental Measure for the Learnability and Compressibility of Distributions", "Abstract": "The profile of a sample is the multiset of its symbol frequencies. We show that for samples of discrete distributions, profile entropy is a fundamental measure unifying the concepts of estimation, inference, and compression. Specifically, profile entropy:  a) determines the speed of estimating the distribution relative to the best natural estimator; b) characterizes the rate of inferring all symmetric properties compared with the best estimator over any label-invariant distribution collection; c) serves as the limit of profile compression, for which we derive optimal near-linear-time block and sequential algorithms. To further our understanding of profile entropy, we investigate its attributes, provide algorithms for approximating its value, and determine its magnitude for numerous structural distribution families."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoADNet", "Title": "Collaborative Aggregation-and-Distribution Networks for Co-Salient Object Detection", "Abstract": "Co-Salient Object Detection (CoSOD) aims at discovering salient objects that repeatedly appear in a given query group containing two or more relevant images. One challenging issue is how to effectively capture co-saliency cues by modeling and exploiting inter-image relationships. In this paper, we present an end-to-end collaborative aggregation-and-distribution network (CoADNet) to capture both salient and repetitive visual patterns from multiple images. First, we integrate saliency priors into the backbone features to suppress the redundant background information through an online intra-saliency guidance structure. After that, we design a two-stage aggregate-and-distribute architecture to explore group-wise semantic interactions and produce the co-saliency features. In the first stage, we propose a group-attentional semantic aggregation module that models inter-image relationships to generate the group-wise semantic representations. In the second stage, we propose a gated group distribution module that adaptively distributes the learned group semantics to different individuals in a dynamic gating mechanism. Finally, we develop a group consistency preserving decoder tailored for the CoSOD task, which maintains group constraints during feature decoding to predict more consistent full-resolution co-saliency maps. The proposed CoADNet is evaluated on four prevailing CoSOD benchmark datasets, which demonstrates the remarkable performance improvement over ten state-of-the-art competitors."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GramGAN", "Title": "Deep 3D Texture Synthesis From 2D Exemplars", "Abstract": "We present a novel texture synthesis framework, enabling the generation of infinite, high-quality 3D textures given a 2D exemplar image. Inspired by recent advances in natural texture synthesis, we train deep neural models to generate textures by non-linearly combining learned noise frequencies. To achieve a highly realistic output conditioned on an exemplar patch, we propose a novel loss function that combines ideas from both style transfer and generative adversarial networks. In particular, we train the synthesis network to match the Gram matrices of deep features from a discriminator network. In addition, we propose two architectural concepts and an extrapolation strategy that significantly improve generalization performance. In particular, we inject both model input and condition into hidden network layers by learning to scale and bias hidden activations. Quantitative and qualitative evaluations on a diverse set of exemplars motivate our design decisions and show that our system performs superior to previous state of the art. Finally, we conduct a user study that confirms the benefits of our framework."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UWSOD", "Title": "Toward Fully-Supervised-Level Capacity Weakly Supervised Object Detection", "Abstract": "Weakly supervised object detection (WSOD) has attracted extensive research attention due to its great flexibility of exploiting large-scale dataset with only image-level annotations for detector training. Despite its great advance in recent years, WSOD still suffers limited performance, which is far below that of fully supervised object detection (FSOD). As most WSOD methods depend on object proposal algorithms to generate candidate regions and are also confronted with challenges like low-quality predicted bounding boxes and large scale variation. In this paper, we propose a unified WSOD framework, termed UWSOD, to develop a high-capacity general detection model with only image-level labels, which is self-contained and does not require external modules or additional supervision. To this end, we exploit three important components, i.e., object proposal generation, bounding-box fine-tuning and scale-invariant features. First, we propose an anchor-based self-supervised proposal generator to hypothesize object locations, which is trained end-to-end with supervision created by UWSOD for both objectness classification and regression. Second, we develop a step-wise bounding-box fine-tuning to refine both detection scores and coordinates by progressively select high-confidence object proposals as positive samples, which bootstraps the quality of predicted bounding boxes. Third, we construct a multi-rate resampling pyramid to aggregate multi-scale contextual information, which is the first in-network feature hierarchy to handle scale variation in WSOD. Extensive experiments on PASCAL VOC and MS COCO show that the proposed UWSOD achieves competitive results with the state-of-the-art WSOD methods while not requiring external modules or additional supervision. Moreover, the upper-bound performance of UWSOD with class-agnostic ground-truth bounding boxes approaches Faster R-CNN, which demonstrates UWSOD has fully-supervised-level capacity."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sample Complexity of Asynchronous Q-Learning", "Title": "Sharper Analysis and Variance Reduction", "Abstract": "Asynchronous Q-learning aims to learn the optimal action-value function (or Q-function) of a Markov decision process (MDP), based on a single trajectory of Markovian samples induced by a behavior policy.  Focusing on a $\\gamma$-discounted MDP with state space S and action space A, we demonstrate that the $ \\ell_{\\infty} $-based sample complexity of classical asynchronous Q-learning --- namely, the number of samples needed to yield an entrywise $\\epsilon$-accurate estimate of the Q-function --- is at most on the order of $ \\frac{1}{ \\mu_{\\min}(1-\\gamma)^5 \\epsilon^2 }+ \\frac{ t_{\\mathsf{mix}} }{ \\mu_{\\min}(1-\\gamma) } $ up to some logarithmic factor, provided that a proper constant learning rate is adopted. Here, $ t_{\\mathsf{mix}} $ and $ \\mu_{\\min} $ denote respectively the mixing time and the minimum state-action occupancy probability of the sample trajectory. The first term of this bound matches the complexity in the case with independent samples drawn from the stationary distribution of  the trajectory. The second term reflects the expense taken for the empirical distribution of the Markovian trajectory to reach a steady state, which is incurred at the very beginning and becomes amortized as the algorithm runs. Encouragingly, the above bound improves upon the state-of-the-art result by a factor of at least |S||A|.  Further, the scaling on the discount complexity can be improved by means of variance reduction."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FedSplit", "Title": "an algorithmic framework for fast federated optimization", "Abstract": "Motivated by federated learning, we consider the hub-and-spoke model of distributed optimization in which a central authority coordinates the computation of a solution among many agents while limiting communication.  We first study some past procedures for federated optimization, and show that their fixed points need not correspond to stationary points of the original optimization problem, even in simple convex settings with deterministic updates.  In order to remedy these issues, we introduce FedSplit, a class of algorithms based on operator splitting procedures for solving distributed convex minimization with additive structure. We prove that these procedures have the correct fixed points, corresponding to optima of the original optimization problem, and we characterize their convergence rates under different settings. Our theory shows that these methods are provably robust to inexact computation of intermediate local quantities.  We complement our theory with some experiments that demonstrate the benefits of our methods in practice."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RL Unplugged", "Title": "A Suite of Benchmarks for Offline Reinforcement Learning", "Abstract": "Offline methods for reinforcement learning have a potential to help bridge the gap between reinforcement learning research and real-world applications. They make it possible to learn policies from offline datasets, thus overcoming concerns associated with online data collection in the real-world, including cost, safety, or ethical concerns.  In this paper, we propose a benchmark called RL Unplugged to evaluate and compare offline RL methods. RL Unplugged includes data from a diverse range of domains including games e.g., Atari benchmark) and simulated motor control problems (e.g., DM Control Suite). The datasets include domains that are partially or fully observable, use continuous or discrete actions, and  have stochastic vs. deterministic dynamics. We propose detailed evaluation protocols for each domain in RL Unplugged and provide an extensive analysis of supervised learning and offline RL methods using these protocols. We will release data for all our tasks and open-source all algorithms presented in this paper. We hope that our suite of benchmarks will increase the reproducibility of experiments and make it possible to study challenging tasks with a limited computational budget, thus making RL research both more systematic and more accessible across the community. Moving forward, we view RL Unplugged as a living benchmark suite that will evolve and grow with datasets contributed by the research community and ourselves. Our project page is available on github."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dual T", "Title": "Reducing Estimation Error for Transition Matrix in Label-noise Learning", "Abstract": "The transition matrix, denoting the transition relationship from clean labels to noisy labels, is essential to build statistically consistent classifiers in label-noise learning. Existing methods for estimating the transition matrix rely heavily on estimating the noisy class posterior. However, the estimation error for noisy class posterior could be large because of the randomness of label noise.  The estimation error would lead the transition matrix to be poorly estimated. Therefore in this paper, we aim to solve this problem by exploiting the divide-and-conquer paradigm. Specifically, we introduce an intermediate class to avoid directly estimating the noisy class posterior. By this intermediate class, the original transition matrix can then be factorized into the product of two easy-to-estimated transition matrices. We term the proposed method as the dual $T$-estimator. Both theoretical analyses and empirical results illustrate the effectiveness of the dual $T$-estimator for estimating transition matrices, leading to better classification performances."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HyNet", "Title": "Learning Local Descriptor with Hybrid Similarity Measure and Triplet Loss", "Abstract": "In this paper, we investigate how L2 normalisation affects the back-propagated descriptor gradients during training. Based on our observations, we propose HyNet, a new local descriptor that leads to state-of-the-art results in matching. HyNet introduces a hybrid similarity measure for triplet margin loss, a regularisation term constraining the descriptor norm, and a new network architecture that performs L2 normalisation of all intermediate feature maps and the output descriptors. HyNet surpasses previous methods by a significant margin on standard benchmarks that include patch matching, verification, and retrieval, as well as outperforming full end-to-end methods on 3D reconstruction tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Preference learning along multiple criteria", "Title": "A game-theoretic perspective", "Abstract": "From a theoretical standpoint, we show that the Blackwell winner of a multi-criteria problem instance can be computed as the solution to a convex optimization problem. Furthermore, given random samples of pairwise comparisons, we show that a simple, \"plug-in\" estimator achieves (near-)optimal minimax sample complexity. Finally, we showcase the practical utility of our framework in a user study on autonomous driving, where we find that the Blackwell winner outperforms the von Neumann winner for the overall preferences."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Once-for-All Adversarial Training", "Title": "In-Situ Tradeoff between Robustness and Accuracy for Free", "Abstract": "Adversarial training and its many variants substantially improve deep network robustness, yet at the cost of compromising standard accuracy. Moreover, the training process is heavy and hence it becomes impractical to thoroughly explore the trade-off between accuracy and robustness. This paper asks this new question: how to quickly calibrate a trained model in-situ, to examine the achievable trade-offs between its standard and robust accuracies, without (re-)training it many times? Our proposed framework, Once-for-all Adversarial Training (OAT), is built on an innovative model-conditional training framework, with a controlling hyper-parameter as the input. The trained model could be adjusted among different standard and robust accuracies “for free” at testing time. As an important knob, we exploit dual batch normalization to separate standard and adversarial feature statistics, so that they can be learned in one model without degrading performance. We further extend OAT to a Once-for-all Adversarial Training and Slimming (OATS) framework, that allows for the joint trade-off among accuracy, robustness and runtime efficiency. Experiments show that, without any re-training nor ensembling, OAT/OATS achieve similar or even superior performance compared to dedicatedly trained models at various configurations. Our codes and pretrained models are available at: https://github.com/VITA-Group/Once-for-All-Adversarial-Training."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Part-dependent Label Noise", "Title": "Towards Instance-dependent Label Noise", "Abstract": "Learning with the \\textit{instance-dependent} label noise is challenging, because it is hard to model such real-world noise. Note that there are psychological and physiological evidences showing that we humans perceive instances by decomposing them into parts. Annotators are therefore more likely to annotate instances based on the parts rather than the whole instances, where a wrong mapping from parts to classes may cause the instance-dependent label noise. Motivated by this human cognition, in this paper, we approximate the instance-dependent label noise by exploiting \\textit{part-dependent} label noise. Specifically, since instances can be approximately reconstructed by a combination of parts, we approximate the instance-dependent \\textit{transition matrix} for an instance by a combination of the transition matrices for the parts of the instance. The transition matrices for parts can be learned by exploiting anchor points (i.e., data points that belong to a specific class almost surely). Empirical evaluations on synthetic and real-world datasets demonstrate our method is superior to the state-of-the-art approaches for learning from the instance-dependent label noise."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ICAM", "Title": "Interpretable Classification via Disentangled Representations and Feature Attribution Mapping", "Abstract": "Feature attribution (FA), or the assignment of class-relevance to different locations in an image, is important for many classification problems but is particularly crucial within the neuroscience domain, where accurate mechanistic models of behaviours, or disease, require knowledge of all features discriminative of a trait. At the same time, predicting class relevance from brain images is challenging as phenotypes are typically heterogeneous, and changes occur against a background of significant natural variation.  Here, we present a novel framework for creating class specific FA maps through image-to-image translation. We propose the use of a VAE-GAN to explicitly disentangle class relevance from background features for improved interpretability properties, which results in meaningful FA maps. We validate our method on 2D and 3D brain image datasets of dementia (ADNI dataset), ageing (UK Biobank), and (simulated) lesion detection. We show that FA maps generated by our method outperform baseline FA methods when validated against ground truth. More significantly, our approach is the first to use latent space sampling to support exploration of phenotype variation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Homophily in Graph Neural Networks", "Title": "Current Limitations and Effective Designs", "Abstract": "We investigate the representation power of graph neural networks in the semi-supervised node classification task under heterophily or low homophily, i.e., in networks where connected nodes may have different class labels and dissimilar features. Many popular GNNs fail to generalize to this setting, and are even outperformed by models that ignore the graph structure (e.g., multilayer perceptrons). Motivated by this limitation, we identify a set of key designs—ego- and neighbor-embedding separation, higher-order neighborhoods, and combination of intermediate representations—that boost learning from the graph structure under heterophily. We combine them into a graph neural network, H2GCN, which we use as the base method to empirically evaluate the effectiveness of the identified designs. Going beyond the traditional benchmarks with strong homophily, our empirical analysis shows that the identified designs increase the accuracy of GNNs by up to 40% and 27% over models without them on synthetic and real networks with heterophily, respectively, and yield competitive performance under homophily."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Efficient Online Learning of Optimal Rankings", "Title": "Dimensionality Reduction via Gradient Descent", "Abstract": "The widely studied Generalized Min-Sum-Set-Cover (GMSSC) problem serves as a formal model for the setting above. GMSSC is NP-hard and the standard application of no-regret online learning algorithms is computationally inefficient, because they operate in the space of rankings. In this work, we show how to achieve low regret for GMSSC in polynomial-time. We employ dimensionality reduction from rankings to the space of doubly stochastic matrices, where we apply Online Gradient Descent. A key step is to show how subgradients can be computed efficiently, by solving the dual of a configuration LP. Using deterministic and randomized rounding schemes, we map doubly stochastic matrices back to rankings with a small loss in the GMSSC objective."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Theory of Transfer Learning", "Title": "The Importance of Task Diversity", "Abstract": "We provide new statistical guarantees for transfer learning via representation learning--when transfer is achieved by learning a feature representation shared across different tasks. This enables learning on new tasks using far less data than is required to learn them in isolation. Formally, we consider $t+1$ tasks parameterized by functions of the form $f_j \\circ h$ in a general function class $F \\circ H$, where each $f_j$ is a task-specific function in $F$ and $h$ is the shared representation in $H$. Letting $C(\\cdot)$ denote the complexity measure of the function class, we show that for diverse training tasks (1) the sample complexity needed to learn the shared representation across the first $t$ training tasks scales as $C(H) + t C(F)$, despite no explicit access to a signal from the feature representation and (2) with an accurate estimate of the representation, the sample complexity needed to learn a new task scales only with $C(F)$. Our results depend upon a new general notion of task diversity--applicable to models with general tasks, features, and losses--as well as a novel chain rule for Gaussian complexities. Finally, we exhibit the utility of our general framework in several models of importance in the literature."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pontryagin Differentiable Programming", "Title": "An End-to-End Learning and Control Framework", "Abstract": "This paper develops a Pontryagin differentiable programming (PDP) methodology, which establishes a unified framework to solve a broad class of learning and control tasks. The PDP  distinguishes from existing methods by two novel techniques: first, we  differentiate through Pontryagin's Maximum Principle,  and this allows  to obtain the analytical derivative of a  trajectory with respect to tunable parameters within an optimal control system,  enabling end-to-end learning of   dynamics, policies, or/and control objective functions; and second, we propose an auxiliary control system in the backward pass of the PDP framework, and  the output of this auxiliary control system is the analytical derivative of the original system's trajectory with respect to the  parameters, which can be iteratively solved using standard control tools. We investigate three learning modes of the PDP: inverse reinforcement learning,  system identification, and  control/planning. We demonstrate the capability of the PDP in each learning mode on different high-dimensional systems, including multilink robot arm,  6-DoF maneuvering UAV, and 6-DoF rocket powered landing."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Devil is in the Detail", "Title": "A Framework for Macroscopic Prediction via Microscopic Models", "Abstract": "Macroscopic data aggregated from microscopic events are pervasive in machine learning, such as country-level COVID-19 infection statistics based on city-level data. Yet, many existing approaches for predicting macroscopic behavior only use aggregated data, leaving a large amount of fine-grained microscopic information unused. In this paper, we propose a principled optimization framework  for macroscopic prediction by fitting microscopic models based on conditional stochastic optimization. The framework leverages both macroscopic and microscopic information, and adapts to individual microscopic models involved in the aggregation. In addition, we propose efficient learning algorithms with convergence  guarantees. In our experiments, we show that the proposed learning framework clearly outperforms other plug-in supervised learning approaches in real-world applications, including the prediction of daily infections of COVID-19 and medicare claims."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Glow-TTS", "Title": "A Generative Flow for Text-to-Speech via Monotonic Alignment Search", "Abstract": "Recently, text-to-speech (TTS) models such as FastSpeech and ParaNet have been proposed to generate mel-spectrograms from text in parallel. Despite the advantage, the parallel TTS models cannot be trained without guidance from autoregressive TTS models as their external aligners. In this work, we propose Glow-TTS, a flow-based generative model for parallel TTS that does not require any external aligner. By combining the properties of flows and dynamic programming, the proposed model searches for the most probable monotonic alignment between text and the latent representation of speech on its own. We demonstrate that enforcing hard monotonic alignments enables robust TTS, which generalizes to long utterances, and employing generative flows enables fast, diverse, and controllable speech synthesis. Glow-TTS obtains an order-of-magnitude speed-up over the autoregressive model, Tacotron 2, at synthesis with comparable speech quality. We further show that our model can be easily extended to a multi-speaker setting."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One Solution is Not All You Need", "Title": "Few-Shot Extrapolation via Structured MaxEnt RL", "Abstract": "While reinforcement learning algorithms can learn effective policies for complex tasks, these policies are often brittle to even minor task variations, especially when variations are not explicitly provided during training. One natural approach to this problem is to train agents with manually specified variation in the training task or environment. However, this may be infeasible in practical situations, either because making perturbations is not possible, or because it is unclear how to choose suitable perturbation strategies without sacrificing performance. The key insight of this work is that learning diverse behaviors for accomplishing a task can directly lead to behavior that generalizes to varying environments, without needing to perform explicit perturbations during training. By identifying multiple solutions for the task in a single environment during training, our approach can generalize to new situations by abandoning solutions that are no longer effective and adopting those that are. We theoretically characterize a robustness set of environments that arises from our algorithm and empirically find that our diversity-driven approach can extrapolate to various changes in the environment and task."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Nimble", "Title": "Lightweight and Parallel GPU Task Scheduling for Deep Learning", "Abstract": "Deep learning (DL) frameworks take advantage of GPUs to improve the speed of DL inference and training. Ideally, DL frameworks should be able to fully utilize the computation power of GPUs such that the running time depends on the amount of computation assigned to GPUs. Yet, we observe that in scheduling GPU tasks, existing DL frameworks suffer from inefficiencies such as large scheduling overhead and unnecessary serial execution. To this end, we propose Nimble, a DL execution engine that runs GPU tasks in parallel with minimal scheduling overhead. Nimble introduces a novel technique called ahead-of-time (AoT) scheduling. Here, the scheduling procedure finishes before executing the GPU kernel, thereby removing most of the scheduling overhead during run time. Furthermore, Nimble automatically parallelizes the execution of GPU tasks by exploiting multiple GPU streams in a single GPU. Evaluation on a variety of neural networks shows that compared to PyTorch, Nimble speeds up inference and training by up to 22.34× and 3.61×, respectively. Moreover, Nimble outperforms state-of-the-art inference systems, TensorRT and TVM, by up to 2.81× and 1.70×, respectively."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Classification Under Misspecification", "Title": "Halfspaces, Generalized Linear Models, and Evolvability", "Abstract": "In this paper, we revisit the problem of distribution-independently learning halfspaces under Massart noise with rate $\\eta$. Recent work resolved a long-standing problem in this model of efficiently learning to error $\\eta + \\epsilon$ for any $\\epsilon > 0$, by giving an improper learner that partitions space into $\\text{poly}(d,1/\\epsilon)$ regions. Here we give a much simpler algorithm and settle a number of outstanding open questions:\n\n(1) We give the first \\emph{proper} learner for Massart halfspaces that achieves $\\eta + \\epsilon$.\n(2) Based on (1), we develop a blackbox knowledge distillation procedure to convert an arbitrarily complex classifier to an equally good proper classifier.\n(3) By leveraging a simple but overlooked connection to \\emph{evolvability}, we show any SQ algorithm requires super-polynomially many queries to achieve $\\mathsf{OPT} + \\epsilon$.\n\nWe then zoom out to study generalized linear models and give an efficient algorithm for learning under a challenging new corruption model generalizing Massart noise. Finally we study our algorithm for learning halfspaces under Massart noise empirically and find that it exhibits some appealing fairness properties as a byproduct of its strong provable robustness guarantees."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond the Mean-Field", "Title": "Structured Deep Gaussian Processes Improve the Predictive Uncertainties", "Abstract": "Deep Gaussian Processes learn probabilistic data representations for supervised learning by cascading multiple Gaussian Processes. While this model family promises flexible predictive distributions, exact inference is not tractable. Approximate inference techniques trade off the ability to closely resemble the posterior distribution against speed of convergence and computational efficiency. We propose a novel Gaussian variational family that allows for retaining covariances between latent processes while achieving fast convergence by marginalising out all global latent variables. After providing a proof of how this marginalisation can be done for general covariances, we restrict them to the ones we empirically found to be most important in order to also achieve computational efficiency. We provide an efficient implementation of our new approach and apply it to several benchmark datasets. It yields excellent results and strikes a better balance between accuracy and calibrated uncertainty estimates than its state-of-the-art alternatives."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PlanGAN", "Title": "Model-based Planning With Sparse Rewards and Multiple Goals", "Abstract": "Learning with sparse rewards remains a significant challenge in reinforcement learning (RL), especially when the aim is to train a policy capable of achieving multiple different goals. To date, the most successful approaches for dealing with multi-goal, sparse reward environments have been model-free RL algorithms. In this work we propose PlanGAN, a model-based algorithm specifically designed for solving multi-goal tasks in environments with sparse rewards. Our method builds on the fact that any trajectory of experience collected by an agent contains useful information about how to achieve the goals observed during that trajectory. We use this to train an ensemble of conditional generative models (GANs) to generate plausible trajectories that lead the agent from its current state towards a specified goal. We then combine these imagined trajectories into a novel planning algorithm in order to achieve the desired goal as efficiently as possible. The performance of PlanGAN has been tested on a number of robotic navigation/manipulation tasks in comparison with a range of model-free reinforcement learning baselines, including Hindsight Experience Replay. Our studies indicate that  PlanGAN can achieve comparable performance whilst being around 4-8 times more sample efficient."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Characterizing Optimal Mixed Policies", "Title": "Where to Intervene and What to Observe", "Abstract": "Intelligent agents are continuously faced with the challenge of optimizing a policy based on what they can observe (see) and which actions they can take (do) in the environment where they are deployed. Most policy can be parametrized in terms of these two dimensions, i.e., as a function of what can be seen and done given a certain situation, which we call a \\textit{mixed policy}. In this paper, we investigate several properties of the class of mixed policies and provide an efficient and effective characterization, including optimality and non-redundancy. Specifically, we introduce a graphical criterion to identify unnecessary contexts for a set of actions, leading to a natural characterization of non-redundancy of mixed policies. We then derive sufficient conditions under which one strategy can dominate the other with respect to their maximum achievable expected rewards (optimality). This characterization leads to a fundamental understanding of the space of mixed policies and a possible refinement of the agent's strategy so that it converges to the optimum faster and more robustly. One surprising result of the causal characterization is that the agent following a more standard approach --- intervening on all intervenable variables and observing all available contexts --- may be hurting itself, and will never achieve an optimal performance."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoPrivacy", "Title": "Automated Layer-wise Parameter Selection for Secure Neural Network Inference", "Abstract": "Hybrid Privacy-Preserving Neural Network (HPPNN) implementing linear layers by Homomorphic Encryption (HE) and nonlinear layers by Garbled Circuit (GC) is one of the most promising secure solutions to emerging Machine Learning as a Service (MLaaS). Unfortunately, a HPPNN suffers from long inference latency, e.g., $\\sim100$ seconds per image, which makes MLaaS unsatisfactory. Because HE-based linear layers of a HPPNN cost $93\\%$ inference latency, it is critical to select a set of HE parameters to minimize computational overhead of linear layers. Prior HPPNNs over-pessimistically select huge HE parameters to maintain large noise budgets, since they use the same set of HE parameters for an entire network and ignore the error tolerance capability of a network.  \n\nIn this paper, for fast and accurate secure neural network inference, we propose an automated layer-wise parameter selector, AutoPrivacy, that leverages deep reinforcement learning to automatically determine a set of HE parameters for each linear layer in a HPPNN. The learning-based HE parameter selection policy outperforms conventional rule-based HE parameter selection policy. Compared to prior HPPNNs, AutoPrivacy-optimized HPPNNs reduce inference latency by $53\\%\\sim70\\%$ with negligible loss of accuracy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AdaShare", "Title": "Learning What To Share For Efficient Deep Multi-Task Learning", "Abstract": "Multi-task learning is an open and challenging problem in computer vision. The typical way of conducting multi-task learning with deep neural networks is either through handcrafted schemes that share all initial layers and branch out at an adhoc point, or through separate task-specific networks with an additional feature sharing/fusion mechanism.   Unlike existing methods,  we propose an adaptive sharing approach, calledAdaShare, that decides what to share across which tasks to achieve the best recognition accuracy, while taking resource efficiency into account. Specifically, our main idea is to learn the sharing pattern through a task-specific policy that selectively chooses which layers to execute for a given task in the multi-task network. We efficiently optimize the task-specific policy jointly with the network weights, using standard back-propagation. Experiments on several challenging and diverse benchmark datasets with a variable number of tasks well demonstrate the efficacy of our approach over state-of-the-art methods.  Project page: https://cs-people.bu.edu/sunxm/AdaShare/project.html"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Exemplar VAE", "Title": "Linking Generative Models, Nearest Neighbor Retrieval, and Data Augmentation", "Abstract": "We introduce Exemplar VAEs, a family of generative models that bridge the\ngap between parametric and non-parametric, exemplar based generative models.\nExemplar VAE is a variant of VAE with a non-parametric latent prior based on a Parzen window estimator. To sample from it, one first draws a random exemplar from a training set, then stochastically transforms that exemplar into a latent code and a new observation. We propose retrieval augmented training (RAT) as a way to speed up Exemplar VAE training by using approximate nearest neighbor search in the latent space to define a lower bound on log marginal likelihood. To enhance generalization, model parameters are learned using exemplar leave-one-out and subsampling. Experiments demonstrate the effectiveness of Exemplar VAEs on density estimation and representation learning. \nImportantly, generative data augmentation using Exemplar VAEs on permutation invariant MNIST and Fashion MNIST reduces classification error from 1.17% to 0.69% and from 8.56% to 8.16%."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COT-GAN", "Title": "Generating Sequential Data via Causal Optimal Transport", "Abstract": "We introduce COT-GAN, an adversarial algorithm to train implicit generative models optimized for producing sequential data. The loss function of this algorithm is formulated using ideas from Causal Optimal Transport (COT), which combines classic optimal transport methods with an additional temporal causality constraint. Remarkably, we find that this causality condition provides a natural framework to parameterize the cost function that is learned by the discriminator as a robust (worst-case) distance, and an ideal mechanism for learning time dependent data distributions. Following Genevay et al. (2018), we also include an entropic penalization term which allows for the use of the Sinkhorn algorithm when computing the optimal transport cost.  Our experiments show effectiveness and stability of COT-GAN when generating both low- and high-dimensional time-series data. The success of the algorithm also relies on a new, improved version of the Sinkhorn divergence which demonstrates less bias in learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PEP", "Title": "Parameter Ensembling by Perturbation", "Abstract": "Ensembling is now recognized as an effective approach for increasing the predictive performance and calibration of deep networks.  We introduce a new approach, Parameter Ensembling by Perturbation (PEP), that constructs an ensemble of parameter values as random perturbations of the optimal parameter set from training by a Gaussian with a single variance parameter.  The variance is chosen to maximize the log-likelihood of the ensemble average (𝕃) on the validation data set. Empirically, and perhaps surprisingly, 𝕃 has a well-defined maximum as the variance grows from zero (which corresponds to the baseline model).  Conveniently, calibration level of predictions also tends to grow favorably until the peak of 𝕃 is reached. In most experiments, PEP provides a small improvement in performance, and, in some cases, a substantial improvement in empirical calibration.  We show that this \"PEP effect'' (the gain in log-likelihood) is related to the mean curvature of the likelihood function and the empirical Fisher information. Experiments on ImageNet pre-trained networks including ResNet, DenseNet, and Inception showed improved calibration and likelihood. We further observed a mild improvement in classification accuracy on these networks. Experiments on classification benchmarks such as MNIST and CIFAR-10 showed improved calibration and likelihood, as well as the relationship between the PEP effect and overfitting; this demonstrates that PEP can be used to probe the level of overfitting that occurred during training. In general, no special training procedure or network architecture is needed, and in the case of pre-trained networks, no additional training is needed."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Theoretical Insights Into Multiclass Classification", "Title": "A High-dimensional Asymptotic View", "Abstract": "Contemporary machine learning applications often involve classification tasks with many classes. Despite their extensive use, a precise understanding of the statistical properties and behavior of classification algorithms is still missing, especially in modern regimes where the number of classes is rather large. In this paper, we take a step in this direction by providing the first asymptotically precise analysis of linear multiclass classification. Our theoretical analysis allows us to precisely characterize how the test error varies over different training algorithms, data distributions, problem dimensions as well as number of classes, inter/intra class correlations and class priors. Specifically, our analysis reveals that the classification accuracy is highly distribution-dependent with different algorithms achieving optimal performance for different data distributions and/or training/features sizes. Unlike linear regression/binary classification, the test error in multiclass classification relies on intricate functions of the trained model (e.g., correlation between some of the trained weights) whose asymptotic behavior is difficult to characterize. This challenge is already present in simple classifiers, such as those minimizing a square loss. Our novel theoretical techniques allow us to overcome some of these challenges. The insights gained may pave the way for a precise understanding of other classification algorithms beyond those studied in this paper."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Residual Distillation", "Title": "Towards Portable Deep Neural Networks without Shortcuts", "Abstract": "By transferring both features and gradients between different layers, shortcut connections explored by ResNets allow us to effectively train very deep neural networks up to hundreds of layers.  However, the additional computation costs induced by those shortcuts are often overlooked. For example, during online inference, the shortcuts in ResNet-50 account for about 40 percent of the entire memory usage on feature maps, because the features in the preceding layers cannot be released until the subsequent calculation is completed.   In this work,    for the first time, we consider training the CNN models with shortcuts and deploying them without.   In particular, we propose a novel joint-training framework to train plain CNN  by leveraging the gradients of the ResNet counterpart. During forward step,  the feature maps of the early stages of plain CNN are passed through later stages of both itself and the ResNet counterpart to calculate the loss. During backpropagation,  gradients calculated from a mixture of these two parts are used to update the plainCNN network to solve the gradient vanishing problem. Extensive experiments on ImageNet/CIFAR10/CIFAR100 demonstrate that the plainCNN network without shortcuts generated by our approach can achieve the same level of accuracy as that of the ResNet baseline while achieving about $1.4\\times $ speed-up and $1.25\\times$ memory reduction. We also verified the feature transferability of our  ImageNet pretrained plain-CNN network by fine-tuning it on MIT 67 and Caltech 101.  Our results show that the performance of the plain-CNN is slightly higher than that of its baseline ResNet-50 on these two datasets. The codes are in: \\href{https://github.com/leoozy/JointRD_Neurips2020}{https://github.com/leoozy/JointRD\\_Neurips2020}"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Provably Efficient Neural Estimation of Structural Equation Models", "Title": "An Adversarial Approach", "Abstract": "Structural equation models (SEMs) are widely \nused in sciences, ranging from economics to psychology,\nto uncover causal relationships underlying a complex system\nunder consideration and estimate structural parameters of interest. \nWe study estimation in a class of generalized SEMs where the object \nof interest is defined as the solution to a linear operator equation.\nWe formulate the linear operator equation as a min-max game, where both \nplayers are parameterized by neural networks (NNs), and learn the\nparameters of these neural networks using the stochastic gradient descent.\nWe consider both 2-layer and multi-layer NNs with ReLU activation \nfunctions and prove global convergence in an overparametrized regime, where\nthe number of neurons is diverging. The results are established using \ntechniques from online learning and local linearization of NNs,\nand improve in several aspects the current state-of-the-art. For the first \ntime we provide a tractable estimation procedure for SEMs\nbased on NNs with provable convergence and without the need for sample\nsplitting."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Chaos, Extremism and Optimism", "Title": "Volume Analysis of Learning in Games", "Abstract": "Using these tools, we prove two novel, rather negative properties of MWU in zero-sum games. (1) Extremism: even in games with a unique fully-mixed Nash equilibrium, the system recurrently gets stuck near pure-strategy profiles, despite them being clearly unstable from game-theoretic perspective. (2) Unavoidability: given any set of good states (with a rather relaxed interpretation of “good” states), the system cannot avoid bad states indefinitely."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hamiltonian Monte Carlo using an adjoint-differentiated Laplace approximation", "Title": "Bayesian inference for latent Gaussian models and beyond", "Abstract": "Gaussian latent variable models are a key class of Bayesian hierarchical models with applications in many fields. Performing Bayesian inference on such models can be challenging as Markov chain Monte Carlo algorithms struggle with the geometry of the resulting posterior distribution and can be prohibitively slow. An alternative is to use a Laplace approximation to marginalize out the latent Gaussian variables and then integrate out the remaining hyperparameters using dynamic Hamiltonian Monte Carlo, a gradient-based Markov chain Monte Carlo sampler. To implement this scheme efficiently, we derive a novel adjoint method that propagates the minimal information needed to construct the gradient of the approximate marginal likelihood. This strategy yields a scalable differentiation method that is orders of magnitude faster than state of the art differentiation techniques when the hyperparameters are high dimensional. We prototype the method in the probabilistic programming framework Stan and test the utility of the embedded Laplace approximation on several models, including one where the dimension of the hyperparameter is ∼6,000. Depending on the cases, the benefits can include an alleviation of the geometric pathologies that frustrate Hamiltonian Monte Carlo and a dramatic speed-up."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Glyph", "Title": "Fast and Accurately Training Deep Neural Networks on Encrypted Data", "Abstract": "In this paper, we propose, Glyph, an FHE-based technique to fast and accurately train DNNs on encrypted data by switching between TFHE (Fast Fully Homomorphic Encryption over the Torus) and BGV cryptosystems. Glyph uses logic-operation-friendly TFHE to implement nonlinear activations, while adopts vectorial-arithmetic-friendly BGV to perform multiply-accumulations (MACs). Glyph further applies transfer learning on DNN training to improve test accuracy and reduce the number of MACs between ciphertext and ciphertext in convolutional layers. Our experimental results show Glyph obtains state-of-the-art accuracy, and reduces training latency by 69%~99% over prior FHE-based privacy-preserving techniques on encrypted datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GNNGuard", "Title": "Defending Graph Neural Networks against Adversarial Attacks", "Abstract": "Deep learning methods for graphs achieve remarkable performance on many tasks. However, despite the proliferation of such methods and their success, recent findings indicate that small, unnoticeable perturbations of graph structure can catastrophically reduce performance of even the strongest and most popular Graph Neural Networks (GNNs). Here, we develop GNNGuard, a general defense approach against a variety of training-time attacks that perturb the discrete graph structure. GNNGuard can be straightforwardly incorporated into any GNN. Its core principle is to detect and quantify the relationship between the graph structure and node features, if one exists, and then exploit that relationship to mitigate the negative effects of the attack. GNNGuard learns how to best assign higher weights to edges connecting similar nodes while pruning edges between unrelated nodes. The revised edges then allow the underlying GNN to robustly propagate neural messages in the graph. GNNGuard introduces two novel components, the neighbor importance estimation, and the layer-wise graph memory, and we show empirically that both components are necessary for a successful defense. Across five GNNs, three defense methods, and four datasets, including a challenging human disease graph, experiments show that GNNGuard outperforms existing defense approaches by 15.3% on average. Remarkably, GNNGuard can effectively restore state-of-the-art performance of GNNs in the face of various adversarial attacks, including targeted and non-targeted attacks, and can defend against attacks on heterophily graphs."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Geo-PIFu", "Title": "Geometry and Pixel Aligned Implicit Functions for Single-view Human Reconstruction", "Abstract": "We propose Geo-PIFu, a method to recover a 3D mesh from a monocular color image of a clothed person.  Our method is based on a deep implicit function-based representation to learn latent voxel features using a structure-aware 3D U-Net, to constrain the model in two ways:  first, to resolve feature ambiguities in query point encoding, second, to serve as a coarse human shape proxy to regularize the high-resolution mesh and encourage global shape regularity. We show that, by both encoding query points and constraining global shape using latent voxel features, the reconstruction we obtain for clothed human meshes exhibits less shape distortion and improved surface details compared to competing methods.  We evaluate Geo-PIFu on a recent human mesh public dataset that is 10x larger than the private commercial dataset used in PIFu and previous derivative work.   On average, we exceed the state of the art by 42.7% reduction in Chamfer and Point-to-Surface Distances, and 19.4% reduction in normal estimation errors."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoinDICE", "Title": "Off-Policy Confidence Interval Estimation", "Abstract": "We study high-confidence behavior-agnostic off-policy evaluation in reinforcement learning, where the goal is to estimate a confidence interval on a target policy's value, given only access to a static experience dataset collected by unknown behavior policies. Starting from a function space embedding of the linear program formulation of the Q-function, we obtain an optimization problem with generalized estimating equation constraints. By applying the generalized empirical likelihood method to the resulting Lagrangian, we propose CoinDICE, a novel and efficient algorithm for computing confidence intervals. Theoretically, we prove the obtained confidence intervals are valid, in both asymptotic and finite-sample regimes. Empirically, we show in a variety of benchmarks that the confidence interval estimates are tighter and more accurate than existing methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Color Visual Illusions", "Title": "A Statistics-based Computational Model", "Abstract": "Visual illusions may be explained by the likelihood of patches in real-world images, as argued by input-driven paradigms in Neuro-Science. However, neither the data nor the tools existed in the past to extensively support these explanations. The era of big data opens a new opportunity to study input-driven approaches. We introduce a tool that computes the likelihood of patches, given a large dataset to learn from. Given this tool, we present a model that supports the approach and explains lightness and color visual illusions in a unified manner. Furthermore, our model generates visual illusions in natural images, by applying the same tool, reversely."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Causal Discovery from Soft Interventions with Unknown Targets", "Title": "Characterization and Learning", "Abstract": "One fundamental problem in the empirical sciences is of reconstructing the causal structure that underlies a phenomenon of interest through observation and experimentation. While there exists a plethora of methods capable of learning the equivalence class of causal structures that are compatible with observations, it is less well-understood how to systematically combine observations and experiments to reconstruct the underlying structure. In this paper, we investigate the task of structural learning in non-Markovian systems (i.e., when latent variables affect more than one observable) from a combination of observational and soft experimental data when the interventional targets are unknown. Using causal invariances found across the collection of observational and interventional distributions (not only conditional independences), we define a property called psi-Markov that connects these distributions to a pair consisting of (1) a causal graph D and (2) a set of interventional targets I. Building on this property, our main contributions are two-fold: First, we provide a graphical characterization that allows one to test whether two causal graphs with possibly different sets of interventional targets belong to the same psi-Markov equivalence class. Second, we develop an algorithm capable of harnessing the collection of data to learn the corresponding equivalence class. We then prove that this algorithm is sound and complete, in the sense that it is the most informative in the sample limit, i.e., it discovers as many tails and arrowheads as can be oriented within a psi-Markov equivalence class."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BoxE", "Title": "A Box Embedding Model for Knowledge Base Completion", "Abstract": "Knowledge base completion (KBC) aims to automatically infer missing facts by exploiting information already present in a knowledge base (KB). A promising approach for KBC is to embed knowledge into latent spaces and make predictions from learned embeddings.  However, existing embedding models are subject to at least one of the following limitations: (1) theoretical inexpressivity, (2) lack of support for prominent inference patterns (e.g., hierarchies), (3) lack of support for KBC over higher-arity relations, and (4) lack of support for incorporating logical rules. Here, we propose a spatio-translational embedding model, called BoxE, that simultaneously addresses all these limitations.  BoxE embeds entities as points, and relations as a set of hyper-rectangles (or boxes), which spatially characterize basic logical properties. This seemingly simple abstraction yields a fully expressive model offering a natural encoding for many desired logical properties. BoxE can both capture and inject rules from rich classes of rule languages, going well beyond individual inference patterns.  By design, BoxE naturally applies to higher-arity KBs. We conduct a detailed experimental analysis, and show that BoxE achieves state-of-the-art performance, both on benchmark knowledge graphs and on more general KBs, and we empirically show the power of integrating logical rules."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MultiON", "Title": "Benchmarking Semantic Map Memory using Multi-Object Navigation", "Abstract": "We propose the multiON task, which requires navigation to an episode-specific sequence of objects in a realistic environment. MultiON generalizes the ObjectGoal navigation task and explicitly tests the ability of navigation agents to locate previously observed goal objects. We perform a set of multiON experiments to examine how a variety of agent models perform across a spectrum of navigation task complexities. Our experiments show that: i) navigation performance degrades dramatically with escalating task complexity; ii) a simple semantic map agent performs surprisingly well relative to more complex neural image feature map agents; and iii) even oracle map agents achieve relatively low performance, indicating the potential for future work in training embodied navigation agents using maps."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ShapeFlow", "Title": "Learnable Deformation Flows Among 3D Shapes", "Abstract": "We present ShapeFlow, a flow-based model for learning a deformation space for entire classes of 3D shapes with large intra-class variations. ShapeFlow allows learning a multi-template deformation space that is agnostic to shape topology, yet preserves fine geometric details. Different from a generative space where a latent vector is directly decoded into a shape, a deformation space decodes a vector into a continuous flow that can advect a source shape towards a target. Such a space naturally allows the disentanglement of  geometric style (coming from the source) and structural pose (conforming to the target). We parametrize the deformation between geometries as a learned continuous flow field via a neural network and show that such deformations can be guaranteed to have desirable properties, such as bijectivity, freedom from self-intersections, or volume preservation. We illustrate the effectiveness of this learned deformation space for various downstream applications, including shape generation via deformation, geometric style transfer, unsupervised learning of a consistent parameterization for entire classes of shapes, and shape interpolation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DynaBERT", "Title": "Dynamic BERT with Adaptive Width and Depth", "Abstract": "The pre-trained language models like BERT, though powerful in many natural language processing tasks, are both computation and memory expensive. To alleviate this problem, one approach is to compress them for specific tasks before deployment. However, recent works on BERT compression usually compress the large BERT model to a fixed smaller size, and can not fully satisfy the requirements of different edge devices with various hardware performances. In this paper, we propose a novel dynamic BERT model (abbreviated as DynaBERT), which can flexibly adjust the size and latency by selecting adaptive width and depth. The training process of DynaBERT includes first training a  width-adaptive BERT and then allowing both adaptive width and depth, by distilling knowledge from the full-sized model to small sub-networks. Network rewiring is also used to  keep the more important attention heads and neurons  shared by more sub-networks. Comprehensive experiments under various efficiency constraints demonstrate that our proposed dynamic BERT (or RoBERTa) at its largest size has comparable performance as BERT-base (or RoBERTa-base), while at smaller widths and depths consistently outperforms existing BERT compression methods.\nCode is available at https://github.com/huawei-noah/Pretrained-Language-Model/tree/master/DynaBERT."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GANSpace", "Title": "Discovering Interpretable GAN Controls", "Abstract": "This paper describes a simple technique to analyze Generative Adversarial Networks (GANs) and create interpretable controls for image synthesis, such as change of viewpoint, aging, lighting, and time of day.  We identify important latent directions based on Principal Component Analysis (PCA) applied either in latent space or feature space. Then, we show that a large number of interpretable controls can be defined by layer-wise perturbation along the principal directions.  Moreover, we show that BigGAN can be controlled with layer-wise inputs in a StyleGAN-like manner. We show results on different GANs trained on various datasets, and demonstrate good qualitative matches to edit directions found through earlier supervised approaches."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Data Diversification", "Title": "A Simple Strategy For Neural Machine Translation", "Abstract": "We introduce Data Diversification: a simple but effective strategy to boost neural machine translation (NMT) performance. It diversifies the training data by using the predictions of multiple forward and backward models and then merging them with the original dataset on which the final NMT model is trained. Our method is applicable to all NMT models. It does not require extra monolingual data like back-translation, nor does it add more computations and parameters like ensembles of models. Our method achieves state-of-the-art BLEU scores of 30.7 and 43.7 in the WMT'14 English-German and English-French translation tasks, respectively. It also substantially improves on 8 other translation tasks: 4 IWSLT tasks (English-German and English-French) and 4 low-resource translation tasks (English-Nepali and English-Sinhala). We demonstrate that our method is more effective than knowledge distillation and dual learning, it exhibits strong correlation with ensembles of models, and it trades perplexity off for better BLEU score."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interstellar", "Title": "Searching Recurrent Architecture for  \tKnowledge Graph Embedding", "Abstract": "Knowledge graph (KG) embedding is well-known in learning representations of KGs. Many models have been proposed to learn the interactions between entities and relations of the triplets. However, long-term information among multiple triplets is also important to KG. In this work, based on the relational paths, which are composed of a sequence of triplets, we define the Interstellar as a recurrent neural architecture search problem for the short-term and long-term information along the paths. First, we analyze the difficulty of using a unified model to work as the Interstellar. Then, we propose to search for recurrent architecture as the Interstellar for different KG tasks. A case study on synthetic data illustrates the importance of the defined search problem. Experiments on real datasets demonstrate the effectiveness of the searched models and the efficiency of the proposed hybrid-search algorithm."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoSE", "Title": "Compositional Stroke Embeddings", "Abstract": "We present a generative model for stroke-based drawing tasks which is able to model complex free-form structures. While previous approaches rely on sequence-based models for drawings of basic objects or handwritten text, we propose a model that treats drawings as a collection of strokes that can be composed into complex structures such as diagrams (e.g., flow-charts). At the core of the approach lies a novel auto-encoder that projects variable-length strokes into a latent space of fixed dimension. This representation space allows a relational model, operating in latent space, to better capture the relationship between strokes and to predict subsequent strokes. We demonstrate qualitatively and quantitatively that our proposed approach is able to model the appearance of individual strokes, as well as the compositional structure of larger diagram drawings. Our approach is suitable for interactive use cases such as auto-completing diagrams. We make code and models publicly available at https://eth-ait.github.io/cose."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaSDF", "Title": "Meta-Learning Signed Distance Functions", "Abstract": "Neural implicit shape representations are an emerging paradigm that offers many potential benefits over conventional discrete representations, including memory efficiency at a high spatial resolution. Generalizing across shapes with such neural implicit representations amounts to learning priors over the respective function space and enables geometry reconstruction from partial or noisy observations. Existing generalization methods rely on conditioning a neural network on a low-dimensional latent code that is either regressed by an encoder or jointly optimized in the auto-decoder framework. Here, we formalize learning of a shape space as a meta-learning problem and leverage gradient-based meta-learning algorithms to solve this task. We demonstrate that this approach performs on par with auto-decoder based approaches while being an order of magnitude faster at test-time inference. We further demonstrate that the proposed gradient-based method outperforms encoder-decoder based methods that leverage pooling-based set encoders."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weighted QMIX", "Title": "Expanding Monotonic Value Function Factorisation for Deep Multi-Agent Reinforcement Learning", "Abstract": "QMIX is a popular $Q$-learning algorithm for cooperative MARL in the centralised training and decentralised execution paradigm.\nIn order to enable easy decentralisation, QMIX restricts the joint action $Q$-values it can represent to be a monotonic mixing of each agent's utilities.\nHowever, this restriction prevents it from representing value functions in which an agent's ordering over its actions can depend on other agents' actions.\nTo analyse this representational limitation, we first formalise the objective QMIX optimises, which allows us to view QMIX as an operator \nthat first computes the $Q$-learning targets and then projects them into the space representable by QMIX.\nThis projection returns a representable $Q$-value that minimises the unweighted squared error across all joint actions.\nWe show in particular that this projection can fail to recover the optimal policy even with access to $Q^*$, which primarily stems from the equal weighting placed on each joint action.\nWe rectify this by introducing a weighting into the projection, in order to place more importance on the better joint actions.\nWe propose two weighting schemes and prove that they recover the correct maximal action for any joint action $Q$-values, and therefore for $Q^*$ as well.\nBased on our analysis and results in the tabular setting we introduce two scalable versions of our algorithm, Centrally-Weighted (CW) QMIX and Optimistically-Weighted (OW) QMIX and demonstrate improved performance on both predator-prey and challenging multi-agent StarCraft benchmark tasks (Samvelyan et al., 2019)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BanditPAM", "Title": "Almost Linear Time k-Medoids Clustering via Multi-Armed Bandits", "Abstract": "Clustering is a ubiquitous task in data science. Compared to the commonly used k-means clustering, k-medoids clustering requires the cluster centers to be actual data points and supports arbitrary distance metrics, which permits greater interpretability and the clustering of structured objects. Current state-of-the-art k-medoids clustering algorithms, such as Partitioning Around Medoids (PAM), are iterative and are quadratic in the dataset size n for each iteration, being prohibitively expensive for large datasets. We propose BanditPAM, a randomized algorithm inspired by techniques from multi-armed bandits, that reduces the complexity of each PAM iteration from O(n^2) to O(nlogn) and returns the same results with high probability, under assumptions on the data that often hold in practice. As such, BanditPAM matches state-of-the-art clustering loss while reaching solutions much faster. We empirically validate our results on several large real-world datasets, including a coding exercise submissions dataset from Code.org, the 10x Genomics 68k PBMC single-cell RNA sequencing dataset, and the MNIST handwritten digits dataset. In these experiments, we observe that BanditPAM returns the same results as state-of-the-art PAM-like algorithms up to 4x faster while performing up to 200x fewer distance computations. The improvements demonstrated by BanditPAM enable k-medoids clustering on a wide range of applications, including identifying cell types in large-scale single-cell data and providing scalable feedback for students learning computer science online. We also release highly optimized Python and C++ implementations of our algorithm."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UDH", "Title": "Universal Deep Hiding for Steganography, Watermarking, and Light Field Messaging", "Abstract": "Neural networks have been shown effective in deep steganography for hiding a full image in another. However, the reason for its success remains not fully clear. Under the existing cover ($C$) dependent deep hiding (DDH) pipeline, it is challenging to analyze how the secret ($S$) image is encoded since the encoded message cannot be analyzed independently. We propose a novel universal deep hiding (UDH) meta-architecture to disentangle the encoding of $S$ from $C$. We perform extensive analysis and demonstrate that the success of deep steganography can be attributed to a frequency discrepancy between $C$ and the encoded secret image. Despite $S$ being hidden in a cover-agnostic manner, strikingly, UDH achieves a performance comparable to the existing DDH. Beyond hiding one image, we push the limits of deep steganography. Exploiting its property of being \\emph{universal}, we propose universal watermarking as a timely solution to address the concern of the exponentially increasing amount of images/videos. UDH is robust to a pixel intensity shift on the container image, which makes it suitable for challenging application of light field messaging (LFM). This is the first work demonstrating the success of (DNN-based) hiding a full image for watermarking and LFM. Code: \\url{https://github.com/ChaoningZhang/Universal-Deep-Hiding}"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoBSS", "Title": "An Efficient Algorithm for Block Stacking Style Search", "Abstract": "Neural network architecture design mostly focuses on the new convolutional operator or special topological structure of network block, little attention is drawn to the configuration of stacking each block, called Block Stacking Style (BSS). Recent studies show that BSS may also have an unneglectable impact on networks, thus we design an efficient algorithm to search it automatically. The proposed method, AutoBSS, is a novel AutoML algorithm based on Bayesian optimization by iteratively refining and clustering Block Stacking Style Code (BSSC), which can find optimal BSS in a few trials without biased evaluation. On ImageNet classification task, ResNet50/MobileNetV2/EfficientNet-B0 with our searched BSS achieve 79.29%/74.5%/77.79%, which outperform the original baselines by a large margin. More importantly, experimental results on model compression, object detection and instance segmentation show the strong generalizability of the proposed AutoBSS, and further verify the unneglectable impact of BSS on neural networks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GPS-Net", "Title": "Graph-based Photometric Stereo Network", "Abstract": "Learning-based photometric stereo methods predict the surface normal either in a per-pixel or an all-pixel manner. Per-pixel methods explore the inter-image intensity variation of each pixel but ignore features from the intra-image spatial domain. All-pixel methods explore the intra-image intensity variation of each input image but pay less attention to the inter-image lighting variation. In this paper, we present a Graph-based Photometric Stereo Network, which unifies per-pixel and all-pixel processings to explore both inter-image and intra-image information. For per-pixel operation, we propose the Unstructured Feature Extraction Layer to connect an arbitrary number of input image-light pairs into graph structures, and introduce Structure-aware Graph Convolution filters to balance the input data by appropriately weighting shadows and specular highlights. For all-pixel operation, we propose the Normal Regression Network to make efficient use of the intra-image spatial information for predicting a surface normal map with rich details. Experimental results on the real-world benchmark show that our method achieves excellent performance under both sparse and dense lighting distributions."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "An Empirical Process Approach to the Union Bound", "Title": "Practical Algorithms for Combinatorial and Linear Bandits", "Abstract": "This paper proposes near-optimal algorithms for the pure-exploration linear bandit problem in the fixed confidence and fixed budget settings. Leveraging ideas from the theory of suprema of empirical processes, we provide an algorithm whose sample complexity scales with the geometry of the instance and avoids an explicit union bound over the number of arms. Unlike previous approaches which sample based on minimizing a worst-case variance (e.g. G-optimal design), we define an experimental design objective based on the Gaussian-width of the underlying arm set.\nWe provide a novel lower bound in terms of this objective that highlights its fundamental role in the sample complexity. The sample complexity of our fixed confidence algorithm matches this lower bound, and in addition is computationally efficient for combinatorial classes, e.g. shortest-path, matchings and matroids, where the arm sets can be exponentially large in the dimension. Finally, we propose the first algorithm for linear bandits in the the fixed budget setting. Its guarantee matches our lower bound up to logarithmic factors."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BRP-NAS", "Title": "Prediction-based NAS using GCNs", "Abstract": "Neural architecture search (NAS) enables researchers to automatically explore broad design spaces in order to improve efficiency of neural networks. This efficiency is especially important in the case of on-device deployment, where improvements in accuracy should be balanced out with computational demands of a model. In practice, performance metrics of model are computationally expensive to obtain. Previous work uses a proxy (e.g., number of operations) or a layer-wise measurement of neural network layers to estimate end-to-end hardware performance but the imprecise prediction diminishes the quality of NAS. To address this problem, we propose BRP-NAS, an efficient hardware-aware NAS enabled by an accurate performance predictor-based on graph convolutional network (GCN). What is more, we investigate prediction quality on different metrics and show that sample efficiency of the predictor-based NAS can be improved by considering binary relations of models and an iterative data selection strategy. We show that our proposed method outperforms all prior methods on NAS-Bench-101, NAS-Bench-201 and DARTS. Finally, to raise awareness of the fact that accurate latency estimation is not a trivial task, we release LatBench -- a latency dataset of NAS-Bench-201 models running on a broad range of devices."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Shells", "Title": "Unsupervised Shape Correspondence with Optimal Transport", "Abstract": "We propose a novel unsupervised learning approach to 3D shape correspondence that builds a multiscale matching pipeline into a deep neural network. This approach is based on smooth shells, the current state-of-the-art axiomatic correspondence method, which requires an a priori stochastic search over the space of initial poses. Our goal is to replace this costly preprocessing step by directly learning good initializations from the input surfaces. To that end, we systematically derive a fully differentiable, hierarchical matching pipeline from entropy regularized optimal transport. This allows us to combine it with a local feature extractor based on smooth, truncated spectral convolution filters. Finally, we show that the proposed unsupervised method significantly improves over the state-of-the-art on multiple datasets, even in comparison to the most recent supervised methods. Moreover, we demonstrate compelling generalization results by applying our learned filters to examples that significantly deviate from the training set."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ISTA-NAS", "Title": "Efficient and Consistent Neural Architecture Search by Sparse Coding", "Abstract": "Neural architecture search (NAS) aims to produce the optimal sparse solution from a high-dimensional space spanned by all candidate connections. Current gradient-based NAS methods commonly ignore the constraint of sparsity in the search phase, but project the optimized solution onto a sparse one by post-processing. As a result, the dense super-net for search is inefficient to train and has a gap with the projected architecture for evaluation. In this paper, we formulate neural architecture search as a sparse coding problem. We perform the differentiable search on a compressed lower-dimensional space that has the same validation loss as the original sparse solution space, and recover an architecture by solving the sparse coding problem. The differentiable search and architecture recovery are optimized in an alternate manner. By doing so, our network for search at each update satisfies the sparsity constraint and is efficient to train. In order to also eliminate the depth and width gap between the network in search and the target-net in evaluation, we further propose a method to search and evaluate in one stage under the target-net settings. When training finishes, architecture variables are absorbed into network weights. Thus we get the searched architecture and optimized parameters in a single run. In experiments, our two-stage method on CIFAR-10 requires only 0.05 GPU-day for search. Our one-stage method produces state-of-the-art performances on both CIFAR-10 and ImageNet at the cost of only evaluation time."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rel3D", "Title": "A Minimally Contrastive Benchmark for Grounding Spatial Relations in 3D", "Abstract": "Understanding spatial relations (e.g., laptop on table) in visual input is important for both humans and robots. Existing datasets are insufficient as they lack large-scale, high-quality 3D ground truth information, which is critical for learning spatial relations. In this paper, we fill this gap by constructing Rel3D: the first large-scale, human-annotated dataset for grounding spatial relations in 3D. Rel3D enables quantifying the effectiveness of 3D information in predicting spatial relations on large-scale human data. Moreover, we propose minimally contrastive data collection---a novel crowdsourcing method for reducing dataset bias. The 3D scenes in our dataset come in minimally contrastive pairs: two scenes in a pair are almost identical, but a spatial relation holds in one and fails in the other. We empirically validate that minimally contrastive examples can diagnose issues with current relation detection models as well as lead to sample-efficient training. Code and data are available at https://github.com/princeton-vl/Rel3D."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Trust the Model When It Is Confident", "Title": "Masked Model-based Actor-Critic", "Abstract": "In this work, we find that better model usage can make a huge difference. We show theoretically that if the use of model-generated data is restricted to state-action pairs where the model error is small, the performance gap between model and real rollouts can be reduced. It motivates us to use model rollouts only when the model is confident about its predictions. We propose Masked Model-based Actor-Critic (M2AC), a novel policy optimization algorithm that maximizes a model-based lower-bound of the true value function. M2AC implements a masking mechanism based on the model's uncertainty estimation to decide whether the model should be used or not. Consequently, the new algorithm tends to give robust policy improvements. Experiments on continuous control benchmarks demonstrate that M2AC has strong performance even when using long model rollouts in very noisy environments, and significantly outperforms previous state-of-the-art methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SIRI", "Title": "Spatial Relation Induced Network For Spatial Description Resolution", "Abstract": "Spatial Description Resolution, as a language-guided localization task, is proposed for target location in a panoramic street view, given corresponding language descriptions. Explicitly characterizing an object-level relationship while distilling spatial relationships are currently absent but crucial to this task. Mimicking humans, who sequentially traverse spatial relationship words and objects with a first-person view to locate their target, we propose a novel spatial relationship induced (SIRI) network. Specifically, visual features are firstly correlated at an implicit object-level in a projected latent space; then they are distilled by each spatial relationship word, resulting in each differently activated feature representing each spatial relationship. Further, we introduce global position priors to fix the absence of positional information, which may result in global positional reasoning ambiguities. Both the linguistic and visual features are concatenated to finalize the target localization. Experimental results on the Touchdown show that our method is around 24\\% better than the state-of-the-art method in terms of accuracy, measured by an 80-pixel radius. Our method also generalizes well on our proposed extended dataset collected using the same settings as Touchdown. The code for this project is\npublicly available at https://github.com/wong-puiyiu/siri-sdr."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HM-ANN", "Title": "Efficient Billion-Point Nearest Neighbor Search on Heterogeneous Memory", "Abstract": "The state-of-the-art approximate nearest neighbor search (ANNS) algorithms face a fundamental tradeoff between query latency and accuracy, because of small main memory capacity: To store indices in main memory for short query latency, the ANNS algorithms have to limit dataset size or use a quantization scheme which hurts search accuracy. The emergence of heterogeneous memory (HM) brings a solution to significantly increase memory capacity and break the above tradeoff: Using HM, billions of data points can be placed in the main memory on a single machine without using any data compression. However, HM consists of both fast (but small) memory and slow (but large) memory, and using HM inappropriately slows down query significantly. \nIn this work, we present a novel graph-based similarity search algorithm called HM-ANN, which takes both memory and data heterogeneity into consideration and enables billion-scale similarity search on a single node without using compression. On two billion-sized datasets BIGANN and DEEP1B, HM-ANN outperforms state-of-the-art compression-based solutions such as L&C and IMI+OPQ in recall-vs-latency by a large margin, obtaining 46% higher recall under the same search latency. We also extend existing graph-based methods such as HNSW and NSG with two strong baseline implementations on HM. At billion-point scale, HM-ANN is 2X and 5.8X faster than our HNSWand NSG baselines respectively to reach the same accuracy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FrugalML", "Title": "How to use ML Prediction APIs more accurately and cheaply", "Abstract": "Offering prediction APIs for fee is a fast growing industry and is an important aspect of machine learning as a service. While many such services are available, the heterogeneity in their price and performance makes it challenging for users to decide which API or combination of APIs to use for their own data and budget. We take a first step towards addressing this challenge by proposing FrugalML, a principled framework that jointly learns the strength and weakness of each API on different data, and performs an efficient optimization to automatically identify the best sequential strategy to adaptively use the available APIs within a budget constraint. Our theoretical analysis shows that natural sparsity in the formulation can be leveraged to make FrugalML efficient. We conduct systematic experiments using ML APIs from Google, Microsoft, Amazon, IBM, Baidu and other providers for tasks including facial emotion recognition, sentiment analysis and speech recognition. Across various tasks, FrugalML can achieve up to 90% cost reduction while matching the accuracy of the best single API, or up to 5% better accuracy while matching the best API’s cost."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Discover, Hallucinate, and Adapt", "Title": "Open Compound Domain Adaptation for Semantic Segmentation", "Abstract": "Unsupervised domain adaptation (UDA) for semantic segmentation has been attracting attention recently, as it could be beneficial for various label-scarce real-world scenarios (e.g., robot control, autonomous driving, medical imaging, etc.). Despite the significant progress in this field, current works mainly focus on a single-source single-target setting, which cannot handle more practical settings of multiple targets or even unseen targets. \nIn this paper, we investigate open compound domain adaptation (OCDA), which deals with mixed and novel situations at the same time, for semantic segmentation.\nWe present a novel framework based on three main design principles: discover, hallucinate, and adapt. The scheme first clusters compound target data based on style, discovering multiple latent domains (discover). Then, it hallucinates multiple latent target domains in source by using image-translation (hallucinate). This step ensures the latent domains in the source and the target to be paired. Finally, target-to-source alignment is learned separately between domains (adapt). In high-level, our solution replaces a hard OCDA problem with much easier multiple UDA problems.\nWe evaluate our solution on standard benchmark GTA to C-driving, and achieved new state-of-the-art results."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SURF", "Title": "A Simple, Universal, Robust, Fast Distribution Learning Algorithm", "Abstract": "Sample- and computationally-efficient distribution estimation is a fundamental tenet in statistics and machine learning. We present $\\SURF$, an algorithm for approximating distributions by piecewise polynomials. $\\SURF$ is:\nsimple, replacing prior complex optimization techniques by straight-forward empirical probability approximation of each potential polynomial piece through simple empirical-probability interpolation, and using plain divide-and-conquer to merge the pieces; universal, as well-known  polynomial-approximation results imply that it accurately approximates a large class of common distributions; \nrobust to distribution mis-specification as for any degree $d \\le 8$, it estimates any distribution to an $\\ell_1$ distance $< 3$ times that of the nearest degree-$d$ piecewise polynomial, improving known factor upper bounds of 3 for single polynomials and 15 for polynomials with arbitrarily many pieces;\nfast, using optimal sample complexity, running in near sample-linear time, and if given sorted samples it may be parallelized to run in sub-linear time.\nIn experiments, $\\SURF$ outperforms state-of-the art algorithms."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "General Transportability of Soft Interventions", "Title": "Completeness Results", "Abstract": "The challenge of generalizing causal knowledge across different environments is pervasive in scientific explorations, including in AI, ML, and Data Science. Experiments are usually performed in one environment (e.g., in a lab, on Earth) with the intent, almost invariably, of being used elsewhere (e.g., outside the lab, on Mars), where the conditions are likely to be different.  In the causal inference literature, this generalization task has been formalized under the rubric of transportability (Pearl and Bareinboim, 2011), where a number of criteria and algorithms have been developed for various settings. Despite the generality of such results, transportability theory has been confined to atomic, do()-interventions. In practice, many real-world applications require more complex, stochastic interventions; for instance, in reinforcement learning, agents need to continuously adapt to the changing conditions of an uncertain and unknown environment.  \nIn this paper, we extend transportability theory to encompass these more complex types of interventions, which are known as \"soft,\" both relative to the input as well as the target distribution of the analysis. Specifically, we develop a graphical condition that is both necessary and sufficient for deciding soft-transportability. Second, we develop an algorithm to determine whether a non-atomic intervention is computable from a combination of the distributions available across domains. As a corollary, we show that the $\\sigma$-calculus is complete for the task of soft-transportability."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GAIT-prop", "Title": "A biologically plausible learning rule derived from backpropagation of error", "Abstract": "Traditional backpropagation of error, though a highly successful algorithm for learning in artificial neural network models, includes features which are biologically implausible for learning in real neural circuits. An alternative called target propagation proposes to solve this implausibility by using a top-down model of neural activity to convert an error at the output of a neural network into layer-wise and plausible ‘targets’ for every unit. These targets can then be used to produce weight updates for network training. However, thus far, target propagation has been heuristically proposed without demonstrable equivalence to backpropagation. Here, we derive an exact correspondence between backpropagation and a modified form of target propagation (GAIT-prop) where the target is a small perturbation of the forward pass. Specifically, backpropagation and GAIT-prop give identical updates when synaptic weight matrices are orthogonal. In a series of simple computer vision experiments, we show near-identical performance between backpropagation and GAIT-prop with a soft orthogonality-inducing regularizer."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SCOP", "Title": "Scientific Control for Reliable Neural Network Pruning", "Abstract": "This paper proposes a reliable neural network pruning algorithm by setting up a scientific control. Existing pruning methods have developed various hypotheses to approximate the importance of filters to the network and then execute filter pruning accordingly. To increase the reliability of the results, we prefer to have a more rigorous research design by including a scientific control group as an essential part to minimize the effect of all factors except the association between the filter and expected network output. Acting as a control group, knockoff feature is generated to mimic the feature map produced by the network filter, but they are conditionally independent of the example label given the real feature map. We theoretically suggest that the knockoff condition can be approximately preserved given the information propagation of network layers.  Besides the real feature map on an intermediate layer, the corresponding knockoff feature is brought in as another auxiliary input signal for the subsequent layers. \nRedundant filters can be discovered in the adversarial process of different features. Through experiments, we demonstrate the superiority of the proposed algorithm over state-of-the-art methods. For example, our method can reduce 57.8% parameters and 60.2% FLOPs of ResNet-101 with only 0.01% top-1 accuracy loss on ImageNet."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sense and Sensitivity Analysis", "Title": "Simple Post-Hoc Analysis of Bias Due to Unobserved Confounding", "Abstract": "It is a truth universally acknowledged that an observed association without known mechanism must be in want of a causal estimate. Causal estimates from observational data will be biased in the presence of ‘unobserved confounding’. However, we might hope that the influence of unobserved confounders is weak relative to a ‘large’ estimated effect. The purpose of this paper is to develop Austen plots, a sensitivity analysis tool to aid such judgments by making it easier to reason about potential bias induced by unobserved confounding. We formalize confounding strength in terms of how strongly the unobserved confounding influences treatment assignment and outcome. For a target level of bias, an Austen plot shows the minimum values of treatment and outcome influence required to induce that level of bias. Austen plots generalize the classic sensitivity analysis approach of Imbens [Imb03]. Critically, Austen plots allow any approach for modeling the observed data. We illustrate the tool by assessing biases for several real causal inference problems, using a variety of machine learning approaches for the initial data analysis. Code, demo data, and a tutorial are available at github.com/anishazaveri/austen_plots."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mix and Match", "Title": "An Optimistic Tree-Search Approach for Learning Models from Mixture Distributions", "Abstract": "We consider a covariate shift problem where one has access to several different\ntraining datasets for the same learning problem and a small validation set\nwhich possibly differs from all the individual training distributions. \nThe distribution shift is due, in part, to \\emph{unobserved} features in the datasets.\nThe objective, then, is to find the best mixture distribution over the training\ndatasets (with only observed features) such that training a learning algorithm\nusing this mixture has the best validation performance. Our proposed algorithm,\n\\textsf{Mix\\&Match}, combines stochastic gradient descent (SGD) with optimistic tree search and model re-use (evolving partially trained models with samples from different mixture distributions) over the space of mixtures, for this task. We prove a novel high probability bound on the final SGD iterate without relying on a global gradient norm bound, and use it to show the advantages of model re-use. Additionally, we provide simple regret guarantees for our algorithm with respect to recovering the optimal mixture, given a total budget of SGD evaluations. Finally, we validate our algorithm on two real-world datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VIME", "Title": "Extending the Success of Self- and Semi-supervised Learning to Tabular Domain", "Abstract": "Self- and semi-supervised learning frameworks have made significant progress in training machine learning models with limited labeled data in image and language domains. These methods heavily rely on the unique structure in the domain datasets (such as spatial relationships in images or semantic relationships in language). They are not adaptable to general tabular data which does not have the same explicit structure as image and language data. In this paper, we fill this gap by proposing novel self- and semi-supervised learning frameworks for tabular data, which we refer to collectively as VIME (Value Imputation and Mask Estimation). We create a novel pretext task of estimating mask vectors from corrupted tabular data in addition to the reconstruction pretext task for self-supervised learning. We also introduce a novel tabular data augmentation method for self- and semi-supervised learning frameworks. In experiments, we evaluate the proposed framework in multiple tabular datasets from various application domains, such as genomics and clinical data. VIME exceeds state-of-the-art performance in comparison to the existing baseline methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Phase retrieval in high dimensions", "Title": "Statistical and computational phase transitions", "Abstract": "We consider the phase retrieval problem of reconstructing a $n$-dimensional real or complex signal $\\mathbf{X}^\\star$ from $m$ (possibly noisy) observations $Y_\\mu = | \\sum_{i=1}^n \\Phi_{\\mu i} X^{\\star}_i/\\sqrt{n}|$, for a large class of correlated real and complex random sensing matrices $\\mathbf{\\Phi}$, in a high-dimensional setting where $m,n\\to\\infty$ while $\\alpha = m/n=\\Theta(1)$. First, we derive sharp asymptotics for the lowest possible estimation error achievable statistically and we unveil the existence of sharp phase transitions for the weak- and full-recovery thresholds as a function of the singular values of the matrix $\\mathbf{\\Phi}$. This is achieved by providing a rigorous proof of a result first obtained by the replica method from statistical mechanics. In particular, the information-theoretic transition to perfect recovery for full-rank matrices appears at $\\alpha=1$ (real case) and  $\\alpha=2$ (complex case). Secondly, we analyze the performance of the best-known polynomial time algorithm for this problem --- approximate message-passing--- establishing the existence of statistical-to-algorithmic gap depending, again, on the spectral properties of $\\mathbf{\\Phi}$. Our work provides an extensive classification of the statistical and algorithmic thresholds in high-dimensional phase retrieval for a broad class of random matrices."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LoCo", "Title": "Local Contrastive Representation Learning", "Abstract": "Deep neural nets typically perform end-to-end backpropagation to learn the weights, a procedure that creates synchronization constraints in the weight update step across layers and is not biologically plausible. Recent advances in unsupervised contrastive representation learning invite the question of whether a learning algorithm can also be made local, that is, the updates of lower layers do not directly depend on the computation of upper layers. While Greedy InfoMax separately learns each block with a local objective, we found that it consistently hurts readout accuracy in state-of-the-art unsupervised contrastive learning algorithms, possibly due to the greedy objective as well as gradient isolation. In this work, we discover that by overlapping local blocks stacking on top of each other, we effectively increase the decoder depth and allow upper blocks to implicitly send feedbacks to lower blocks. This simple design closes the performance gap between local learning and end-to-end contrastive learning algorithms for the first time. Aside from standard ImageNet experiments, we also show results on complex downstream tasks such as object detection and instance segmentation directly using readout features."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SnapBoost", "Title": "A Heterogeneous Boosting Machine", "Abstract": "Modern gradient boosting software frameworks, such as XGBoost and LightGBM, implement Newton descent in a functional space. At each boosting iteration, their goal is to find the base hypothesis, selected from some base hypothesis class, that is closest to the Newton descent direction in a Euclidean sense. Typically, the base hypothesis class is fixed to be all binary decision trees up to a given depth. In this work, we study a Heterogeneous Newton Boosting Machine (HNBM) in which the base hypothesis class may vary across boosting iterations. Specifically, at each boosting iteration, the base hypothesis class is chosen, from a fixed set of subclasses, by sampling from a probability distribution. We derive a global linear convergence rate for the HNBM under certain assumptions, and show that it agrees with existing rates for Newton's method when the Newton direction can be perfectly fitted by the base hypothesis at each boosting iteration. We then describe a particular realization of a HNBM, SnapBoost, that, at each boosting iteration, randomly selects between either a decision tree of variable depth or a linear regressor with random Fourier features. We describe how SnapBoost is implemented, with a focus on the training complexity. Finally, we present experimental results, using OpenML and Kaggle datasets, that show that SnapBoost is able to achieve better generalization loss than competing boosting frameworks, without taking significantly longer to tune."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RELATE", "Title": "Physically Plausible Multi-Object Scene Synthesis Using Structured Latent Spaces", "Abstract": "We present RELATE, a model that learns to generate physically plausible scenes and videos of multiple interacting objects.\nSimilar to other generative approaches, RELATE is trained end-to-end on raw, unlabeled data.\nRELATE combines an object-centric GAN formulation with a model that explicitly accounts for correlations between individual objects.\nThis allows the model to generate realistic scenes and videos from a physically-interpretable parameterization.\nFurthermore, we show that modeling the object correlation is necessary to learn to disentangle object positions and identity.\nWe find that RELATE is also amenable to physically realistic scene editing and that it significantly outperforms prior art in object-centric scene generation in both synthetic (CLEVR, ShapeStacks) and real-world data (cars).\nIn addition, in contrast to state-of-the-art methods in object-centric generative modeling, RELATE also extends naturally to dynamic scenes and generates videos of high visual fidelity. Source code, datasets and more results are available at http://geometry.cs.ucl.ac.uk/projects/2020/relate/."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GreedyFool", "Title": "Distortion-Aware Sparse Adversarial Attack", "Abstract": "Modern deep neural networks(DNNs) are vulnerable to adversarial samples. Sparse adversarial samples are a special branch of adversarial samples that can fool the target model by only perturbing a few pixels. The existence of the sparse adversarial attack points out that DNNs are much more vulnerable than people believed, which is also a new aspect for analyzing DNNs. However, current sparse adversarial attack methods still have some shortcomings on both sparsity and invisibility. In this paper, we propose a novel two-stage distortion-aware greedy-based method dubbed as ''GreedyFool\". Specifically, it first selects the most effective candidate positions to modify by considering both the gradient(for adversary) and the distortion map(for invisibility), then drops some less important points in the reduce stage.\nExperiments demonstrate that compared with the start-of-the-art method, we only need to modify 3 times fewer pixels under the same sparse perturbation setting. For target attack, the success rate of our method is 9.96% higher than the start-of-the-art method under the same pixel budget."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VAEM", "Title": "a Deep Generative Model for Heterogeneous Mixed Type Data", "Abstract": "Deep generative models often perform poorly in real-world applications due to the heterogeneity of natural data sets. Heterogeneity arises from data containing different types of features (categorical, ordinal, continuous, etc.) and  features of the same type having different marginal distributions. We propose an extension of \nvariational autoencoders (VAEs) called VAEM to handle such heterogeneous data. VAEM is a deep generative model that is trained in a two stage manner, such that the first stage provides a more uniform representation of the data to the second stage, thereby sidestepping the problems caused by heterogeneous data.\nWe provide extensions of VAEM to handle partially observed data, and demonstrate its performance in data generation, missing data prediction and sequential feature selection tasks. Our results show that VAEM broadens the range of real-world applications where deep generative models can be successfully deployed."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RetroXpert", "Title": "Decompose Retrosynthesis Prediction Like A Chemist", "Abstract": "Retrosynthesis is the process of recursively decomposing target molecules into available building blocks. It plays an important role in solving problems in organic synthesis planning. To automate or assist in the retrosynthesis analysis, various retrosynthesis prediction algorithms have been proposed. However, most of them are cumbersome and lack interpretability about their predictions. In this paper, we devise a novel template-free algorithm for automatic retrosynthetic expansion inspired by how chemists approach retrosynthesis prediction. Our method disassembles retrosynthesis into two steps: i) identify the potential reaction center of the target molecule through a novel graph neural network and generate intermediate synthons, and ii) generate the reactants associated with synthons via a robust reactant generation model. While outperforming the state-of-the-art baselines by a significant margin, our model also provides chemically reasonable interpretation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TinyTL", "Title": "Reduce Memory, Not Parameters for Efficient On-Device Learning", "Abstract": "Efficient on-device learning requires a small memory footprint at training time to fit the tight memory constraint. Existing work solves this problem by reducing the number of trainable parameters. However, this doesn't directly translate to memory saving since the major bottleneck is the activations, not parameters.\nIn this work, we present Tiny-Transfer-Learning (TinyTL) for memory-efficient on-device learning. TinyTL freezes the weights while only learns the memory-efficient bias modules, thus no need to store the intermediate activations. To maintain the adaptation capacity, we introduce a new memory-efficient bias module, the lite residual module, to refine the feature extractor by learning small residual feature maps adding only 3.8% memory overhead. Extensive experiments show that TinyTL significantly saves the memory (up to 6.5x) with little accuracy loss compared to fine-tuning the full network. Compared to fine-tuning the last layer, TinyTL provides significant accuracy improvements (up to 33.8%) with little memory overhead. Furthermore, combined with feature extractor adaptation, TinyTL provides 7.5-12.9x memory saving without sacrificing accuracy compared to fine-tuning the full Inception-V3. Code is released at https://github.com/mit-han-lab/tinyML/tree/master/tinyTL."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RD$^2$", "Title": "Reward Decomposition with Representation Decomposition", "Abstract": "Reward decomposition, which aims to decompose the full reward into multiple sub-rewards, has been proven beneficial for improving sample efficiency in reinforcement learning. Existing works on discovering reward decomposition are mostly policy dependent, which constrains diverse or disentangled behavior between different policies induced by different sub-rewards. In this work, we propose a set of novel reward decomposition principles by constraining uniqueness and compactness of different state features/representations relevant to different sub-rewards. Our principles encourage sub-rewards with minimal relevant features, while maintaining the uniqueness of each sub-reward. We derive a deep learning algorithm based on our principle, and term our method as RD$^2$, since we learn reward decomposition and representation decomposition jointly. RD$^2$ is evaluated on a toy case, where we have the true reward structure, and some Atari environments where reward structure exists but is unknown to the agent to demonstrate the effectiveness of RD$^2$ against existing reward decomposition methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Factorized Neural Processes for Neural Processes", "Title": "K-Shot Prediction of Neural Responses", "Abstract": "In recent years, artificial neural networks have achieved state-of-the-art performance for predicting the responses of neurons in the visual cortex to natural stimuli. However, they require a time consuming parameter optimization process for accurately modeling the tuning function of newly observed neurons, which prohibits many applications including real-time, closed-loop experiments. We overcome this limitation by formulating the problem as $K$-shot prediction to directly infer a neuron's tuning function from a small set of stimulus-response pairs using a Neural Process. This required us to developed a Factorized Neural Process, which embeds the observed set into a latent space partitioned into the receptive field location and the tuning function properties. We show on simulated responses that the predictions and reconstructed receptive fields from the Factorized Neural Process approach ground truth with increasing number of trials. \nCritically, the latent representation that summarizes the tuning function of a neuron is inferred in a quick, single forward pass through the network. Finally, we validate this approach on real neural data from visual cortex and find that the predictive accuracy is comparable to --- and for small $K$ even greater than --- optimization based approaches, while being substantially faster. We believe this novel deep learning systems identification framework will facilitate better real-time integration of artificial neural network modeling into neuroscience experiments."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "JAX MD", "Title": "A Framework for Differentiable Physics", "Abstract": "We introduce JAX MD, a software package for performing differentiable physics simulations with a focus on molecular dynamics. JAX MD includes a number of statistical physics simulation environments as well as interaction potentials and neural networks that can be integrated into these environments without writing any additional code. Since the simulations themselves are differentiable functions, entire trajectories can be differentiated to perform meta-optimization. These features are built on primitive operations, such as spatial partitioning, that allow simulations to scale to hundreds-of-thousands of particles on a single GPU. These primitives are flexible enough that they can be used to scale up workloads outside of molecular dynamics. We present several examples that highlight the features of JAX MD including: integration of graph neural networks into traditional simulations, meta-optimization through minimization of particle packings, and a multi-agent flocking simulation. JAX MD is available at www.github.com/google/jax-md."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SDF-SRN", "Title": "Learning Signed Distance 3D Object Reconstruction from Static Images", "Abstract": "Dense 3D object reconstruction from a single image has recently witnessed remarkable advances, but supervising neural networks with ground-truth 3D shapes is impractical due to the laborious process of creating paired image-shape datasets. Recent efforts have turned to learning 3D reconstruction without 3D supervision from RGB images with annotated 2D silhouettes, dramatically reducing the cost and effort of annotation. These techniques, however, remain impractical as they still require multi-view annotations of the same object instance during training. As a result, most experimental efforts to date have been limited to synthetic datasets. \nIn this paper, we address this issue and propose SDF-SRN, an approach that requires only a single view of objects at training time, offering greater utility for real-world scenarios. SDF-SRN learns implicit 3D shape representations to handle arbitrary shape topologies that may exist in the datasets. To this end, we derive a novel differentiable rendering formulation for learning signed distance functions (SDF) from 2D silhouettes. Our method outperforms the state of the art under challenging single-view supervision settings on both synthetic and real-world datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaPerturb", "Title": "Transferable Regularizer for Heterogeneous Tasks and Architectures", "Abstract": "Regularization and transfer learning are two popular techniques to enhance model generalization on unseen data, which is a fundamental problem of machine learning. Regularization techniques are versatile, as they are task- and architecture-agnostic, but they do not exploit a large amount of data available. Transfer learning methods learn to transfer knowledge from one domain to another, but may not generalize across tasks and architectures, and may introduce new training cost for adapting to the target task. To bridge the gap between the two, we propose a transferable perturbation, MetaPerturb, which is meta-learned to improve generalization performance on unseen data. MetaPerturb is implemented as a set-based lightweight network that is agnostic to the size and the order of the input, which is shared across the layers.  Then, we propose a meta-learning framework, to jointly train the perturbation function over heterogeneous tasks in parallel. As MetaPerturb is a set-function trained over diverse distributions across layers and tasks, it can generalize to heterogeneous tasks and architectures. We validate the efficacy and generality of MetaPerturb trained on a specific source domain and architecture, by applying it to the training of diverse neural architectures on heterogeneous target datasets against various regularizers and fine-tuning.  The results show that the networks trained with MetaPerturb significantly outperform the baselines on most of the tasks and architectures, with a negligible increase in the parameter size and no hyperparameters to tune."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probabilistic Inference with Algebraic Constraints", "Title": "Theoretical Limits and Practical Approximations", "Abstract": "Weighted model integration (WMI) is a framework to perform advanced probabilistic inference on hybrid domains, i.e., on distributions over mixed continuous-discrete random variables and in presence of complex logical and arithmetic constraints. In this work, we advance the WMI framework on both the theoretical and algorithmic side. First, we exactly trace the boundaries of tractability for WMI inference by proving that to be amenable to exact and efficient inference a WMI problem has to posses a tree-shaped structure with logarithmic diameter. While this result deepens our theoretical understanding of WMI it hinders the practical applicability of exact WMI solvers to real-world problems. To overcome this, we propose the first approximate WMI solver that does not resort to sampling, but performs exact inference on one approximate models. Our solution performs message passing in a relaxed problem structure iteratively to recover certain lost dependencies and, as our experiments suggest, is competitive with other SOTA WMI solvers."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Learned Bloom Filter (Ada-BF)", "Title": "Efficient Utilization of the Classifier with Application to Real-Time Information Filtering on the Web", "Abstract": "Recent work suggests improving the performance of Bloom filter by incorporating a machine learning model as a binary classifier. However, such learned Bloom filter does not take full advantage of the predicted probability scores. We propose new algorithms that generalize the learned Bloom filter by using the complete spectrum of the score regions. We prove our algorithms have lower false positive rate (FPR) and memory usage compared with the existing approaches to learned Bloom filter. We also demonstrate the improved performance of our algorithms on real-world information filtering tasks over the web."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MCUNet", "Title": "Tiny Deep Learning on IoT Devices", "Abstract": "Machine learning on tiny IoT devices based on microcontroller units (MCU) is appealing but challenging: the memory of microcontrollers is 2-3 orders of magnitude smaller even than mobile phones. We propose MCUNet, a framework that jointly designs the efficient neural architecture (TinyNAS) and the lightweight inference engine (TinyEngine), enabling ImageNet-scale inference on microcontrollers. TinyNAS adopts a two-stage neural architecture search approach that first optimizes the search space to fit the resource constraints, then specializes the network architecture in the optimized search space. TinyNAS can automatically handle diverse constraints (i.e. device, latency, energy, memory) under low search costs. TinyNAS is co-designed with TinyEngine, a memory-efficient inference library to expand the search space and fit a larger model. TinyEngine adapts the memory scheduling according to the overall network topology rather than layer-wise optimization, reducing the memory usage by 3.4×, and accelerating the inference by 1.7-3.3× compared to TF-Lite Micro [3] and CMSIS-NN [28]. MCUNet is the first to achieves >70% ImageNet top1 accuracy on an off-the-shelf commercial microcontroller, using 3.5× less SRAM and 5.7× less Flash compared to quantized MobileNetV2 and ResNet-18. On visual&audio wake words tasks, MCUNet achieves state-of-the-art accuracy and runs 2.4-3.4× faster than Mo- bileNetV2 and ProxylessNAS-based solutions with 3.7-4.1× smaller peak SRAM. Our study suggests that the era of always-on tiny machine learning on IoT devices has arrived."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepI2I", "Title": "Enabling Deep Hierarchical Image-to-Image Translation by Transferring from GANs", "Abstract": "Image-to-image translation has recently achieved remarkable results. But despite current success, it suffers from inferior performance when translations between classes require large shape changes. We attribute this to the high-resolution bottlenecks which are used by current state-of-the-art image-to-image methods. \nTherefore, in this work, we propose a novel deep hierarchical Image-to-Image Translation method, called DeepI2I. We learn a model by leveraging  hierarchical features: (a) structural information contained in the bottom layers and (b) semantic information extracted from the top layers.  To enable the training of deep I2I models on small datasets, we propose a novel transfer learning method, that transfers knowledge from pre-trained GANs.  Specifically, we leverage the discriminator of a pre-trained GANs (i.e. BigGAN or StyleGAN) to initialize both the encoder and the discriminator and the pre-trained generator to initialize the generator of our model.  Applying knowledge transfer leads to an alignment problem between the encoder and generator. We introduce an adaptor network to address this.   On many-class image-to-image translation on three datasets (Animal faces, Birds, and Foods) we decrease mFID by at least 35% when compared to the state-of-the-art. Furthermore, we qualitatively and quantitatively demonstrate that transfer learning significantly improves the performance of I2I systems, especially for small datasets. \nFinally, we are the first to perform I2I translations for domains with over 100 classes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CSI", "Title": "Novelty Detection via Contrastive Learning on Distributionally Shifted Instances", "Abstract": "Novelty detection, i.e., identifying whether a given sample is drawn from outside the training distribution, is essential for reliable machine learning. To this end, there have been many attempts at learning a representation well-suited for novelty detection and designing a score based on such representation. In this paper, we propose a simple, yet effective method named contrasting shifted instances (CSI), inspired by the recent success on contrastive learning of visual representations. Specifically, in addition to contrasting a given sample with other instances as in conventional contrastive learning methods, our training scheme contrasts the sample with distributionally-shifted augmentations of itself. Based on this, we propose a new detection score that is specific to the proposed training scheme. Our experiments demonstrate the superiority of our method under various novelty detection scenarios, including unlabeled one-class, unlabeled multi-class and labeled multi-class settings, with various image benchmark datasets. Code and pre-trained models are available at https://github.com/alinlab/CSI."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MATE", "Title": "Plugging in Model Awareness to Task Embedding for Meta Learning", "Abstract": "Meta-learning improves generalization of machine learning models when faced with previously unseen tasks by leveraging experiences from different, yet related prior tasks. To allow for better generalization, we propose a novel task representation called model-aware task embedding (MATE) that incorporates not only the data distributions of different tasks, but also the complexity of the tasks through the models used. The task complexity is taken into account by a novel variant of kernel mean embedding, combined with an instance-adaptive attention mechanism inspired by an SVM-based feature selection algorithm. Together with conditioning layers in deep neural networks, MATE can be easily incorporated into existing meta learners as a plug-and-play module. While MATE is widely applicable to general tasks where the concept of task/environment is involved, we demonstrate its effectiveness in few-shot learning by improving a state-of-the-art model consistently on two benchmarks. Source codes for this paper are available at https://github.com/VITA-Group/MATE."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TSPNet", "Title": "Hierarchical Feature Learning via Temporal Semantic Pyramid for Sign Language Translation", "Abstract": "Sign language translation (SLT) aims to interpret sign video sequences into text-based natural language sentences. Sign videos consist of continuous sequences of sign gestures with no clear boundaries in between. Existing SLT models usually represent sign visual features in a frame-wise manner so as to avoid needing to explicitly segmenting the videos into isolated signs. However, these methods neglect the temporal information of signs and lead to substantial ambiguity in translation. In this paper, we explore the temporal semantic structures of sign videos to learn more discriminative features. To this end, we first present a novel sign video segment representation which takes into account multiple temporal granularities, thus alleviating the need for accurate video segmentation. Taking advantage of the proposed segment representation, we develop a novel hierarchical sign video feature learning method via a temporal semantic pyramid network, called TSPNet. Specifically, TSPNet introduces an inter-scale attention to evaluate and enhance local semantic consistency of sign segments and an intra-scale attention to resolve semantic ambiguity by using non-local video context. Experiments show that our TSPNet outperforms the state-of-the-art with significant improvements on the BLEU score (from 9.58 to 13.41) and ROUGE score (from 31.80 to 34.96) on the largest commonly used SLT dataset. Our implementation is available at https://github.com/verashira/TSPNet."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaPoison", "Title": "Practical General-purpose Clean-label Data Poisoning", "Abstract": "Data poisoning---the process by which an attacker takes control of a model by making imperceptible changes to a subset of the training data---is an emerging threat in the context of neural networks. Existing attacks for data poisoning neural networks have relied on hand-crafted heuristics, because solving the poisoning problem directly via bilevel optimization is generally thought of as intractable for deep models. We propose MetaPoison, a first-order method that approximates the bilevel problem via meta-learning and crafts poisons that fool neural networks. MetaPoison is effective: it outperforms previous clean-label poisoning methods by a large margin. MetaPoison is robust: poisoned data made for one model transfer to a variety of victim models with unknown training settings and architectures. MetaPoison is general-purpose, it works not only in fine-tuning scenarios, but also for end-to-end training from scratch, which till now hasn't been feasible for clean-label attacks with deep nets. MetaPoison can achieve arbitrary adversary goals---like using poisons of one class to make a target image don the label of another arbitrarily chosen class. Finally, MetaPoison works in the real-world. We demonstrate for the first time successful data poisoning of models trained on the black-box Google Cloud AutoML API."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FracTrain", "Title": "Fractionally Squeezing Bit Savings Both Temporally and Spatially for Efficient DNN Training", "Abstract": "Recent breakthroughs in deep neural networks (DNNs) have fueled a tremendous demand for intelligent edge devices featuring on-site learning, while the practical realization of such systems remains a challenge due to the limited resources available at the edge and the required massive training costs for state-of-the-art (SOTA) DNNs. As reducing precision is one of the most effective knobs for boosting training time/energy efficiency, there has been a growing interest in low-precision DNN training. In this paper, we explore from an orthogonal direction: how to fractionally squeeze out more training cost savings from the most redundant bit level, progressively along the training trajectory and dynamically per input. Specifically, we propose FracTrain that integrates (i) progressive fractional quantization which gradually increases the precision of activations, weights, and gradients that will not reach the precision of SOTA static quantized DNN training until the final training stage, and (ii) dynamic fractional quantization which assigns precisions to both the activations and gradients of each layer in an input-adaptive manner, for only \"fractionally\" updating layer parameters. Extensive simulations and ablation studies (six models, four datasets, and three training settings including standard, adaptation, and fine-tuning) validate the effectiveness of FracTrain in reducing computational cost and hardware-quantified energy/latency of DNN training while achieving a comparable or better (-0.12%~+1.87%) accuracy. For example, when training ResNet-74 on CIFAR-10, FracTrain achieves 77.6% and 53.5% computational cost and training latency savings, respectively, compared with the best SOTA baseline, while achieving a comparable (-0.07%) accuracy. Our codes are available at: https://github.com/RICE-EIC/FracTrain."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Leverage the Average", "Title": "an Analysis of KL Regularization in Reinforcement Learning", "Abstract": "Recent Reinforcement Learning (RL) algorithms making use of  Kullback-Leibler (KL) regularization as a core component have shown outstanding performance. Yet, only little is understood theoretically about why KL regularization helps, so far. We study KL regularization within an approximate value iteration scheme and show that it implicitly averages q-values. Leveraging this insight, we provide a very strong performance bound, the very first to combine two desirable aspects: a linear dependency to the horizon (instead of quadratic) and an error propagation term involving an averaging effect of the estimation errors (instead of an accumulation effect). We also study the more general case of an additional entropy regularizer. The resulting abstract scheme encompasses many existing RL algorithms. Some of our assumptions do not hold with neural networks, so we complement this theoretical analysis with an extensive empirical study."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Individualized Recourse", "Title": "Interpretable and Interactive Summaries of Actionable Recourses", "Abstract": "As predictive models are increasingly being deployed in high-stakes decision-making, there has been a lot of interest in developing algorithms which can provide recourses to affected individuals. While developing such tools is important, it is even more critical to analyze and interpret a predictive model, and vet it thoroughly to ensure that the recourses it offers are meaningful and non-discriminatory before it is deployed in the real world. To this end, we propose a novel model agnostic framework called Actionable Recourse Summaries (AReS) to construct global counterfactual explanations which provide an interpretable and accurate summary of recourses for the entire population.  We formulate a novel objective which simultaneously optimizes for correctness of the recourses and interpretability of the explanations, while minimizing overall recourse costs across the entire population. More specifically, our objective enables us to learn, with optimality guarantees on recourse correctness, a small number of compact rule sets each of which capture recourses for well defined subpopulations within the data. We also demonstrate theoretically that several of the prior approaches proposed to generate recourses for individuals are special cases of our framework. Experimental evaluation with real world datasets and user studies demonstrate that our framework can provide decision makers with a comprehensive overview of recourses corresponding to any black box model, and consequently help detect undesirable model biases and discrimination."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization error in high-dimensional perceptrons", "Title": "Approaching Bayes error with convex optimization", "Abstract": "We consider a commonly studied supervised classification of a synthetic dataset whose labels are generated by feeding a one-layer non-linear neural network with random iid inputs. We study the generalization performances of standard classifiers in the high-dimensional regime where $\\alpha=\\frac{n}{d}$ is kept finite in the limit of a high dimension $d$ and number of samples $n$. Our contribution is three-fold: First, we prove a formula for the generalization error achieved by $\\ell_2$ regularized classifiers that minimize a convex loss. This formula was first obtained by the heuristic replica method of statistical physics. Secondly, focussing on commonly used loss functions and optimizing the $\\ell_2$ regularization strength, we observe that while ridge regression performance is poor, logistic and hinge regression are surprisingly able to approach the Bayes-optimal generalization error extremely closely. As $\\alpha \\to \\infty$ they lead to Bayes-optimal rates, a fact that does not follow from predictions of margin-based generalization error bounds. Third, we design an optimal loss and regularizer that provably leads to Bayes-optimal generalization error."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PGM-Explainer", "Title": "Probabilistic Graphical Model Explanations for Graph Neural Networks", "Abstract": "In Graph Neural Networks (GNNs), the graph structure is incorporated into the learning of node representations. This complex structure makes explaining GNNs' predictions become much more challenging. In this paper, we propose PGM-Explainer, a Probabilistic Graphical Model (PGM) model-agnostic explainer for GNNs. Given a prediction to be explained, PGM-Explainer identifies crucial graph components and generates an explanation in form of a PGM approximating that prediction. Different from existing explainers for GNNs where the explanations are drawn from a set of linear functions of explained features, PGM-Explainer is able to demonstrate the dependencies of explained features in form of conditional probabilities. Our theoretical analysis shows that the PGM generated by PGM-Explainer includes the Markov-blanket of the target prediction, i.e. including all its statistical information. We also show that the explanation returned by PGM-Explainer contains the same set of independence statements in the perfect map. Our experiments on both synthetic and real-world datasets show that PGM-Explainer achieves better performance than existing explainers in many benchmark tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Invertible Gaussian Reparameterization", "Title": "Revisiting the Gumbel-Softmax", "Abstract": "The Gumbel-Softmax is a continuous distribution over the simplex that is often used as a relaxation of discrete distributions. Because it can be readily interpreted and easily reparameterized, it enjoys widespread use. We propose a modular and more flexible family of reparameterizable distributions where Gaussian noise is transformed into a one-hot approximation through an invertible function. This invertible function is composed of a modified softmax and can incorporate diverse transformations that serve different specific purposes. For example, the stick-breaking procedure allows us to extend the reparameterization trick to distributions with countably infinite support, thus enabling the use of our distribution along nonparametric models, or normalizing flows let us increase the flexibility of the distribution. Our construction enjoys theoretical advantages over the Gumbel-Softmax, such as closed form KL, and significantly outperforms it in a variety of experiments. Our code is available at https://github.com/cunningham-lab/igr."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Soft Advantage Fitting", "Title": "Imitation Learning without Policy Optimization", "Abstract": "Adversarial Imitation Learning alternates between learning a discriminator -- which tells apart expert's demonstrations from generated ones -- and a generator's policy to produce trajectories that can fool this discriminator. This alternated optimization is known to be delicate in practice since it compounds unstable adversarial training with brittle and sample-inefficient reinforcement learning. We propose to remove the burden of the policy optimization steps by leveraging a novel discriminator formulation. Specifically, our discriminator is explicitly conditioned on two policies: the one from the previous generator's iteration and a learnable policy. When optimized, this discriminator directly learns the optimal generator's policy. Consequently, our discriminator's update solves the generator's optimization problem for free: learning a policy that imitates the expert does not require an additional optimization loop. This formulation effectively cuts by half the implementation and computational burden of Adversarial Imitation Learning algorithms by removing the Reinforcement Learning phase altogether. We show on a variety of tasks that our simpler approach is competitive to prevalent Imitation Learning methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Agree to Disagree", "Title": "Adaptive Ensemble Knowledge Distillation in Gradient Space", "Abstract": "Distilling knowledge from an ensemble of teacher models is expected to have a more promising performance than that from a single one. Current methods mainly adopt a vanilla average rule, i.e., to simply take the average of all teacher losses for training the student network. However, this approach treats teachers equally and ignores the diversity among them. When conflicts or competitions exist among teachers, which is common, the inner compromise might hurt the distillation performance. In this paper, we examine the diversity of teacher models in the gradient space and regard the ensemble knowledge distillation as a multi-objective optimization problem so that we can determine a better optimization direction for the training of student network. Besides, we also introduce a tolerance parameter to accommodate disagreement among teachers. In this way, our method can be seen as a dynamic weighting method for each teacher in the ensemble. Extensive experiments validate the effectiveness of our method for both logits-based and feature-based cases."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "wav2vec 2.0", "Title": "A Framework for Self-Supervised Learning of Speech Representations", "Abstract": "We show for the first time that learning powerful representations from speech audio alone followed by fine-tuning on transcribed speech can outperform the best semi-supervised methods while being conceptually simpler. wav2vec 2.0 masks the speech input in the latent space and solves a contrastive task defined over a quantization of the latent representations which are jointly learned. Experiments using all labeled data of Librispeech achieve 1.8/3.3 WER on the clean/other test sets. When lowering the amount of labeled data to one hour, wav2vec 2.0 outperforms the previous state of the art on the 100 hour subset while using 100 times less labeled data. Using just ten minutes of labeled data and pre-training on 53k hours of unlabeled data still achieves 4.8/8.2 WER. This demonstrates the feasibility of speech recognition with limited amounts of labeled data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CSER", "Title": "Communication-efficient SGD with Error Reset", "Abstract": "The scalability of Distributed Stochastic Gradient Descent (SGD) is today limited by communication bottlenecks. We propose a novel SGD variant: \\underline{C}ommunication-efficient \\underline{S}GD with \\underline{E}rror \\underline{R}eset, or \\underline{CSER}. The key idea in CSER is first a new technique called ``error reset'' that adapts arbitrary compressors for SGD, producing bifurcated local models with periodic reset of resulting local residual errors. \nSecond we introduce partial synchronization for both the gradients and the models, leveraging advantages from them.\nWe prove the convergence of CSER for smooth non-convex problems. \nEmpirical results show that when combined with highly aggressive compressors, the CSER algorithms accelerate the distributed training by nearly $10\\times$ for CIFAR-100, and by $4.5\\times$ for ImageNet."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Forget About the LiDAR", "Title": "Self-Supervised Depth Estimators with MED Probability Volumes", "Abstract": "Self-supervised depth estimators have recently shown results comparable to the supervised methods on the challenging single image depth estimation (SIDE) task, by exploiting the geometrical relations between target and reference views in the training data. However, previous methods usually learn forward or backward image synthesis, but not depth estimation, as they cannot effectively neglect occlusions between the target and the reference images. Previous works rely on rigid photometric assumptions or on the SIDE network to infer depth and occlusions, resulting in limited performance. On the other hand, we propose a method to \"Forget About the LiDAR\" (FAL), with Mirrored Exponential Disparity (MED) probability volumes for the training of monocular depth estimators from stereo images. Our MED representation allows us to obtain geometrically inspired occlusion maps with our novel Mirrored Occlusion Module (MOM), which does not impose a learning burden on our FAL-net. Contrary to the previous methods that learn SIDE from stereo pairs by regressing disparity in the linear space, our FAL-net regresses disparity by binning it into the exponential space, which allows for better detection of distant and nearby objects. We define a two-step training strategy for our FAL-net: It is first trained for view synthesis and then fine-tuned for depth estimation with our MOM. Our FAL-net is remarkably light-weight and outperforms the previous state-of-the-art methods with 8$\\times$ fewer parameters and 3$\\times$ faster inference speeds on the challenging KITTI dataset. We present extensive experimental results on the KITTI, CityScapes, and Make3D datasets to verify our method's effectiveness. To the authors' best knowledge, the presented method performs the best among all the previous self-supervised methods until now."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GS-WGAN", "Title": "A Gradient-Sanitized Approach for Learning Differentially Private Generators", "Abstract": "The wide-spread availability of rich data has fueled the growth of machine learning applications in numerous domains. However, growth in domains with highly-sensitive data (e.g., medical) is largely hindered as the private nature of data prohibits it from being shared. To this end, we propose Gradient-sanitized Wasserstein Generative Adversarial Networks (GS-WGAN), which allows releasing a sanitized form of the sensitive data with rigorous privacy guarantees.\nIn contrast to prior work, our approach is able to distort gradient information more precisely, and thereby enabling training deeper models which generate more informative samples. Moreover, our formulation naturally allows for training GANs in both centralized and federated (i.e., decentralized) data scenarios.\nThrough extensive experiments, we find our approach consistently outperforms state-of-the-art approaches across multiple metrics (e.g., sample quality) and datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SurVAE Flows", "Title": "Surjections to Bridge the Gap between VAEs and Flows", "Abstract": "Normalizing flows and variational autoencoders are powerful generative models that can represent complicated density functions. However, they both impose constraints on the models: Normalizing flows use bijective transformations to model densities whereas VAEs learn stochastic transformations that are non-invertible and thus typically do not provide tractable estimates of the marginal likelihood. In this paper, we introduce SurVAE Flows: A modular framework of composable transformations that encompasses VAEs and normalizing flows. SurVAE Flows bridge the gap between normalizing flows and VAEs with surjective transformations, wherein the transformations are deterministic in one direction -- thereby allowing exact likelihood computation, and stochastic in the reverse direction -- hence providing a lower bound on the corresponding likelihood. We show that several recently proposed methods, including dequantization and augmented normalizing flows, can be expressed as SurVAE Flows. Finally, we introduce common operations such as the max value, the absolute value, sorting and stochastic permutation as composable layers in SurVAE Flows."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Segmentation Networks", "Title": "Modelling Spatially Correlated Aleatoric Uncertainty", "Abstract": "In image segmentation, there is often more than one plausible solution for a given input. In medical imaging, for example, experts will often disagree about the exact location of object boundaries. Estimating this inherent uncertainty and predicting multiple plausible hypotheses is of great interest in many applications, yet this ability is lacking in most current deep learning methods. In this paper, we introduce stochastic segmentation networks (SSNs), an efficient probabilistic method for modelling aleatoric uncertainty with any image segmentation network architecture. In contrast to approaches that produce pixel-wise estimates, SSNs model joint distributions over entire label maps and thus can generate multiple spatially coherent hypotheses for a single image. By using a low-rank multivariate normal distribution over the logit space to model the probability of the label map given the image, we obtain a spatially consistent probability distribution that can be efficiently computed by a neural network without any changes to the underlying architecture. We tested our method on the segmentation of real-world medical data, including lung nodules in 2D CT and brain tumours in 3D multimodal MRI scans. SSNs outperform state-of-the-art for modelling correlated uncertainty in ambiguous images while being much simpler, more flexible, and more efficient."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ICE-BeeM", "Title": "Identifiable Conditional Energy-Based Deep Models Based on Nonlinear ICA", "Abstract": "We consider the identifiability theory of probabilistic models and establish sufficient conditions under which the representations learnt by a very broad family of conditional energy-based models are unique in function space, up to a simple transformation. In our model family, the energy function is the dot-product between two feature extractors, one for the dependent variable, and one for the conditioning variable. We show that under mild conditions, the features are unique up to scaling and permutation. Our results extend recent developments in nonlinear ICA, and in fact, they lead to an important generalization of ICA models. In particular, we show that our model can be used for the estimation of the components in the framework of Independently Modulated Component Analysis (IMCA), a new generalization of nonlinear ICA that relaxes the independence assumption. A thorough empirical study show that representations learnt by our model from real-world image datasets are identifiable, and improve performance in transfer learning and semi-supervised learning tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CogLTX", "Title": "Applying BERT to Long Texts", "Abstract": "BERTs are incapable of processing long texts due to its quadratically increasing memory and time consumption. The straightforward thoughts to address this problem, such as slicing the text by a sliding window or simplifying transformers, suffer from insufficient long-range attentions or need customized CUDA kernels. The limited text length of BERT reminds us the limited capacity (5∼ 9 chunks) of the working memory of humans – then how do human beings Cognize Long TeXts? Founded on the cognitive theory stemming from Baddeley, our CogLTX framework identifies key sentences by training a judge model, concatenates them for reasoning and enables multi-step reasoning via rehearsal and decay. Since relevance annotations are usually unavailable, we propose to use treatment experiments to create supervision. As a general algorithm, CogLTX outperforms or gets comparable results to SOTA models on NewsQA, HotpotQA, multi-class and multi-label long-text classification tasks with memory overheads independent of the text length."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "f-GAIL", "Title": "Learning f-Divergence for Generative Adversarial Imitation Learning", "Abstract": "Imitation learning (IL) aims to learn a policy from expert demonstrations that minimizes the discrepancy between the learner and expert behaviors. Various imitation learning algorithms have been proposed with different pre-determined divergences to quantify the discrepancy. This naturally gives rise to the following question: Given a set of expert demonstrations, which divergence can recover the expert policy more accurately with higher data efficiency? In this work, we propose f-GAIL – a new generative adversarial imitation learning model – that automatically learns a discrepancy measure from the f-divergence family as well as a policy capable of producing expert-like behaviors. Compared with IL baselines with various predefined divergence measures, f-GAIL learns better policies with higher data efficiency in six physics-based control tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ConvBERT", "Title": "Improving BERT with Span-based Dynamic Convolution", "Abstract": "Pre-trained language models like BERT and its variants have recently achieved impressive performance in various natural language understanding tasks. However, BERT heavily relies on the global self-attention block and thus suffers large memory footprint and computation cost. Although all its attention heads query on the whole input sequence for generating the attention map from a global perspective, we observe some heads only need to learn local dependencies, which means existence of computation redundancy. We therefore propose a novel span-based dynamic convolution to replace these self-attention heads to directly model local dependencies. The novel convolution heads, together with the rest self-attention heads, form a new mixed attention block that is more efficient at both global and local context learning. We equip BERT with this mixed attention design and build a ConvBERT model. Experiments have shown that ConvBERT significantly outperforms BERT and its variants in various downstream tasks, with lower training cost and fewer model parameters. Remarkably, ConvBERTbase model achieves 86.4 GLUE score, 0.7 higher than ELECTRAbase, using less than 1/4 training cost. Code and pre-trained models will be released."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Walking in the Shadow", "Title": "A New Perspective on Descent Directions for Constrained Minimization", "Abstract": "Descent directions such as movement towards Frank-Wolfe vertices, away steps, in-face away steps and pairwise directions have been an important design consideration in conditional gradient descent (CGD) variants. In this work, we attempt to demystify the impact of movement in these directions towards attaining constrained minimizers. The best local direction of descent is the directional derivative of the projection of the gradient, which we refer to as the \"shadow\" of the gradient. We show that the continuous-time dynamics of moving in the shadow are equivalent to those of PGD however non-trivial to discretize. By projecting gradients in PGD, one not only ensures feasibility but also is able to \"wrap\" around the convex region. We show that Frank-Wolfe (FW) vertices in fact recover the maximal wrap one can obtain by projecting gradients, thus providing a new perspective to these steps. We also claim that the shadow steps give the best direction of descent emanating from the convex hull of all possible away-vertices. Opening up the PGD movements in terms of shadow steps gives linear convergence, dependent on the number of faces. We combine these insights into a novel Shadow-CG method that uses FW steps (i.e., wrap around the polytope) and shadow steps (i.e., optimal local descent direction), while enjoying linear convergence. Our analysis develops properties of directional derivatives of projections (which may be of independent interest), while providing a unifying view of various descent directions in the CGD literature."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LoopReg", "Title": "Self-supervised Learning of Implicit Surface Correspondences, Pose and Shape for 3D Human Mesh Registration", "Abstract": "We address the problem of fitting 3D human models to 3D scans of dressed humans. Classical methods optimize both the data-to-model correspondences and the human model parameters (pose and shape), but are reliable only when initialised close to the solution. Some methods initialize the optimization based on fully supervised correspondence predictors, which is not differentiable end-to-end, and can only process a single scan at a time.  Our main contribution is LoopReg, an end-to-end learning framework to register a corpus of scans to a common 3D human model.  The key idea is to create a self-supervised loop.  A backward map, parameterized by a Neural Network, predicts the correspondence from every scan point to the surface of the human model. A forward map, parameterized by a human model, transforms the  corresponding points back to the scan based on the model parameters (pose and shape), thus closing the loop. Formulating this closed loop is not straightforward because it is not trivial to force the output of the NN to be on the surface of the human model -- outside this surface the human model is not even defined. To this end, we propose two key innovations. First, we define the canonical surface implicitly as the zero level set of a distance field in R3, which in contrast to more common UV parameterizations does not require cutting the surface, does not have discontinuities, and does not induce distortion.  Second, we diffuse the human model to the 3D domain. This allows to map the NN predictions forward, even when they slightly deviate from the zero level set.  Results demonstrate that we can train LoopReg mainly self-supervised -- following a supervised warm-start, the model becomes increasingly more accurate as additional unlabelled raw scans are processed. Our code and pre-trained models can be downloaded for research."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CompRess", "Title": "Self-Supervised Learning by Compressing Representations", "Abstract": "Self-supervised learning aims to learn good representations with unlabeled data. Recent works have shown that larger models benefit more from self-supervised learning than smaller models. As a result, the gap between supervised and self-supervised learning has been greatly reduced for larger models. In this work, instead of designing a new pseudo task for self-supervised learning, we develop a model compression method to compress an already learned, deep self-supervised model (teacher) to a smaller one (student). We train the student model so that it mimics the relative similarity between the datapoints in the teacher's embedding space. For AlexNet, our method outperforms all previous methods including the fully supervised model on ImageNet linear evaluation (59.0% compared to 56.5%) and on nearest neighbor evaluation (50.7% compared to 41.4%). To the best of our knowledge, this is the first time a self-supervised AlexNet has outperformed supervised one on ImageNet classification. Our code is available here: https://github.com/UMBCvision/CompRess"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EcoLight", "Title": "Intersection Control in Developing Regions Under Extreme Budget and Network Constraints", "Abstract": "Effective intersection control can play an important role in reducing traffic congestion and associated vehicular emissions. This is vitally needed in developing countries, where air pollution is reaching life threatening levels. This paper presents EcoLight intersection control for developing regions, where budget is constrained and network connectivity is very poor. EcoLight learns effective control offline using state-of-the-art Deep Reinforcement Learning methods, but deploys highly efficient runtime control algorithms on low cost embedded devices that work stand-alone on road without server connectivity. EcoLight optimizes both average case and worst case values of throughput, travel time and other metrics, as evaluated on open-source datasets from New York and on a custom developing region dataset."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Grasp Proposal Networks", "Title": "An End-to-End Solution for Visual Learning of Robotic Grasps", "Abstract": "Learning robotic grasps from visual observations is a promising yet challenging task. Recent research shows its great potential by preparing and learning from large-scale synthetic datasets. For the popular, 6 degree-of-freedom (6-DOF) grasp setting of parallel-jaw gripper, most of existing methods take the strategy of heuristically sampling grasp candidates and then evaluating them using learned scoring functions. This strategy is limited in terms of the conflict between sampling efficiency and coverage of optimal grasps. To this end, we propose in this work a novel, end-to-end \\emph{Grasp Proposal Network (GPNet)}, to predict a diverse set of 6-DOF grasps for an unseen object observed from a single and unknown camera view. GPNet builds on a key design of grasp proposal module that defines \\emph{anchors of grasp centers} at discrete but regular 3D grid corners, which is flexible to support either more precise or more diverse grasp predictions. To test GPNet, we contribute a synthetic dataset of 6-DOF object grasps; evaluation is conducted using rule-based criteria, simulation test, and real test. Comparative results show the advantage of our methods over existing ones. Notably, GPNet gains better simulation results via the specified coverage, which helps achieve a ready translation in real test. Our code and dataset are available on \\url{https://github.com/CZ-Wu/GPNet}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fictitious Play for Mean Field Games", "Title": "Continuous Time Analysis and Applications", "Abstract": "In this paper, we deepen the analysis of continuous time Fictitious Play learning algorithm to the consideration of various finite state Mean Field Game settings (finite horizon, $\\gamma$-discounted), allowing in particular for the introduction of an additional common noise. \n  We first present a theoretical convergence analysis of the continuous time Fictitious Play process and prove that the induced exploitability decreases at a rate $O(\\frac{1}{t})$. Such analysis emphasizes the use of exploitability as a relevant metric for evaluating the convergence towards a Nash equilibrium in the context of Mean Field Games. These theoretical contributions are supported by numerical experiments provided in either model-based or model-free settings. We provide hereby for the first time converging learning dynamics for Mean Field Games in the presence of common noise."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interferobot", "Title": "aligning an optical interferometer by a reinforcement learning agent", "Abstract": "Limitations in acquiring training data restrict potential applications of deep reinforcement learning (RL) methods to the training of real-world robots. Here we train an RL agent to align a Mach-Zehnder interferometer, which is an essential part of many optical experiments, based on images of interference fringes acquired by a monocular camera. The agent is trained in a simulated environment, without any hand-coded features or a priori information about the physics, and subsequently transferred to a physical interferometer. Thanks to a set of domain randomizations simulating uncertainties in physical measurements, the agent successfully aligns this interferometer without any fine-tuning, achieving a performance level of a human expert."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PC-PG", "Title": "Policy Cover Directed Exploration for Provable Policy Gradient Learning", "Abstract": "Direct policy gradient methods for reinforcement learning are a successful approach for a variety of reasons: they are model free, they directly optimize the performance metric of interest, and they allow for richly parameterized policies. Their primary drawback is that, by being local in nature, they fail to adequately explore the environment. In contrast, while model-based approaches and Q-learning can, at least in theory, directly handle exploration through the use of optimism, their ability to handle model misspecification and function approximation is far less evident. This work introduces the the POLICY COVER GUIDED POLICY GRADIENT (PC- PG) algorithm, which provably balances the exploration vs. exploitation tradeoff using an ensemble of learned policies (the policy cover). PC-PG enjoys polynomial sample complexity and run time for both tabular MDPs and, more generally, linear MDPs in an infinite dimensional RKHS. Furthermore, PC-PG also has strong guarantees under model misspecification that go beyond the standard worst case L infinity assumptions; these include approximation guarantees for state aggregation under an average case error assumption, along with guarantees under a more general assumption where the approximation error under distribution shift is controlled. We complement the theory with empirical evaluation across a variety of domains in both reward-free and reward-driven settings."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VarGrad", "Title": "A Low-Variance Gradient Estimator for Variational Inference", "Abstract": "We analyse the properties of an unbiased gradient estimator of the ELBO for variational inference, based on the score function method with leave-one-out control variates. We show that this gradient estimator can be obtained using a new loss, defined as the variance of the log-ratio between the exact posterior and the variational approximation, which we call the log-variance loss. Under certain conditions, the gradient of the log-variance loss equals the gradient of the (negative) ELBO. We show theoretically that this gradient estimator, which we call VarGrad due to its connection to the log-variance loss, exhibits lower variance than the score function method in certain settings, and that the leave-one-out control variate coefficients are close to the optimal ones. We empirically demonstrate that VarGrad offers a favourable variance versus computation trade-off compared to other state-of-the-art estimators on a discrete VAE."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ScaleCom", "Title": "Scalable Sparsified Gradient Compression for Communication-Efficient Distributed Training", "Abstract": "Large-scale distributed training of Deep Neural Networks (DNNs) on state-of-the-art platforms are expected to be severely communication constrained. To overcome this limitation, numerous gradient compression techniques have been proposed and have demonstrated high compression ratios. However, most existing compression methods do not scale well to large scale distributed systems (due to gradient build-up) and / or lack evaluations in large datasets. To mitigate these issues, we propose a new compression technique, Scalable Sparsified Gradient Compression (ScaleComp), that (i) leverages similarity in the gradient distribution amongst learners to provide a commutative compressor and keep communication cost constant to worker number and (ii) includes low-pass filter in local gradient accumulations to mitigate the impacts of large batch size training and significantly improve scalability. Using theoretical analysis, we show that ScaleComp provides favorable convergence guarantees and is compatible with gradient all-reduce techniques.  Furthermore, we experimentally demonstrate that ScaleComp has small overheads, directly reduces gradient traffic and provides high compression rates (70-150X) and excellent scalability (up to 64-80 learners and 10X larger batch sizes over normal training) across a wide range of applications (image, language, and speech) without significant accuracy loss."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RelationNet++", "Title": "Bridging Visual Representations for Object Detection via Transformer Decoder", "Abstract": "Existing object detection frameworks are usually built on a single format of object/part representation, i.e., anchor/proposal rectangle boxes in RetinaNet and Faster R-CNN, center points in FCOS and RepPoints, and corner points in CornerNet. While these different representations usually drive the frameworks to perform well in different aspects, e.g., better classification or finer localization, it is in general difficult to combine these representations in a single framework to make good use of each strength, due to the heterogeneous or non-grid feature extraction by different representations. This paper presents an attention-based decoder module similar as that in Transformer~\\cite{vaswani2017attention} to bridge other representations into a typical object detector built on a single representation format, in an end-to-end fashion. The other representations act as a set of \\emph{key} instances to strengthen the main \\emph{query} representation features in the vanilla detectors. Novel techniques are proposed towards efficient computation of the decoder module, including a \\emph{key sampling} approach and a \\emph{shared location embedding} approach. The proposed module is named \\emph{bridging visual representations} (BVR). It can perform in-place and we demonstrate its broad effectiveness in bridging other representations into prevalent object detection frameworks, including RetinaNet, Faster R-CNN, FCOS and ATSS, where about $1.5\\sim3.0$ AP improvements are achieved. In particular, we improve a state-of-the-art framework with a strong backbone by about $2.0$ AP, reaching $52.7$ AP on COCO test-dev. The resulting network is named RelationNet++. The code is available at \\url{https://github.com/microsoft/RelationNet2}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fairness in Streaming Submodular Maximization", "Title": "Algorithms and Hardness", "Abstract": "Submodular maximization has become established as the method of choice for the task of selecting representative and diverse summaries of data. However, if datapoints have sensitive attributes such as gender or age, such machine learning algorithms, left unchecked, are known to exhibit bias: under- or over-representation of particular groups. This has made the design of fair machine learning algorithms increasingly important. In this work we address the question: Is it possible to create fair summaries for massive datasets?\nTo this end, we develop the first streaming approximation algorithms for submodular maximization under fairness constraints, for both monotone and non-monotone functions. We validate our findings empirically on exemplar-based clustering, movie recommendation, DPP-based summarization, and maximum coverage in social networks, showing that fairness constraints do not significantly impact utility."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning with Optimized Random Features", "Title": "Exponential Speedup by Quantum Machine Learning without Sparsity and Low-Rank Assumptions", "Abstract": "Kernel methods augmented with random features give scalable algorithms for learning from big data. But it has been computationally hard to sample random features according to a probability distribution that is optimized for the data, so as to minimize the required number of features for achieving the learning to  a desired accuracy. Here, we develop a quantum algorithm for sampling from this optimized distribution over features, in runtime O(D) that is linear in the dimension D of the input data. Our algorithm achieves an exponential speedup in D compared to any known classical algorithm for this sampling task. In contrast to existing quantum machine learning algorithms, our algorithm circumvents sparsity and low-rank assumptions and thus has wide applicability. We also show that the sampled features can be combined with regression by stochastic gradient descent to achieve the learning without canceling out our exponential speedup. Our algorithm based on sampling optimized random features leads to an accelerated framework for machine learning that takes advantage of quantum computers."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CaSPR", "Title": "Learning Canonical Spatiotemporal Point Cloud Representations", "Abstract": "We propose CaSPR, a method to learn object-centric Canonical Spatiotemporal Point Cloud Representations of dynamically moving or evolving objects. Our goal is to enable information aggregation over time and the interrogation of object state at any spatiotemporal neighborhood in the past, observed or not. Different from previous work, CaSPR learns representations that support spacetime continuity, are robust to variable and irregularly spacetime-sampled point clouds, and generalize to unseen object instances. Our approach divides the problem into two subtasks. First, we explicitly encode time by mapping an input point cloud sequence to a spatiotemporally-canonicalized object space. We then leverage this canonicalization to learn a spatiotemporal latent representation using neural ordinary differential equations and a generative model of dynamically evolving shapes using continuous normalizing flows. We demonstrate the effectiveness of our method on several applications including shape reconstruction, camera pose estimation, continuous spatiotemporal sequence reconstruction, and correspondence estimation from irregularly or intermittently sampled observations."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Understanding Gradient Clipping in Private SGD", "Title": "A Geometric Perspective", "Abstract": "Deep learning models are increasingly popular in many machine learning applications where the training data may contain sensitive information. To provide formal and rigorous privacy guarantee, many learning systems now incorporate differential privacy by training their models with (differentially) private SGD. A key step in each private SGD update is gradient clipping that shrinks the gradient of an individual example whenever its l2 norm exceeds a certain threshold. We first demonstrate how gradient clipping can prevent SGD from converging to a stationary point. We then provide a theoretical analysis on private SGD with gradient clipping. Our analysis fully characterizes the clipping bias on the gradient norm, which can be upper bounded by the Wasserstein distance between the gradient distribution and a geometrically symmetric distribution. Our empirical evaluation further suggests that the gradient distributions along the trajectory of private SGD indeed exhibit such symmetric structure. Together, our results provide an explanation why private SGD with gradient clipping remains effective in practice despite its potential clipping bias. Finally, we develop a new perturbation-based technique that can provably correct the clipping bias even for instances with highly asymmetric gradient distributions."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "O(n) Connections are Expressive Enough", "Title": "Universal Approximability of Sparse Transformers", "Abstract": "Recently, Transformer networks have redefined the state of the art in many NLP tasks. However, these models suffer from quadratic computational cost in the input sequence length $n$ to compute pairwise attention in each layer. This has prompted recent research into sparse Transformers that sparsify the connections in the attention layers. While empirically promising for long sequences, fundamental questions remain unanswered: Can sparse Transformers approximate any arbitrary sequence-to-sequence function, similar to their dense counterparts? How does the sparsity pattern and the sparsity level affect their performance? In this paper, we address these questions and provide a unifying framework that captures existing sparse attention models. We propose sufficient conditions under which we prove that a sparse attention model can universally approximate any sequence-to-sequence function. Surprisingly, our results show that sparse Transformers with only $O(n)$ connections per attention layer can approximate the same function class as the dense model with $n^2$ connections. Lastly, we present experiments comparing different patterns/levels of sparsity on standard NLP tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MinMax Methods for Optimal Transport and Beyond", "Title": "Regularization, Approximation and Numerics", "Abstract": "We study MinMax solution methods for a general class of optimization problems related to (and including) optimal transport. Theoretically, the focus is on fitting a large class of problems into a single MinMax framework and generalizing regularization techniques known from classical optimal transport. We show that regularization techniques justify the utilization of neural networks to solve such problems by proving approximation theorems and illustrating fundamental issues if no regularization is used. We further study the relation to the literature on generative adversarial nets, and analyze which algorithmic techniques used therein are particularly suitable to the class of problems studied in this paper. Several numerical experiments showcase the generality of the setting and highlight which theoretical insights are most beneficial in practice."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond accuracy", "Title": "quantifying trial-by-trial behaviour of CNNs and humans by measuring error consistency", "Abstract": "A central problem in cognitive science and behavioural neuroscience as well as in machine learning and artificial intelligence research is to ascertain whether two or more decision makers---be they brains or algorithms---use the same strategy. Accuracy alone cannot distinguish between strategies: two systems may achieve similar accuracy with very different strategies. The need to differentiate beyond accuracy is particularly pressing if two systems are at or near ceiling performance, like Convolutional Neural Networks (CNNs) and humans on visual object recognition.\nHere we introduce trial-by-trial error consistency, a quantitative analysis for measuring whether two decision making systems systematically make errors on the same inputs. Making consistent errors on a trial-by-trial basis is a necessary condition if we want to ascertain similar processing strategies between decision makers. Our analysis is applicable to compare algorithms with algorithms, humans with humans, and algorithms with humans.\nWhen applying error consistency to visual object recognition we obtain three main findings: (1.) Irrespective of architecture, CNNs are remarkably consistent with one another. (2.) The consistency between CNNs and human observers, however, is little above what can be expected by chance alone---indicating that humans and CNNs are likely implementing very different strategies. (3.) CORnet-S, a recurrent model termed the \"current best model of the primate ventral visual stream\", fails to capture essential characteristics of human behavioural data and behaves essentially like a standard purely feedforward ResNet-50 in our analysis; highlighting that certain behavioural failure cases are not limited to feedforward models. Taken together, error consistency analysis suggests that the strategies used by human and machine vision are still very different---but we envision our general-purpose error consistency analysis to serve as a fruitful tool for quantifying future progress."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RANet", "Title": "Region Attention Network for Semantic Segmentation", "Abstract": "Recent semantic segmentation methods model the relationship between pixels to construct the contextual representations. In this paper, we introduce the \\emph{Region Attention Network} (RANet), a novel attention network for modeling the relationship between object regions. RANet divides the image into object regions, where we select representative information. In contrast to the previous methods, RANet configures the information pathways between the pixels in different regions, enabling the region interaction to exchange the regional context for enhancing all of the pixels in the image. We train the construction of object regions, the selection of the representative regional contents, the configuration of information pathways and the context exchange between pixels, jointly, to improve the segmentation accuracy. We extensively evaluate our method on the challenging segmentation benchmarks, demonstrating that RANet effectively helps to achieve the state-of-the-art results."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A random matrix analysis of random Fourier features", "Title": "beyond the Gaussian kernel, a precise phase transition, and the corresponding double descent", "Abstract": "This article characterizes the exact asymptotics of random Fourier feature (RFF) regression, in the realistic setting where the number of data samples $n$, their dimension $p$, and the dimension of feature space $N$ are all large and comparable. In this regime, the random RFF Gram matrix no longer converges to the well-known limiting Gaussian kernel matrix (as it does when $N \\to \\infty$ alone), but it still has a tractable behavior that is captured by our analysis. This analysis also provides accurate estimates of training and test regression errors for large $n,p,N$. Based on these estimates, a precise characterization of two qualitatively different phases of learning, including the phase transition between them, is provided; and the corresponding double descent test error curve is derived from this phase transition behavior. These results do not depend on strong assumptions on the data distribution, and they perfectly match empirical results on real-world data sets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Private Learning of Halfspaces", "Title": "Simplifying the Construction and Reducing the Sample Complexity", "Abstract": "We present a differentially private learner for halfspaces over a finite grid $G$ in $\\R^d$ with sample complexity $\\approx d^{2.5}\\cdot 2^{\\log^*|G|}$, which improves the state-of-the-art result of [Beimel et al., COLT 2019] by a $d^2$ factor. The building block for our learner is a new differentially private algorithm for approximately solving the linear feasibility problem: Given a feasible collection of $m$ linear constraints of the form $Ax\\geq b$, the task is to {\\em privately} identify a solution $x$ that satisfies {\\em most} of the constraints. Our algorithm is iterative, where each iteration determines the next coordinate of the constructed solution $x$."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NanoFlow", "Title": "Scalable Normalizing Flows with Sublinear Parameter Complexity", "Abstract": "Normalizing flows (NFs) have become a prominent method for deep generative models that allow for an analytic probability density estimation and efficient synthesis. However, a flow-based network is considered to be inefficient in parameter complexity because of reduced expressiveness of bijective mapping, which renders the models unfeasibly expensive in terms of parameters. We present an alternative parameterization scheme called NanoFlow, which uses a single neural density estimator to model multiple transformation stages. Hence, we propose an efficient parameter decomposition method and the concept of flow indication embedding, which are key missing components that enable density estimation from a single neural network. Experiments performed on audio and image models confirm that our method provides a new parameter-efficient solution for scalable NFs with significant sublinear parameter complexity."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Group Knowledge Transfer", "Title": "Federated Learning of Large CNNs at the Edge", "Abstract": "Scaling up the convolutional neural network (CNN) size (e.g., width, depth, etc.) is known to effectively improve model accuracy. However, the large model size impedes training on resource-constrained edge devices. For instance, federated learning (FL) may place undue burden on the compute capability of edge nodes, even though there is a strong practical need for FL due to its privacy and confidentiality properties. To address the resource-constrained reality of edge devices, we reformulate FL as a group knowledge transfer training algorithm, called FedGKT. FedGKT designs a variant of the alternating minimization approach to train small CNNs on edge nodes and periodically transfer their knowledge by knowledge distillation to a large server-side CNN. FedGKT consolidates several advantages into a single framework: reduced demand for edge computation, lower communication bandwidth for large CNNs, and asynchronous training, all while maintaining model accuracy comparable to FedAvg. We train CNNs designed based on ResNet-56 and ResNet-110 using three distinct datasets (CIFAR-10, CIFAR-100, and CINIC-10) and their non-IID variants. Our results show that FedGKT can obtain comparable or even slightly higher accuracy than FedAvg. More importantly, FedGKT makes edge training affordable. Compared to the edge training using FedAvg, FedGKT demands 9 to 17 times less computational power (FLOPs) on edge devices and requires 54 to 105 times fewer parameters in the edge CNN. Our source code is released at FedML (https://fedml.ai)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MOPO", "Title": "Model-based Offline Policy Optimization", "Abstract": "Offline reinforcement learning (RL) refers to the problem of learning policies entirely from a batch of previously collected data. This problem setting is compelling, because it offers the promise of utilizing large, diverse, previously collected datasets to acquire policies without any costly or dangerous active exploration, but it is also exceptionally difficult, due to the distributional shift between the offline training data and the learned policy. While there has been significant progress in model-free offline RL, the most successful prior methods constrain the policy to the support of the data, precluding generalization to new states. In this paper, we observe that an existing model-based RL algorithm on its own already produces significant gains in the offline setting, as compared to model-free approaches, despite not being designed for this setting. However, although many standard model-based RL methods already estimate the uncertainty of their model, they do not by themselves provide a mechanism to avoid the issues associated with distributional shift in the offline setting. We therefore propose to modify existing model-based RL methods to address these issues by casting offline model-based RL into a penalized MDP framework. We theoretically show that, by using this penalized MDP, we are maximizing a lower bound of the return in the true MDP. Based on our theoretical results, we propose a new model-based offline RL algorithm that applies the variance of a Lipschitz-regularized model as a penalty to the reward function. We find that this algorithm outperforms both standard model-based RL methods and existing state-of-the-art model-free offline RL approaches on existing offline RL benchmarks, as well as two challenging continuous control tasks that require generalizing from data collected for a different task."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GradAug", "Title": "A New Regularization Method for Deep Neural Networks", "Abstract": "We propose a new regularization method to alleviate over-fitting in deep neural networks. The key idea is utilizing randomly transformed training samples to regularize a set of sub-networks, which are originated by sampling the width of the original network, in the training process. As such, the proposed method introduces self-guided disturbances to the raw gradients of the network and therefore is termed as Gradient Augmentation (GradAug). We demonstrate that GradAug can help the network learn well-generalized and more diverse representations. Moreover, it is easy to implement and can be applied to various structures and applications. GradAug improves ResNet-50 to 78.79% on ImageNet classification, which is a new state-of-the-art accuracy. By combining with CutMix, it further boosts the performance to 79.67%, which outperforms an ensemble of advanced training tricks. The generalization ability is evaluated on COCO object detection and instance segmentation where GradAug significantly surpasses other state-of-the-art methods. GradAug is also robust to image distortions and FGSM adversarial attacks and is highly effective in low data regimes. Code is available at \\url{https://github.com/taoyang1122/GradAug}"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DISK", "Title": "Learning local features with policy gradient", "Abstract": "Local feature frameworks are difficult to learn in an end-to-end fashion due to the discreteness inherent to the selection and matching of sparse keypoints. We introduce DISK (DIScrete Keypoints), a novel method that overcomes these obstacles by leveraging principles from Reinforcement Learning (RL), optimizing end-to-end for a high number of correct feature matches. Our simple yet expressive probabilistic model lets us keep the training and inference regimes close, while maintaining good enough convergence properties to reliably train from scratch. Our features can be extracted very densely while remaining discriminative, challenging commonly held assumptions about what constitutes a good keypoint, as showcased in Fig. 1, and deliver state-of-the-art results on three public benchmarks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GOCor", "Title": "Bringing Globally Optimized Correspondence Volumes into Your Neural Network", "Abstract": "The feature correlation layer serves as a key neural network module in numerous computer vision problems that involve dense correspondences between image pairs. It predicts a correspondence volume by evaluating dense scalar products between feature vectors extracted from pairs of locations in two images.\nHowever, this point-to-point feature comparison is insufficient when disambiguating multiple similar regions in an image, severely affecting the performance of the end task.\nWe propose GOCor, a fully differentiable dense matching module, acting as a direct replacement to the feature correlation layer.\nThe correspondence volume generated by our module is the result of an internal optimization procedure that explicitly accounts for similar regions in the scene. Moreover, our approach is capable of effectively learning spatial matching priors to resolve further matching ambiguities.\nWe analyze our GOCor module in extensive ablative experiments. When integrated into state-of-the-art networks, our approach significantly outperforms the feature correlation layer for the tasks of geometric matching, optical flow, and dense semantic matching. The code and trained models will be made available at github.com/PruneTruong/GOCor."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel Methods Through the Roof", "Title": "Handling Billions of Points Efficiently", "Abstract": "Kernel methods provide an elegant and principled approach to nonparametric learning, but so far could hardly be used in large scale problems, since naïve implementations scale poorly with data size.\nRecent advances have shown the benefits of a number of algorithmic ideas, for example combining optimization, numerical linear algebra and random projections.\nHere, we push these efforts further to develop and test a solver that takes full advantage of GPU hardware.\nTowards this end, we designed a preconditioned gradient solver for kernel methods  exploiting both GPU acceleration and parallelization with multiple GPUs, implementing out-of-core variants of common linear algebra operations to guarantee optimal hardware utilization.\nFurther, we optimize the numerical precision of different\noperations and maximize efficiency of matrix-vector multiplications. As a result\nwe can experimentally show dramatic speedups on datasets with billions of points,\nwhile still guaranteeing state of the art performance.\nAdditionally, we make our software available as an easy to use library."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MESA", "Title": "Boost Ensemble Imbalanced Learning with MEta-SAmpler", "Abstract": "Imbalanced learning (IL), i.e., learning unbiased models from class-imbalanced data, is a challenging problem. Typical IL methods including resampling and reweighting were designed based on some heuristic assumptions. They often suffer from unstable performance, poor applicability, and high computational cost in complex tasks where their assumptions do not hold. In this paper, we introduce a novel ensemble IL framework named MESA. It adaptively resamples the training set in iterations to get multiple classifiers and forms a cascade ensemble model. MESA directly learns the sampling strategy from data to optimize the final metric beyond following random heuristics. Moreover, unlike prevailing meta-learning-based IL solutions, we decouple the model-training and meta-training in MESA by independently train the meta-sampler over task-agnostic meta-data. This makes MESA generally applicable to most of the existing learning models and the meta-sampler can be efficiently applied to new tasks. Extensive experiments on both synthetic and real-world tasks demonstrate the effectiveness, robustness, and transferability of MESA. Our code is available at https://github.com/ZhiningLiu1998/mesa."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoinPress", "Title": "Practical Private Mean and Covariance Estimation", "Abstract": "We present simple differentially private estimators for the parameters of multivariate sub-Gaussian data that are accurate at small sample sizes.  We demonstrate the effectiveness of our algorithms both theoretically and empirically using synthetic and real-world datasets---showing that their asymptotic error rates match the state-of-the-art theoretical bounds, and that they concretely outperform all previous methods. Specifically, previous estimators either have weak empirical accuracy at small sample sizes, perform poorly for multivariate data, or require the user to provide strong a priori estimates for the parameters."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Planning with General Objective Functions", "Title": "Going Beyond Total Rewards", "Abstract": "Standard sequential decision-making paradigms aim to maximize the cumulative reward when interacting with the unknown environment., i.e., maximize $\\sum_{h = 1}^H r_h$ where $H$ is the planning horizon. However, this paradigm fails to model important practical applications, e.g., safe control that aims to maximize the lowest reward, i.e., maximize $\\min_{h= 1}^H r_h$. In this paper, based on techniques in sketching algorithms, we propose a novel planning algorithm in deterministic systems which deals with a large class of objective functions of the form $f(r_1, r_2, ... r_H)$ that are of interest to practical applications. We show that efficient planning is possible if $f$ is symmetric under permutation of coordinates and satisfies certain technical conditions. Complementing our algorithm, we further prove that removing any of the conditions will make the problem intractable in the worst case and thus demonstrate the necessity of our conditions."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scattering GCN", "Title": "Overcoming Oversmoothness in Graph Convolutional Networks", "Abstract": "Graph convolutional networks (GCNs) have shown promising results in processing graph data by extracting structure-aware features. This gave rise to extensive work in geometric deep learning, focusing on designing network architectures that ensure neuron activations conform to regularity patterns within the input graph. However, in most cases the graph structure is only accounted for by considering the similarity of activations between adjacent nodes, which limits the capabilities of such methods to discriminate between nodes in a graph. Here, we propose  to augment conventional GCNs with geometric scattering transforms and residual convolutions. The former enables band-pass filtering of graph signals, thus alleviating the so-called oversmoothing often encountered in GCNs, while the latter is introduced to clear the resulting features of high-frequency noise. We establish the advantages of the presented Scattering GCN with both theoretical results establishing the complementary benefits of scattering and GCN features, as well as experimental results showing the benefits of our method compared to leading graph neural networks for semi-supervised node classification, including the recently proposed GAT network that typically alleviates oversmoothing using graph attention mechanisms."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KFC", "Title": "A Scalable Approximation Algorithm for $k$−center Fair Clustering", "Abstract": "In this paper, we study the problem of fair clustering on the $k-$center objective. In fair clustering, the input is $N$ points, each belonging to at least one of $l$ protected groups, e.g. male, female, Asian, Hispanic. The objective is to cluster the $N$ points into $k$ clusters to minimize a classical clustering objective function. However, there is an additional constraint that each cluster needs to be fair, under some notion of fairness. This ensures that no group is either ``over-represented'' or ``under-represented'' in any cluster. Our work builds on the work of Chierichetti et al. (NIPS 2017), Bera et al. (NeurIPS 2019), Ahmadian et al. (KDD 2019), and Bercea et al. (APPROX 2019). We obtain a randomized $3-$approximation algorithm for the $k-$center objective function, beating the previous state of the art ($4-$approximation). We test our algorithm on real datasets, and show that our algorithm is effective in finding good clusters without over-representation or under-representation, surpassing the current state of the art in runtime speed, clustering cost, while achieving similar fairness violations."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reconciling Modern Deep Learning with Traditional Optimization Analyses", "Title": "The Intrinsic Learning Rate", "Abstract": "Recent works (e.g., (Li \\& Arora, 2020)) suggest that the use of popular normalization schemes  (including Batch Normalization) in today's deep learning can move it far from a traditional optimization viewpoint, e.g., use of exponentially increasing learning rates. The current paper highlights other ways in which behavior of normalized nets departs from traditional viewpoints, and then initiates a formal framework for studying their mathematics via suitable adaptation of the conventional framework namely, modeling SGD-induced training trajectory via a suitable stochastic differential equation (SDE) with a noise term that captures gradient noise. This yields: \n(a) A new \\textquotedblleft intrinsic learning rate\\textquotedblright\\ parameter that is the product of the normal learning rate $\\eta$ and weight decay factor $\\lambda$. Analysis of the SDE shows how the effective speed of learning varies and equilibrates over time under the control of intrinsic LR.\n (b) A challenge---via theory and experiments---to popular belief that good generalization requires large learning rates at the start of training. \n (c) New experiments, backed by mathematical intuition, suggesting the number of steps to equilibrium (in function space) scales as the inverse of the intrinsic learning rate,  as opposed to the exponential time convergence bound implied by SDE analysis. We name it the \\emph{Fast Equilibrium Conjecture} and suggest it holds the key to why  Batch Normalization is effective."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Assisted Learning", "Title": "A Framework for Multi-Organization Learning", "Abstract": "In an increasing number of AI scenarios, collaborations among different organizations or agents (e.g., human and robots, mobile units) are often essential to accomplish an organization-specific mission. However, to avoid leaking useful and possibly proprietary information, organizations typically enforce stringent security constraints on sharing modeling algorithms and data, which significantly limits collaborations. In this work, we introduce the Assisted Learning framework for organizations to assist each other in supervised learning tasks without revealing any organization's algorithm, data, or even task. An organization seeks assistance by broadcasting task-specific but nonsensitive statistics and incorporating others' feedback in one or more iterations to eventually improve its predictive performance. Theoretical and experimental studies, including real-world medical benchmarks, show that Assisted Learning can often achieve near-oracle learning performance as if data and training processes were centralized."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STLnet", "Title": "Signal Temporal Logic Enforced Multivariate Recurrent Neural Networks", "Abstract": "Recurrent Neural Networks (RNNs) have made great achievements for sequential prediction tasks. In practice, the target sequence often follows certain model properties or patterns (e.g., reasonable ranges, consecutive changes, resource constraint, temporal correlations between multiple variables, existence, unusual cases, etc.). However, RNNs cannot guarantee their learned distributions satisfy these model properties. It is even more challenging for predicting large-scale and complex Cyber-Physical Systems. Failure to produce outcomes that meet these model properties will result in inaccurate and even meaningless results. In this paper, we develop a new temporal logic-based learning framework, STLnet, which guides the RNN learning process with auxiliary knowledge of model properties, and produces a more robust model for improved future predictions. Our framework can be applied to general sequential deep learning models, and trained in an end-to-end manner with back-propagation. We evaluate the performance of STLnet using large-scale real-world city data. The experimental results show STLnet not only improves the accuracy of predictions, but importantly also guarantees the satisfaction of model properties and increases the robustness of RNNs."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Election Coding for Distributed Learning", "Title": "Protecting SignSGD against Byzantine Attacks", "Abstract": "Current distributed learning systems suffer from serious performance degradation under Byzantine attacks. This paper proposes Election Coding, a coding-theoretic framework to guarantee Byzantine-robustness for distributed learning algorithms based on signed stochastic gradient descent (SignSGD) that minimizes the worker-master communication load. The suggested framework explores new information-theoretic limits of finding the majority opinion when some workers could be attacked by adversary, and paves the road to implement robust and communication-efficient distributed learning algorithms. Under this framework, we construct two types of codes, random Bernoulli codes and deterministic algebraic codes, that tolerate Byzantine attacks with a controlled amount of computational redundancy and guarantee convergence in general non-convex scenarios. \nFor the Bernoulli codes, we provide an upper bound on the error probability in estimating the signs of the true gradients, which gives useful insights into code design for Byzantine tolerance. The proposed deterministic codes are proven to perfectly tolerate arbitrary Byzantine attacks. Experiments on real datasets confirm that the suggested codes provide substantial improvement in Byzantine tolerance of distributed learning systems employing SignSGD."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Top-k Training of GANs", "Title": "Improving GAN Performance by Throwing Away Bad Samples", "Abstract": "We introduce a simple (one line of code) modification to the Generative Adversarial Network (GAN) training algorithm that materially improves results with no increase in computational cost. When updating the generator parameters, we simply zero out the gradient contributions from the elements of the batch that the critic scores as least realistic'. Through experiments on many different GAN variants, we show that thistop-k update' procedure is a generally applicable improvement. In order to understand the nature of the improvement, we conduct extensive analysis on a simple mixture-of-Gaussians dataset and discover several interesting phenomena. Among these is that, when gradient updates are computed using the worst-scoring batch elements, samples can actually be pushed further away from the their nearest mode. We also apply our method to state-of-the-art GAN models including BigGAN and improve state-of-the-art FID for conditional generation on CIFAR-10 from 9.21 to 8.57."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Entropic Causal Inference", "Title": "Identifiability and Finite Sample Results", "Abstract": "Entropic causal inference is a framework for inferring the causal direction between two categorical variables from observational data. The central assumption is that the amount of unobserved randomness in the system is not too large. This unobserved randomness is measured by the entropy of the exogenous variable in the underlying structural causal model, which governs the causal relation between the observed variables. Kocaoglu et al. conjectured that the causal direction is identifiable when the entropy of the exogenous variable is not too large. In this paper, we prove a variant of their conjecture. Namely, we show that for almost all causal models where the exogenous variable has entropy that does not scale with the number of states of the observed variables, the causal direction is identifiable from observational data. We also consider the minimum entropy coupling-based algorithmic approach presented by Kocaoglu et al., and for the first time demonstrate algorithmic identifiability guarantees using a finite number of samples. We conduct extensive experiments to evaluate the robustness of the method to relaxing some of the assumptions in our theory and demonstrate that both the constant-entropy exogenous variable and the no latent confounder assumptions can be relaxed in practice. We also empirically characterize the number of observational samples needed for causal identification. Finally, we apply the algorithm on Tuebingen cause-effect pairs dataset."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rewriting History with Inverse RL", "Title": "Hindsight Inference for Policy Improvement", "Abstract": "Multi-task reinforcement learning (RL) aims to simultaneously learn policies for solving many tasks. Several prior works have found that relabeling past experience with different reward functions can improve sample efficiency. Relabeling methods typically pose the question: if, in hindsight, we assume that our experience was optimal for some task, for what task was it optimal? Inverse RL answers this question. In this paper we show that inverse RL is a principled mechanism for reusing experience across tasks. We use this idea to generalize goal-relabeling techniques from prior work to arbitrary types of reward functions. Our experiments confirm that relabeling data using inverse RL outperforms prior relabeling methods on goal-reaching tasks, and accelerates learning on more general multi-task settings where prior methods are not applicable, such as domains with discrete sets of rewards and those with linear reward functions."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Variance-Reduced Off-Policy TDC Learning", "Title": "Non-Asymptotic Convergence Analysis", "Abstract": "Variance reduction techniques have been successfully applied to temporal-difference (TD) learning and help to improve the sample complexity in policy evaluation. However, the existing work applied variance reduction to either the less popular one time-scale TD algorithm or the two time-scale GTD algorithm but with a finite number of i.i.d.\\ samples, and both algorithms apply to only the on-policy setting. In this work, we develop a variance reduction scheme for the two time-scale TDC algorithm in the off-policy setting and analyze its non-asymptotic convergence rate over both i.i.d.\\ and Markovian samples. In the i.i.d setting, our algorithm achieves an improved sample complexity $\\calO(\\epsilon^{-\\frac{3}{5}} \\log{\\epsilon}^{-1})$ over the state-of-the-art result $\\calO(\\epsilon^{-1} \\log {\\epsilon}^{-1})$. In the Markovian setting, our algorithm achieves the state-of-the-art sample complexity $\\calO(\\epsilon^{-1} \\log {\\epsilon}^{-1})$ that is near-optimal. Experiments demonstrate that the proposed variance-reduced TDC achieves a smaller asymptotic convergence error than both the conventional TDC and the variance-reduced TD."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AdaTune", "Title": "Adaptive Tensor Program Compilation Made Efficient", "Abstract": "In this paper, we present a new method, called AdaTune, that significantly reduces the optimization time of tensor programs for high-performance deep learning inference. In particular, we propose an adaptive evaluation method that statistically early terminates a costly hardware measurement without losing much accuracy. We further devise a surrogate model with uncertainty quantification that allows the optimization to adapt to hardware and model heterogeneity better. Finally, we introduce a contextual optimizer that provides adaptive control of the exploration and exploitation to improve the transformation space searching effectiveness. \nWe evaluate and compare the levels of optimization obtained by a state-of-the-art DL compiler and AdaTune. The experiment results show that AdaTune obtains up to 115% higher GFLOPS than the baseline under the same optimization time budget. Furthermore, AdaTune provides 1.3--3.9X speedup in optimization time over the state-of-the-art to reach the same optimization quality for a range of models across different hardware architectures."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STEER ", "Title": "Simple Temporal Regularization For Neural ODE", "Abstract": "Training Neural Ordinary Differential Equations (ODEs) is often computationally expensive. Indeed, computing the forward pass of such models involves solving an ODE which can become arbitrarily complex during training. Recent works have shown that regularizing the dynamics of the ODE can partially alleviate this. In this paper we propose a new regularization technique: randomly sampling the end time of the ODE during training. The proposed regularization is simple to implement, has negligible overhead and is effective across a wide variety of tasks. Further, the technique is orthogonal to several other methods proposed to regularize the dynamics of ODEs and as such can be used in conjunction with them. We show through experiments on normalizing flows, time series models and image recognition that the proposed regularization can significantly decrease training time and even improve performance over baseline models."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "See, Hear, Explore", "Title": "Curiosity via Audio-Visual Association", "Abstract": "Exploration is one of the core challenges in reinforcement learning. A common formulation of curiosity-driven exploration uses the difference between the real future and the future predicted by a learned model. However, predicting the future is an inherently difficult task which can be ill-posed in the face of stochasticity. In this paper, we introduce an alternative form of curiosity that rewards novel associations between different senses. Our approach exploits multiple modalities to provide a stronger signal for more efficient exploration. Our method is inspired by the fact that, for humans, both sight and sound play a critical role in exploration. We present results on several Atari environments and Habitat (a photorealistic navigation simulator), showing the benefits of using an audio-visual association model for intrinsically guiding learning agents in the absence of external rewards. For videos and code, see https://vdean.github.io/audio-curiosity.html."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online learning with dynamics", "Title": "A minimax perspective", "Abstract": "Our approach provides a unifying analysis that recovers regret bounds for several well studied problems including online learning with memory, online control of linear quadratic regulators, online Markov decision processes, and tracking adversarial targets. In addition, we show how our tools help obtain tight regret bounds for a new problems (with non-linear dynamics and non-convex losses) for which such bounds were not known prior to our work."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Experimental Design with Temporal Interference", "Title": "A Maximum Likelihood Approach", "Abstract": "Suppose an online platform wants to compare a treatment and control policy (e.g., two different matching algorithms in a ridesharing system, or two different inventory management algorithms in an online retail site).  Standard experimental approaches to this problem are biased (due to temporal interference between the policies), and not sample efficient.  We study optimal experimental design for this setting.  We view testing the two policies as the problem of estimating the steady state difference in reward between two unknown Markov chains (i.e., policies).  We assume estimation of the steady state reward for each chain proceeds via nonparametric maximum likelihood, and search for consistent (i.e., asymptotically unbiased) experimental designs that are efficient (i.e., asymptotically minimum variance).  Characterizing such designs is equivalent to a Markov decision problem with a minimum variance objective; such problems generally do not admit tractable solutions.  Remarkably, in our setting, using a novel application of classical martingale analysis of Markov chains via Poisson's equation, we characterize efficient designs via a succinct convex optimization problem.  We use this characterization to propose a consistent, efficient online experimental design that adaptively samples the two Markov chains."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Trees to Continuous Embeddings and Back", "Title": "Hyperbolic Hierarchical Clustering", "Abstract": "Similarity-based Hierarchical Clustering (HC) is a classical unsupervised machine learning algorithm that has traditionally been solved with heuristic algorithms like Average-Linkage. Recently, Dasgupta reframed HC as a discrete optimization problem by introducing a global cost function measuring the quality of a given tree. In this work, we provide the first continuous relaxation of Dasgupta's discrete optimization problem with provable quality guarantees. The key idea of our method, HypHC, is showing a direct correspondence from discrete trees to continuous representations (via the hyperbolic embeddings of their leaf nodes) and back (via a decoding algorithm that maps leaf embeddings to a dendrogram), allowing us to search the space of discrete binary trees with continuous optimization. Building on analogies between trees and hyperbolic space, we derive a continuous analogue for the notion of lowest common ancestor, which leads to a continuous relaxation of Dasgupta's discrete objective. We can show that after decoding, the global minimizer of our continuous relaxation yields a discrete tree with a (1+eps)-factor approximation for Dasgupta's optimal tree, where eps can be made arbitrarily small and controls optimization challenges. We experimentally evaluate HypHC on a variety of HC benchmarks and find that even approximate solutions found with gradient descent have superior clustering quality than agglomerative heuristics or other gradient based algorithms. Finally, we highlight the flexibility of HypHC using end-to-end training in a downstream classification task."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COBE", "Title": "Contextualized Object Embeddings from Narrated Instructional Video", "Abstract": "Many objects in the real world undergo dramatic variations in visual appearance. For example, a tomato may be red or green, sliced or chopped, fresh or fried, liquid or solid. Training a single detector to accurately recognize tomatoes in all these different states is challenging. On the other hand, contextual cues (e.g., the presence of a knife, a cutting board, a strainer or a pan) are often strongly indicative of how the object appears in the scene. Recognizing such contextual cues is useful not only to improve the accuracy of object detection or to determine the state of the object, but also to understand its functional properties and to infer ongoing or upcoming human-object interactions. A fully-supervised approach to recognizing object states and their contexts in the real-world is unfortunately marred by the long-tailed, open-ended distribution of the data, which would effectively require massive amounts of annotations to capture the appearance of objects in all their different forms. Instead of relying on manually-labeled data for this task, we propose a new framework for learning Contextualized OBject Embeddings (COBE)  from automatically-transcribed narrations of instructional videos. We leverage the semantic and compositional structure of language by training a visual detector to predict a contextualized word embedding of the object and its associated narration. This enables the learning of an object representation where concepts relate according to a semantic language metric. Our experiments show that our detector learns to predict a rich variety of contextual object information, and that it is highly effective in the settings of few-shot and zero-shot learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Finite Versus Infinite Neural Networks", "Title": "an Empirical Study", "Abstract": "We perform a careful, thorough, and large scale empirical study of the correspondence between wide neural networks and kernel methods. By doing so, we resolve a variety of open questions related to the study of infinitely wide neural networks. Our experimental results include: kernel methods outperform fully-connected finite-width networks, but underperform convolutional finite width networks; neural network Gaussian process (NNGP) kernels frequently outperform neural tangent (NT) kernels; centered and ensembled finite networks have reduced posterior variance and behave more similarly to infinite networks; weight decay and the use of a large learning rate break the correspondence between finite and infinite networks; the NTK parameterization outperforms the standard parameterization for finite width networks; diagonal regularization of kernels acts similarly to early stopping; floating point precision limits kernel performance beyond a critical dataset size; regularized ZCA whitening improves accuracy; finite network performance depends non-monotonically on width in ways not captured by double descent phenomena; equivariance of CNNs is only beneficial for narrow networks far from the kernel regime. Our experiments additionally motivate an improved layer-wise scaling for weight decay which improves generalization in finite-width networks. Finally, we develop improved best practices for using NNGP and NT kernels for prediction, including a novel ensembling technique. Using these best practices we achieve state-of-the-art results on CIFAR-10 classification for kernels corresponding to each architecture class we consider."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Boosting First-Order Methods by Shifting Objective", "Title": "New Schemes with Faster Worst-Case Rates", "Abstract": "We propose a new methodology to design first-order methods for unconstrained strongly convex problems. Specifically, instead of tackling the original objective directly, we construct a shifted objective function that has the same minimizer as the original objective and encodes both the smoothness and strong convexity of the original objective in an interpolation condition. We then propose an algorithmic template for tackling the shifted objective, which can exploit such a condition. Following this template, we derive several new accelerated schemes for problems that are equipped with various first-order oracles and show that the interpolation condition allows us to vastly simplify and tighten the analysis of the derived methods. In particular, all the derived methods have faster worst-case convergence rates than their existing counterparts. Experiments on machine learning tasks are conducted to evaluate the new methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "System Identification with Biophysical Constraints", "Title": "A Circuit Model of the Inner Retina", "Abstract": "Visual processing in the retina has been studied in great detail at all levels such that a comprehensive picture of the retina's cell types and the many neural circuits they form is emerging. However, the currently best performing models of retinal function are black-box CNN models which are agnostic to such biological knowledge. In particular, these models typically neglect the role of the many inhibitory circuits involving amacrine cells and the biophysical mechanisms underlying synaptic release. Here, we present a computational model of temporal processing in the inner retina, including inhibitory feedback circuits and realistic synaptic release mechanisms. Fit to the responses of bipolar cells, the model generalized well to new stimuli including natural movie sequences, performing on par with or better than a benchmark black-box model. In pharmacology experiments, the model replicated in silico the effect of blocking specific amacrine cell populations with high fidelity, indicating that it had learned key circuit functions. Also, more in depth comparisons showed that connectivity patterns learned by the model were well matched to connectivity patterns extracted from connectomics data. Thus, our model provides a biologically interpretable data-driven account of temporal processing in the inner retina, filling the gap between purely black-box and detailed biophysical modeling."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Active Invariant Causal Prediction", "Title": "Experiment Selection through Stability", "Abstract": "A fundamental difficulty of causal learning is that causal models can generally not be fully identified based on observational data only. Interventional data, that is, data originating from different experimental environments, improves identifiability. However, the improvement depends critically on the target and nature of the interventions carried out in each experiment. Since in real applications experiments tend to be costly, there is a need to perform the right interventions such that as few as possible are required. In this work we propose a new active learning (i.e. experiment selection) framework (A-ICP) based on Invariant Causal Prediction (ICP) (Peters et al. 2016). For general structural causal models, we characterize the effect of interventions on so-called stable sets, a notion introduced by Pfister et al. 2019. We leverage these results to propose several intervention selection policies for A-ICP which quickly reveal the direct causes of a response variable in the causal graph while maintaining the error control inherent in ICP. Empirically, we analyze the performance of the proposed policies in both population and finite-regime experiments."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BOSS", "Title": "Bayesian Optimization over String Spaces", "Abstract": "This article develops a Bayesian optimization (BO) method which acts directly over raw strings, proposing the first uses of string kernels and genetic algorithms within BO loops. Recent applications of BO over strings have been hindered by the need to map inputs into a smooth and unconstrained latent space. Learning this projection is computationally and data-intensive. Our approach instead builds a powerful Gaussian process surrogate model based on string kernels, naturally supporting variable length inputs, and performs efficient acquisition function maximization for spaces with syntactic constraints. Experiments demonstrate considerably improved optimization over existing approaches across a broad range of constraints, including the popular setting where syntax is governed by a context-free grammar."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Markovian Score Climbing", "Title": "Variational Inference with KL(p||q)", "Abstract": "Modern variational inference (VI) uses stochastic gradients to avoid intractable expectations, enabling large-scale probabilistic inference in complex models. VI posits a family of approximating distributions q and then finds the member of that family that is closest to the exact posterior p. Traditionally, VI algorithms minimize the “exclusive Kullback-Leibler (KL)” KL(q||p), often for computational convenience. Recent research, however, has also focused on the “inclusive KL” KL(p||q), which has good statistical properties that makes it more appropriate for certain inference problems. This paper develops a simple algorithm for reliably minimizing the inclusive KL using stochastic gradients with vanishing bias. This method, which we call Markovian score climbing (MSC), converges to a local optimum of the inclusive KL. It does not suffer from the systematic errors inherent in existing methods, such as Reweighted Wake-Sleep and Neural Adaptive Sequential Monte Carlo, which lead to bias in their final estimates. We illustrate convergence on a toy model and demonstrate the utility of MSC on Bayesian probit regression for classification as well as a stochastic volatility model for financial data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bias no more", "Title": "high-probability data-dependent regret bounds for adversarial bandits and MDPs", "Abstract": "Besides its simplicity, our approach enjoys several advantages. First, the obtained high-probability regret bounds are data-dependent and could be much smaller than the worst-case bounds, which resolves an open problem asked by Neu (2015). Second, resolving another open problem of Bartlett et al. (2008) and Abernethy and Rakhlin (2009), our approach leads to the first general and efficient algorithm with a high-probability regret bound for adversarial linear bandits, while previous methods are either inefficient or only applicable to specific action sets. Finally, our approach can also be applied to learning adversarial Markov Decision Processes and provides the first algorithm with a high-probability small-loss bound for this problem."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "StratLearner", "Title": "Learning a Strategy for Misinformation Prevention in Social Networks", "Abstract": "Given a combinatorial optimization problem taking an input, can we learn a strategy to solve it from the examples of input-solution pairs without knowing its objective function? In this paper, we consider such a setting and study the misinformation prevention problem. Given the examples of attacker-protector pairs, our goal is to learn a strategy to compute protectors against future attackers, without the need of knowing the underlying diffusion model. To this end, we design a structured prediction framework, where the main idea is to parameterize the scoring function using random features constructed through distance functions on randomly sampled subgraphs, which leads to a kernelized scoring function with weights learnable via the large margin method. Evidenced by experiments, our method can produce near-optimal protectors without using any information of the diffusion model, and it outperforms other possible graph-based and learning-based methods by an evident margin."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Kernel Alignment Risk Estimator", "Title": "Risk Prediction from Training Data", "Abstract": "We study the risk (i.e. generalization error) of Kernel Ridge Regression (KRR) for a kernel $K$ with ridge $\\lambda>0$ and i.i.d. observations. For this, we introduce two objects: the Signal Capture Threshold (SCT) and the Kernel Alignment Risk Estimator (KARE). The SCT $\\vartheta_{K,\\lambda}$ is a function of the data distribution: it can be used to identify the components of the data that the KRR predictor captures, and to approximate the (expected) KRR risk. This then leads to a KRR risk approximation by the KARE $\\rho_{K, \\lambda}$, an explicit function of the training data, agnostic of the true data distribution. We phrase the regression problem in a functional setting. The key results then follow from a finite-size adaptation of the resolvent method for general Wishart random matrices. Under a natural universality assumption (that the KRR moments depend asymptotically on the first two moments of the observations) we capture the mean and variance of the KRR predictor. We numerically investigate our findings on the Higgs and MNIST datasets for various classical kernels: the KARE gives an excellent approximation of the risk. This supports our universality hypothesis. Using the KARE, one can compare choices of Kernels and hyperparameters directly from the training set. The KARE thus provides a promising data-dependent procedure to select Kernels that generalize well."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hitting the High Notes", "Title": "Subset Selection for Maximizing Expected Order Statistics", "Abstract": "We consider the fundamental problem of selecting $k$ out of $n$ random variables in a way that the expected highest or second-highest value is maximized. This question captures several applications where we have uncertainty about the quality of candidates (e.g. auction bids, search results) and have the capacity to explore only a small subset due to an exogenous constraint. For example, consider a second price auction where system constraints (e.g., costly retrieval or model computation) allow the participation of only $k$ out of $n$ bidders, and the goal is to optimize the expected efficiency (highest bid) or expected revenue (second highest bid).\n\n\nWe study the case where we are given an explicit description of each random variable. We give a PTAS for the problem of maximizing the expected highest value. For the second-highest value, we prove a hardness result: assuming the Planted Clique Hypothesis, there is no constant factor approximation algorithm that runs in polynomial time. Surprisingly, under the assumption that each random variable has monotone hazard rate (MHR), a simple score-based algorithm, namely picking the $k$ random variables with the largest $1/\\sqrt{k}$ top quantile value,  is a constant approximation to the expected highest and second highest value, \\emph{simultaneously}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regret Bounds without Lipschitz Continuity", "Title": "Online Learning with Relative-Lipschitz Losses", "Abstract": "In this work, we consider OCO for relative Lipschitz and relative strongly convex functions. We extend the known regret bounds for classical OCO algorithms to the relative setting. Specifically, we show regret bounds for the follow the regularized leader algorithms and a variant of online mirror descent. Due to the generality of these methods, these results yield regret bounds for a wide variety of OCO algorithms. Furthermore, we further extend the results to algorithms with extra regularization such as regularized dual averaging."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Label-Aware Neural Tangent Kernel", "Title": "Toward Better Generalization and Local Elasticity", "Abstract": "As a popular approach to modeling the dynamics of training overparametrized neural networks (NNs), the neural tangent kernels (NTK) are known to fall behind real-world NNs in generalization ability. This performance gap is in part due to the \\textit{label agnostic} nature of the NTK, which renders the resulting kernel not as \\textit{locally elastic} as NNs~\\citep{he2019local}. In this paper, we introduce a novel approach from the perspective of \\emph{label-awareness} to reduce this gap for the NTK. Specifically, we propose two label-aware kernels that are each a superimposition of a label-agnostic part and a hierarchy of label-aware parts with increasing complexity of label dependence, using the Hoeffding decomposition. Through both theoretical and empirical evidence, we show that the models trained with the proposed kernels better simulate NNs in terms of generalization ability and local elasticity."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Perturbations", "Title": "Learning Guarantees with Arbitrary Adversarial Test Examples", "Abstract": "We present a transductive learning algorithm that takes as input training examples\nfrom a distribution P and arbitrary (unlabeled) test examples, possibly chosen by\nan adversary. This is unlike prior work that assumes that test examples are small\nperturbations of P. Our algorithm outputs a selective classifier, which abstains from predicting on some examples. By considering selective transductive learning, we give the first nontrivial guarantees for learning classes of bounded VC dimension with arbitrary train and test distributions—no prior guarantees were known even for simple classes of functions such as intervals on the line. In particular, for any function in a class C of bounded VC dimension, we guarantee a low test error rate and a low rejection rate with respect to P. Our algorithm is efficient given an Empirical Risk Minimizer (ERM) for C. Our guarantees hold even for test examples chosen by an unbounded white-box adversary. We also give guarantees for generalization, agnostic, and unsupervised settings."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AdvFlow", "Title": "Inconspicuous Black-box Adversarial Attacks using Normalizing Flows", "Abstract": "Deep learning classifiers are susceptible to well-crafted, imperceptible variations of their inputs, known as adversarial attacks. In this regard, the study of powerful attack models sheds light on the sources of vulnerability in these classifiers, hopefully leading to more robust ones. In this paper, we introduce AdvFlow: a novel black-box adversarial attack method on image classifiers that exploits the power of normalizing flows to model the density of adversarial examples around a given target image. We see that the proposed method generates adversaries that closely follow the clean data distribution, a property which makes their detection less likely. Also, our experimental results show competitive performance of the proposed approach with some of the existing attack methods on defended classifiers."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dark Experience for General Continual Learning", "Title": "a Strong, Simple Baseline", "Abstract": "Continual Learning has inspired a plethora of approaches and evaluation settings; however, the majority of them overlooks the properties of a practical scenario, where the data stream cannot be shaped as a sequence of tasks and offline training is not viable. We work towards General Continual Learning (GCL), where task boundaries blur and the domain and class distributions shift either gradually or suddenly. We address it through mixing rehearsal with knowledge distillation and regularization; our simple baseline, Dark Experience Replay, matches the network's logits sampled throughout the optimization trajectory, thus promoting consistency with its past. By conducting an extensive analysis on both standard benchmarks and a novel GCL evaluation setting (MNIST-360), we show that such a seemingly simple baseline outperforms consolidated approaches and leverages limited resources. We further explore the generalization capabilities of our objective, showing its regularization being beneficial beyond mere performance."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Utilize Shaping Rewards", "Title": "A New Approach of Reward Shaping", "Abstract": "Reward shaping is an effective technique for incorporating domain knowledge into reinforcement learning (RL). Existing approaches such as potential-based reward shaping normally make full use of a given shaping reward function. However, since the transformation of human knowledge into numeric reward values is often imperfect due to reasons such as human cognitive bias, completely utilizing the shaping reward function may fail to improve the performance of RL algorithms. In this paper, we consider the problem of adaptively utilizing a given shaping reward function. We formulate the utilization of shaping rewards as a bi-level optimization problem, where the lower level is to optimize policy using the shaping rewards and the upper level is to optimize a parameterized shaping weight function for true reward maximization. We formally derive the gradient of the expected true reward with respect to the shaping weight function parameters and accordingly propose three learning algorithms based on different assumptions. Experiments in sparse-reward cartpole and MuJoCo environments show that our algorithms can fully exploit beneficial shaping rewards, and meanwhile ignore unbeneficial shaping rewards or even transform them into beneficial ones."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the linearity of large non-linear models", "Title": "when and why the tangent kernel is constant", "Abstract": "The goal of this work is to shed light on the remarkable phenomenon of \"transition to linearity\" of certain neural networks as their width approaches infinity. We show that the \"transition to linearity'' of the model and, equivalently, constancy of the (neural) tangent kernel (NTK) result from the scaling properties of the norm of the Hessian matrix of the network as a function of the network width.\nWe present a general framework for understanding the constancy of the tangent kernel via Hessian scaling applicable to the standard classes of neural networks. Our analysis provides a new perspective on the phenomenon of constant tangent kernel, which is different from the widely accepted \"lazy training''.\nFurthermore, we show that the \"transition to linearity\" is not a general property of wide neural networks and does not hold when the last layer of the network is non-linear. \nIt is also not necessary for successful optimization by gradient descent."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PLLay", "Title": "Efficient Topological Layer based on Persistent Landscapes", "Abstract": "We propose PLLay, a novel topological layer for general deep learning models based on persistence landscapes, in which we can efficiently exploit the underlying topological features of the input data structure. In this work, we show differentiability with respect to layer inputs, for a general persistent homology with arbitrary filtration. Thus, our proposed layer can be placed anywhere in the network and feed critical information on the topological features of input data into subsequent layers to improve the learnability of the networks toward a given task. A task-optimal structure of PLLay is learned during training via backpropagation, without requiring any input featurization or data preprocessing. We provide a novel adaptation for the DTM function-based filtration, and show that the proposed layer is robust against noise and outliers through a stability analysis. We demonstrate the effectiveness of our approach by classification experiments on various datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Attack of the Tails", "Title": "Yes, You Really Can Backdoor Federated Learning", "Abstract": "Due to its decentralized nature, Federated Learning (FL) lends itself to adversarial attacks in the form of backdoors during training. The goal of a backdoor is to corrupt the performance of the trained model on specific sub-tasks (e.g., by classifying green cars as frogs). A range of FL backdoor attacks have been introduced in the literature, but also methods to defend against them, and it is currently an open question whether FL systems can be tailored to be robust against backdoors. In this work, we provide evidence to the contrary. We first establish that, in the general case, robustness to backdoors implies model robustness to adversarial examples, a major open problem in itself. Furthermore, detecting the presence of a backdoor in a FL model is unlikely assuming first-order oracles or polynomial time. We couple our theoretical results with a new family of backdoor attacks, which we refer to as edge-case backdoors. An edge-case backdoor forces a model to misclassify on seemingly easy inputs that are however unlikely to be part of the training, or test data, i.e., they live on the tail of the input distribution. We explain how these edge-case backdoors can lead to unsavory failures and may have serious repercussions on fairness. We further exhibit that, with careful tuning at the side of the adversary, one can insert them across a range of machine learning tasks (e.g., image classification, OCR, text prediction, sentiment analysis), and bypass state-of-the-art defense mechanisms."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Skeleton-bridged Point Completion", "Title": "From Global Inference to Local Adjustment", "Abstract": "Point completion refers to complete the missing geometries of objects from partial point clouds. Existing works usually estimate the missing shape by decoding a latent feature encoded from the input points. However, real-world objects are usually with diverse topologies and surface details, which a latent feature may fail to represent to recover a clean and complete surface. To this end, we propose a skeleton-bridged point completion network (SK-PCN) for shape completion. Given a partial scan, our method first predicts its 3D skeleton to obtain the global structure, and completes the surface by learning displacements from skeletal points. We decouple the shape completion into structure estimation and surface reconstruction, which eases the learning difficulty and benefits our method to obtain on-surface details. Besides, considering the missing features during encoding input points, SK-PCN adopts a local adjustment strategy that merges the input point cloud to our predictions for surface refinement. Comparing with previous methods, our skeleton-bridged manner better supports point normal estimation to obtain the full surface mesh beyond point clouds. The qualitative and quantitative experiments on both point cloud and mesh completion show that our approach outperforms the existing methods on various object categories."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Explore Aggressively, Update Conservatively", "Title": "Stochastic Extragradient Methods with Variable Stepsize Scaling", "Abstract": "Owing to their stability and convergence speed, extragradient methods have become a staple for solving large-scale saddle-point problems in machine learning. The basic premise of these algorithms is the use of an extrapolation step before performing an update; thanks to this exploration step, extra-gradient methods overcome many of the non-convergence issues that plague gradient descent/ascent schemes. On the other hand, as we show in this paper, running vanilla extragradient with stochastic gradients may jeopardize its convergence, even in simple bilinear models. To overcome this failure, we investigate a double stepsize extragradient algorithm where the exploration step evolves at a more aggressive time-scale compared to the update step. We show that this modification allows the method to converge even with stochastic gradients, and we derive sharp convergence rates under an error bound condition."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Patch2Self", "Title": "Denoising Diffusion MRI with Self-Supervised Learning​", "Abstract": "Diffusion-weighted magnetic resonance imaging (DWI) is the only non-invasive method for quantifying microstructure and reconstructing white-matter pathways in the living human brain. Fluctuations from multiple sources create significant noise in DWI data which must be suppressed before subsequent microstructure analysis. We introduce a self-supervised learning method for denoising DWI data, Patch2Self, which uses the entire volume to learn a full-rank locally linear denoiser for that volume. By taking advantage of the oversampled q-space of DWI data, Patch2Self can separate structure from noise without requiring an explicit model for either. We demonstrate the effectiveness of Patch2Self via quantitative and qualitative improvements in microstructure modeling, tracking (via fiber bundle coherency) and model estimation relative to other unsupervised methods on real and simulated data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepSVG", "Title": "A Hierarchical Generative Network for Vector Graphics Animation", "Abstract": "Scalable Vector Graphics (SVG) are ubiquitous in modern 2D interfaces due to their ability to scale to different resolutions. However, despite the success of deep learning-based models applied to rasterized images, the problem of vector graphics representation learning and generation remains largely unexplored. In this work, we propose a novel hierarchical generative network, called DeepSVG, for complex SVG icons generation and interpolation. Our architecture effectively disentangles high-level shapes from the low-level commands that encode the shape itself. The network directly predicts a set of shapes in a non-autoregressive fashion. We introduce the task of complex SVG icons generation by releasing a new large-scale dataset along with an open-source library for SVG manipulation. We demonstrate that our network learns to accurately reconstruct diverse vector graphics, and can serve as a powerful animation tool by performing interpolations and other latent space operations. Our code is available at https://github.com/alexandre01/deepsvg."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SoftFlow", "Title": "Probabilistic Framework for Normalizing Flow on Manifolds", "Abstract": "Flow-based generative models are composed of invertible transformations between two random variables of the same dimension. Therefore, flow-based models cannot be adequately trained if the dimension of the data distribution does not match that of the underlying target distribution. In this paper, we propose SoftFlow, a probabilistic framework for training normalizing flows on manifolds. To sidestep the dimension mismatch problem, SoftFlow estimates a conditional distribution of the perturbed input data instead of learning the data distribution directly. We experimentally show that SoftFlow can capture the innate structure of the manifold data and generate high-quality samples unlike the conventional flow-based models. Furthermore, we apply the proposed framework to 3D point clouds to alleviate the difficulty of forming thin structures for flow-based models. The proposed model for 3D point clouds, namely SoftPointFlow, can estimate the distribution of various shapes more accurately and achieves state-of-the-art performance in point cloud generation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Greedy Optimization Provably Wins the Lottery", "Title": "Logarithmic Number of Winning Tickets is Enough", "Abstract": "Despite the great success of deep learning, recent works show that large deep neural networks are often highly redundant and can be significantly reduced in size. However, the theoretical question of how much we can prune a neural network given a specified tolerance of accuracy drop is still open. This paper provides one answer to this question by proposing a greedy optimization based pruning method. The proposed method has the guarantee that the discrepancy between the pruned network and the original network decays with exponentially fast rate w.r.t. the size of the pruned network, under weak assumptions that apply for most practical settings. Empirically, our method improves prior arts on pruning various network architectures including ResNet, MobilenetV2/V3 on ImageNet."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Conditioning and Processing", "Title": "Techniques to Improve Information-Theoretic Generalization Bounds", "Abstract": "Obtaining generalization bounds for learning algorithms is one of the main subjects studied in theoretical machine learning. In recent years, information-theoretic bounds on generalization have gained the attention of researchers. This approach provides an insight into learning algorithms by considering the mutual information between the model and the training set. In this paper, a probabilistic graphical representation of this approach is adopted and two general techniques to improve the bounds are introduced, namely conditioning and processing. In conditioning, a random variable in the graph is considered as given, while in processing a random variable is substituted with one of its children. These techniques can be used to improve the bounds by either sharpening them or increasing their applicability. It is demonstrated that the proposed framework provides a simple and unified way to explain a variety of recent tightening results. New improved bounds derived by utilizing these techniques are also proposed."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bongard-LOGO", "Title": "A New Benchmark for Human-Level Concept Learning and Reasoning", "Abstract": "Humans have an inherent ability to learn novel concepts from only a few samples and generalize these concepts to different situations. Even though today's machine learning models excel with a plethora of training data on standard recognition tasks, a considerable gap exists between machine-level pattern recognition and human-level concept learning. To narrow this gap, the Bongard Problems (BPs) were introduced as an inspirational challenge for visual cognition in intelligent systems. Albeit new advances in representation learning and learning to learn, BPs remain a daunting challenge for modern AI. Inspired by the original one hundred BPs, we propose a new benchmark Bongard-LOGO for human-level concept learning and reasoning. We develop a program-guided generation technique to produce a large set of human-interpretable visual cognition problems in action-oriented LOGO language. Our benchmark captures three core properties of human cognition: 1) context-dependent perception, in which the same object may have disparate interpretations given different contexts; 2) analogy-making perception, in which some meaningful concepts are traded off for other meaningful concepts; and 3) perception with a few samples but infinite vocabulary. In experiments, we show that the state-of-the-art deep learning methods perform substantially worse than human subjects, implying that they fail to capture core human cognition properties. Finally, we discuss  research directions towards a general architecture for visual reasoning to tackle this benchmark."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Fast Adaptation and Knowledge Accumulation (OSAKA)", "Title": "a New Approach to Continual Learning", "Abstract": "Continual learning agents experience a stream of (related) tasks. The main challenge is that the agent must not forget previous tasks and also adapt to novel tasks in the stream. We are interested in the intersection of two recent continual-learning scenarios. In meta-continual learning, the model is pre-trained using meta-learning to minimize catastrophic forgetting of previous tasks. In continual-meta learning, the aim is to train agents for faster remembering of previous tasks through adaptation. In their original formulations, both methods have limitations. We stand on their shoulders to propose a more general scenario, OSAKA, where an agent must quickly solve new (out-of-distribution) tasks, while also requiring fast remembering. We show that current continual learning, meta-learning, meta-continual learning, and continual-meta learning techniques fail in this new scenario.\nWe propose Continual-MAML, an online extension of the popular MAML algorithm as a strong baseline for this scenario. We show in an empirical study that Continual-MAML is better suited to the new scenario than the aforementioned methodologies including standard continual learning and meta-learning approaches."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Least Squares Regression with Markovian Data", "Title": "Fundamental Limits and Algorithms", "Abstract": "We study the problem of least squares linear regression where the datapoints are dependent and are sampled from a Markov chain. We establish sharp information theoretic minimax lower bounds for this problem in terms of $\\tmix$, the mixing time of the underlying Markov chain, under different noise settings. Our results establish that in general, optimization with Markovian data is strictly harder than optimization with independent data and a trivial algorithm (SGD-DD) that works with only one in every $\\tmix$ samples, which are approximately independent, is minimax optimal. In fact, it is strictly better than the popular Stochastic Gradient Descent (SGD) method with constant step-size which is otherwise minimax optimal in the regression with independent data setting.\n\nBeyond a worst case analysis, we investigate whether structured datasets seen in practice such as Gaussian auto-regressive dynamics can admit more efficient optimization schemes. Surprisingly, even in this specific and natural setting, Stochastic Gradient Descent (SGD) with constant step-size is still no better than SGD-DD. Instead, we propose an algorithm based on experience replay--a popular reinforcement learning technique--that achieves a significantly better error rate. Our improved rate serves as one of the first results where an algorithm outperforms SGD-DD on an interesting Markov chain and also provides one of the first theoretical analyses to support the use of experience replay in practice."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AViD Dataset", "Title": "Anonymized Videos from Diverse Countries", "Abstract": "We introduce a new public video dataset for action recognition: Anonymized Videos from Diverse countries (AViD). Unlike existing public video datasets, AViD is a collection of action videos from many different countries. The motivation is to create a public dataset that would benefit training and pretraining of action recognition models for everybody, rather than making it useful for limited countries. Further, all the face identities in the AViD videos are properly anonymized to protect their privacy. It also is a static dataset where each video is licensed with the creative commons license. We confirm that most of the existing video datasets are statistically biased to only capture action videos from a limited number of countries. We experimentally illustrate that models trained with such biased datasets do not transfer perfectly to action videos from the other countries, and show that AViD addresses such problem. We also confirm that the new AViD dataset could serve as a good dataset for pretraining the models, performing comparably or better than prior datasets. The dataset is available at https://github.com/piergiaj/AViD"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RATT", "Title": "Recurrent Attention to Transient Tasks for Continual Image Captioning", "Abstract": "Research on continual learning has led to a variety of approaches to\nmitigating catastrophic forgetting in feed-forward classification networks.\nUntil now surprisingly little attention has been focused on continual learning\nof recurrent models applied to problems like image captioning. In this paper\nwe take a systematic look at continual learning of LSTM-based models for image\ncaptioning. We propose an attention-based approach that explicitly\naccommodates the transient nature of vocabularies in continual image\ncaptioning tasks -- i.e. that task vocabularies are not disjoint. We call our\nmethod Recurrent Attention to Transient Tasks (RATT), and also show how to\nadapt continual learning approaches based on weight regularization and\nknowledge distillation to recurrent continual learning problems. We apply our\napproaches to incremental image captioning problem on two new continual\nlearning benchmarks we define using the MS-COCO and Flickr30 datasets. Our\nresults demonstrate that RATT is able to sequentially learn five captioning\ntasks while incurring no forgetting of previously learned ones."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hierarchical Patch VAE-GAN", "Title": "Generating Diverse Videos from a Single Sample", "Abstract": "We consider the task of generating diverse and novel videos from a single video sample.\nRecently, new hierarchical patch-GAN based approaches were proposed for generating diverse images, given only a single sample at training time. Moving to videos, these approaches fail to generate diverse samples, and often collapse into generating samples similar to the training video. We introduce a novel patch-based variational autoencoder (VAE) which allows for a much greater diversity in generation. Using this tool, a new hierarchical video generation scheme is constructed: at coarse scales, our patch-VAE is employed, ensuring samples are of high diversity. Subsequently, at finer scales, a patch-GAN renders the fine details, resulting in high quality videos.\nOur experiments show that the proposed method produces diverse samples in both the image domain, and the more challenging video domain. \nOur code and supplementary material (SM) with additional samples are available at https://shirgur.github.io/hp-vae-gan"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MPNet", "Title": "Masked and Permuted Pre-training for Language Understanding", "Abstract": "BERT adopts masked language modeling (MLM) for pre-training and is one of the most successful pre-training models. Since BERT neglects dependency among predicted tokens, XLNet introduces permuted language modeling (PLM) for pre-training to address this problem. However, XLNet does not leverage the full position information of a sentence and thus suffers from position discrepancy between pre-training and fine-tuning. In this paper, we propose MPNet, a novel pre-training method that inherits the advantages of BERT and XLNet and avoids their limitations. MPNet leverages the dependency among predicted tokens through permuted language modeling (vs. MLM in BERT), and takes auxiliary position information as input to make the model see a full sentence and thus reducing the position discrepancy (vs. PLM in XLNet). We pre-train MPNet on a large-scale dataset (over 160GB text corpora) and fine-tune on a variety of down-streaming tasks (GLUE, SQuAD, etc). Experimental results show that MPNet outperforms MLM and PLM by a large margin, and achieves better results on these tasks compared with previous state-of-the-art pre-trained methods (e.g., BERT, XLNet, RoBERTa) under the same model setting. We attach the code in the supplemental materials."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bayes Consistency vs. H-Consistency", "Title": "The Interplay between Surrogate Loss Functions and the Scoring Function Class", "Abstract": "A fundamental question in multiclass classification concerns understanding the consistency properties of surrogate risk minimization algorithms, which minimize a (often convex) surrogate to the multiclass 0-1 loss. In particular, the framework of calibrated surrogates has played an important role in analyzing the Bayes consistency properties of such algorithms, i.e. in studying convergence to a Bayes optimal classifier (Zhang, 2004; Tewari and Bartlett, 2007). However, follow-up work has suggested this framework can be of limited value when studying H-consistency; in particular, concerns have been raised that even when the data comes from an underlying linear model, minimizing certain convex calibrated surrogates over linear scoring functions fails to recover the true model (Long and Servedio, 2013). In this paper, we investigate this apparent conundrum. We find that while some calibrated surrogates can indeed fail to provide H-consistency when minimized over a natural-looking but naively chosen scoring function class F, the situation can potentially be remedied by minimizing them over a more carefully chosen class of scoring functions F. In particular, for the popular one-vs-all hinge and logistic surrogates, both of which are calibrated (and therefore provide Bayes consistency) under realizable models, but were previously shown to pose problems for realizable H-consistency, we derive a form of scoring function class F that enables H-consistency. When H is the class of linear models, the class F consists of certain piecewise linear scoring functions that are characterized by the same number of parameters as in the linear case, and minimization over which can be performed using an adaptation of the min-pooling idea from neural network training. Our experiments confirm that the one-vs-all surrogates, when trained over this class of nonlinear scoring functions F, yield better linear multiclass classifiers than when trained over standard linear scoring functions."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CryptoNAS", "Title": "Private Inference on a ReLU Budget", "Abstract": "Machine learning as a service has given raise to privacy concerns surrounding clients' data and providers' models and has catalyzed research in private inference (PI): methods to process inferences without disclosing inputs.\nRecently, researchers have adapted cryptographic techniques to show PI is possible, however all solutions increase inference latency beyond practical limits. \nThis paper makes the observation that existing models are ill-suited for PI and proposes a novel NAS method, named CryptoNAS, for finding and tailoring models to the needs of PI. The key insight is that in PI operator latency cost are inverted: \nnon-linear operations (e.g., ReLU) dominate latency, while linear layers become effectively free. We develop the idea of a ReLU budget as a proxy for inference latency and use CryptoNAS to build models that maximize accuracy within a given budget. CryptoNAS improves accuracy by 3.4% and  latency by 2.4x over the state-of-the-art."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CHIP", "Title": "A Hawkes Process Model for Continuous-time Networks with Scalable and Consistent Estimation", "Abstract": "In many application settings involving networks, such as messages between users of an on-line social network or transactions between traders in financial markets, the observed data consist of timestamped relational events, which form a continuous-time network. We propose the Community Hawkes Independent Pairs (CHIP) generative model for such networks. We show that applying spectral clustering to an aggregated adjacency matrix constructed from the CHIP model provides consistent community detection for a growing number of nodes and time duration. We also develop consistent and computationally efficient estimators for the model parameters. We demonstrate that our proposed CHIP model and estimation procedure scales to large networks with tens of thousands of nodes and provides superior fits than existing continuous-time network models on several real networks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SAC", "Title": "Accelerating and Structuring Self-Attention via Sparse Adaptive Connection", "Abstract": "While the self-attention mechanism has been widely used in a wide variety of tasks, it has the unfortunate property of a quadratic cost with respect to the input  length, which makes it difficult to deal with long inputs. In this paper, we present a  method for accelerating and structuring self-attentions: Sparse Adaptive Connection (SAC). In SAC, we regard the input sequence as a graph and attention operations are performed between linked nodes. In contrast with previous self-attention models with pre-defined structures (edges), the model learns to construct attention edges to  improve task-specific performances. \nIn this way, the model is able to select the most salient nodes and reduce the quadratic complexity regardless of the sequence length. Based on SAC, we show that previous variants of self-attention models are its special cases. Through extensive experiments on neural machine translation, language modeling, graph representation learning and image classification, we demonstrate SAC is competitive with state-of-the-art models while significantly reducing  memory cost."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HiFi-GAN", "Title": "Generative Adversarial Networks for Efficient and High Fidelity Speech Synthesis", "Abstract": "Several recent work on speech synthesis have employed generative adversarial networks (GANs) to produce raw waveforms. Although such methods improve the sampling efficiency and memory usage, their sample quality has not yet reached that of autoregressive and flow-based generative models. In this work, we propose HiFi-GAN, which achieves both efficient and high-fidelity speech synthesis. As speech audio consists of sinusoidal signals with various periods, we demonstrate that modeling periodic patterns of an audio is crucial for enhancing sample quality. A subjective human evaluation (mean opinion score, MOS) of a single speaker dataset indicates that our proposed method demonstrates similarity to human quality while generating 22.05 kHz high-fidelity audio 167.9 times faster than real-time on a single V100 GPU. We further show the generality of HiFi-GAN to the mel-spectrogram inversion of unseen speakers and end-to-end speech synthesis. Finally, a small footprint version of HiFi-GAN generates samples 13.4 times faster than real-time on CPU with comparable quality to an autoregressive counterpart."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CLEARER", "Title": "Multi-Scale Neural Architecture Search for Image Restoration", "Abstract": "Multi-scale neural networks have shown effectiveness in image restoration tasks, which are usually designed and integrated in a handcrafted manner. Different from the existing labor-intensive handcrafted architecture design paradigms, we present a novel method, termed as multi-sCaLe nEural ARchitecture sEarch for image Restoration (CLEARER), which is a speciﬁcally designed neural architecture search (NAS) for image restoration. Our contributions are twofold. On one hand, we design a multi-scale search space that consists of three task-ﬂexible modules. Namely, 1) Parallel module that connects multi-resolution neural blocks in parallel, while preserving the channels and spatial-resolution in each neural block, 2) Transition module remains the existing multi-resolution features while extending them to a lower resolution, 3) Fusion module integrates multi-resolution features by passing the features of the parallel neural blocks to the current neural blocks. On the other hand, we present novel losses which could 1) balance the tradeoff between the model complexity and performance, which is highly expected to image restoration; and 2) relax the discrete architecture parameters into a continuous distribution which approximates to either 0 or 1. As a result, a differentiable strategy could be employed to search when to fuse or extract multi-resolution features, while the discretization issue faced by the gradient-based NAS could be alleviated. The proposed CLEARER could search a promising architecture in two GPU hours. Extensive experiments show the promising performance of our method comparing with nine image denoising methods and eight image deraining approaches in quantitative and qualitative evaluations. The codes are available at https://github.com/limit-scu."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Functional Regularization for Representation Learning", "Title": "A Unified Theoretical Perspective", "Abstract": "Unsupervised and self-supervised learning approaches have become a crucial tool to learn representations for downstream prediction tasks. While these approaches are widely used in practice and achieve impressive empirical gains, their theoretical understanding largely lags behind. Towards bridging this gap, we present a unifying perspective where several such approaches can be viewed as imposing a regularization on the representation via a learnable function using unlabeled data. We propose a discriminative theoretical framework for analyzing the sample complexity of these approaches, which generalizes the framework of (Balcan and Blum, 2010) to allow learnable regularization functions. Our sample complexity bounds show that, with carefully chosen hypothesis classes to exploit the structure in the data, these learnable regularization functions can prune the hypothesis space, and help reduce the amount of labeled data needed. We then provide two concrete examples of functional regularization, one using auto-encoders and the other using masked self-supervision, and apply our framework to quantify the reduction in the sample complexity bound of labeled data. We also provide complementary empirical results to support our analysis."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Big Bird", "Title": "Transformers for Longer Sequences", "Abstract": "Transformers-based models, such as BERT, have been one of the most successful deep learning models for NLP. Unfortunately, one of their core limitations is the quadratic dependency (mainly in terms of memory) on the sequence length due to their full attention mechanism.  To remedy this, we propose, BigBird, a sparse attention mechanism that reduces this quadratic dependency to linear.  We show that BigBird is a universal approximator of sequence functions and is Turing complete, thereby preserving these  properties of the quadratic, full attention model. Along the way, our theoretical analysis reveals  some of the benefits of having $O(1)$ global tokens (such as CLS), that attend to the entire sequence  as part of the sparse attention mechanism. The proposed sparse attention can handle sequences of length up to 8x of  what was previously possible using  similar hardware.  As a consequence of the capability to handle longer context, BigBird  drastically improves performance  on various NLP tasks  such as question answering and summarization. We also propose novel applications to genomics data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Execution Engines", "Title": "Learning to Execute Subroutines", "Abstract": "A significant effort has been made to train neural networks that replicate algorithmic reasoning, but they often fail to learn the abstract concepts underlying these algorithms. This is evidenced by their inability to generalize to data distributions that are outside of their restricted training sets, namely larger inputs and unseen data. We study these generalization issues at the level of numerical subroutines that comprise common algorithms like sorting, shortest paths, and minimum spanning trees. First, we observe that transformer-based sequence-to-sequence models can learn subroutines like sorting a list of numbers, but their performance rapidly degrades as the length of lists grows beyond those found in the training set. We demonstrate that this is due to attention weights that lose fidelity with longer sequences, particularly when the input numbers are numerically similar. To address the issue, we propose a learned conditional masking mechanism, which enables the model to strongly generalize far outside of its training range with near-perfect accuracy on a variety of algorithms. Second, to generalize to unseen data, we show that encoding numbers with a binary representation leads to embeddings with rich structure once trained on downstream tasks like addition or multiplication. This allows the embedding to handle missing data by faithfully interpolating numbers not seen during training."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Random Reshuffling", "Title": "Simple Analysis with Vast Improvements", "Abstract": "Random Reshuffling (RR) is an algorithm for minimizing finite-sum functions that utilizes iterative gradient descent steps in conjunction with data reshuffling. Often contrasted with its sibling Stochastic Gradient Descent (SGD), RR is usually faster in practice and enjoys significant popularity in convex and non-convex optimization. The convergence rate of RR has attracted substantial attention recently and, for strongly convex and smooth functions, it was shown to converge faster than SGD if 1) the stepsize is small, 2) the gradients are bounded, and 3) the number of epochs is large. We remove these 3 assumptions, improve the dependence on the condition number from $\\kappa^2$ to $\\kappa$ (resp.\\ from $\\kappa$ to $\\sqrt{\\kappa}$) and, in addition, show that RR has a different type of variance. We argue through theory and experiments that the new variance type gives an additional justification of the superior performance of RR. To go beyond strong convexity, we present several results for non-strongly convex and non-convex objectives. We show that in all cases, our theory improves upon existing literature. Finally, we prove fast convergence of the Shuffle-Once (SO) algorithm, which shuffles the data only once, at the beginning of the optimization process. Our theory for strongly convex objectives tightly matches the known lower bounds for both RR and SO and substantiates the common practical heuristic of shuffling once or only a few times. As a byproduct of our analysis, we also get new results for the Incremental Gradient algorithm (IG), which does not shuffle the data at all."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Advances in Black-Box VI", "Title": "Normalizing Flows, Importance Weighting, and Optimization", "Abstract": "Recent research has seen several advances relevant to black-box VI, but the current state of automatic posterior inference is unclear. One such advance is the use of normalizing flows to define flexible posterior densities for deep latent variable models. Another direction is the integration of Monte-Carlo methods to serve two purposes; first, to obtain tighter variational objectives for optimization, and second, to define enriched variational families through sampling. However, both flows and variational Monte-Carlo methods remain relatively unexplored for black-box VI. Moreover, on a pragmatic front, there are several optimization considerations like step-size scheme, parameter initialization, and choice of gradient estimators, for which there are no clear guidance in the existing literature. In this paper, we postulate that black-box VI is best addressed through a careful combination of numerous algorithmic components. We evaluate components relating to optimization, flows, and Monte-Carlo methods on a benchmark of 30 models from the Stan model library. The combination of these algorithmic components significantly advances the state-of-the-art \"out of the box\" variational inference."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ImpatientCapsAndRuns", "Title": "Approximately Optimal Algorithm Configuration from an Infinite Pool", "Abstract": "Algorithm configuration procedures optimize parameters of a given algorithm to perform well over a distribution of inputs. Recent theoretical work focused on the case of selecting between a small number of alternatives. In practice, parameter spaces are often very large or infinite, and so successful heuristic procedures discard parameters ``impatiently'', based on very few observations. Inspired by this idea, we introduce ImpatientCapsAndRuns, which quickly discards less promising configurations, significantly speeding up the search procedure compared to previous algorithms with theoretical guarantees, while still achieving optimal runtime up to logarithmic factors under mild assumptions. Experimental results demonstrate a practical improvement."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SGD with shuffling", "Title": "optimal rates without component convexity and large epoch requirements", "Abstract": "We study without-replacement SGD for solving finite-sum optimization problems. Specifically, depending on how the indices of the finite-sum are shuffled, we consider the RandomShuffle (shuffle at the beginning of each epoch) and SingleShuffle (shuffle only once) algorithms. First, we establish minimax optimal convergence rates of these algorithms up to poly-log factors. Notably, our analysis is general enough to cover gradient dominated nonconvex costs, and does not rely on the convexity of individual component functions unlike existing optimal convergence results. Secondly, assuming convexity of the individual components, we further sharpen the tight convergence results for RandomShuffle by removing the drawbacks common to all prior arts: large number of epochs required for the results to hold, and extra poly-log factor gaps to the lower bound."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Synthesize, Execute and Debug", "Title": "Learning to Repair for Neural Program Synthesis", "Abstract": "The use of deep learning techniques has achieved significant progress for program synthesis from input-output examples. However, when the program semantics become more complex, it still remains a challenge to synthesize programs that are consistent with the specification. In this work, we propose SED, a neural program generation framework that incorporates synthesis, execution, and debugging stages. Instead of purely relying on the neural program synthesizer to generate the final program, SED first produces initial programs using the neural program synthesizer component, then utilizes a neural program debugger to iteratively repair the generated programs. The integration of the debugger component enables SED to modify the programs based on the execution results and specification, which resembles the coding process of human programmers. On Karel, a challenging input-output program synthesis benchmark, SED reduces the error rate of the neural program synthesizer itself by a considerable margin, and outperforms the standard beam search for decoding."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ARMA Nets", "Title": "Expanding Receptive Field for Dense Prediction", "Abstract": "Global information is essential for dense prediction problems, whose goal is to compute a discrete or continuous label for each pixel in the images. Traditional convolutional layers in neural networks, initially designed for image classification, are restrictive in these problems since the filter size limits their receptive fields. In this work, we propose to replace any traditional convolutional layer with an autoregressive moving-average (ARMA) layer, a novel module with an adjustable receptive field controlled by the learnable autoregressive coefficients. Compared with traditional convolutional layers, our ARMA layer enables explicit interconnections of the output neurons and learns its receptive field by adapting the autoregressive coefficients of the interconnections. ARMA layer is adjustable to different types of tasks: for tasks where global information is crucial, it is capable of learning relatively large autoregressive coefficients to allow for an output neuron's receptive field covering the entire input; for tasks where only local information is required, it can learn small or near zero autoregressive coefficients and automatically reduces to a traditional convolutional layer. We show both theoretically and empirically that the effective receptive field of networks with ARMA layers (named ARMA networks) expands with larger autoregressive coefficients. We also provably solve the instability problem of learning and prediction in the ARMA layer through a re-parameterization mechanism. Additionally, we demonstrate that ARMA networks substantially improve their baselines on challenging dense prediction tasks, including video prediction and semantic segmentation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SOLOv2", "Title": "Dynamic and Fast Instance Segmentation", "Abstract": "In this work, we design a simple, direct, and fast framework for instance segmentation with strong performance. To this end, we propose a novel and effective approach, termed SOLOv2, following the principle of the SOLO method [32]. First, our new framework is empowered by an efficient and holistic instance mask representation scheme, which dynamically segments each instance in the image, without resorting to bounding box detection. Specifically, the object mask generation is decoupled into a mask kernel prediction and mask feature learning, which are responsible for generating convolution kernels and the feature maps to be convolved with, respectively. Second, SOLOv2 significantly reduces inference overhead with our novel matrix non-maximum suppression (NMS) technique. Our Matrix NMS performs NMS with parallel matrix operations in one shot, and yields better results. We demonstrate that the proposed SOLOv2 achieves the state-of-the- art performance with high efficiency, making it suitable for both mobile and cloud applications. A light-weight version of SOLOv2 executes at 31.3 FPS and yields 37.1% AP on COCO test-dev. Moreover, our state-of-the-art results in object detection (from our mask byproduct) and panoptic segmentation show the potential of SOLOv2 to serve as a new strong baseline for many instance-level recognition tasks. Code is available at https://git.io/AdelaiDet"}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fewer is More", "Title": "A Deep Graph Metric Learning Perspective Using Fewer Proxies", "Abstract": "Deep metric learning plays a key role in various machine learning tasks. Most of the previous works have been confined to sampling from a mini-batch, which cannot precisely characterize the global geometry of the embedding space. Although researchers have developed proxy- and classification-based methods to tackle the sampling issue, those methods inevitably incur a redundant computational cost. In this paper, we propose a novel Proxy-based deep Graph Metric Learning (ProxyGML) approach from the perspective of graph classification, which uses fewer proxies yet achieves better comprehensive performance. Specifically, multiple global proxies are leveraged to collectively approximate the original data points for each class. To efficiently capture local neighbor relationships, a small number of such proxies are adaptively selected to construct similarity subgraphs between these proxies and each data point. Further, we design a novel reverse label propagation algorithm, by which the neighbor relationships are adjusted according to ground-truth labels, so that a discriminative metric space can be learned during the process of subgraph classification. Extensive experiments carried out on widely-used CUB-200-2011, Cars196, and Stanford Online Products datasets demonstrate the superiority of the proposed ProxyGML over the state-of-the-art methods in terms of both effectiveness and efficiency. The source code is publicly available at \\url{https://github.com/YuehuaZhu/ProxyGML}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning outside the Black-Box", "Title": "The pursuit of interpretable models", "Abstract": "Machine learning has proved its ability to produce accurate models -- but the deployment of these models outside the machine learning community has been hindered by the difficulties of interpreting these models. This paper proposes an algorithm that produces a continuous global interpretation of any given continuous black-box function. Our algorithm employs a variation of projection pursuit in which the ridge functions are chosen to be Meijer G-functions, rather than the usual polynomial splines. Because Meijer G-functions are differentiable in their parameters, we can \"tune\" the parameters of the representation by gradient descent; as a consequence, our algorithm is efficient. Using five familiar data sets from the UCI repository and two familiar machine learning algorithms, we demonstrate that our algorithm produces global interpretations that are both faithful (highly accurate) and parsimonious (involve a small number of terms). Our interpretations permit easy understanding of the relative importance of features and feature interactions. Our interpretation algorithm represents a leap forward from the previous state of the art."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarially Robust Few-Shot Learning", "Title": "A Meta-Learning Approach", "Abstract": "Previous work on adversarially robust neural networks for image classification requires large training sets and computationally expensive training procedures.  On the other hand, few-shot learning methods are highly vulnerable to adversarial examples.  The goal of our work is to produce networks which both perform well at few-shot classification tasks and are simultaneously robust to adversarial examples.  We develop an algorithm, called Adversarial Querying (AQ), for producing adversarially robust meta-learners, and we thoroughly investigate the causes for adversarial vulnerability.  Moreover, our method achieves far superior robust performance on few-shot image classification tasks, such as Mini-ImageNet and CIFAR-FS, than robust transfer learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cream of the Crop", "Title": "Distilling Prioritized Paths For One-Shot Neural Architecture Search", "Abstract": "One-shot weight sharing methods have recently drawn great attention in neural architecture search due to high efficiency and competitive performance. However, weight sharing across models has an inherent deficiency, i.e., insufficient training of subnetworks in the hypernetwork. To alleviate this problem, we present a simple yet effective architecture distillation method. The central idea is that subnetworks can learn collaboratively and teach each other throughout the training process, aiming to boost the convergence of individual models. We introduce the concept of prioritized path, which refers to the architecture candidates exhibiting superior performance during training. Distilling knowledge from the prioritized paths is able to boost the training of subnetworks. Since the prioritized paths are changed on the fly depending on their performance and complexity, the final obtained paths are the cream of the crop. We directly select the most promising one from the prioritized paths as the final architecture, without using other complex search methods, such as reinforcement learning or evolution algorithms. The experiments on ImageNet verify such path distillation method can improve the convergence ratio and performance of the hypernetwork, as well as boosting the training of subnetworks. The discovered architectures achieve superior performance compared to the recent MobileNetV3 and EfficientNet families under aligned settings. Moreover, the experiments on object detection and more challenging search space show the generality and robustness of the proposed method. Code and models are available at \\url{https://github.com/neurips-20/cream.git}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DiffGCN", "Title": "Graph Convolutional Networks via Differential Operators and Algebraic Multigrid Pooling", "Abstract": "Graph Convolutional Networks (GCNs) have shown to be effective in handling\nunordered data like point clouds and meshes. In this work we propose novel\napproaches for graph convolution, pooling and unpooling, inspired from finite\ndifferences and algebraic multigrid frameworks. We form a parameterized convolution\nkernel based on discretized differential operators, leveraging the graph mass,\ngradient and Laplacian. This way, the parameterization does not depend on the\ngraph structure, only on the meaning of the network convolutions as differential\noperators. To allow hierarchical representations of the input, we propose pooling\nand unpooling operations that are based on algebraic multigrid methods, which\nare mainly used to solve partial differential equations on unstructured grids. To\nmotivate and explain our method, we compare it to standard convolutional neural\nnetworks, and show their similarities and relations in the case of a regular grid. Our\nproposed method is demonstrated in various experiments like classification and\npart-segmentation, achieving on par or better than state of the art results. We also\nanalyze the computational cost of our method compared to other GCNs."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Elastic-InfoGAN", "Title": "Unsupervised Disentangled Representation Learning in Class-Imbalanced Data", "Abstract": "We propose a novel unsupervised generative model that learns to disentangle object identity from other low-level aspects in class-imbalanced data. We first investigate the issues surrounding the assumptions about uniformity made by InfoGAN, and demonstrate its ineffectiveness to properly disentangle object identity in imbalanced data. Our key idea is to make the discovery of the discrete latent factor of variation invariant to identity-preserving transformations in real images, and use that as a signal to learn the appropriate latent distribution representing object identity. Experiments on both artificial (MNIST, 3D cars, 3D chairs, ShapeNet) and real-world (YouTube-Faces) imbalanced datasets demonstrate the effectiveness of our method in disentangling object identity as a latent factor of variation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Direct Policy Gradients", "Title": "Direct Optimization of Policies in Discrete Action Spaces", "Abstract": "Direct optimization (McAllester et al., 2010; Song et al., 2016) is an appealing framework that replaces integration with optimization of a random objective for approximating gradients in models with discrete random variables (Lorberbom et al., 2018).  A* sampling (Maddison et al., 2014) is a framework for optimizing such random objectives over large spaces.  We show how to combine these techniques to yield a reinforcement learning algorithm that approximates a policy gradient by finding trajectories that optimize a random objective.  We call the resulting algorithms \\emph{direct policy gradient} (DirPG) algorithms. A main benefit of DirPG algorithms is that they allow the insertion of domain knowledge in the form of upper bounds on return-to-go at training time, like is used in heuristic search, while still directly computing a policy gradient. We further analyze their properties, showing there are cases where DirPG has an exponentially larger probability of sampling informative gradients compared to REINFORCE. We also show that there is a built-in variance reduction technique and that a parameter that was previously viewed as a numerical approximation can be interpreted as controlling risk sensitivity. Empirically, we evaluate the effect of key degrees of freedom and show that the algorithm performs well in illustrative domains compared to baselines."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "WoodFisher", "Title": "Efficient Second-Order Approximation for Neural Network Compression", "Abstract": "Our main application is to neural network compression, where we build on the classic Optimal Brain Damage/Surgeon framework. We demonstrate that WoodFisher significantly outperforms popular state-of-the-art methods for one-shot pruning. Further, even when iterative, gradual pruning is allowed, our method results in a gain in test accuracy over the state-of-the-art approaches for popular image classification datasets such as ImageNet ILSVRC. Further, we show how our method can be extended to take into account first-order information, and illustrate its ability to automatically set layer-wise pruning thresholds, or perform compression in the limited-data regime."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reinforcement Learning in Factored MDPs", "Title": "Oracle-Efficient Algorithms and Tighter Regret Bounds for the Non-Episodic Setting", "Abstract": "We study reinforcement learning in non-episodic factored Markov decision processes (FMDPs). We propose two near-optimal and oracle-efficient algorithms for FMDPs. Assuming oracle access to an FMDP planner, they enjoy a Bayesian and a frequentist regret bound respectively, both of which reduce to the near-optimal bound $O(DS\\sqrt{AT})$ for standard non-factored MDPs. We propose a tighter connectivity measure, factored span, for FMDPs and prove a lower bound that depends on the factored span rather than the diameter $D$. In order to decrease the gap between lower and upper bounds, we propose an adaptation of the REGAL.C algorithm whose regret bound depends on the factored span. Our oracle-efficient algorithms outperform previously proposed near-optimal algorithms on computer network administration simulations."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Precise expressions for random projections", "Title": "Low-rank approximation and randomized Newton", "Abstract": "It is often desirable to reduce the dimensionality of a large dataset\nby projecting it onto a low-dimensional subspace.  Matrix sketching\nhas emerged as a powerful technique for performing such dimensionality\nreduction very efficiently.  Even though there is an extensive\nliterature on the worst-case performance of sketching, existing\nguarantees are typically very different from what is observed in\npractice.  We exploit recent developments in the spectral analysis of\nrandom matrices to develop novel techniques that provide provably\naccurate expressions for the expected value of random projection\nmatrices obtained via sketching.  These expressions can be used to\ncharacterize the performance of dimensionality reduction in a variety\nof common machine learning tasks, ranging from low-rank approximation\nto iterative stochastic optimization.  Our results apply to several\npopular sketching methods, including Gaussian and Rademacher \nsketches, and they enable precise analysis of these methods in terms of \nspectral properties of the data.  Empirical results show that the \nexpressions we derive reflect the practical performance of these \nsketching methods, down to lower-order effects and even constant factors."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "X-CAL", "Title": "Explicit Calibration for Survival Analysis", "Abstract": "Survival analysis models the distribution of time until an event of interest, such as discharge from the hospital or admission to the ICU. When a model’s predicted number of events within any time interval is similar to the observed number, it is called well-calibrated. A survival model’s calibration can be measured using, for instance, distributional calibration (D-CALIBRATION) [Haider et al., 2020] which computes the squared difference between the observed and predicted number of events within different time intervals. Classically, calibration is addressed in post-training analysis. We develop explicit calibration (X-CAL), which turns D-CALIBRATION into a differentiable objective that can be used in survival modeling alongside maximum likelihood estimation and other objectives. X-CAL allows us to directly optimize calibration and strike a desired trade-off between predictive power and calibration. In our experiments, we fit a variety of shallow and deep models on simulated data, a survival dataset based on MNIST, on length-of-stay prediction using MIMIC-III data, and on brain cancer data from The Cancer Genome Atlas. We show that the models we study can be miscalibrated. We give experimental evidence on these datasets that X-CAL improves D-CALIBRATION without a large decrease in concordance or likelihood."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BERT Loses Patience", "Title": "Fast and Robust Inference with Early Exit", "Abstract": "In this paper, we propose Patience-based Early Exit, a straightforward yet effective inference method that can be used as a plug-and-play technique to simultaneously improve the efficiency and robustness of a pretrained language model (PLM). To achieve this, our approach couples an internal-classifier with each layer of a PLM and dynamically stops inference when the intermediate predictions of the internal classifiers do not change for a pre-defined number of steps. Our approach improves inference efficiency as it allows the model to make a prediction with fewer layers. Meanwhile, experimental results with an ALBERT model show that our method can improve the accuracy and robustness of the model by preventing it from overthinking and exploiting multiple classifiers for prediction, yielding a better accuracy-speed trade-off compared to existing early exit methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BAIL", "Title": "Best-Action Imitation Learning for Batch Deep Reinforcement Learning", "Abstract": "There has recently been a surge in research in batch Deep Reinforcement Learning (DRL), which aims for learning a high-performing policy from a given dataset without additional interactions with the environment. We propose a new algorithm, Best-Action Imitation Learning (BAIL), which strives for both simplicity and performance. BAIL learns a V function, uses the V function to select actions it believes to be high-performing, and then uses those actions to train a policy network using imitation learning. For the MuJoCo benchmark, we provide a comprehensive experimental study of BAIL, comparing its performance to four other batch Q-learning and imitation-learning schemes for a large variety of batch datasets. Our experiments show that BAIL's performance is much higher than the other schemes, and is also computationally much faster than the batch Q-learning schemes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoMIR", "Title": "Contrastive Multimodal Image Representation for Registration", "Abstract": "We propose contrastive coding to learn shared, dense image representations, referred to as CoMIRs (Contrastive Multimodal Image Representations). CoMIRs enable the registration of multimodal images where existing registration methods often fail due to a lack of sufficiently similar image structures. CoMIRs reduce the multimodal registration problem to a monomodal one, in which general intensity-based, as well as feature-based, registration algorithms can be applied. The method involves training one neural network per modality on aligned images, using a contrastive loss based on noise-contrastive estimation (InfoNCE). Unlike other contrastive coding methods, used for, e.g., classification, our approach generates image-like representations that contain the information shared between modalities. We introduce a novel, hyperparameter-free modification to InfoNCE, to enforce rotational equivariance of the learnt representations, a property essential to the registration task. We assess the extent of achieved rotational equivariance and the stability of the representations with respect to weight initialization, training set, and hyperparameter settings, on a remote sensing dataset of RGB and near-infrared images. We evaluate the learnt representations through registration of a biomedical dataset of bright-field and second-harmonic generation microscopy images; two modalities with very little apparent correlation. The proposed approach based on CoMIRs significantly outperforms registration of representations created by GAN-based image-to-image translation, as well as a state-of-the-art, application-specific method which takes additional knowledge about the data into account. Code is available at: https://github.com/MIDA-group/CoMIR."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GCN meets GPU", "Title": "Decoupling “When to Sample” from “How to Sample”", "Abstract": "Sampling-based methods promise scalability improvements when paired with stochastic gradient descent in training Graph Convolutional Networks (GCNs). While effective in alleviating the neighborhood explosion, due to bandwidth and memory bottlenecks, these methods lead to computational overheads in preprocessing and loading new samples in heterogeneous systems, which significantly deteriorate the sampling performance. By decoupling the frequency of sampling from the sampling strategy, we propose LazyGCN, a general yet effective framework that can be integrated with any sampling strategy to substantially improve the training time. The basic idea behind LazyGCN is to perform sampling periodically and effectively recycle the sampled nodes to mitigate data preparation overhead. We theoretically analyze the proposed algorithm and show that under a mild condition on the recycling size, by reducing the variance of inner layers, we are able to obtain the same convergence rate as the underlying sampling method. We also give corroborating empirical evidence on large real-world graphs, demonstrating that the proposed schema can significantly reduce the number of sampling steps and yield superior speedup without compromising the accuracy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HAWQ-V2", "Title": "Hessian Aware trace-Weighted Quantization of Neural Networks", "Abstract": "Quantization is an effective method for reducing memory footprint and inference time of Neural Networks. However, ultra low precision quantization could lead to significant degradation in model accuracy. A promising method to address this is to perform mixed-precision quantization, where more sensitive layers are kept at higher precision. However, the search space for a mixed-precision quantization is exponential in the number of layers. Recent work has proposed a novel Hessian based framework, with the aim of reducing this exponential search space by using second-order information. While promising, this prior work has three major limitations: (i) they only use a heuristic metric based on top Hessian eigenvalue as a measure of sensitivity and do not consider the rest of the Hessian spectrum; (ii) their approach only provides relative sensitivity of different layers and therefore requires a manual selection of the mixed-precision setting; and (iii) they do not consider mixed-precision activation quantization. Here, we present HAWQ-V2 which addresses these shortcomings. For (i), we theoretically prove that the right sensitivity metric is the average Hessian trace, instead of just top Hessian eigenvalue. For (ii), we develop a Pareto frontier based method for automatic bit precision selection of different layers without any manual intervention. For (iii), we develop the first Hessian based analysis for mixed-precision activation quantization, which is very beneficial for object detection. We show that HAWQ-V2 achieves new state-of-the-art results for a wide range of tasks. In particular, we present quantization results for InceptionV3, ResNet50, and SqueezeNext, all without any manual bit selection. Furthermore, we present results for object detection on Microsoft COCO, where we achieve 2.6 higher mAP than direct uniform quantization and 1.6 higher mAP than the recently proposed method of FQN, with a smaller model size of 17.9MB."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DisCor", "Title": "Corrective Feedback in Reinforcement Learning via Distribution Correction", "Abstract": "Deep reinforcement learning can learn effective policies for a wide range of tasks, but is notoriously difficult to use due to instability and sensitivity to hyperparameters. The reasons for this remain unclear. In this paper, we study how RL methods based on bootstrapping-based Q-learning can suffer from a pathological interaction between function approximation and the data distribution used to train the Q-function: with standard supervised learning, online data collection should induce corrective feedback, where new data corrects mistakes in old predictions. With dynamic programming methods like Q-learning, such feedback may be absent. This can lead to potential instability, sub-optimal convergence, and poor results when learning from noisy, sparse or delayed rewards. Based on these observations, we propose a new algorithm, DisCor, which explicitly optimizes for data distributions that can correct for accumulated errors in the value function. DisCor computes a tractable approximation to the distribution that optimally induces corrective feedback, which we show results in reweighting samples based on the estimated accuracy of their target values. Using this distribution for training, DisCor results in substantial improvements in a range of challenging RL settings, such as multi-task learning and learning from noisy reward signals."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OTLDA", "Title": "A Geometry-aware Optimal Transport Approach for Topic Modeling", "Abstract": "We present an optimal transport framework for learning topics from textual data. While the celebrated Latent Dirichlet allocation (LDA) topic model and its variants have been applied to many disciplines, they mainly focus on word-occurrences and neglect to incorporate semantic regularities in language. Even though recent works have tried to exploit the semantic relationship between words to bridge this gap, however, these models which are usually extensions of LDA or Dirichlet Multinomial mixture (DMM) are tailored to deal effectively with either regular or short documents. The optimal transport distance provides an appealing tool to incorporate the geometry of word semantics into it. Moreover, recent developments on efficient computation of optimal transport distance also promote its application in topic modeling. In this paper we ground on optimal transport theory to naturally exploit the geometric structures of semantically related words in embedding spaces which leads to more interpretable learned topics. Comprehensive experiments illustrate that the proposed framework outperforms competitive approaches in terms of topic coherence on assorted text corpora which include both long and short documents. The representation of learned topic also leads to better accuracy on classification downstream tasks, which is considered as an extrinsic evaluation."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RandAugment", "Title": "Practical Automated Data Augmentation with a Reduced Search Space", "Abstract": "Recent work on automated data augmentation strategies has led to state-of-the-art results in image classification and object detection. An obstacle to a large-scale adoption of these methods is that they require a separate and expensive search phase. A common way to overcome the expense of the search phase was to use a smaller proxy task. However, it was not clear if the optimized hyperparameters found on the proxy task are also optimal for the actual task. In this work, we rethink the process of designing automated data augmentation strategies. We find that while previous work required searching for many augmentation parameters (e.g. magnitude and probability) independently for each augmentation operation, it is sufficient to only search for a single parameter that jointly controls all operations. Hence, we propose a search space that is vastly smaller (e.g. from 10^32 to 10^2 potential candidates). The smaller search space significantly reduces the computational expense of automated data augmentation and permits the removal of a separate proxy task. Despite the simplifications, our method achieves state-of-the-art performance on CIFAR-10, SVHN, and ImageNet. On EfficientNet-B7, we achieve 84.7% accuracy, a 1.0% increase over baseline augmentation and a 0.4% improvement over AutoAugment on the ImageNet dataset. On object detection, the same method used for classification leads to 1.0-1.3% improvement over the baseline augmentation method on COCO. Code is available online."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DisARM", "Title": "An Antithetic Gradient Estimator for Binary Latent Variables", "Abstract": "Training models with discrete latent variables is challenging due to the difficulty of estimating the gradients accurately. Much of the recent progress has been achieved by taking advantage of continuous relaxations of the system, which are not always available or even possible. The Augment-REINFORCE-Merge (ARM) estimator provides an alternative that, instead of relaxation, uses continuous augmentation. Applying antithetic sampling over the augmenting variables yields a relatively low-variance and unbiased estimator applicable to any model with binary latent variables. However, while antithetic sampling reduces variance, the augmentation process increases variance. We show that ARM can be improved by analytically integrating out the randomness introduced by the augmentation process, guaranteeing substantial variance reduction. Our estimator, DisARM, is simple to implement and has the same computational cost as ARM. We evaluate DisARM on several generative modeling benchmarks and show that it consistently outperforms ARM and a strong independent sample baseline in terms of both variance and log-likelihood. Furthermore, we propose a local version of DisARM designed for optimizing the multi-sample variational bound, and show that it outperforms VIMCO, the current state-of-the-art method."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ICNet", "Title": "Intra-saliency Correlation Network for Co-Saliency Detection", "Abstract": "Intra-saliency and inter-saliency cues have been extensively studied for co-saliency detection (Co-SOD). Model-based methods produce coarse Co-SOD results due to hand-crafted intra- and inter-saliency features. Current data-driven models exploit inter-saliency cues, but undervalue the potential power of intra-saliency cues. In this paper, we propose an Intra-saliency Correlation Network (ICNet) to extract intra-saliency cues from the single image saliency maps (SISMs) predicted by any off-the-shelf SOD method, and obtain inter-saliency cues by correlation techniques. Specifically, we adopt normalized masked average pooling (NMAP) to extract latent intra-saliency categories from the SISMs and semantic features as intra cues. Then we employ a correlation fusion module (CFM) to obtain inter cues by exploiting correlations between the intra cues and single-image features. To improve Co-SOD performance, we propose a category-independent rearranged self-correlation feature (RSCF) strategy. Experiments on three benchmarks show that our ICNet outperforms previous state-of-the-art methods on Co-SOD. Ablation studies validate the effectiveness of our contributions. The PyTorch code is available at https://github.com/blanclist/ICNet."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AdaBelief Optimizer", "Title": "Adapting Stepsizes by the Belief in Observed Gradients", "Abstract": "Most popular optimizers for deep learning can be broadly categorized as adaptive methods (e.g.~Adam) and accelerated schemes (e.g.~stochastic gradient descent (SGD) with momentum).\nFor many models such as convolutional neural networks (CNNs), adaptive methods typically converge faster but generalize worse compared to SGD; for complex settings such as generative adversarial networks (GANs), adaptive methods are typically the default because of their stability. We propose AdaBelief to simultaneously achieve three goals: fast convergence as in adaptive methods, good generalization as in SGD, and training stability. The intuition for AdaBelief is to adapt the stepsize according to the \"belief\" in the current gradient direction.\nViewing the exponential moving average (EMA) of the noisy gradient as the prediction of the gradient at the next time step, if the observed gradient greatly deviates from the prediction, we distrust the current observation and take a small step; if the observed gradient is close to the prediction, we trust it and take a large step.\nWe validate AdaBelief in extensive experiments, showing that it outperforms other methods with fast convergence and high accuracy on image classification and language modeling. Specifically, on ImageNet, AdaBelief achieves comparable accuracy to SGD. Furthermore, in the training of a GAN on Cifar10, AdaBelief demonstrates high stability and improves the quality of generated samples compared to a well-tuned Adam optimizer."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One Ring to Rule Them All", "Title": "Certifiably Robust Geometric Perception with Outliers", "Abstract": "We propose the first general and practical framework to design certifiable algorithms for robust geometric perception in the presence of a large amount of outliers. We investigate the use of a truncated least squares (TLS) cost function, which is known to be robust to outliers, but leads to hard, nonconvex, and nonsmooth optimization problems. Our first contribution is to show that –for a broad class of geometric perception problems– TLS estimation can be reformulated as an optimization over the ring of polynomials and Lasserre’s hierarchy of convex moment relaxations is empirically tight at the minimum relaxation order (i.e., certifiably obtains the global minimum of the nonconvex TLS problem). Our second contribution is to exploit the structural sparsity of the objective and constraint polynomials and leverage basis reduction to significantly reduce the size of the semidefinite program (SDP) resulting from the moment relaxation, without compromising its tightness. Our third contribution is to develop scalable dual optimality certifiers from the lens of sums-of-squares (SOS) relaxation, that can compute the suboptimality gap and possibly certify global optimality of any candidate solution (e.g., returned by fast heuristics such as RANSAC or graduated non-convexity). Our dual certifiers leverage Douglas-Rachford Splitting to solve a convex feasibility SDP. Numerical experiments across different perception problems, including single rotation averaging, shape alignment, 3D point cloud and mesh registration, and high-integrity satellite pose estimation, demonstrate the tightness of our relaxations, the correctness of the certification, and the scalability of the proposed dual certifiers to large problems, beyond the reach of current SDP solvers."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisiting Frank-Wolfe for Polytopes", "Title": "Strict Complementarity and Sparsity", "Abstract": "In recent years it was proved that simple modifications of the classical Frank-Wolfe algorithm (aka conditional gradient algorithm) for smooth convex minimization over convex and compact polytopes, converge with linear rate, assuming the objective function has the quadratic growth property. However, the rate of these methods depends explicitly on the dimension of the problem which cannot explain their empirical success for large scale problems. In this paper we first demonstrate that already for very simple problems and even when the optimal solution lies on a low-dimensional face of the polytope, such dependence on the dimension cannot be avoided in worst case. We then revisit the addition of a strict complementarity assumption already considered in Wolfe's classical book \\cite{Wolfe1970}, and prove that under this condition, the Frank-Wolfe method with away-steps and line-search converges linearly with rate that depends explicitly only on the dimension of the optimal face, hence providing a significant improvement in case the optimal solution is sparse. We motivate this strict complementarity condition by proving that it implies sparsity-robustness of optimal solutions to noise."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast Convergence of Langevin Dynamics on Manifold", "Title": "Geodesics meet Log-Sobolev", "Abstract": "Sampling is a fundamental and arguably very important task with numerous applications in Machine Learning. One approach to sample from a high dimensional distribution $e^{-f}$ for some function $f$ is the Langevin Algorithm (LA). Recently, there has been a lot of progress in showing fast convergence of LA even in cases where $f$ is non-convex, notably \\cite{VW19}, \\cite{MoritaRisteski} in which the former paper focuses on functions $f$ defined in $\\mathbb{R}^n$ and the latter paper focuses on functions with symmetries (like matrix completion type objectives) with manifold structure. Our work generalizes the results of \\cite{VW19} where $f$ is defined on a manifold $M$ rather than $\\mathbb{R}^n$. From technical point of view, we show that KL decreases in a geometric rate whenever the distribution $e^{-f}$ satisfies a log-Sobolev inequality on $M$."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ColdGANs", "Title": "Taming Language GANs with Cautious Sampling Strategies", "Abstract": "We report experimental results obtained on three tasks: unconditional text generation, question generation, and abstractive summarization. For the first time, to the best of our knowledge, the proposed language GANs compare favorably to MLE, and obtain improvements over the state-of-the-art on the considered tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hedging in games", "Title": "Faster convergence of external and swap regrets", "Abstract": "We consider the setting where players run the Hedge algorithm or its optimistic variant \\cite{syrgkanis2015fast} to play an n-action game repeatedly for T rounds.\n1) For two-player games, we show that the regret of optimistic Hedge decays at \\tilde{O}( 1/T ^{5/6} ), improving the previous bound O(1/T^{3/4}) by \\cite{syrgkanis2015fast}.\n2) In contrast, we show that the convergence rate of vanilla Hedge is no better than \\tilde{\\Omega}(1/ \\sqrt{T})}, addressing an open question posted in \\cite{syrgkanis2015fast}.\nFor general m-player games, we show that the swap regret of each player decays at rate \\tilde{O}(m^{1/2} (n/T)^{3/4}) when they combine optimistic Hedge with the classical external-to-internal reduction of Blum and Mansour \\cite{blum2007external}. The algorithm can also be modified to achieve the same rate against itself and a rate of \\tilde{O}(\\sqrt{n/T}) against adversaries. Via standard connections, our upper bounds also imply faster convergence to coarse correlated equilibria in two-player games and to correlated equilibria in multiplayer games."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MMA Regularization", "Title": "Decorrelating Weights of Neural Networks by Maximizing the Minimal Angles", "Abstract": "The strong correlation between neurons or filters can significantly weaken the generalization ability of neural networks. Inspired by the well-known Tammes problem, we propose a novel diversity regularization method to address this issue, which makes the normalized weight vectors of neurons or filters distributed on a hypersphere as uniformly as possible, through maximizing the minimal pairwise angles (MMA). This method can easily exert its effect by plugging the MMA regularization term into the loss function with negligible computational overhead. The MMA regularization is simple, efficient, and effective. Therefore, it can be used as a basic regularization method in neural network training. Extensive experiments demonstrate that MMA regularization is able to enhance the generalization ability of various modern models and achieves considerable performance improvements on CIFAR100 and TinyImageNet datasets. In addition, experiments on face verification show that MMA regularization is also effective for feature learning. Code is available at: https://github.com/wznpub/MMA_Regularization."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HRN", "Title": "A Holistic Approach to One Class Learning", "Abstract": "Existing neural network based one-class learning methods mainly use various forms of auto-encoders or GAN style adversarial training to learn a latent representation of the given one class of data. This paper proposes an entirely different approach based on a novel regularization, called holistic regularization (or H-regularization), which enables the system to consider the data holistically, not to produce a model that biases towards some features.  Combined with a proposed 2-norm instance-level data normalization, we obtain an effective one-class learning method, called HRN. To our knowledge, the proposed regularization and the normalization method have not been reported before. Experimental evaluation using both benchmark image classification and traditional anomaly detection datasets show that HRN markedly outperforms the state-of-the-art existing deep/non-deep learning models."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization bound of globally optimal non-convex neural network training", "Title": "Transportation map estimation by infinite dimensional Langevin dynamics", "Abstract": "We introduce a new theoretical framework to analyze deep learning optimization with connection to its generalization error.\nExisting frameworks such as mean field theory and neural tangent kernel theory \nfor neural network optimization analysis \ntypically require taking limit of infinite width of the network to show its global convergence.\nThis potentially makes it difficult to directly deal with finite width network; especially in the neural tangent kernel regime, we cannot reveal favorable properties of neural networks {\\it beyond kernel methods}. \nTo realize more natural analysis, we consider a completely different approach in which \nwe formulate the parameter training as a transportation map estimation and show its global convergence via the theory of the {\\it infinite dimensional Langevin dynamics}.\nThis enables us to analyze narrow and wide networks in a unifying manner.\nMoreover, we give generalization gap and excess risk bounds for the solution obtained by the dynamics.\nThe excess risk bound achieves the so-called fast learning rate. \nIn particular, we show an exponential convergence for a classification problem and a minimax optimal rate for a regression problem."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BayReL", "Title": "Bayesian Relational Learning for Multi-omics Data Integration", "Abstract": "High-throughput molecular profiling technologies have produced high-dimensional multi-omics data, enabling systematic understanding of living systems at the genome scale. Studying molecular interactions across different data types helps reveal signal transduction mechanisms across different classes of molecules. In this paper, we develop a novel Bayesian representation learning method that infers the relational interactions across multi-omics data types. Our method, Bayesian Relational Learning (BayReL) for multi-omics data integration, takes advantage of a priori known relationships among the same class of molecules, modeled as a graph at each corresponding view, to learn view-specific latent variables as well as a multi-partite graph that encodes the interactions across views. Our experiments on several real-world datasets demonstrate enhanced performance of BayReL in inferring meaningful interactions compared to existing baselines."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Iterative Deep Graph Learning for Graph Neural Networks", "Title": "Better and Robust Node Embeddings", "Abstract": "In this paper, we propose an end-to-end graph learning framework, namely \\textbf{I}terative \\textbf{D}eep \\textbf{G}raph \\textbf{L}earning (\\alg), for jointly and iteratively learning graph structure and graph embedding. The key rationale of \\alg is to learn a better graph structure based on better node embeddings, and vice versa (i.e., better node embeddings based on a better graph structure). Our iterative method dynamically stops when the learned graph structure approaches close enough to the graph optimized for the downstream prediction task. In addition, we cast the graph learning problem as a similarity metric learning problem and leverage adaptive graph regularization for controlling the quality of the learned graph. Finally, combining the anchor-based approximation technique, we further propose a scalable version of \\alg, namely \\salg, which significantly reduces the time and space complexity of \\alg without compromising the performance. Our extensive experiments on nine benchmarks show that our proposed \\alg models can consistently outperform or match the state-of-the-art baselines. Furthermore, \\alg can be more robust to adversarial graphs and cope with both transductive and inductive learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COPT", "Title": "Coordinated Optimal Transport on Graphs", "Abstract": "We introduce COPT, a novel distance metric between graphs defined via an optimization routine, computing a coordinated pair of optimal transport maps simultaneously. This gives an unsupervised way to learn general-purpose graph representation, applicable to both graph sketching and graph comparison. COPT involves simultaneously optimizing dual transport plans, one between the vertices of two graphs, and another between graph signal probability distributions. We show theoretically that our method preserves important global structural information on graphs, in particular spectral information, and analyze connections to existing studies. Empirically, COPT outperforms state of the art methods in graph classification on both synthetic and real datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "No Subclass Left Behind", "Title": "Fine-Grained Robustness in Coarse-Grained Classification Problems", "Abstract": "In real-world classification tasks, each class often comprises multiple finer-grained \"subclasses.\" As the subclass labels are frequently unavailable, models trained using only the coarser-grained class labels often exhibit highly variable performance across different subclasses. This phenomenon, known as hidden stratification, has important consequences for models deployed in safety-critical applications such as medicine. We propose GEORGE, a method to both measure and mitigate hidden stratification even when subclass labels are unknown. We first observe that unlabeled subclasses are often separable in the feature space of deep models, and exploit this fact to estimate subclass labels for the training data via clustering techniques. We then use these approximate subclass labels as a form of noisy supervision in a distributionally robust optimization objective. We theoretically characterize the performance of GEORGE in terms of the worst-case generalization error across any subclass. We empirically validate GEORGE on a mix of real-world and benchmark image classification datasets, and show that our approach boosts worst-case subclass accuracy by up to 15 percentage points compared to standard training techniques, without requiring any information about the subclasses."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Model Rubik’s Cube", "Title": "Twisting Resolution, Depth and Width for TinyNets", "Abstract": "To obtain excellent deep neural architectures, a series of techniques are carefully designed in EfficientNets. The giant formula for simultaneously enlarging the resolution, depth and width provides us a Rubik’s cube for neural networks. So that we can find networks with high efficiency and excellent performance by twisting the three dimensions. This paper aims to explore the twisting rules for obtaining deep neural networks with minimum model sizes and computational costs. Different from the network enlarging, we observe that resolution and depth are more important than width for tiny networks. Therefore, the original method, \\ie the compound scaling in EfficientNet is no longer suitable. To this end, we summarize a tiny formula for downsizing neural architectures through a series of smaller models derived from the EfficientNet-B0 with the FLOPs constraint. Experimental results on the ImageNet benchmark illustrate that our TinyNet performs much better than the smaller version of EfficientNets using the inversed giant formula. For instance, our TinyNet-E achieves a 59.9\\% Top-1 accuracy with only 24M FLOPs, which is about 1.9\\% higher than that of the previous best MobileNetV3 with similar computational cost. Code will be available at \\url{https://github.com/huawei-noah/CV-Backbones/tree/master/tinynet}, and \\url{https://gitee.com/mindspore/mindspore/tree/master/model_zoo/research/cv/tinynet}."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Self-Adaptive Training", "Title": "beyond Empirical Risk Minimization", "Abstract": "We propose self-adaptive training---a new training algorithm that dynamically calibrates training process by model predictions without incurring extra computational cost---to improve generalization of deep learning for potentially corrupted training data. This problem is important to robustly learning from data that are corrupted by, e.g., random noises and adversarial examples. The standard empirical risk minimization (ERM) for such data, however, may easily overfit noises and thus suffers from sub-optimal performance. In this paper, we observe that model predictions can substantially benefit the training process: self-adaptive training significantly mitigates the overfitting issue and improves generalization over ERM under both random and adversarial noises. Besides, in sharp contrast to the recently-discovered double-descent phenomenon in ERM, self-adaptive training exhibits a single-descent error-capacity curve, indicating that such a phenomenon might be a result of overfitting of noises. Experiments on the CIFAR and ImageNet datasets verify the effectiveness of our approach in two applications: classification with label noise and selective classification."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TaylorGAN", "Title": "Neighbor-Augmented Policy Update Towards Sample-Efficient Natural Language Generation", "Abstract": "Score function-based natural language generation (NLG) approaches such as REINFORCE, in general, suffer from low sample efficiency and training instability problems.\nThis is mainly due to the non-differentiable nature of the discrete space sampling and thus these methods have to treat the discriminator as a black box and ignore the gradient information.\nTo improve the sample efficiency and reduce the variance of REINFORCE, we propose a novel approach, TaylorGAN, which augments the gradient estimation by off-policy update and the first-order Taylor expansion.\nThis approach enables us to train NLG models from scratch with smaller batch size --- without maximum likelihood pre-training, and outperforms existing GAN-based methods on multiple metrics of quality and diversity."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Feature Shift Detection", "Title": "Localizing Which Features Have Shifted via Conditional Distribution Tests", "Abstract": "While previous distribution shift detection approaches can identify if a shift has occurred, these approaches cannot localize which specific features have caused a distribution shift---a critical step in diagnosing or fixing any underlying issue. For example, in military sensor networks, users will want to detect when one or more of the sensors has been compromised, and critically, they will want to know which specific sensors might be compromised. Thus, we first define a formalization of this problem as multiple conditional distribution hypothesis tests and propose both non-parametric and parametric statistical tests. For both efficiency and flexibility, we then propose to use a test statistic based on the density model score function (\\ie gradient with respect to the input)---which can easily compute test statistics for all dimensions in a single forward and backward pass. Any density model could be used for computing the necessary statistics including deep density models such as normalizing flows or autoregressive models. We additionally develop methods for identifying when and where a shift occurs in multivariate time-series data and show results for multiple scenarios using realistic attack models on both simulated and real-world data."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Flajolet-Martin Sketch Itself Preserves Differential Privacy", "Title": "Private Counting with Minimal Space", "Abstract": "We revisit the problem of counting the number of distinct elements $\\dist$ in a data stream $D$, over a domain $[u]$. We propose an $(\\epsilon,\\delta)$-differentially private algorithm that approximates $\\dist$ within a factor of $(1\\pm\\gamma)$, and with additive error of $O(\\sqrt{\\ln(1/\\delta)}/\\epsilon)$, using space $O(\\ln(\\ln(u)/\\gamma)/\\gamma^2)$. We improve on the prior work at least quadratically and up to exponentially, in terms of both space and additive error. Our additive error guarantee is optimal up to a factor of $O(\\sqrt{\\ln(1/\\delta)})$, and the space bound is optimal up to a factor of $O\\left(\\min\\left\\{\\ln\\left(\\frac{\\ln(u)}{\\gamma}\\right), \\frac{1}{\\gamma^2}\\right\\}\\right)$. We assume the existence of an ideal uniform random hash function, and ignore the space required to store it. We later relax this requirement by assuming pseudorandom functions and appealing to a computational variant of differential privacy, SIM-CDP.\n\nOur algorithm is built on top of the celebrated Flajolet-Martin (FM) sketch. We show that FM-sketch is differentially private as is, as long as there are $\\approx \\sqrt{\\ln(1/\\delta)}/(\\epsilon\\gamma)$ distinct elements in the data set. Along the way, we prove a structural result showing that the maximum of $k$ i.i.d. random variables is statistically close (in the sense of $\\epsilon$-differential privacy) to the maximum of $(k+1)$ i.i.d. samples from the same distribution, as long as $k=\\Omega\\left(\\frac{1}{\\epsilon}\\right)$. \n\nFinally, experiments show that our algorithms introduces error within an order of magnitude of the non-private analogues for streams with thousands of distinct elements, even while providing strong privacy guarantee ($\\eps\\leq 1$)."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HYDRA", "Title": "Pruning Adversarially Robust Neural Networks", "Abstract": "In safety-critical but computationally resource-constrained applications, deep learning faces two key challenges: lack of robustness against adversarial attacks and large neural network size (often millions of parameters). While the research community has extensively explored the use of robust training and network pruning \\emph{independently} to address one of these challenges, only a few recent works have studied them jointly.  However, these works inherit a heuristic pruning strategy that was developed for benign training, which performs poorly when integrated with robust training techniques, including adversarial training and verifiable robust training. To overcome this challenge, we propose to make pruning techniques aware of the robust training objective and let the training objective guide the search for which connections to prune. We realize this insight by formulating the pruning objective as an empirical risk minimization problem which is solved efficiently using SGD. We demonstrate that our approach, titled HYDRA, achieves compressed networks with \\textit{state-of-the-art} benign and robust accuracy, \\textit{simultaneously}. We demonstrate the success of our approach across CIFAR-10, SVHN, and ImageNet dataset with four robust training techniques: iterative adversarial training, randomized smoothing, MixTrain, and CROWN-IBP. We also demonstrate the existence of highly robust sub-networks within non-robust networks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NVAE", "Title": "A Deep Hierarchical Variational Autoencoder", "Abstract": "Normalizing flows, autoregressive models, variational autoencoders (VAEs), and deep energy-based models are among competing likelihood-based frameworks for deep generative learning. Among them, VAEs have the advantage of fast and tractable sampling and easy-to-access encoding networks. However, they are currently outperformed by other models such as normalizing flows and autoregressive models. While the majority of the research in VAEs is focused on the statistical challenges, we explore the orthogonal direction of carefully designing neural architectures for hierarchical VAEs. We propose Nouveau VAE (NVAE), a deep hierarchical VAE built for image generation using depth-wise separable convolutions and batch normalization. NVAE is equipped with a residual parameterization of Normal distributions and its training is stabilized by spectral regularization. We show that NVAE achieves state-of-the-art results among non-autoregressive likelihood-based models on the MNIST, CIFAR-10, CelebA 64, and CelebA HQ datasets and it provides a strong baseline on FFHQ. For example, on CIFAR-10, NVAE pushes the state-of-the-art from 2.98 to 2.91 bits per dimension, and it produces high-quality images on CelebA HQ. To the best of our knowledge, NVAE is the first successful VAE applied to natural images as large as 256x256 pixels. The source code is publicly available."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Wisdom of the Ensemble", "Title": "Improving Consistency of Deep Learning Models", "Abstract": "Deep learning classifiers are assisting humans in making decisions and hence the user's trust in these models is of paramount importance. Trust is often a function of constant behavior. From an AI model perspective it means given the same input the user would expect the same output, especially for correct outputs, or in other words consistently correct outputs. This paper studies a model behavior in the context of periodic retraining of deployed models where the outputs from successive generations of the models might not agree on the correct labels assigned to the same input. We formally define consistency and correct-consistency of a learning model. We prove that consistency and correct-consistency of an ensemble learner is not less than the average consistency and correct-consistency of individual learners and correct-consistency can be improved with a probability by combining learners with accuracy not less than the average accuracy of ensemble component learners. To validate the theory using three datasets and two state-of-the-art deep learning classifiers we also propose an efficient dynamic snapshot ensemble method and demonstrate its value.\nCode for our algorithm is available at https://github.com/christa60/dynens."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EvolveGraph", "Title": "Multi-Agent Trajectory Prediction with Dynamic Relational Reasoning", "Abstract": "Multi-agent interacting systems are prevalent in the world, from purely physical systems to complicated social dynamic systems. In many applications, effective understanding of the situation and accurate trajectory prediction of interactive agents play a significant role in downstream tasks, such as decision making and planning. In this paper, we propose a generic trajectory forecasting framework (named EvolveGraph) with explicit relational structure recognition and prediction via latent interaction graphs among multiple heterogeneous, interactive agents. Considering the uncertainty of future behaviors, the model is designed to provide multi-modal prediction hypotheses. Since the underlying interactions may evolve even with abrupt changes, and different modalities of evolution may lead to different outcomes, we address the necessity of dynamic relational reasoning and adaptively evolving the interaction graphs. We also introduce a double-stage training pipeline which not only improves training efficiency and accelerates convergence, but also enhances model performance. The proposed framework is evaluated on both synthetic physics simulations and multiple real-world benchmark datasets in various areas. The experimental results illustrate that our approach achieves state-of-the-art performance in terms of prediction accuracy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Bandits with Corruptions", "Title": "Regret Lower Bound and No-regret Algorithm", "Abstract": "This paper studies adversarial bandits with corruptions. In the basic adversarial bandit setting, the reward of arms is predetermined by an adversary who is oblivious to the learner’s policy. In this paper, we consider an extended setting in which an attacker sits in-between the environment and the learner, and is endowed with a limited budget to corrupt the reward of the selected arm. We have two main results. First, we derive a lower bound on the regret of any bandit algorithm that is aware of the budget of the attacker. Also, for budget-agnostic algorithms, we characterize an impossibility result demonstrating that even when the attacker has a sublinear budget, i.e., a budget growing sublinearly with time horizon T, they fail to achieve a sublinear regret.\nSecond, we propose ExpRb, a bandit algorithm that incorporates a biased estimator and a robustness parameter to deal with corruption. We characterize the regret of ExpRb as a function of the corruption budget and show that for the case of a known corruption budget, the regret of ExpRb is tight."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beta R-CNN", "Title": "Looking into Pedestrian Detection from Another Perspective", "Abstract": "Recently significant progress has been made in pedestrian detection, but it remains challenging to achieve high performance in occluded and crowded scenes. It could be mostly attributed to the widely used representation of pedestrians, i.e., 2Daxis-aligned bounding box, which just describes the approximate location and size of the object. Bounding box models the object as a uniform distribution within the boundary, making pedestrians indistinguishable in occluded and crowded scenes due to much noise. To eliminate the problem, we propose a novel representation based on 2D beta distribution, named Beta Representation. It pictures a pedestrianby explicitly constructing the relationship between full-body and visible boxes, and emphasizes the center of visual mass by assigning different probability valuesto  pixels.   As  a  result,  Beta  Representation  is  much  better  for  distinguishing highly-overlapped instances in crowded scenes with a new NMS strategy named BetaNMS. What’s more, to fully exploit Beta Representation, a novel pipeline Beta R-CNN equipped with BetaHead and BetaMask is proposed, leading to high detection performance in occluded and crowded scenes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dialog without Dialog Data", "Title": "Learning Visual Dialog Agents from VQA Data", "Abstract": "Can we develop visually grounded dialog agents that can efficiently adapt to new tasks without forgetting how to talk to people? Such agents could leverage a larger variety of existing data to generalize to a new task, minimizing expensive data collection and annotation. In this work, we study a setting we call \n\"Dialog without Dialog\", which requires agents to develop visually grounded dialog models that can adapt to new tasks without language level supervision.\nBy factorizing intention and language, our model minimizes linguistic drift after fine-tuning for new tasks. We present qualitative results, automated metrics, and human studies that all show our model can adapt to new tasks and maintain language quality. Baselines either fail to perform well at new tasks or experience language drift, becoming unintelligible to humans. Code has been made available at: https://github.com/mcogswell/dialogwithoutdialog."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GCOMB", "Title": "Learning Budget-constrained Combinatorial Algorithms over Billion-sized Graphs", "Abstract": "There has been an increased interest in discovering heuristics for combinatorial problems on graphs through machine learning. While existing techniques have primarily focused on obtaining high-quality solutions, scalability to billion-sized graphs has not been adequately addressed. In addition, the impact of a budget-constraint, which is necessary for many practical scenarios, remains to be studied. In this paper, we propose a framework called GCOMB to bridge these gaps. GCOMB trains a Graph Convolutional Network (GCN) using a novel probabilistic greedy mechanism to predict the quality of a node. To further facilitate the combinatorial nature of the problem, GCOMB utilizes a Q-learning framework, which is made efficient through importance sampling. We perform extensive experiments on real graphs to benchmark the efficiency and efficacy of GCOMB. Our results establish that GCOMB is 100 times faster and marginally better in quality than state-of-the-art algorithms for learning combinatorial algorithms. Additionally, a case-study on the practical combinatorial problem of Influence Maximization (IM) shows GCOMB is 150 times faster than the specialized IM algorithm IMM with similar quality."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OrganITE", "Title": "Optimal transplant donor organ offering using an individual treatment effect", "Abstract": "Transplant-organs are a scarce medical resource. The uniqueness of each organ and the patients' heterogeneous responses to the organs present a unique and challenging machine learning problem. In this problem there are two key challenges: (i) assigning each organ \"optimally\" to a patient in the queue; (ii) accurately estimating the potential outcomes associated with each patient and each possible organ. In this paper, we introduce OrganITE, an organ-to-patient assignment methodology that assigns organs based not only on its own estimates of the potential outcomes but also on organ scarcity. By modelling and accounting for organ scarcity we significantly increase total life years across the population, compared to the existing greedy approaches that simply optimise life years for the current organ available. Moreover, we propose an individualised treatment effect model capable of addressing the high dimensionality of the organ space. We test our method on real and simulated data, resulting in as much as an additional year of life expectancy as compared to existing organ-to-patient policies."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FLAMBE", "Title": "Structural Complexity and Representation Learning of Low Rank MDPs", "Abstract": "In order to deal with the curse of dimensionality in reinforcement learning (RL), it is common practice to make parametric assumptions where values or policies are functions of some low dimensional feature space. This work focuses on the representation learning question: how can we learn such features? Under the assumption that the underlying (unknown) dynamics correspond to a low rank transition matrix, we show how the representation learning question is related to a particular non-linear matrix decomposition problem. Structurally, we make precise connections between these low rank MDPs and latent variable models, showing how they significantly generalize prior formulations, such as block MDPs, for representation learning in RL. Algorithmically, we develop FLAMBE, which engages in exploration and representation learning for provably efficient RL in low rank transition models. On a technical level, our analysis eliminates reachability assumptions that appear in prior results on the simpler block MDP model and may be of independent interest."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Black-Box Ripper", "Title": "Copying black-box models using generative evolutionary algorithms", "Abstract": "We study the task of replicating the functionality of black-box neural models, for which we only know the output class probabilities provided for a set of input images. We assume back-propagation through the black-box model is not possible and its training images are not available, e.g. the model could be exposed only through an API. In this context, we present a teacher-student framework that can distill the black-box (teacher) model into a student model with minimal accuracy loss. To generate useful data samples for training the student, our framework (i) learns to generate images on a proxy data set (with images and classes different from those used to train the black-box) and (ii) applies an evolutionary strategy to make sure that each generated data sample exhibits a high response for a specific class when given as input to the black box. Our framework is compared with several baseline and state-of-the-art methods on three benchmark data sets. The empirical evidence indicates that our model is superior to the considered baselines. Although our method does not back-propagate through the black-box network, it generally surpasses state-of-the-art methods that regard the teacher as a glass-box model. Our code is available at: https://github.com/antoniobarbalau/black-box-ripper."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TorsionNet", "Title": "A Reinforcement Learning Approach to Sequential Conformer Search", "Abstract": "Molecular geometry prediction of flexible molecules, or conformer search, is a long-standing challenge in computational chemistry. This task is of great importance for predicting structure-activity relationships for a wide variety of substances ranging from biomolecules to ubiquitous materials. Substantial computational resources are invested in Monte Carlo and Molecular Dynamics methods to generate diverse and representative conformer sets for medium to large molecules, which are yet intractable to chemoinformatic conformer search methods. We present TorsionNet, an efficient sequential conformer search technique based on reinforcement learning under the rigid rotor approximation. The model is trained via curriculum learning, whose theoretical benefit is explored in detail, to maximize a novel metric grounded in thermodynamics called the Gibbs Score. Our experimental results show that TorsionNet outperforms the highest-scoring chemoinformatics method by 4x on large branched alkanes, and by several orders of magnitude on the previously unexplored biopolymer lignin, with applications in renewable energy. TorsionNet also outperforms the far more exhaustive but computationally intensive Self-Guided Molecular Dynamics sampling method."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GRAF", "Title": "Generative Radiance Fields for 3D-Aware Image Synthesis", "Abstract": "While 2D generative adversarial networks have enabled high-resolution image synthesis, they largely lack an understanding of the 3D world and the image formation process. Thus, they do not provide precise control over camera viewpoint or object pose. To address this problem, several recent approaches leverage intermediate voxel-based representations in combination with differentiable rendering. However, existing methods either produce low image resolution or fall short in disentangling camera and scene properties, e.g., the object identity may vary with the viewpoint. In this paper, we propose a generative model for radiance fields which have recently proven successful for novel view synthesis of a single scene. In contrast to voxel-based representations, radiance fields are not confined to a coarse discretization of the 3D space, yet allow for disentangling camera and scene properties while degrading gracefully in the presence of reconstruction ambiguity. By introducing a multi-scale patch-based discriminator, we demonstrate synthesis of high-resolution images while training our model from unposed 2D images alone. We systematically analyze our approach on several challenging synthetic and real-world datasets. Our experiments reveal that radiance fields are a powerful representation for generative image synthesis, leading to 3D consistent models that render with high fidelity."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PIE-NET", "Title": "Parametric Inference of Point Cloud Edges", "Abstract": "We introduce an end-to-end learnable technique to robustly identify feature edges in 3D point cloud data. We represent these edges as a collection of parametric curves (i.e.,~lines, circles, and B-splines). Accordingly, our deep neural network, coined PIE-NET, is trained for parametric inference of edges. The network relies on a \"region proposal\" architecture, where a first module proposes an over-complete collection of edge and corner points, and a second module ranks each proposal to decide whether it should be considered. We train and evaluate our method on the ABC dataset, a large dataset of CAD models, and compare our results to those produced by traditional (non-learning) processing pipelines, as well as a recent deep learning based edge detector (EC-NET). Our results significantly improve over the state-of-the-art from both a quantitative and qualitative standpoint."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Leap-Of-Thought", "Title": "Teaching Pre-Trained Models to Systematically Reason Over Implicit Knowledge", "Abstract": "To what extent can a neural network systematically reason over symbolic facts? Evidence suggests that large pre-trained language models (LMs) acquire some reasoning capacity, but this ability is difficult to control. \nRecently, it has been shown that Transformer-based models succeed in consistent reasoning over explicit symbolic facts, under a \"closed-world\" assumption.\nHowever, in an open-domain setup, it is desirable to tap into the vast reservoir of implicit knowledge already encoded in the parameters of pre-trained LMs. \nIn this work, we provide a first demonstration that LMs can be trained to reliably perform systematic reasoning combining both implicit, pre-trained knowledge and explicit natural language statements. \nTo do this, we describe a procedure for automatically generating datasets that teach a model new reasoning skills, and demonstrate that models learn to effectively perform inference which involves implicit taxonomic and world knowledge, chaining and counting. \nFinally, we show that \"teaching\" models to reason generalizes beyond the training distribution: they successfully compose the usage of multiple reasoning skills in single examples.\nOur work paves a path towards open-domain systems that constantly improve by interacting with users who can instantly correct a model by adding simple natural language statements."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pipeline PSRO", "Title": "A Scalable Approach for Finding Approximate Nash Equilibria in Large Games", "Abstract": "Finding approximate Nash equilibria in zero-sum imperfect-information games is challenging when the number of information states is large. Policy Space Response Oracles (PSRO) is a deep reinforcement learning algorithm grounded in game theory that is guaranteed to converge to an approximate Nash equilibrium. However, PSRO requires training a reinforcement learning policy at each iteration, making it too slow for large games. We show through counterexamples and experiments that DCH and Rectified PSRO, two existing approaches to scaling up PSRO, fail to converge even in small games. We introduce Pipeline PSRO (P2SRO), the first scalable PSRO-based method for finding approximate Nash equilibria in large zero-sum imperfect-information games. P2SRO is able to parallelize PSRO with convergence guarantees by maintaining a hierarchical pipeline of reinforcement learning workers, each training against the policies generated by lower levels in the hierarchy. We show that unlike existing methods, P2SRO converges to an approximate Nash equilibrium, and does so faster as the number of parallel workers increases, across a variety of imperfect information games. We also introduce an open-source environment for Barrage Stratego, a variant of Stratego with an approximate game tree complexity of 10^50. P2SRO is able to achieve state-of-the-art performance on Barrage Stratego and beats all existing bots. Experiment code is available at https://github.com/JBLanier/pipeline-psro."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Noise2Same", "Title": "Optimizing A Self-Supervised Bound for Image Denoising", "Abstract": "Self-supervised frameworks that learn denoising models with merely individual noisy images have shown strong capability and promising performance in various image denoising tasks. Existing self-supervised denoising frameworks are mostly built upon the same theoretical foundation, where the denoising models are required to be J-invariant. However, our analyses indicate that the current theory and the J-invariance may lead to denoising models with reduced performance. In this work, we introduce Noise2Same, a novel self-supervised denoising framework. In Noise2Same, a new self-supervised loss is proposed by deriving a self-supervised upper bound of the typical supervised loss. In particular, Noise2Same requires neither J-invariance nor extra information about the noise model and can be used in a wider range of denoising applications. We analyze our proposed Noise2Same both theoretically and experimentally. The experimental results show that our Noise2Same remarkably outperforms previous self-supervised denoising methods in terms of denoising performance and training efficiency."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LAPAR", "Title": "Linearly-Assembled Pixel-Adaptive Regression Network for Single Image Super-resolution and Beyond", "Abstract": "Single image super-resolution (SISR) deals with a fundamental problem of upsampling a low-resolution (LR) image to its high-resolution (HR) version. Last few years have witnessed impressive progress propelled by deep learning methods. However, one critical challenge faced by existing methods is to strike a sweet spot of deep model complexity and resulting SISR quality. This paper addresses this pain point by proposing a linearly-assembled pixel-adaptive regression network (LAPAR), which casts the direct LR to HR mapping learning into a linear coefficient regression task over a dictionary of multiple predefined filter bases. Such a parametric representation renders our model highly lightweight and easy to optimize while achieving state-of-the-art results on SISR benchmarks. Moreover, based on the same idea, LAPAR is extended to tackle other restoration tasks, e.g., image denoising and JPEG image deblocking, and again, yields strong performance."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Movement Pruning", "Title": "Adaptive Sparsity by Fine-Tuning", "Abstract": "Magnitude pruning is a widely used strategy for reducing model size in pure supervised learning; however, it is less effective in the transfer learning regime that has become standard for state-of-the-art natural language processing applications. We propose the use of movement pruning, a simple, deterministic first-order weight pruning method that is more adaptive to pretrained model fine-tuning. We give mathematical foundations to the method and compare it to existing zeroth- and first-order pruning methods. Experiments show that when pruning large pretrained language models, movement pruning shows significant improvements in high-sparsity regimes. When combined with distillation, the approach achieves minimal accuracy loss with down to only 3% of the model parameters."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sanity-Checking Pruning Methods", "Title": "Random Tickets can Win the Jackpot", "Abstract": "Network pruning is a method for reducing test-time computational resource requirements with minimal performance degradation. Conventional wisdom of pruning algorithms suggests that: (1) Pruning methods exploit information from training data to find good subnetworks; (2) The architecture of the pruned network is crucial for good performance. In this paper, we conduct sanity checks for the above beliefs on several recent unstructured pruning methods and surprisingly find that: (1) A set of methods which aims to find good subnetworks of the randomly-initialized network (which we call initial tickets''), hardly exploits any information from the training data; (2) For the pruned networks obtained by these methods, randomly changing the preserved weights in each layer, while keeping the total number of preserved weights unchanged per layer, does not affect the final performance. These findings inspire us to choose a series of simple \\emph{data-independent} prune ratios for each layer, and randomly prune each layer accordingly to get a subnetwork (which we callrandom tickets''). Experimental results show that our zero-shot random tickets outperforms or attains similar performance compared to existing initial tickets''. In addition, we identify one existing pruning method that passes our sanity checks. We hybridize the ratios in our random ticket with this method and propose a new method calledhybrid tickets'', which achieves further improvement."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RNNPool", "Title": "Efficient Non-linear Pooling for RAM Constrained Inference", "Abstract": "Standard Convolutional Neural Networks (CNNs) designed for computer vision tasks tend to have large intermediate activation maps. These require large working memory and are thus unsuitable for deployment on resource-constrained devices typically used for inference on the edge. Aggressively downsampling the images via pooling or strided convolutions can address the problem but leads to a significant decrease in accuracy due to gross aggregation of the feature map by standard pooling operators. In this paper, we introduce RNNPool, a novel pooling operator based on Recurrent Neural Networks (RNNs), that efficiently aggregates features over large patches of an image and rapidly downsamples activation maps.  Empirical evaluation indicates that an RNNPool layer can effectively replace multiple blocks in a variety of architectures such as MobileNets, DenseNet when applied to standard vision tasks like image classification and face detection. That is, RNNPool can significantly decrease computational complexity and peak memory usage for inference while retaining comparable accuracy. We use RNNPool with the standard S3FD architecture to construct a face detection method that achieves state-of-the-art MAP for tiny ARM Cortex-M4 class microcontrollers with under 256 KB of RAM. Code is released at https://github.com/Microsoft/EdgeML."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "3D Multi-bodies", "Title": "Fitting Sets of Plausible 3D Human Models to Ambiguous Image Data", "Abstract": "We consider the problem of obtaining dense 3D reconstructions of deformable objects from single and partially occluded views. In such cases, the visual evidence is usually insufficient to identify a 3D reconstruction uniquely, so we aim at recovering several plausible reconstructions compatible with the input data. We suggest that ambiguities can be modeled more effectively by parametrizing the possible body shapes and poses via a suitable 3D model, such as SMPL for humans.  We propose to learn a multi-hypothesis neural network regressor using a best-of-M loss, where each of the M hypotheses is constrained to lie on a manifold of plausible human poses by means of a generative model. We show that our method outperforms alternative approaches in ambiguous pose recovery on standard benchmarks for 3D humans, and in heavily occluded versions of these benchmarks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Auto-Panoptic", "Title": "Cooperative Multi-Component Architecture Search for Panoptic Segmentation", "Abstract": "Panoptic segmentation is posed as a new popular test-bed for the state-of-the-art holistic scene understanding methods with the requirement of simultaneously segmenting both foreground things and background stuff. The state-of-the-art panoptic segmentation network exhibits high structural complexity in different network components, i.e. backbone, proposal-based foreground branch, segmentation-based background branch, and feature fusion module across branches, which heavily relies on expert knowledge and tedious trials. In this work, we propose an efficient, cooperative and highly automated framework to simultaneously search for all main components including backbone, segmentation branches, and feature fusion module in a unified panoptic segmentation pipeline based on the prevailing one-shot Network Architecture Search (NAS) paradigm. Notably, we extend the common single-task NAS into the multi-component scenario by taking the advantages of the newly proposed intra-modular search space and problem-oriented inter-modular search space, which helps us to obtain an optimal network architecture that not only performs well in both instance segmentation and semantic segmentation tasks but also be aware of the reciprocal relations between foreground things and background stuff classes. To relieve the vast computation burden incurred by applying NAS to complicated network architectures, we present a novel path-priority greedy search policy to find a robust, transferrable architecture with significantly reduced searching overhead. Our searched architecture, namely Auto-Panoptic, achieves the new state-of-the-art on the challenging COCO and ADE20K benchmarks. Moreover, extensive experiments are conducted to demonstrate the effectiveness of path-priority policy and transferability of Auto-Panoptic across different datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "IDEAL", "Title": "Inexact DEcentralized Accelerated Augmented Lagrangian Method", "Abstract": "We introduce a framework for designing primal methods under the decentralized optimization setting where local functions are smooth and strongly convex. Our approach consists of approximately solving a sequence of sub-problems induced by the accelerated augmented Lagrangian method, thereby providing a systematic way for deriving several well-known decentralized algorithms including EXTRA and SSDA. When coupled with accelerated gradient descent, our framework yields a novel primal algorithm whose convergence rate is optimal and matched by recently derived lower bounds. We provide experimental results that demonstrate the effectiveness of the proposed algorithm on highly ill-conditioned problems."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Evolving Graphical Planner", "Title": "Contextual Global Planning for Vision-and-Language Navigation", "Abstract": "The ability to perform effective planning is crucial for building an instruction-following agent. When navigating through a new environment, an agent is challenged with (1) connecting the natural language instructions with its progressively growing knowledge of the world; and (2) performing long-range planning and decision making in the form of effective exploration and error correction. Current methods are still limited on both fronts despite extensive efforts.  In this paper, we introduce Evolving Graphical Planner (EGP), a module that allows global planning for navigation based on raw sensory input. The module dynamically constructs a graphical representation, generalizes the local action space to allow for more flexible decision making, and performs efficient planning on a proxy representation. We demonstrate our model on a challenging Vision-and-Language Navigation (VLN) task with photorealistic images, and achieve superior performance compared to previous navigation architectures. Concretely, we achieve 53% success rate on the test split of Room-to-Room navigation task (Anderson et al.) through pure imitation learning, outperforming previous architectures by up to 5%."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from Failure", "Title": "De-biasing Classifier from Biased Classifier", "Abstract": "Neural networks often learn to make predictions that overly rely on spurious corre- lation existing in the dataset, which causes the model to be biased. While previous work tackles this issue by using explicit labeling on the spuriously correlated attributes or presuming a particular bias type, we instead utilize a cheaper, yet generic form of human knowledge, which can be widely applicable to various types of bias. We first observe that neural networks learn to rely on the spurious correlation only when it is “easier” to learn than the desired knowledge, and such reliance is most prominent during the early phase of training. Based on the obser- vations, we propose a failure-based debiasing scheme by training a pair of neural networks simultaneously. Our main idea is twofold; (a) we intentionally train the first network to be biased by repeatedly amplifying its “prejudice”, and (b) we debias the training of the second network by focusing on samples that go against the prejudice of the biased network in (a). Extensive experiments demonstrate that our method significantly improves the training of network against various types of biases in both synthetic and real-world datasets. Surprisingly, our framework even occasionally outperforms the debiasing methods requiring explicit supervision of the spuriously correlated attributes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Likelihood Regret", "Title": "An Out-of-Distribution Detection Score For Variational Auto-encoder", "Abstract": "Deep probabilistic generative models enable modeling the likelihoods of very high dimensional data. An important application of generative modeling should be the ability to detect out-of-distribution (OOD) samples by setting a threshold on the likelihood. However, a recent study shows that probabilistic generative models can, in some cases, assign higher likelihoods on certain types of OOD samples, making the OOD detection rules based on likelihood threshold problematic. To address this issue, several OOD detection methods have been proposed for deep generative models. In this paper, we make the observation that some of these methods fail when applied to generative models based on  Variational Auto-encoders (VAE). As an alternative, we propose Likelihood Regret, an efficient OOD score for VAEs. We benchmark our proposed method over existing approaches, and empirical results suggest that our method obtains the best overall OOD detection performances compared with other OOD method applied on VAE."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Top-KAST", "Title": "Top-K Always Sparse Training", "Abstract": "Sparse neural networks are becoming increasingly important as the field seeks to improve the performance of existing models by scaling them up, while simultaneously trying to reduce power consumption and computational footprint. Unfortunately, most existing methods for inducing performant sparse models still entail the instantiation of dense parameters, or dense gradients in the backward-pass, during training. For very large models this requirement can be prohibitive. In this work we propose Top-KAST, a method that preserves constant sparsity throughout training (in both the forward and backward-passes). We demonstrate the efficacy of our approach by showing that it performs comparably to or better than previous works when training models on the established ImageNet benchmark, whilst fully maintaining sparsity. In addition to our ImageNet results, we also demonstrate our approach in the domain of language modeling where the current best performing architectures tend to have tens of billions of parameters and scaling up does not yet seem to have saturated performance. Sparse versions of these architectures can be run with significantly fewer resources, making them more widely accessible and applicable. Furthermore, in addition to being effective, our approach is straightforward and can easily be implemented in a wide range of existing machine learning frameworks with only a few additional lines of code.  We therefore hope that our contribution will help enable the broader community to explore the potential held by massive models, without incurring massive computational cost."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Knowledge Distillation in Wide Neural Networks", "Title": "Risk Bound, Data Efficiency and Imperfect Teacher", "Abstract": "Knowledge distillation is a strategy of training a student network with guide of the soft output from a teacher network. It has been a successful method of model compression and knowledge transfer. However, currently knowledge distillation lacks a convincing theoretical understanding. On the other hand, recent finding on neural tangent kernel enables us to approximate a wide neural network with a linear model of the network's random features.   In this paper, we theoretically analyze the knowledge distillation of a wide neural network. First we provide a transfer risk bound for the linearized model of the network. Then we propose a metric of the task's training difficulty, called data inefficiency. Based on this metric, we show that for a perfect teacher, a high ratio of teacher's soft labels can be beneficial. Finally, for the case of imperfect teacher, we find that hard labels can correct teacher's wrong prediction, which explains the practice of mixing hard and soft labels."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Canonical 3D Deformer Maps", "Title": "Unifying parametric and non-parametric methods for dense weakly-supervised category reconstruction", "Abstract": "We propose the Canonical 3D Deformer Map, a new representation of the 3D shape of common object categories that can be learned from a collection of 2D images of independent objects. Our method builds in a novel way on concepts from parametric deformation models, non-parametric 3D reconstruction, and canonical embeddings, combining their individual advantages. In particular, it learns to associate each image pixel with a deformation model of the corresponding 3D object point which is canonical, i.e. intrinsic to the identity of the point and shared across objects of the category. The result is a method that, given only sparse 2D supervision at training time, can, at test time, reconstruct the 3D shape and texture of objects from single views, while establishing meaningful dense correspondences between object instances. It also achieves state-of-the-art results in dense 3D reconstruction on public in-the-wild datasets of faces, cars, and birds."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Cone of Silence", "Title": "Speech Separation by Localization", "Abstract": "Given a multi-microphone recording of an unknown number of speakers talking concurrently, we simultaneously localize the sources and separate the individual speakers. At the core of our method is a deep network, in the waveform domain, which isolates sources within an angular region $\\theta \\pm w/2$, given an angle of interest $\\theta$ and angular window size $w$. By exponentially decreasing $w$, we can perform a binary search to localize and separate all sources in logarithmic time. Our algorithm also allows for an arbitrary number of potentially moving speakers at test time, including more speakers than seen during training. Experiments demonstrate state of the art performance for both source separation and source localization, particularly in high levels of background noise."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Train-by-Reconnect", "Title": "Decoupling Locations of Weights from Their Values", "Abstract": "What makes untrained deep neural networks (DNNs) different from the trained performant ones? By zooming into the weights in well-trained DNNs, we found that it is the location of weights that holds most of the information encoded by the training. Motivated by this observation, we hypothesized that weights in DNNs trained using stochastic gradient-based methods can be separated into two dimensions: the location of weights, and their exact values. To assess our hypothesis, we propose a novel method called lookahead permutation (LaPerm) to train DNNs by reconnecting the weights. We empirically demonstrate LaPerm's versatility while producing extensive evidence to support our hypothesis: when the initial weights are random and dense, our method demonstrates speed and performance similar to or better than that of regular optimizers, e.g., Adam. When the initial weights are random and sparse (many zeros), our method changes the way neurons connect, achieving accuracy comparable to that of a well-trained dense network. When the initial weights share a single value, our method finds a weight agnostic neural network with far-better-than-chance accuracy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning discrete distributions", "Title": "user vs item-level privacy", "Abstract": "Much of the literature on differential privacy focuses on item-level privacy, where loosely speaking, the goal is to provide privacy per item or training example. However, recently many practical applications such as federated learning require preserving privacy for all items of a single user, which is much harder to achieve. Therefore understanding the theoretical limit of user-level privacy becomes crucial. \n\nWe study the fundamental problem of learning discrete distributions over $k$ symbols with user-level differential privacy. If each user has $m$ samples, we show that straightforward applications of Laplace or Gaussian mechanisms require the number of users to be $\\mathcal{O}(k/(m\\alpha^2) + k/\\epsilon\\alpha)$ to achieve an $\\ell_1$ distance of $\\alpha$ between the true and estimated distributions, with the privacy-induced penalty $k/\\epsilon\\alpha$ independent of the number of samples per user $m$. Moreover, we show that any mechanism that only operates on the final aggregate should require a user complexity of the same order. We then propose a mechanism such that the number of users scales as  $\\tilde{\\mathcal{O}}(k/(m\\alpha^2) + k/\\sqrt{m}\\epsilon\\alpha)$ and further show that it is nearly-optimal under certain regimes. Thus the privacy penalty is $\\tilde{\\Theta}(\\sqrt{m})$ times smaller compared to the standard mechanisms. \n\nWe also propose general techniques for obtaining lower bounds on restricted differentially private estimators and a lower bound on the total variation between binomial distributions, both of which might be of independent interest."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalized Focal Loss", "Title": "Learning Qualified and Distributed Bounding Boxes for Dense Object Detection", "Abstract": "One-stage detector basically formulates object detection as dense classification and localization (i.e., bounding box regression). The classification is usually optimized by Focal Loss and the box location is commonly learned under Dirac delta distribution. A recent trend for one-stage detectors is to introduce an \\emph{individual} prediction branch to estimate the quality of localization, where the predicted quality facilitates the classification to improve detection performance. This paper delves into the \\emph{representations} of the above three fundamental elements: quality estimation, classification and localization. Two problems are discovered in existing practices, including (1) the inconsistent usage of the quality estimation and classification between training and inference, and (2) the inflexible Dirac delta distribution for localization. To address the problems, we design new representations for these elements. Specifically, we merge the quality estimation into the class prediction vector to form a joint representation, and use a vector to represent arbitrary distribution of box locations. The improved representations eliminate the inconsistency risk and accurately depict the flexible distribution in real data, but contain \\emph{continuous} labels, which is beyond the scope of Focal Loss. We then propose Generalized Focal Loss (GFL) that generalizes Focal Loss from its discrete form to the \\emph{continuous} version for successful optimization. On COCO {\\tt test-dev}, GFL achieves 45.0\\% AP using ResNet-101 backbone, surpassing state-of-the-art SAPD (43.5\\%) and ATSS (43.6\\%) with higher or comparable inference speed."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CircleGAN", "Title": "Generative Adversarial Learning across Spherical Circles", "Abstract": "We present a novel discriminator for GANs that improves realness and diversity of generated samples by learning a structured hypersphere embedding space using spherical circles. \nThe proposed discriminator learns to populate realistic samples around the longest spherical circle, i.e., a great circle, while pushing unrealistic samples toward the poles perpendicular to the great circle. Since longer circles occupy larger area on the hypersphere, they encourage more diversity in representation learning, and vice versa. Discriminating samples based on their corresponding spherical circles can thus naturally induce diversity to generated samples. \nWe also extend the proposed method for conditional settings with class labels by creating a hypersphere for each category and performing class-wise discrimination and update. In experiments, we validate the effectiveness for both unconditional and conditional generation on standard benchmarks, achieving the state of the art."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "WOR and $p$'s", "Title": "Sketches for $\\ell_p$-Sampling Without Replacement", "Abstract": "Weighted sampling is a fundamental tool in data analysis and machine learning pipelines. Samples are used for efficient estimation of statistics or as sparse representations of the data.  When weight distributions are skewed, as is often the case in practice, without-replacement (WOR) sampling is much more effective than with-replacement (WR) sampling: It provides a broader representation and higher accuracy for the same number of samples. We design novel composable sketches for WOR {\\em $\\ell_p$ sampling}, weighted sampling of keys according to a power $p\\in[0,2]$ of their frequency (or for signed data, sum of updates). Our sketches have size that grows only linearly with sample size. Our design is simple and practical, despite intricate analysis, and based on off-the-shelf use of widely implemented heavy hitters sketches such as \\texttt{CountSketch}. Our method is the first to provide WOR sampling in the important regime of $p>1$ and the first to handle signed updates for $p>0$."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hypersolvers", "Title": "Toward Fast Continuous-Depth Models", "Abstract": "The infinite-depth paradigm pioneered by Neural ODEs has launched a renaissance in the search for novel dynamical system-inspired deep learning primitives; however, their utilization in problems of non-trivial size has often proved impossible due to poor computational scalability. This work paves the way for scalable Neural ODEs with time-to-prediction comparable to traditional discrete networks. We introduce hypersolvers, neural networks designed to solve ODEs with low overhead and theoretical guarantees on accuracy. The synergistic combination of hypersolvers and Neural ODEs allows for cheap inference and unlocks a new frontier for practical application of continuous-depth models. Experimental evaluations on standard benchmarks, such as sampling for continuous normalizing flows, reveal consistent pareto efficiency over classical numerical methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Log-Likelihood Ratio Minimizing Flows", "Title": "Towards Robust and Quantifiable Neural Distribution Alignment", "Abstract": "Distribution alignment has many applications in deep learning, including domain adaptation and unsupervised image-to-image translation. Most prior work on unsupervised distribution alignment relies either on minimizing simple non-parametric statistical distances such as maximum mean discrepancy or on adversarial alignment. However, the former fails to capture the structure of complex real-world distributions, while the latter is difficult to train and does not provide any universal convergence guarantees or automatic quantitative validation procedures. In this paper, we propose a new distribution alignment method based on a log-likelihood ratio statistic and normalizing flows. We show that, under certain assumptions, this combination yields a deep neural likelihood-based minimization objective that attains a known lower bound upon convergence. We experimentally verify that minimizing the resulting objective results in domain alignment that preserves the local structure of input domains."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "POMO", "Title": "Policy Optimization with Multiple Optima for Reinforcement Learning", "Abstract": "In neural combinatorial optimization (CO), reinforcement learning (RL) can turn a deep neural net into a fast, powerful heuristic solver of NP-hard problems. This approach has a great potential in practical applications because it allows near-optimal solutions to be found without expert guides armed with substantial domain knowledge. We introduce Policy Optimization with Multiple Optima (POMO), an end-to-end approach for building such a heuristic solver. POMO is applicable to a wide range of CO problems. It is designed to exploit the symmetries in the representation of a CO solution. POMO uses a modified REINFORCE algorithm that forces diverse rollouts towards all optimal solutions. Empirically, the low-variance baseline of POMO makes RL training fast and stable, and it is more resistant to local minima compared to previous approaches. We also introduce a new augmentation-based inference method, which accompanies POMO nicely. We demonstrate the effectiveness of POMO by solving three popular NP-hard problems, namely, traveling salesman (TSP), capacitated vehicle routing (CVRP), and 0-1 knapsack (KP). For all three, our solver based on POMO shows a significant improvement in performance over all recent learned heuristics. In particular, we achieve the optimality gap of 0.14% with TSP100 while reducing inference time by more than an order of magnitude."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Every View Counts", "Title": "Cross-View Consistency in 3D Object Detection with Hybrid-Cylindrical-Spherical Voxelization", "Abstract": "Recent voxel-based 3D object detectors for autonomous vehicles learn point cloud representations either from bird eye view (BEV) or range view (RV, a.k.a. the perspective view). However, each view has its own strengths and weaknesses. In this paper, we present a novel framework to unify and leverage the benefits from both BEV and RV. The widely-used cuboid-shaped voxels in Cartesian coordinate system only benefit learning BEV feature map. Therefore, to enable learning both BEV and RV feature maps, we introduce Hybrid-Cylindrical-Spherical voxelization. Our findings show that simply adding detection on another view as auxiliary supervision will lead to poor performance. We proposed a pair of cross-view transformers to transform the feature maps into the other view and introduce cross-view consistency loss on them. Comprehensive experiments on the challenging NuScenes Dataset validate the effectiveness of our proposed method by virtue of joint optimization and complementary information on both views. Remarkably, our approach achieved mAP of 55.8%, outperforming all published approaches by at least 3% in overall performance and up to 16.5% in safety-crucial categories like cyclist."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Quantifying the Empirical Wasserstein Distance to a Set of Measures", "Title": "Beating the Curse of Dimensionality", "Abstract": "We consider the problem of estimating the Wasserstein distance between the empirical measure and a set of probability measures whose expectations over a class of functions (hypothesis class) are constrained. If this class is sufficiently rich to characterize a particular distribution (e.g., all Lipschitz functions), then our formulation recovers the Wasserstein distance to such a distribution. We establish a strong duality result that generalizes the celebrated Kantorovich-Rubinstein duality. We also show that our formulation can be used to beat the curse of dimensionality, which is well known to affect the rates of statistical convergence of the empirical Wasserstein distance. In particular, examples of infinite-dimensional hypothesis classes are presented, informed by a complex correlation structure, for which it is shown that the empirical Wasserstein distance to such classes converges to zero at the standard parametric rate. Our formulation provides insights that help clarify why, despite the curse of dimensionality, the Wasserstein distance enjoys favorable empirical performance across a wide range of statistical applications."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RSKDD-Net", "Title": "Random Sample-based Keypoint Detector and Descriptor", "Abstract": "Keypoint detector and descriptor are two main components of point cloud registration. Previous learning-based keypoint detectors rely on saliency estimation for each point or farthest point sample (FPS) for candidate points selection, which are inefficient and not applicable in large scale scenes. This paper proposes Random Sample-based Keypoint Detector and Descriptor Network (RSKDD-Net) for large scale point cloud registration. The key idea is using random sampling to efficiently select candidate points and using a learning-based method to jointly generate keypoints and corresponding descriptors. To tackle the information loss of random sampling, we exploit a novel random dilation cluster strategy to enlarge the receptive field of each sampled point and an attention mechanism to aggregate the positions and features of neighbor points. Furthermore, we propose a matching loss to train the descriptor in a weakly supervised manner. Extensive experiments on two large scale outdoor LiDAR datasets show that the proposed RSKDD-Net achieves state-of-the-art performance with more than 15 times faster than existing methods. Our code is available at https://github.com/ispc-lab/RSKDD-Net."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Efficient Clustering for Stretched Mixtures", "Title": "Landscape and Optimality", "Abstract": "This paper considers a canonical clustering problem where one receives unlabeled samples drawn from a balanced mixture of two elliptical distributions and aims for a classifier to estimate the labels. Many popular methods including PCA and k-means require individual components of the mixture to be somewhat spherical, and perform poorly when they are stretched. To overcome this issue, we propose a non-convex program seeking for an affine transform to turn the data into a one-dimensional point cloud concentrating around -1 and 1, after which clustering becomes easy. Our theoretical contributions are two-fold: (1) we show that the non-convex loss function exhibits desirable geometric properties when the sample size exceeds some constant multiple of the dimension, and (2) we leverage this to prove that an efficient first-order algorithm achieves near-optimal statistical precision without good initialization. We also propose a general methodology for clustering with flexible choices of feature transforms and loss objectives."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ContraGAN", "Title": "Contrastive Learning for Conditional Image Generation", "Abstract": "Conditional image generation is the task of generating diverse images using class label information. Although many conditional Generative Adversarial Networks (GAN) have shown realistic results, such methods consider pairwise relations between the embedding of an image and the embedding of the corresponding label (data-to-class relations) as the conditioning losses. In this paper, we propose ContraGAN that considers relations between multiple image embeddings in the same batch (data-to-data relations) as well as the data-to-class relations by using a conditional contrastive loss. The discriminator of ContraGAN discriminates the authenticity of given samples and minimizes a contrastive objective to learn the relations between training images. Simultaneously, the generator tries to generate realistic images that deceive the authenticity and have a low contrastive loss. The experimental results show that ContraGAN outperforms state-of-the-art-models by 7.3% and 7.7% on Tiny ImageNet and ImageNet datasets, respectively. Besides, we experimentally demonstrate that ContraGAN helps to relieve the overfitting of the discriminator. For a fair comparison, we re-implement twelve state-of-the-art GANs using the PyTorch library. The software package is available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Loss Landscape of Adversarial Training", "Title": "Identifying Challenges and How to Overcome Them", "Abstract": "We analyze the influence of adversarial training on the loss landscape of machine learning models.\nTo this end, we first provide analytical studies of the properties of adversarial loss functions under different adversarial budgets.\nWe then demonstrate that the adversarial loss landscape is less favorable to optimization, due to increased curvature and more scattered gradients.\nOur conclusions are validated by numerical analyses, which show that training under large adversarial budgets impede the escape from suboptimal random initialization, cause non-vanishing gradients and make the models' minima found sharper.\nBased on these observations, we show that a periodic adversarial scheduling (PAS) strategy can effectively overcome these challenges, yielding better results than vanilla adversarial training while being much less sensitive to the choice of learning rate."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BoTorch", "Title": "A Framework for Efficient Monte-Carlo Bayesian Optimization", "Abstract": "Bayesian optimization provides sample-efficient global optimization for a broad range of applications, including automatic machine learning, engineering, physics, and experimental design. We introduce BoTorch, a modern programming framework for Bayesian optimization that combines Monte-Carlo (MC) acquisition functions, a novel sample average approximation optimization approach, auto-differentiation, and variance reduction techniques. BoTorch's modular design facilitates flexible specification and optimization of probabilistic models written in PyTorch, simplifying implementation of new acquisition functions. Our approach is backed by novel theoretical convergence results and made practical by a distinctive algorithmic foundation that leverages fast predictive distributions, hardware acceleration, and deterministic optimization. We also propose a novel \"one-shot\" formulation of the Knowledge Gradient, enabled by a combination of our theoretical and software contributions. In experiments, we demonstrate the improved sample efficiency of BoTorch relative to other popular libraries."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust Federated Learning", "Title": "The Case of Affine Distribution Shifts", "Abstract": "Federated learning is a distributed  paradigm that aims at training  models using samples distributed across multiple users in a network while keeping the samples on users’ devices with the aim of efficiency and  protecting users privacy. In such settings, the training data is often statistically heterogeneous and manifests various distribution shifts across users, which degrades the performance of the learnt model. The primary goal of this paper is to develop a robust federated learning algorithm that achieves satisfactory performance against distribution shifts in users' samples. To achieve this goal, we first consider a structured affine distribution shift in users' data that captures the device-dependent data heterogeneity in federated settings. This perturbation model is applicable to various federated learning problems such as image classification where the images undergo device-dependent imperfections, e.g. different intensity, contrast, and brightness. To address affine distribution shifts across users, we propose a Federated Learning framework Robust to Affine distribution shifts (FLRA) that is provably robust against affine Wasserstein shifts to the distribution of observed samples. To solve the FLRA's distributed minimax optimization problem, we propose a fast and efficient optimization method and provide convergence and performance  guarantees via a gradient Descent Ascent (GDA) method. We further prove generalization error bounds for the learnt classifier to show proper generalization from empirical distribution of samples to the true underlying distribution. We perform several numerical experiments to empirically support FLRA. We show that an affine distribution shift indeed suffices to significantly decrease the performance of the learnt classifier in a new test user, and our proposed algorithm achieves a significant gain in comparison to standard federated learning and adversarial training methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Training with Heterogeneous Data", "Title": "Bridging Median- and Mean-Based Algorithms", "Abstract": "Recently, there is a growing interest in the study of median-based algorithms for distributed non-convex optimization. Two prominent examples include signSGD with majority vote, an effective approach for communication reduction via 1-bit compression on the local gradients, and medianSGD, an algorithm recently proposed to ensure robustness against Byzantine workers. The convergence analyses for these algorithms critically rely on the assumption that all the distributed data are drawn iid from the same distribution. However, in applications such as Federated Learning, the data across different nodes or machines can be inherently heterogeneous, which violates such an iid assumption. This work analyzes signSGD and medianSGD in distributed settings with heterogeneous data. We show that these algorithms are non-convergent whenever there is some disparity between the expected median and mean over the local gradients. To overcome this gap, we provide a novel gradient correction mechanism that perturbs the local gradients with noise, which we show can provably close the gap between mean and median of the gradients. The proposed methods largely preserve nice properties of these median-based algorithms, such as the low per-iteration communication complexity of signSGD, and further enjoy global convergence to stationary solutions. Our perturbation technique can be of independent interest when one wishes to estimate mean through a median estimator."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "H-Mem", "Title": "Harnessing synaptic plasticity with Hebbian Memory Networks", "Abstract": "The ability to base current computations on memories from the past is critical for many cognitive tasks such as story understanding. Hebbian-type synaptic plasticity is believed to underlie the retention of memories over medium and long time scales in the brain. However, it is unclear how such plasticity processes are integrated with computations in cortical networks. Here, we propose Hebbian Memory Networks (H-Mems), a simple neural network model that is built around a core hetero-associative network subject to Hebbian plasticity. We show that the network can be optimized to utilize the Hebbian plasticity processes for its computations. H-Mems can one-shot memorize associations between stimulus pairs and use these associations for decisions later on. Furthermore, they can solve demanding question-answering tasks on synthetic stories. Our study shows that  neural network models are able to enrich their computations with memories through simple Hebbian plasticity processes."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Convex Relaxation Barrier, Revisited", "Title": "Tightened Single-Neuron Relaxations for Neural Network Verification", "Abstract": "We improve the effectiveness of propagation- and linear-optimization-based neural network verification algorithms with a new tightened convex relaxation for ReLU neurons. Unlike previous single-neuron relaxations which focus only on the univariate input space of the ReLU, our method considers the multivariate input space of the affine pre-activation function preceding the ReLU. Using results from submodularity and convex geometry, we derive an explicit description of the tightest possible convex relaxation when this multivariate input is over a box domain. We show that our convex relaxation is significantly stronger than the commonly used univariate-input relaxation which has been proposed as a natural convex relaxation barrier for verification. While our description of the relaxation may require an exponential number of inequalities, we show that they can be separated in linear time and hence can be efficiently incorporated into optimization algorithms on an as-needed basis. Based on this novel relaxation, we design two polynomial-time algorithms for neural network verification: a linear-programming-based algorithm that leverages the full power of our relaxation, and a fast propagation algorithm that generalizes existing approaches. In both cases, we show that for a modest increase in computational effort, our strengthened relaxation enables us to verify a significantly larger number of instances compared to similar algorithms."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AOT", "Title": "Appearance Optimal Transport Based Identity Swapping for Forgery Detection", "Abstract": "Recent studies have shown that the performance of forgery detection can be improved with diverse and challenging Deepfakes datasets. However, due to the lack of Deepfakes datasets with large variance in appearance, which can be hardly produced by recent identity swapping methods, the detection algorithm may fail in this situation. In this work, we provide a new identity swapping algorithm with large differences in appearance for face forgery detection. The appearance gaps mainly arise from the large discrepancies in illuminations and skin colors that widely exist in real-world scenarios. However, due to the difficulties of modeling the complex appearance mapping, it is challenging to transfer fine-grained appearances adaptively while preserving identity traits. This paper formulates appearance mapping as an optimal transport problem and proposes an Appearance Optimal Transport model (AOT) to formulate it in both latent and pixel space. Specifically, a relighting generator is designed to simulate the optimal transport plan. It is solved via minimizing the Wasserstein distance of the learned features in the latent space, enabling better performance and less computation than conventional optimization. To further refine the solution of the optimal transport plan, we develop a segmentation game to minimize the Wasserstein distance in the pixel space. A discriminator is introduced to distinguish the fake parts from a mix of real and fake image patches. Extensive experiments reveal that the superiority of our method when compared with state-of-the-art methods and the ability of our generated data to improve the performance of face forgery detection."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Delta-STN", "Title": "Efficient Bilevel Optimization for Neural Networks using Structured Response Jacobians", "Abstract": "Hyperparameter optimization of neural networks can be elegantly formulated as a bilevel optimization problem. While research on bilevel optimization of neural networks has been dominated by implicit differentiation and unrolling, hypernetworks such as Self-Tuning Networks (STNs) have recently gained traction due to their ability to amortize the optimization of the inner objective. In this paper, we diagnose several subtle pathologies in the training of STNs. Based on these observations, we propose the Delta-STN, an improved hypernetwork architecture which stabilizes training and optimizes hyperparameters much more efficiently than STNs. The key idea is to focus on accurately approximating the best-response Jacobian rather than the full best-response function; we achieve this by reparameterizing the hypernetwork and linearizing the network around the current parameters. We demonstrate empirically that our Delta-STN can tune regularization hyperparameters (e.g. weight decay, dropout, number of cutout holes) with higher accuracy, faster convergence, and improved stability compared to existing approaches."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Not All Unlabeled Data are Equal", "Title": "Learning to Weight Data in Semi-supervised Learning", "Abstract": "Existing semi-supervised learning (SSL) algorithms use a single weight to balance the loss of labeled and unlabeled examples, i.e., all unlabeled examples are equally weighted. But not all unlabeled data are equal. In this paper we study how to use a different weight for “every” unlabeled example. Manual tuning of all those weights -- as done in prior work -- is no longer possible. Instead, we adjust those weights via an algorithm based on the influence function, a measure of a model's dependency on one training example. To make the approach efficient, we propose a fast and effective approximation of the influence function. We demonstrate that this technique outperforms state-of-the-art methods on semi-supervised image and language classification tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MOReL", "Title": "Model-Based Offline Reinforcement Learning", "Abstract": "In offline reinforcement learning (RL), the goal is to learn a highly rewarding policy based solely on a dataset of historical interactions with the environment. This serves as an extreme test for an agent's ability to effectively use historical data which is known to be critical for efficient RL. Prior work in offline RL has been confined almost exclusively to model-free RL approaches. In this work, we present MOReL, an algorithmic framework for model-based offline RL. This framework consists of two steps: (a) learning a pessimistic MDP using the offline dataset; (b) learning a near-optimal policy in this pessimistic MDP. The design of the pessimistic MDP is such that for any policy, the performance in the real environment is approximately lower-bounded by the performance in the pessimistic MDP. This enables the pessimistic MDP to serve as a good surrogate for purposes of policy evaluation and learning. Theoretically, we show that MOReL is minimax optimal (up to log factors) for offline RL. Empirically, MOReL matches or exceeds state-of-the-art results on widely used offline RL benchmarks. Overall, the modular design of MOReL enables translating advances in its components (for e.g., in model learning, planning etc.) to improvements in offline RL."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weisfeiler and Leman go sparse", "Title": "Towards scalable higher-order graph embeddings", "Abstract": "Graph kernels based on the $1$-dimensional Weisfeiler-Leman algorithm and corresponding neural architectures recently emerged as powerful tools for (supervised) learning with graphs. However, due to the purely local nature of the algorithms, they might miss essential patterns in the given data and can only handle binary relations. The $k$-dimensional Weisfeiler-Leman algorithm addresses this by considering $k$-tuples, defined over the set of vertices, and defines a suitable notion of adjacency between these vertex tuples. Hence, it accounts for the higher-order interactions between vertices. However, it does not scale and may suffer from overfitting when used in a machine learning setting. Hence, it remains an important open problem to design WL-based graph learning methods that are simultaneously expressive, scalable, and non-overfitting. Here, we propose local variants and corresponding neural architectures, which consider a subset of the original neighborhood, making them more scalable, and less prone to overfitting. The expressive power of (one of) our algorithms is strictly higher than the original algorithm, in terms of ability to distinguish non-isomorphic graphs. Our experimental study confirms that the local algorithms, both kernel and neural architectures, lead to vastly reduced computation times, and prevent overfitting. The kernel version establishes a new state-of-the-art for graph classification on a wide range of benchmark datasets, while the neural version shows promising performance on large-scale molecular regression tasks."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Contextual Games", "Title": "Multi-Agent Learning with Side Information", "Abstract": "We formulate the novel class of contextual games, a type of repeated games driven by contextual information at each round. By means of kernel-based regularity assumptions, we model the correlation between different contexts and game outcomes and propose a novel online (meta) algorithm that exploits such correlations to minimize the contextual regret of individual players. We define game-theoretic notions of contextual Coarse Correlated Equilibria (c-CCE) and optimal contextual welfare for this new class of games and show that c-CCEs and optimal welfare can be approached whenever players' contextual regrets vanish. Finally, we empirically validate our results in a traffic routing experiment, where our algorithm leads to better performance and higher welfare compared to baselines that do not exploit the available contextual information or the correlations present in the game."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Denoised Smoothing", "Title": "A Provable Defense for Pretrained Classifiers", "Abstract": "We present a method for provably defending any pretrained image classifier against $\\ell_p$ adversarial attacks. This method, for instance, allows public vision API providers and users to seamlessly convert pretrained non-robust classification services into provably robust ones. By prepending a custom-trained denoiser to any off-the-shelf image classifier and using randomized smoothing, we effectively create a new classifier that is guaranteed to be $\\ell_p$-robust to adversarial examples, without modifying the pretrained classifier. Our approach applies to both the white-box and the black-box settings of the pretrained classifier. We refer to this defense as denoised smoothing, and we demonstrate its effectiveness through extensive experimentation on ImageNet and CIFAR-10. Finally, we use our approach to provably defend the Azure, Google, AWS, and ClarifAI image classification APIs. Our code replicating all the experiments in the paper can be found at: https://github.com/microsoft/denoised-smoothing."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CrossTransformers", "Title": "spatially-aware few-shot transfer", "Abstract": "Given new tasks with very little data---such as new classes in a classification problem or a domain shift in the input---performance of modern vision systems degrades remarkably quickly. In this work, we illustrate how the neural network representations which underpin modern vision systems are subject to supervision collapse, whereby they lose any information that is not necessary for performing the training task, including information that may be necessary for transfer to new tasks or domains. We then propose two methods to mitigate this problem. First, we employ self-supervised learning to encourage general-purpose features that transfer better. Second, we propose a novel Transformer based neural network architecture called CrossTransformers, which can take a small number of labeled images and an unlabeled query, find coarse spatial correspondence between the query and the labeled images, and then infer class membership by computing distances between spatially-corresponding features. The result is a classifier that is more robust to task and domain shift, which we demonstrate via state-of-the-art performance on Meta-Dataset, a recent dataset for evaluating transfer from ImageNet to many other vision datasets."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SEVIR ", "Title": "A Storm Event Imagery Dataset for Deep Learning Applications in Radar and Satellite Meteorology", "Abstract": "Modern deep learning approaches have shown promising results in meteorological applications like precipitation nowcasting, synthetic radar generation, front detection and several others.  In order to effectively train and validate these complex algorithms, large and diverse datasets containing high-resolution imagery are required. Petabytes of weather data, such as from the Geostationary Environmental Satellite System (GOES) and the Next-Generation Radar (NEXRAD) system, are available to the public; however, the size and complexity of these datasets is a hindrance to developing and training deep models. To help address this problem, we introduce the Storm EVent ImagRy (SEVIR) dataset - a single, rich dataset that combines spatially and temporally aligned data from multiple sensors, along with baseline implementations of deep learning models and evaluation metrics, to accelerate new algorithmic innovations. SEVIR is an annotated, curated and spatio-temporally aligned dataset containing over 10,000 weather events that each consist of 384 km x 384 km image sequences spanning 4 hours of time. Images in SEVIR were sampled and aligned across five different data types: three channels (C02, C09, C13) from the GOES-16 advanced baseline imager, NEXRAD vertically integrated liquid mosaics, and GOES-16 Geostationary Lightning Mapper (GLM) flashes.  Many events in SEVIR were selected and matched to the NOAA Storm Events database so that additional descriptive information such as storm impacts and storm descriptions can be linked to the rich imagery provided by the sensors. We describe the data collection methodology and illustrate the applications of this dataset with two examples of deep learning in meteorology: precipitation nowcasting and synthetic weather radar generation. In addition, we also describe a set of metrics that can be used to evaluate the outputs of these models. The SEVIR dataset and baseline implementations of selected applications are available for download."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Stability and Convergence of Robust Adversarial Reinforcement Learning", "Title": "A Case Study on Linear Quadratic Systems", "Abstract": "Reinforcement learning (RL) algorithms can fail to generalize due to the gap between the simulation and the real world. One standard remedy is to use robust adversarial RL (RARL) that accounts for this gap during the policy training, by modeling the gap as an adversary against the training agent. In this work, we reexamine the effectiveness of RARL under a fundamental robust control setting: the linear quadratic (LQ) case. We first observe that the popular RARL scheme that greedily alternates agents’ updates can easily destabilize the system. Motivated by this, we propose several other policy-based RARL algorithms whose convergence behaviors are then studied both empirically and theoretically. We find: i) the conventional RARL framework (Pinto et al., 2017) can learn a destabilizing policy if the initial policy does not enjoy the robust stability property against the adversary; and ii) with robustly stabilizing initializations, our proposed double-loop RARL algorithm provably converges to the global optimal cost while maintaining robust stability on-the-fly. We also examine the stability and convergence issues of other variants of policy-based RARL algorithms, and then discuss several ways to learn robustly stabilizing initializations. From a robust control perspective, we aim to provide some new and critical angles about RARL, by identifying and addressing the stability issues in this fundamental LQ setting in continuous control. Our results make an initial attempt toward better theoretical understandings of policy-based RARL, the core approach in Pinto et al., 2017."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Set2Graph", "Title": "Learning Graphs From Sets", "Abstract": "This paper advocates a family of neural network models for learning Set2Graph functions that is both practical and of maximal expressive power (universal), that is, can approximate arbitrary continuous Set2Graph functions over compact sets. Testing these models on different machine learning tasks, mainly an application to particle physics, we find them favorable to existing baselines."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Open Graph Benchmark", "Title": "Datasets for Machine Learning on Graphs", "Abstract": "We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks, and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using meaningful application-specific data splits and evaluation metrics. In addition to building the datasets, we also perform extensive benchmark experiments for each dataset. Our experiments suggest that OGB datasets present significant challenges of scalability to large-scale graphs and out-of-distribution generalization under realistic data splits, indicating fruitful opportunities for future research. Finally, OGB provides an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders, evaluation scripts, baseline code, and leaderboards are publicly available at https://ogb.stanford.edu ."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Towards Understanding Hierarchical Learning", "Title": "Benefits of Neural Representations", "Abstract": "Deep neural networks can empirically perform efficient hierarchical learning, in which the layers learn useful representations of the data. However, how they make use of the intermediate representations are not explained by recent theories that relate them to ``shallow learners'' such as kernels. In this work, we demonstrate that intermediate \\emph{neural representations} add more flexibility to neural networks and can be advantageous over raw inputs. We consider a fixed, randomly initialized neural network as a representation function fed into another trainable network. When the trainable network is the quadratic Taylor model of a wide two-layer network, we show that neural representation can achieve improved sample complexities compared with the raw input: For learning a low-rank degree-$p$ polynomial ($p \\geq 4$) in $d$ dimension, neural representation requires only $\\widetilde{O}(d^{\\ceil{p/2}})$ samples, while the best-known sample complexity upper bound for the raw input is $\\widetilde{O}(d^{p-1})$. We contrast our result with a lower bound showing that neural representations do not improve over the raw input (in the infinite width limit), when the trainable network is instead a neural tangent kernel. Our results characterize when neural representations are beneficial, and may provide a new perspective on why depth is important in deep learning."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MuSCLE", "Title": "Multi Sweep Compression of LiDAR using Deep Entropy Models", "Abstract": "We present a novel compression algorithm for reducing the storage of LiDAR sensory data streams. Our model exploits spatio-temporal relationships across multiple LIDAR sweeps to reduce the bitrate of both geometry and intensity values. Towards this goal, we propose a novel conditional entropy model that models the probabilities of the octree symbols, by considering both coarse level geometry and previous sweeps’ geometric and intensity information. We then exploit the learned probability to encode the full data-stream into a compact one. Our experiments demonstrate that our method significantly reduces the joint geometry and intensity bitrate over prior state-of-the-art LiDAR compression methods, with a reduction of 7–17% and 15–35% on the UrbanCity and SemanticKITTI datasets respectively."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Implicit Bias in Deep Linear Classification", "Title": "Initialization Scale vs Training Accuracy", "Abstract": "We provide a detailed asymptotic study of gradient flow trajectories and their implicit optimization bias when minimizing the exponential loss over \"diagonal linear networks\". This is the simplest model displaying a transition between \"kernel\" and non-kernel (\"rich\" or \"active\") regimes.  We show how the transition is controlled by the relationship between the initialization scale and how accurately we minimize the training loss.  Our results indicate that some limit behavior of gradient descent only kick in at ridiculous training accuracies (well beyond 10^-100). Moreover, the implicit bias at reasonable initialization scales and training accuracies is more complex and not captured by these limits."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Auditing Differentially Private Machine Learning", "Title": "How Private is Private SGD?", "Abstract": "We investigate whether Differentially Private SGD offers better privacy in practice than what is guaranteed by its state-of-the-art analysis. We do so via novel data poisoning attacks, which we show correspond to realistic privacy attacks. While previous work (Ma et al., arXiv 2019) proposed this connection between differential privacy and data poisoning as a defense against data poisoning, our use as a tool for understanding the privacy of a specific mechanism is new. More generally, our work takes a quantitative, empirical approach to understanding the privacy afforded by specific implementations of differentially private algorithms that we believe has the potential to complement and influence analytical work on differential privacy."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from Label Proportions", "Title": "A Mutual Contamination Framework", "Abstract": "Learning from label proportions (LLP) is a weakly supervised setting for classification in which unlabeled training instances are grouped into bags, and each bag is annotated with the proportion of each class occurring in that bag. Prior work on LLP has yet to establish a consistent learning procedure, nor does there exist a theoretically justified, general purpose training criterion. In this work we address these two issues by posing LLP in terms of mutual contamination models (MCMs), which have recently been applied successfully to study various other weak supervision settings. In the process, we establish several novel technical results for MCMs, including unbiased losses and generalization error bounds under non-iid sampling plans. We also point out the limitations of a common experimental setting for LLP, and propose a new one based on our MCM framework."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Follow the Perturbed Leader", "Title": "Optimism and Fast Parallel Algorithms for Smooth Minimax Games", "Abstract": "We consider the problem of online learning and its application to solving minimax games. For the online learning problem, Follow the Perturbed Leader (FTPL) is a widely studied algorithm which enjoys the optimal $O(T^{1/2})$ \\emph{worst case} regret guarantee for both convex and nonconvex losses. In this work, we show that when the sequence of loss functions is \\emph{predictable}, a simple modification of FTPL which incorporates optimism can achieve better regret guarantees, while retaining the optimal worst-case regret guarantee for unpredictable sequences. A key challenge in obtaining these tighter regret bounds is the stochasticity and optimism in the algorithm, which requires different analysis techniques than those commonly used in the analysis of FTPL. The key ingredient we utilize in our analysis is the dual view of perturbation as regularization.\nWhile our algorithm has several applications, we consider the specific application of minimax games. For solving smooth convex-concave games, our algorithm only requires access to a linear optimization oracle. For Lipschitz and smooth nonconvex-nonconcave games, our algorithm requires access to an optimization oracle which computes the perturbed best response. In both these settings, our algorithm solves the game up to an accuracy of $O(T^{-1/2})$ using $T$ calls to the optimization oracle. An important feature of our algorithm is that it is highly parallelizable and requires only $O(T^{1/2})$ iterations, with each iteration making $O(T^{1/2})$ parallel calls to the optimization oracle."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Agnostic $Q$-learning with Function Approximation in Deterministic Systems", "Title": "Near-Optimal Bounds on Approximation Error and Sample Complexity", "Abstract": "The current paper studies the problem of agnostic $Q$-learning with function approximation in deterministic systems where the optimal $Q$-function is approximable by a function in the class $\\mathcal{F}$ with approximation error $\\delta \\ge 0$. We propose a novel recursion-based algorithm and show that if  $\\delta = O\\left(\\rho/\\sqrt{\\dim_E}\\right)$, then one can find the optimal policy using $O(\\dim_E)$ trajectories, where $\\rho$ is the gap between the optimal $Q$-value of the best actions and that of the second-best actions and $\\dim_E$ is the Eluder dimension of $\\mathcal{F}$. Our result has two implications:\n\\begin{enumerate}\n\\item In conjunction with the lower bound in [Du et al., 2020], our upper bound suggests that the condition $\\delta = \\widetilde{\\Theta}\\left(\\rho/\\sqrt{\\dim_E}\\right)$ is necessary and sufficient for algorithms with polynomial sample complexity.\n\\item In conjunction with the obvious lower bound in the tabular case, our upper bound suggests that the sample complexity $\\widetilde{\\Theta}\\left(\\dim_E\\right)$ is tight in the agnostic setting.\n\\end{enumerate}\nTherefore, we help address the open problem on agnostic $Q$-learning proposed in [Wen and Van Roy, 2013]. We further extend our algorithm to the stochastic reward setting and obtain similar results."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Firefly Neural Architecture Descent", "Title": "a General Approach for Growing Neural Networks", "Abstract": "We propose firefly neural architecture descent, a general framework for progressively and dynamically growing neural networks to jointly optimize the networks' parameters and architectures. Our method works in a steepest descent fashion, which iteratively finds the best network within a functional neighborhood of the original network that includes a diverse set of candidate network structures. By using Taylor approximation, the optimal network structure in the neighborhood can be found with a greedy selection procedure. We show that firefly descent can flexibly grow networks both wider and deeper, and can be applied to learn accurate but resource-efficient neural architectures that avoid catastrophic forgetting in continual learning. Empirically, firefly descent achieves promising results on both neural architecture search and continual learning. In particular, on a challenging continual image classification task, it learns networks that are smaller in size but have higher average accuracy than those learned by the state-of-the-art methods."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Risk-Sensitive Reinforcement Learning", "Title": "Near-Optimal Risk-Sample Tradeoff in Regret", "Abstract": "We study risk-sensitive reinforcement learning in episodic Markov decision processes with unknown transition kernels, where the goal is to optimize the total reward under the risk measure of exponential utility. We propose two provably efficient model-free algorithms, Risk-Sensitive Value Iteration (RSVI) and Risk-Sensitive Q-learning (RSQ). These algorithms implement a form of risk-sensitive optimism in the face of uncertainty, which adapts to both risk-seeking and risk-averse modes of exploration. We prove that RSVI attains an \\ensuremath{\\tilde{O}\\big(\\lambda(|\\beta| H^2) \\cdot \\sqrt{H^{3} S^{2}AT} \\big)}$ regret, while RSQ attains an $\\ensuremath{\\tilde{O}\\big(\\lambda(|\\beta| H^2) \\cdot \\sqrt{H^{4} SAT} \\big)}$ regret, where $\\lambda(u) = (e^{3u}-1)/u$ for $u>0$. In the above, $\\beta$ is the risk parameter of the exponential utility function, $S$ the number of states, $A$ the number of actions,  $T$ the total number of timesteps, and $H$ the episode length. On the flip side, we establish a regret lower bound showing that the exponential dependence on $|\\beta|$ and $H$ is unavoidable for any algorithm with an $\\tilde{O}(\\sqrt{T})$ regret (even when the risk objective is on the same scale as the original reward), thus certifying the near-optimality of the proposed algorithms. Our results demonstrate that incorporating risk awareness into reinforcement learning necessitates an exponential cost in $|\\beta|$ and $H$,   which quantifies the fundamental tradeoff between risk sensitivity (related to aleatoric uncertainty) and sample efficiency (related to epistemic uncertainty). To the best of our knowledge, this is the first regret analysis of risk-sensitive reinforcement learning with the exponential utility."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Decode", "Title": "Reinforcement Learning for Decoding of Sparse Graph-Based Channel Codes", "Abstract": "We show in this work that reinforcement learning can be successfully applied to decoding short to moderate length sparse graph-based channel codes. Specifically, we focus on low-density parity check (LDPC) codes, which for example have been standardized in the context of 5G cellular communication systems due to their excellent error correcting performance. These codes are typically decoded via belief propagation iterative decoding on the corresponding bipartite (Tanner) graph of the code via flooding, i.e., all check and variable nodes in the Tanner graph are updated at once. In contrast, in this paper we utilize a sequential update policy which selects the optimum check node (CN) scheduling in order to improve decoding performance. In particular, we model the CN update process as a multi-armed bandit process with dependent arms and employ a Q-learning scheme for optimizing the CN scheduling policy. In order to reduce the learning complexity, we propose a novel graph-induced CN clustering approach to partition the state space in such a way that dependencies between clusters are minimized. Our results show that compared to other decoding approaches from the literature, the proposed reinforcement learning scheme not only significantly improves the decoding performance, but also reduces the decoding complexity dramatically once\nthe scheduling policy is learned."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PLANS", "Title": "Neuro-Symbolic Program Learning from Videos", "Abstract": "Recent years have seen the rise of statistical program learning based on neural models as an alternative to traditional rule-based systems for programming by example. Rule-based approaches offer correctness guarantees in an unsupervised way as they inherently capture logical rules, while neural models are more realistically scalable to raw, high-dimensional input, and provide resistance to noisy I/O specifications. We introduce PLANS (Program LeArning from Neurally inferred Specifications), a hybrid model for program synthesis from visual observations that gets the best of both worlds, relying on (i) a neural architecture trained to extract abstract, high-level information from each raw individual input (ii) a rule-based system using the extracted information as I/O specifications to synthesize a program capturing the different observations. In order to address the key challenge of making PLANS resistant to noise in the network's output, we introduce a dynamic filtering algorithm for I/O specifications based on selective classification techniques. We obtain state-of-the-art performance at program synthesis from diverse demonstration videos in the Karel and ViZDoom environments, while requiring no ground-truth program for training."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MeshSDF", "Title": "Differentiable Iso-Surface Extraction", "Abstract": "We use two different applications to validate our theoretical insight: Single-View Reconstruction via Differentiable Rendering and Physically-Driven Shape Optimization. In both cases our differentiable parameterization gives us an edge over state-of-the-art algorithms."}
{"Type": "conference", "Year": "2020", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COOT", "Title": "Cooperative Hierarchical Transformer for Video-Text Representation Learning", "Abstract": "Many real-world video-text tasks involve different levels of granularity, such as frames and words, clip and sentences or videos and paragraphs, each with distinct semantics. In this paper, we propose a Cooperative hierarchical Transformer (COOT) to leverage this hierarchy information and model the interactions between different levels of granularity and different modalities. The method consists of three major components: an attention-aware feature aggregation layer, which leverages the local temporal context (intra-level, e.g., within a clip), a contextual transformer to learn the interactions between low-level and high-level semantics (inter-level, e.g. clip-video, sentence-paragraph), and a cross-modal cycle-consistency loss to connect video and text. The resulting method compares favorably to the state of the art on several benchmarks while having few parameters."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Value-Function Gaps", "Title": "Improved Instance-Dependent Regret Bounds for Episodic Reinforcement Learning", "Abstract": "We provide improved gap-dependent regret bounds for reinforcement learning in finite episodic Markov decision processes. Compared to prior work, our bounds depend on alternative definitions of gaps. These definitions are based on the insight that, in order to achieve a favorable regret, an algorithm does not need to learn how to behave optimally in states that are not reached by an optimal policy. We prove tighter upper regret bounds for optimistic algorithms and accompany them with new information-theoretic lower bounds for a large class of MDPs. Our results show that optimistic algorithms can not achieve the information-theoretic lower bounds even in deterministic MDPs unless there is a unique optimal policy."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UniDoc", "Title": "Unified Pretraining Framework for Document Understanding", "Abstract": "Document intelligence automates the extraction of information from documents and supports many business applications. Recent self-supervised learning methods on large-scale unlabeled document datasets have opened up promising directions towards reducing annotation efforts by training models with self-supervised objectives. However, most of the existing document pretraining methods are still language-dominated. We present UDoc, a new unified pretraining framework for document understanding. UDoc is designed to support most document understanding tasks, extending the Transformer to take multimodal embeddings as input. Each input element is composed of words and visual features from a semantic region of the input document image. An important feature of UDoc is that it learns a generic representation by making use of three self-supervised losses, encouraging the representation to model sentences, learn similarities, and align modalities. Extensive empirical analysis demonstrates that the pretraining procedure learns better joint representations and leads to improvements in downstream tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BAST", "Title": "Bayesian Additive Regression Spanning Trees for Complex Constrained Domain", "Abstract": "Nonparametric regression on complex domains has been a challenging task as most existing methods, such as ensemble models based on binary decision trees, are not designed to account for intrinsic geometries and domain boundaries. This article proposes a Bayesian additive regression spanning trees (BAST) model for nonparametric regression on manifolds, with an emphasis on complex constrained domains or irregularly shaped spaces embedded in Euclidean spaces. Our model is built upon a random spanning tree manifold partition model as each weak learner, which is capable of capturing any irregularly shaped spatially contiguous partitions while respecting intrinsic geometries and domain boundary constraints. Utilizing many nice properties of spanning tree structures, we design an efficient Bayesian inference algorithm. Equipped with a soft prediction scheme, BAST is demonstrated to significantly outperform other competing methods in simulation experiments and in an application to the chlorophyll data in Aral Sea, due to its strong local adaptivity to different levels of smoothness."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Backward-Compatible Prediction Updates", "Title": "A Probabilistic Approach", "Abstract": "When machine learning systems meet real world applications, accuracy is only one of several requirements. In this paper, we assay a complementary perspective originating from the increasing availability of pre-trained and regularly improving state-of-the-art models. While new improved models develop at a fast pace, downstream tasks vary more slowly or stay constant. Assume that we have a large unlabelled data set for which we want to maintain accurate predictions. Whenever a new and presumably better ML models becomes available, we encounter two problems: (i) given a limited budget, which data points should be re-evaluated using the new model?; and (ii) if the new predictions differ from the current ones, should we update? Problem (i) is about compute cost, which matters for very large data sets and models. Problem (ii) is about maintaining consistency of the predictions, which can be highly relevant for downstream applications; our demand is to avoid negative flips, i.e., changing correct to incorrect predictions. In this paper, we formalize the Prediction Update Problem and present an efficient probabilistic approach as answer to the above questions. In extensive experiments on standard classification benchmark data sets, we show that our method outperforms alternative strategies along key metrics for backward-compatible prediction updates."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ReAct", "Title": "Out-of-distribution Detection With Rectified Activations", "Abstract": "Out-of-distribution (OOD) detection has received much attention lately due to its practical importance in enhancing the safe deployment of neural networks. One of the primary challenges is that models often produce highly confident predictions on OOD data, which undermines the driving principle in OOD detection that the model should only be confident about in-distribution samples. In this work, we propose ReAct—a simple and effective technique for reducing model overconfidence on OOD data. Our method is motivated by novel analysis on internal activations of neural networks, which displays highly distinctive signature patterns for OOD distributions. Our method can generalize effectively to different network architectures and different OOD detection scores. We empirically demonstrate that ReAct achieves competitive detection performance on a comprehensive suite of benchmark datasets, and give theoretical explication for our method’s efficacy. On the ImageNet benchmark, ReAct reduces the false positive rate (FPR95) by 25.05% compared to the previous best method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AugMax", "Title": "Adversarial Composition of Random Augmentations for Robust Training", "Abstract": "Data augmentation is a simple yet effective way to improve the robustness of deep neural networks (DNNs). Diversity and hardness are two complementary dimensions of data augmentation to achieve robustness. For example, AugMix explores random compositions of a diverse set of augmentations to enhance broader coverage, while adversarial training generates adversarially hard samples to spot the weakness. Motivated by this, we propose a data augmentation framework, termed AugMax, to unify the two aspects of diversity and hardness. AugMax first randomly samples multiple augmentation operators and then learns an adversarial mixture of the selected operators. Being a stronger form of data augmentation, AugMax leads to a significantly augmented input distribution which makes model training more challenging. To solve this problem, we further design a disentangled normalization module, termed DuBIN (Dual-Batch-and-Instance Normalization), that disentangles the instance-wise feature heterogeneity arising from AugMax. Experiments show that AugMax-DuBIN leads to significantly improved out-of-distribution robustness, outperforming prior arts by 3.03%, 3.49%, 1.82% and 0.71% on CIFAR10-C, CIFAR100-C, Tiny ImageNet-C and ImageNet-C. Codes and pretrained models are available: https://github.com/VITA-Group/AugMax."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Habitat 2.0", "Title": "Training Home Assistants to Rearrange their Habitat", "Abstract": "We introduce Habitat 2.0 (H2.0), a simulation platform for training virtual robots in interactive 3D environments and complex physics-enabled scenarios. We make comprehensive contributions to all levels of the embodied AI stack – data, simulation, and benchmark tasks. Specifically, we present: (i) ReplicaCAD: an artist-authored, annotated, reconfigurable 3D dataset of apartments (matching real spaces) with articulated objects (e.g. cabinets and drawers that can open/close); (ii) H2.0: a high-performance physics-enabled 3D simulator with speeds exceeding 25,000 simulation steps per second (850x real-time) on an 8-GPU node, representing 100x speed-ups over prior work; and, (iii) Home Assistant Benchmark (HAB): a suite of common tasks for assistive robots (tidy the house, stock groceries, set the table) that test a range of mobile manipulation capabilities. These large-scale engineering contributions allow us to systematically compare deep reinforcement learning (RL) at scale and classical sense-plan-act (SPA) pipelines in long-horizon structured tasks, with an emphasis on generalization to new objects, receptacles, and layouts. We find that (1) flat RL policies struggle on HAB compared to hierarchical ones; (2) a hierarchy with independent skills suffers from ‘hand-off problems’, and (3) SPA pipelines are more brittle than RL policies."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VoiceMixer", "Title": "Adversarial Voice Style Mixup", "Abstract": "Although recent advances in voice conversion have shown significant improvement, there still remains a gap between the converted voice and target voice. A key factor that maintains this gap is the insufficient decomposition of content and voice style from the source speech. This insufficiency leads to the converted speech containing source speech style or losing source speech content. In this paper, we present VoiceMixer which can effectively decompose and transfer voice style through a novel information bottleneck and adversarial feedback. With self-supervised representation learning, the proposed information bottleneck can decompose the content and style with only a small loss of content information. Also, for adversarial feedback of each information, the discriminator is decomposed into content and style discriminator with self-supervision, which enable our model to achieve better generalization to the voice style of the converted speech. The experimental results show the superiority of our model in disentanglement and transfer performance, and improve audio quality by preserving content information."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predicting What You Already Know Helps", "Title": "Provable Self-Supervised Learning", "Abstract": "Self-supervised representation learning solves auxiliary prediction tasks (known as pretext tasks), that do not require labeled data, to learn semantic representations. These pretext tasks are created solely using the input features, such as predicting a missing image patch, recovering the color channels of an image from context, or predicting missing words, yet predicting this \\textit{known} information helps in learning representations effective for downstream prediction tasks. This paper posits a mechanism based on approximate conditional independence to formalize how solving certain pretext tasks can learn representations that provably decrease the sample complexity of downstream supervised tasks. Formally, we quantify how the approximate independence between the components of the pretext task (conditional on the label and latent variables) allows us to learn representations that can solve the downstream task with drastically reduced sample complexity by just training a linear layer on top of the learned representation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CentripetalText", "Title": "An Efficient Text Instance Representation for Scene Text Detection", "Abstract": "Scene text detection remains a grand challenge due to the variation in text curvatures, orientations, and aspect ratios. One of the hardest problems in this task is how to represent text instances of arbitrary shapes. Although many methods have been proposed to model irregular texts in a flexible manner, most of them lose simplicity and robustness. Their complicated post-processings and the regression under Dirac delta distribution undermine the detection performance and the generalization ability. In this paper, we propose an efficient text instance representation named CentripetalText (CT), which decomposes text instances into the combination of text kernels and centripetal shifts. Specifically, we utilize the centripetal shifts to implement pixel aggregation, guiding the external text pixels to the internal text kernels. The relaxation operation is integrated into the dense regression for centripetal shifts, allowing the correct prediction in a range instead of a specific value. The convenient reconstruction of text contours and the tolerance of prediction errors in our method guarantee the high detection accuracy and the fast inference speed, respectively. Besides, we shrink our text detector into a proposal generation module, namely CentripetalText Proposal Network (CPN), replacing Segmentation Proposal Network (SPN) in Mask TextSpotter v3 and producing more accurate proposals. To validate the effectiveness of our method, we conduct experiments on several commonly used scene text benchmarks, including both curved and multi-oriented text datasets. For the task of scene text detection, our approach achieves superior or competitive performance compared to other existing methods, e.g., F-measure of 86.3% at 40.0 FPS on Total-Text, F-measure of 86.1% at 34.8 FPS on MSRA-TD500, etc. For the task of end-to-end scene text recognition, our method outperforms Mask TextSpotter v3 by 1.1% in F-measure on Total-Text."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DRIVE", "Title": "One-bit Distributed Mean Estimation", "Abstract": "We consider the problem where $n$ clients transmit $d$-dimensional real-valued vectors using $d(1+o(1))$ bits each, in a manner that allows the receiver to approximately reconstruct their mean. Such compression problems naturally arise in distributed and federated learning. We provide novel mathematical results and derive computationally efficient algorithms that are more accurate than previous compression techniques.  We evaluate our methods on a collection of distributed and federated learning tasks, using a variety of datasets, and show a consistent improvement over the state of the art."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Complexity of Bayesian Network Learning", "Title": "Revisiting the Superstructure", "Abstract": "We investigate the parameterized complexity of Bayesian Network Structure Learning (BNSL), a classical problem that has received significant attention in empirical but also purely theoretical studies. We follow up on previous works that have analyzed the complexity of BNSL w.r.t. the so-called superstructure of the input. While known results imply that BNSL is unlikely to be fixed-parameter tractable even when parameterized by the size of a vertex cover in the superstructure, here we show that a different kind of parameterization - notably by the size of a feedback edge set - yields fixed-parameter tractability. We proceed by showing that this result can be strengthened to a localized version of the feedback edge set, and provide corresponding lower bounds that complement previous results to provide a complexity classification of BNSL w.r.t. virtually all well-studied graph parameters.We then analyze how the complexity of BNSL depends on the representation of the input. In particular, while the bulk of past theoretical work on the topic assumed the use of the so-called non-zero representation, here we prove that if an additive representation can be used instead then BNSL becomes fixed-parameter tractable even under significantly milder restrictions to the superstructure, notably when parameterized by the treewidth alone. Last but not least, we show how our results can be extended to the closely related problem of Polytree Learning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TopicNet", "Title": "Semantic Graph-Guided Topic Discovery", "Abstract": "Existing deep hierarchical topic models are able to extract semantically meaningful topics from a text corpus  in an unsupervised manner and automatically organize them into a topic hierarchy.  However, it is unclear how to incorporate prior belief such as knowledge graph to guide the learning of the topic hierarchy. To address this issue, we introduce TopicNet as a deep hierarchical topic model that can inject prior structural knowledge as inductive bias to influence the learning. TopicNet represents each topic as a Gaussian-distributed embedding vector, projects the topics of all layers into a shared embedding space, and explores both the symmetric and asymmetric similarities between Gaussian embedding vectors to incorporate prior semantic hierarchies. With a variational auto-encoding inference network,  the model parameters are optimized by minimizing the evidence lower bound and supervised loss via stochastic gradient descent. Experiments on widely used benchmark show that TopicNet outperforms related deep topic models on discovering deeper interpretable topics and mining better document representations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "T-LoHo", "Title": "A Bayesian Regularization Model for Structured Sparsity and Smoothness on Graphs", "Abstract": "Graphs have been commonly used to represent complex data structures. In models dealing with graph-structured data, multivariate parameters may not only exhibit sparse patterns but have structured sparsity and smoothness in the sense that both zero and non-zero parameters tend to cluster together. We propose a new prior for high-dimensional parameters with graphical relations, referred to as the Tree-based Low-rank Horseshoe (T-LoHo) model, that generalizes the popular univariate Bayesian horseshoe shrinkage prior to the multivariate setting to detect structured sparsity and smoothness simultaneously. The T-LoHo prior can be embedded in many high-dimensional hierarchical models. To illustrate its utility, we apply it to regularize a Bayesian high-dimensional regression problem where the regression coefficients are linked by a graph, so that the resulting clusters have flexible shapes and satisfy the cluster contiguity constraint with respect to the graph. We design an efficient Markov chain Monte Carlo algorithm that delivers full Bayesian inference with uncertainty measures for model parameters such as the number of clusters. We offer theoretical investigations of the clustering effects and posterior concentration results. Finally, we illustrate the performance of the model with simulation studies and a real data application for anomaly detection on a road network. The results indicate substantial improvements over other competing methods such as the sparse fused lasso."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Landmark-RxR", "Title": "Solving Vision-and-Language Navigation with Fine-Grained Alignment Supervision", "Abstract": "In Vision-and-Language Navigation (VLN) task, an agent is asked to navigate inside 3D indoor environments following given instructions. Cross-modal alignment is one of the most critical challenges in VLN because the predicted trajectory needs to match the given instruction accurately. In this paper, we address the cross-modal alignment challenge from the perspective of fine-grain. Firstly, to alleviate weak cross-modal alignment supervision from coarse-grained data, we introduce a human-annotated fine-grained VLN dataset, namely Landmark-RxR. Secondly, to further enhance local cross-modal alignment under fine-grained supervision, we investigate the focal-oriented rewards with soft and hard forms, by focusing on the critical points sampled from fine-grained Landmark-RxR. Moreover, to fully evaluate the navigation process, we also propose a re-initialization mechanism that makes metrics insensitive to difficult points, which can cause the agent to deviate from the correct trajectories. Experimental results show that our agent has superior navigation performance on Landmark-RxR, en-RxR and R2R. Our dataset and code are available at https://github.com/hekj/Landmark-RxR."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Winning Hand", "Title": "Compressing Deep Networks Can Improve Out-of-Distribution Robustness", "Abstract": "Successful adoption of deep learning (DL) in the wild requires models to be: (1) compact, (2) accurate, and (3) robust to distributional shifts. Unfortunately, efforts towards simultaneously meeting these requirements have mostly been unsuccessful. This raises an important question: Is the inability to create Compact, Accurate, and Robust Deep neural networks (CARDs) fundamental? To answer this question, we perform a large-scale analysis of popular model compression techniques which uncovers several intriguing patterns. Notably, in contrast to traditional pruning approaches (e.g., fine tuning and gradual magnitude pruning), we find that ``lottery ticket-style'' approaches can surprisingly be used to produce CARDs, including binary-weight CARDs. Specifically, we are able to create extremely compact CARDs that, compared to their larger counterparts, have similar test accuracy and matching (or better) robustness---simply by pruning and (optionally) quantizing. Leveraging the compactness of CARDs, we develop a simple domain-adaptive test-time ensembling approach (CARD-Decks) that uses a gating module to dynamically select appropriate CARDs from the CARD-Deck based on their spectral-similarity with test samples. The proposed approach builds a \"winning hand'' of CARDs that establishes a new state-of-the-art (on RobustBench) on CIFAR-10-C accuracies (i.e., 96.8% standard and 92.75% robust) and CIFAR-100-C accuracies (80.6% standard and 71.3% robust) with better memory usage than non-compressed baselines (pretrained CARDs and CARD-Decks available at https://github.com/RobustBench/robustbench). Finally, we provide theoretical support for our empirical findings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Iterative Methods for Private Synthetic Data", "Title": "Unifying Framework and New Methods", "Abstract": "We study private synthetic data generation for query release, where the goal is to construct a sanitized version of a sensitive dataset, subject to differential privacy, that approximately preserves the answers to a large collection of statistical queries. We first present an algorithmic framework that unifies a long line of iterative algorithms in the literature. Under this framework, we propose two new methods. The first method, private entropy projection (PEP), can be viewed as an advanced variant of MWEM that adaptively reuses past query measurements to boost accuracy. Our second method, generative networks with the exponential mechanism (GEM), circumvents computational bottlenecks in algorithms such as MWEM and PEP by optimizing over generative models parameterized by neural networks, which capture a rich family of distributions while enabling fast gradient-based optimization. We demonstrate that PEP and GEM empirically outperform existing algorithms. Furthermore, we show that GEM nicely incorporates prior information from public data while overcoming limitations of PMW^Pub, the existing state-of-the-art method that also leverages public data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mirror Langevin Monte Carlo", "Title": "the Case Under Isoperimetry", "Abstract": "Motivated by the connection between sampling and optimization, we study a mirror descent analogue of Langevin dynamics and analyze three different discretization schemes, giving nonasymptotic convergence rate under functional inequalities such as Log-Sobolev in the corresponding metric. Compared to the Euclidean setting, the result reveals intricate relationship between the underlying geometry and the target distribution and suggests that care might need to be taken in order for the discretized algorithm to achieve vanishing bias with diminishing stepsize for sampling from potentials under weaker smoothness/convexity regularity conditions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeurWIN", "Title": "Neural Whittle Index Network For Restless Bandits Via Deep RL", "Abstract": "Whittle index policy is a powerful tool to obtain asymptotically optimal solutions for the notoriously intractable problem of restless bandits. However, finding the Whittle indices remains a difficult problem for many practical restless bandits with convoluted transition kernels. This paper proposes NeurWIN, a neural Whittle index network that seeks to learn the Whittle indices for any restless bandits by leveraging mathematical properties of the Whittle indices. We show that a neural network that produces the Whittle index is also one that produces the optimal control for a set of Markov decision problems. This property motivates using deep reinforcement learning for the training of NeurWIN. We demonstrate the utility of NeurWIN by evaluating its performance for three recently studied restless bandit problems.Our experiment results show that the performance of NeurWIN is significantly better than other RL algorithms."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sageflow", "Title": "Robust Federated Learning against Both Stragglers and Adversaries", "Abstract": "While federated learning (FL) allows efficient model training with local data at edge devices, among major issues still to be resolved are: slow devices known as stragglers and malicious attacks launched by adversaries.   While the presence of both of these issues raises serious concerns in practical FL systems, no known schemes or combinations of schemes effectively address them at the same time. We propose Sageflow, staleness-aware grouping with entropy-based filtering and loss-weighted averaging, to handle both stragglers and adversaries simultaneously. Model grouping and weighting according to staleness (arrival delay) provides robustness against stragglers, while entropy-based filtering and loss-weighted averaging, working in a highly complementary fashion at each grouping stage,  counter a wide range of adversary attacks. A theoretical bound is established to provide key insights into the convergence behavior of Sageflow. Extensive experimental results show that Sageflow outperforms various existing methods aiming to handle stragglers/adversaries."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Noise2Score", "Title": "Tweedie’s Approach to Self-Supervised Image Denoising without Clean Images", "Abstract": "Recently, there has  been extensive research interest in training  deep networks to denoise images without clean reference.However, the representative approaches such as Noise2Noise, Noise2Void, Stein's unbiased risk estimator (SURE), etc.  seem to differ from one another and it is difficult to find the coherent mathematical structure. To address this, here we present a novel approach, called Noise2Score, which reveals a missing link in order to unite these seemingly different approaches.Specifically, we  show that   image denoising  problems  without clean images can be addressed by finding the mode of the posterior distribution and that the Tweedie's formula offers an explicit solution through the score function (i.e. the gradient of loglikelihood). Our method then uses the  recent finding that  the score function  can be stably estimated from the noisy images using the amortized residual denoising autoencoder, the method of which is closely related to Noise2Noise or Nose2Void. Our Noise2Score approach is so universal  that the same network training can be used to remove noises from images that are corrupted by any exponential family distributions and noise parameters. Using extensive  experiments with Gaussian, Poisson, and Gamma noises, we show  that  Noise2Score significantly outperforms the state-of-the-art self-supervised denoising methods in the benchmark data set such as (C)BSD68, Set12, and Kodak, etc."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Perturb-and-max-product", "Title": "Sampling and learning in discrete energy-based models", "Abstract": "Perturb-and-MAP offers an elegant approach to approximately sample from a energy-based model (EBM) by computing the maximum-a-posteriori (MAP) configuration of a perturbed version of the model. Sampling in turn enables learning. However, this line of research has been hindered by the general intractability of the MAP computation. Very few works venture outside tractable models, and when they do, they use linear programming approaches, which as we will show, have several limitations. In this work we present perturb-and-max-product (PMP), a parallel and scalable mechanism for sampling and learning in discrete EBMs. Models can be arbitrary as long as they are built using tractable factors. We show that (a) for Ising models, PMP is orders of magnitude faster than Gibbs and Gibbs-with-Gradients (GWG) at learning and generating samples of similar or better quality; (b) PMP is able to learn and sample from RBMs; (c) in a large, entangled graphical model in which Gibbs and GWG fail to mix, PMP succeeds."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CAFE", "Title": "Catastrophic Data Leakage in Vertical Federated Learning", "Abstract": "Recent studies show that private training data can be leaked through the gradients sharing mechanism deployed in distributed machine learning systems, such as federated learning (FL). Increasing batch size to complicate data recovery is often viewed as a promising defense strategy against data leakage. In this paper, we revisit this defense premise and propose an advanced data leakage attack with theoretical justification to efficiently recover batch data from the shared aggregated gradients. We name our proposed method as catastrophic data leakage in vertical federated learning (CAFE). Comparing to existing data leakage attacks, our extensive experimental results on vertical FL settings demonstrate the effectiveness of CAFE to perform large-batch data leakage attack with improved data recovery quality. We also propose a practical countermeasure to mitigate CAFE. Our results suggest that private data participated in standard FL, especially the vertical case, have a high risk of being leaked from the training gradients. Our analysis implies unprecedented and practical data leakage risks in those learning settings. The code of our work is available at https://github.com/DeRafael/CAFE."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Compacter", "Title": "Efficient Low-Rank Hypercomplex Adapter Layers", "Abstract": "Adapting large-scale pretrained language models to downstream tasks via fine-tuning is the standard method for achieving state-of-the-art performance on NLP benchmarks. However, fine-tuning all weights of models with millions or billions of parameters is sample-inefficient, unstable in low-resource settings, and wasteful as it requires storing a separate copy of the model for each task. Recent work has developed parameter-efficient fine-tuning methods,  but these approaches either still require a relatively large number of parameters or underperform standard fine-tuning. In this work, we propose Compacter, a method for fine-tuning large-scale language models with a better trade-off between task performance and the number of trainable parameters than prior work. Compacter accomplishes this by building on top of ideas from adapters, low-rank optimization, and parameterized hypercomplex multiplication layers.Specifically, Compacter inserts task-specific weight matrices into a pretrained model's weights, which are computed efficiently as a sum of Kronecker products between shared slow'' weights andfast'' rank-one matrices defined per Compacter layer. By only training 0.047% of a pretrained model's parameters, Compacter performs on par with standard fine-tuning on GLUE and outperforms standard fine-tuning on SuperGLUE and low-resource settings. Our code is publicly available at https://github.com/rabeehk/compacter."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BatchQuant", "Title": "Quantized-for-all Architecture Search with Robust Quantizer", "Abstract": "As the applications of deep learning models on edge devices increase at an accelerating pace, fast adaptation to various scenarios with varying resource constraints has become a crucial aspect of model deployment. As a result, model optimization strategies with adaptive configuration are becoming increasingly popular. While single-shot quantized neural architecture search enjoys flexibility in both model architecture and quantization policy, the combined search space comes with many challenges, including instability when training the weight-sharing supernet and difficulty in navigating the exponentially growing search space. Existing methods tend to either limit the architecture search space to a small set of options or limit the quantization policy search space to fixed precision policies. To this end, we propose BatchQuant, a robust quantizer formulation that allows fast and stable training of a compact, single-shot, mixed-precision, weight-sharing supernet. We employ BatchQuant to train a compact supernet (offering over $10^{76}$ quantized subnets) within substantially fewer GPU hours than previous methods. Our approach, Quantized-for-all (QFA), is the first to seamlessly extend one-shot weight-sharing NAS supernet to support subnets with arbitrary ultra-low bitwidth mixed-precision quantization policies without retraining. QFA opens up new possibilities in joint hardware-aware neural architecture search and quantization. We demonstrate the effectiveness of our method on ImageNet and achieve SOTA Top-1 accuracy under a low complexity constraint (<20 MFLOPs)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization Bounds for Graph Embedding Using Negative Sampling", "Title": "Linear vs Hyperbolic", "Abstract": "Graph embedding, which represents real-world entities in a mathematical space, has enabled numerous applications such as analyzing natural languages, social networks, biochemical networks, and knowledge bases.It has been experimentally shown that graph embedding in hyperbolic space can represent hierarchical tree-like data more effectively than embedding in linear space, owing to hyperbolic space's exponential growth property. However, since the theoretical comparison has been limited to ideal noiseless settings, the potential for the hyperbolic space's property to worsen the generalization error for practical data has not been analyzed.In this paper, we provide a generalization error bound applicable for graph embedding both in linear and hyperbolic spaces under various negative sampling settings that appear in graph embedding. Our bound states that error is polynomial and exponential with respect to the embedding space's radius in linear and hyperbolic spaces, respectively, which implies that hyperbolic space's exponential growth property worsens the error.Using our bound, we clarify the data size condition on which graph embedding in hyperbolic space can represent a tree better than in Euclidean space by discussing the bias-variance trade-off.Our bound also shows that imbalanced data distribution, which often appears in graph embedding, can worsen the error."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gradient Starvation", "Title": "A Learning Proclivity in Neural Networks", "Abstract": "We identify and formalize a fundamental gradient descent phenomenon resulting in a learning proclivity in over-parameterized neural networks. Gradient Starvation arises when cross-entropy loss is minimized by capturing only a subset of features relevant for the task, despite the presence of other predictive features that fail to be discovered. This work provides a theoretical explanation for the emergence of such feature imbalance in neural networks. Using tools from Dynamical Systems theory, we identify simple properties of learning dynamics during gradient descent that lead to this imbalance, and prove that such a situation can be expected given certain statistical structure in training data. Based on our proposed formalism, we develop guarantees for a novel regularization method aimed at decoupling feature learning dynamics, improving accuracy and robustness in cases hindered by gradient starvation. We illustrate our findings with simple and real-world out-of-distribution (OOD) generalization experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Optimality and Stability in Federated Learning", "Title": "A Game-theoretic Approach", "Abstract": "Federated learning is a distributed learning paradigm where multiple agents, each only with access to local data, jointly learn a global model. There has recently been an explosion of research aiming not only to improve the accuracy rates of federated learning, but also provide certain guarantees around social good properties such as total error. One branch of this research has taken a game-theoretic approach, and in particular, prior work has viewed federated learning as a hedonic game, where error-minimizing players arrange themselves into federating coalitions. This past work proves the existence of stable coalition partitions, but leaves open a wide range of questions, including how far from optimal these stable solutions are. In this work, we motivate and define a notion of optimality given by the average error rates among federating agents (players). First, we provide and prove the correctness of an efficient algorithm to calculate an optimal (error minimizing) arrangement of players. Next, we analyze the relationship between the stability and optimality of an arrangement. First, we show that for some regions of parameter space, all stable arrangements are optimal (Price of Anarchy equal to 1). However, we show this is not true for all settings: there exist examples of stable arrangements with higher cost than optimal (Price of Anarchy greater than 1). Finally, we give the first constant-factor bound on the performance gap between stability and optimality, proving that the total error of the worst stable solution can be no higher than 9 times the total error of an optimal solution (Price of Anarchy bound of 9)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shapeshifter", "Title": "a Parameter-efficient Transformer using Factorized Reshaped Matrices", "Abstract": "Language models employ a very large number of trainable parameters. Despite being highly overparameterized, these networks often achieve good out-of-sample test performance on the original task and easily fine-tune to related tasks. Recent observations involving, for example, intrinsic dimension of the objective landscape and  the lottery ticket hypothesis, indicate that often training actively involves only a small fraction of the parameter space. Thus, a question remains how large a parameter space needs to be in the first place –- the evidence from recent work on model compression, parameter sharing, factorized representations, and knowledge distillation increasingly shows that models can be made much smaller and still perform well. Here, we focus on factorized representations of matrices that underpin dense, embedding, and self-attention layers. We use low-rank factorized representation of a reshaped and rearranged original matrix to achieve space efficient and expressive linear layers. We prove that stacking such low-rank layers increases their expressiveness, providing theoretical understanding for their effectiveness in deep networks. In Transformer models, our approach leads to more than ten-fold reduction in the number of total trainable parameters, including embedding, attention, and feed-forward layers, with little degradation in on-task performance. The approach operates out-of-the-box,  replacing each parameter matrix with its compact equivalent while maintaining the architecture of the network."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TransformerFusion", "Title": "Monocular RGB Scene Reconstruction using Transformers", "Abstract": "We introduce TransformerFusion, a transformer-based 3D scene reconstruction approach. From an input monocular RGB video, the video frames are processed by a transformer network that fuses the observations into a volumetric feature grid representing the scene; this feature grid is then decoded into an implicit 3D scene representation. Key to our approach is the transformer architecture that enables the network to learn to attend to the most relevant image frames for each 3D location in the scene, supervised only by the scene reconstruction task. Features are fused in a coarse-to-fine fashion, storing fine-level features only where needed, requiring lower memory storage and enabling fusion at interactive rates. The feature grid is then decoded to a higher-resolution scene reconstruction, using an MLP-based surface occupancy prediction from interpolated coarse-to-fine 3D features. Our approach results in an accurate surface reconstruction, outperforming state-of-the-art multi-view stereo depth estimation methods, fully-convolutional 3D reconstruction approaches, and approaches using LSTM- or GRU-based recurrent networks for video sequence fusion."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Regularized Frank-Wolfe for Dense CRFs", "Title": "Generalizing Mean Field and Beyond", "Abstract": "We introduce regularized Frank-Wolfe, a general and effective algorithm for inference and learning of dense conditional random fields (CRFs). The algorithm optimizes a nonconvex continuous relaxation of the CRF inference problem using vanilla Frank-Wolfe with approximate updates, which are equivalent to minimizing a regularized energy function. Our proposed method is a generalization of existing algorithms such as mean field or concave-convex procedure. This perspective not only offers a unified analysis of these algorithms, but also allows an easy way of exploring different variants that potentially yield better performance. We illustrate this in our empirical results on standard semantic segmentation datasets, where several instantiations of our regularized Frank-Wolfe outperform mean field inference, both as a standalone component and as an end-to-end trainable layer in a neural network. We also show that dense CRFs, coupled with our new algorithms, produce significant improvements over strong CNN baselines."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Terra", "Title": "Imperative-Symbolic Co-Execution of Imperative Deep Learning Programs", "Abstract": "Imperative programming allows users to implement their deep neural networks (DNNs) easily and has become an essential part of recent deep learning (DL) frameworks. Recently, several systems have been proposed to combine the usability of imperative programming with the optimized performance of symbolic graph execution. Such systems convert imperative Python DL programs to optimized symbolic graphs and execute them. However, they cannot fully support the usability of imperative programming. For example, if an imperative DL program contains a Python feature with no corresponding symbolic representation (e.g., third-party library calls or unsupported dynamic control flows) they fail to execute the program. To overcome this limitation, we propose Terra, an imperative-symbolic co-execution system that can handle any imperative DL programs while achieving the optimized performance of symbolic graph execution. To achieve this, Terra builds a symbolic graph by decoupling DL operations from Python features. Then, Terra conducts the imperative execution to support all Python features, while delegating the decoupled operations to the symbolic execution. We evaluated Terra’s performance improvement and coverage with ten imperative DL programs for several DNN architectures. The results show that Terra can speed up the execution of all ten imperative DL programs, whereas AutoGraph, one of the state-of-the-art systems, fails to execute five of them."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Play to Grade", "Title": "Testing Coding Games as Classifying Markov Decision Process", "Abstract": "Contemporary coding education often presents students with the task of developing programs that have user interaction and complex dynamic systems, such as mouse based games. While pedagogically compelling, there are no contemporary autonomous methods for providing feedback. Notably, interactive programs are impossible to grade by traditional unit tests. In this paper we formalize the challenge of providing feedback to interactive programs as a task of classifying Markov Decision Processes (MDPs). Each student's program fully specifies an MDP where the agent needs to operate and decide, under reasonable generalization, if the dynamics and reward model of the input MDP should be categorized as correct or broken. We demonstrate that by designing a cooperative objective between an agent and an autoregressive model, we can use the agent to sample differential trajectories from the input MDP that allows a classifier to determine membership: Play to Grade. Our method enables an automatic feedback system for interactive code assignments. We release a dataset of 711,274 anonymized student submissions to a single assignment with hand-coded bug labels to support future research."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Think Big, Teach Small", "Title": "Do Language Models Distil Occam’s Razor?", "Abstract": "Large language models have recently shown a remarkable ability for few-shot learning, including patterns of algorithmic nature. However, it is still an open question to determine what kind of patterns these models can capture and how many examples they need in their prompts. We frame this question as a teaching problem with strong priors, and study whether language models can identify simple algorithmic concepts from small witness sets. In particular, we explore how several GPT architectures, program induction systems and humans perform in terms of the complexity of the concept and the number of additional examples, and how much their behaviour differs. This first joint analysis of language models and machine teaching can address key questions for artificial intelligence and machine learning, such as whether some strong priors, and Occam’s razor in particular, can be distilled from data, making learning from a few examples possible."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "USCO-Solver", "Title": "Solving Undetermined Stochastic Combinatorial Optimization Problems", "Abstract": "Real-world decision-making systems are often subject to uncertainties that have to be resolved through observational data. Therefore, we are frequently confronted with combinatorial optimization problems of which the objective function is unknown and thus has to be debunked using empirical evidence. In contrast to the common practice that relies on a learning-and-optimization strategy, we consider the regression between combinatorial spaces, aiming to infer high-quality optimization solutions from samples of input-solution pairs -- without the need to learn the objective function. Our main deliverable is a universal solver that is able to handle abstract undetermined stochastic combinatorial optimization problems. For learning foundations, we present learning-error analysis under the PAC-Bayesian framework using a new margin-based analysis. In empirical studies, we demonstrate our design using proof-of-concept experiments, and compare it with other methods that are potentially applicable. Overall, we obtain highly encouraging experimental results for several classic combinatorial problems on both synthetic and real-world datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KS-GNN", "Title": "Keywords Search over Incomplete Graphs via Graphs Neural Network", "Abstract": "Keyword search is a fundamental task to retrieve information that is the most relevant to the query keywords. Keyword search over graphs aims to find subtrees or subgraphs containing all query keywords ranked according to some criteria. Existing studies all assume that the graphs have complete information. However, real-world graphs may contain some missing information (such as edges or keywords), thus making the problem much more challenging. To solve the problem of keyword search over incomplete graphs, we propose a novel model named KS-GNN based on the graph neural network and the auto-encoder. By considering the latent relationships and the frequency of different keywords, the proposed KS-GNN aims to alleviate the effect of missing information and is able to learn low-dimensional representative node embeddings that preserve both graph structure and keyword features. Our model can effectively answer keyword search queries with linear time complexity over incomplete graphs. The experiments on four real-world datasets show that our model consistently achieves better performance than state-of-the-art baseline methods in graphs having missing information."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NxMTransformer", "Title": "Semi-Structured Sparsification for Natural Language Understanding via ADMM", "Abstract": "Natural Language Processing (NLP) has recently achieved great success by using huge pre-trained Transformer networks. However, these models often contain hundreds of millions or even billions of parameters, bringing challenges to online deployment due to latency constraints. Recently, hardware manufacturers have introduced dedicated hardware for NxM sparsity to provide the flexibility of unstructured pruning with the runtime efficiency of structured approaches. NxM sparsity permits arbitrarily selecting M parameters to retain from a contiguous group of N in the dense representation. However, due to the extremely high complexity of pre-trained models, the standard sparse fine-tuning techniques often fail to generalize well on downstream tasks, which have limited data resources. To address such an issue in a principled manner, we introduce a new learning framework, called NxMTransformer, to induce NxM semi-structured sparsity on pretrained language models for natural language understanding to obtain better performance. In particular, we propose to formulate the NxM sparsity as a constrained optimization problem and use Alternating Direction Method of Multipliers (ADMM) to optimize the downstream tasks while taking the underlying hardware constraints into consideration. ADMM decomposes the NxM sparsification problem into two sub-problems that can be solved sequentially, generating sparsified Transformer networks that achieve high accuracy while being able to effectively execute on newly released hardware. We apply our approach to a wide range of NLP tasks, and our proposed method is able to achieve 1.7 points higher accuracy in GLUE score than current best practices. Moreover, we perform detailed analysis on our approach and shed light on how ADMM affects fine-tuning accuracy for downstream tasks. Finally, we illustrate how NxMTransformer achieves additional performance improvement with knowledge distillation based methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Wisdom of the Crowd Voting", "Title": "Truthful Aggregation of Voter Information and Preferences", "Abstract": "We consider two-alternative elections where voters' preferences depend on a state variable that is not directly observable. Each voter receives a private signal that is correlated to the state variable. As a special case, our model captures the common scenario where voters can be categorized into three types: those who always prefer one alternative, those who always prefer the other, and those contingent voters whose preferences depends on the state.  In this setting, even if every voter is a contingent voter, agents voting according to their private information need not result in the adoption of the universally preferred alternative, because the signals can be systematically biased.We present a mechanism that elicits and aggregates the private signals from the voters, and outputs the alternative that is favored by the majority.  In particular, voters truthfully reporting their signals forms a strong Bayes Nash equilibrium (where no coalition of voters can deviate and receive a better outcome)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "There Is No Turning Back", "Title": "A Self-Supervised Approach for Reversibility-Aware Reinforcement Learning", "Abstract": "We propose to learn to distinguish reversible from irreversible actions for better informed decision-making in Reinforcement Learning (RL). From theoretical considerations, we show that approximate reversibility can be learned through a simple surrogate task: ranking randomly sampled trajectory events in chronological order. Intuitively, pairs of events that are always observed in the same order are likely to be separated by an irreversible sequence of actions. Conveniently, learning the temporal order of events can be done in a fully self-supervised way, which we use to estimate the reversibility of actions from experience, without any priors.We propose two different strategies that incorporate reversibility in RL agents, one strategy for exploration (RAE) and one strategy for control (RAC). We demonstrate the potential of reversibility-aware agents in several environments, including the challenging Sokoban game. In synthetic tasks, we show that we can learn control policies that never fail and reduce to zero the side-effects of interactions, even without access to the reward function."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Execute", "Title": "Efficient Learning of Universal Plan-Conditioned Policies in Robotics", "Abstract": "Applications of Reinforcement Learning (RL) in robotics are often limited by high data demand. On the other hand, approximate models are readily available in many robotics scenarios, making model-based approaches like planning a data-efficient alternative. Still, the performance of these methods suffers if the model is imprecise or wrong. In this sense, the respective strengths and weaknesses of RL and model-based planners are complementary. In the present work, we investigate how both approaches can be integrated into one framework that combines their strengths. We introduce Learning to Execute (L2E), which leverages information contained in approximate plans to learn universal policies that are conditioned on plans. In our robotic manipulation experiments, L2E exhibits increased performance when compared to pure RL, pure planning, or baseline methods combining learning and planning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Self-Diagnosing GAN", "Title": "Diagnosing Underrepresented Samples in Generative Adversarial Networks", "Abstract": "Despite remarkable performance in producing realistic samples, Generative Adversarial Networks (GANs) often produce low-quality samples near low-density regions of the data manifold, e.g., samples of minor groups. Many techniques have been developed to improve the quality of generated samples, either by post-processing generated samples or by pre-processing the empirical data distribution, but at the cost of reduced diversity. To promote diversity in sample generation without degrading the overall quality, we propose a simple yet effective method to diagnose and emphasize underrepresented samples during training of a GAN. The main idea is to use the statistics of the discrepancy between the data distribution and the model distribution at each data instance. Based on the observation that the underrepresented samples have a high average discrepancy or high variability in discrepancy, we propose a method to emphasize those samples during training of a GAN. Our experimental results demonstrate that the proposed method improves GAN performance on various datasets, and it is especially effective in improving the quality and diversity of sample generation for minor groups."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TransMatcher", "Title": "Deep Image Matching Through Transformers for Generalizable Person Re-identification", "Abstract": "Transformers have recently gained increasing attention in computer vision. However, existing studies mostly use Transformers for feature representation learning, e.g. for image classification and dense predictions, and the generalizability of Transformers is unknown. In this work, we further investigate the possibility of applying Transformers for image matching and metric learning given pairs of images. We find that the Vision Transformer (ViT) and the vanilla Transformer with decoders are not adequate for image matching due to their lack of image-to-image attention. Thus, we further design two naive solutions, i.e. query-gallery concatenation in ViT, and query-gallery cross-attention in the vanilla Transformer. The latter improves the performance, but it is still limited. This implies that the attention mechanism in Transformers is primarily designed for global feature aggregation, which is not naturally suitable for image matching. Accordingly, we propose a new simplified decoder, which drops the full attention implementation with the softmax weighting, keeping only the query-key similarity computation. Additionally, global max pooling and a multilayer perceptron (MLP) head are applied to decode the matching result. This way, the simplified decoder is computationally more efficient, while at the same time more effective for image matching. The proposed method, called TransMatcher, achieves state-of-the-art performance in generalizable person re-identification, with up to 6.1% and 5.7% performance gains in Rank-1 and mAP, respectively, on several popular datasets. Code is available at https://github.com/ShengcaiLiao/QAConv."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-Objective SPIBB", "Title": "Seldonian Offline Policy Improvement with Safety Constraints in Finite MDPs", "Abstract": "We study the problem of Safe Policy Improvement (SPI) under constraints in the offline Reinforcement Learning (RL) setting. We consider the scenario where: (i) we have a dataset collected under a known baseline policy, (ii) multiple reward signals are received from the environment inducing as many objectives to optimize. We present an SPI formulation for this RL setting that takes into account the preferences of the algorithm’s user for handling the trade-offs for different reward signals while ensuring that the new policy performs at least as well as the baseline policy along each individual objective. We build on traditional SPI algorithms and propose a novel method based on Safe Policy Iteration with Baseline Bootstrapping (SPIBB, Laroche et al., 2019) that provides high probability guarantees on the performance of the agent in the true environment. We show the effectiveness of our method on a synthetic grid-world safety task as well as in a real-world critical care context to learn a policy for the administration of IV fluids and vasopressors to treat sepsis."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "INDIGO", "Title": "GNN-Based Inductive Knowledge Graph Completion Using Pair-Wise Encoding", "Abstract": "The aim of knowledge graph (KG) completion is to extend an incomplete KG with missing triples. Popular approaches based on graph embeddings typically work by first representing the KG in a vector space, and then applying a predefined scoring function to the resulting vectors to complete the KG. These approaches work well in transductive settings, where predicted triples involve only constants seen during training; however, they are not applicable in inductive settings, where the KG on which the model was trained is extended with new constants or merged with other KGs. The use of Graph Neural Networks (GNNs) has recently been proposed as a way to overcome these limitations; however, existing approaches do not fully exploit the capabilities of GNNs and still rely on heuristics and ad-hoc scoring functions. In this paper, we propose a novel approach, where the KG is fully encoded into a GNN in a transparent way, and where the predicted triples can be read out directly from the last layer of the GNN without the need for additional components or scoring functions. Our experiments show that our model outperforms state-of-the-art approaches on inductive KG completion benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Attacks on Black Box Video Classifiers", "Title": "Leveraging the Power of Geometric Transformations", "Abstract": "When compared to the image classification models, black-box adversarial attacks against video classification models have been largely understudied. This could be possible because, with video, the temporal dimension poses significant additional challenges in gradient estimation. Query-efficient black-box attacks rely on effectively estimated gradients towards maximizing the probability of misclassifying the target video. In this work, we demonstrate that such effective gradients can be searched for by parameterizing the temporal structure of the search space with geometric transformations. Specifically, we design a novel iterative algorithm GEOmetric TRAnsformed Perturbations (GEO-TRAP), for attacking video classification models. GEO-TRAP employs standard geometric transformation operations to reduce the search space for effective gradients into searching for a small group of parameters that define these operations. This group of parameters describes the geometric progression of gradients, resulting in a reduced and structured search space. Our algorithm inherently leads to successful perturbations with surprisingly few queries. For example, adversarial examples generated from GEO-TRAP have better attack success rates with ~73.55% fewer queries compared to the state-of-the-art method for video adversarial attacks on the widely used Jester dataset. Overall, our algorithm exposes vulnerabilities of diverse video classification models and achieves new state-of-the-art results under black-box settings on two large datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Skyformer", "Title": "Remodel Self-Attention with Gaussian Kernel and Nystr\\\"om Method", "Abstract": "Transformers are expensive to train due to the quadratic time and space complexity in the self-attention mechanism. On the other hand, although kernel machines suffer from the same computation bottleneck in pairwise dot products, several approximation schemes have been successfully incorporated to considerably reduce their computational cost without sacrificing too much accuracy. In this work, we leverage the computation methods for kernel machines to alleviate the high computational cost and introduce Skyformer, which replaces the softmax structure with a Gaussian kernel to stabilize the model training and adapts the Nyström method to a non-positive semidefinite matrix to accelerate the computation. We further conduct theoretical analysis by showing that the matrix approximation error of our proposed method is small in the spectral norm. Experiments on Long Range Arena benchmark show that the proposed method is sufficient in getting comparable or even better performance than the full self-attention while requiring fewer computation resources."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TransMIL", "Title": "Transformer based Correlated Multiple Instance Learning for Whole Slide Image Classification", "Abstract": "Multiple instance learning (MIL) is a powerful tool to solve the weakly supervised classification in whole slide image (WSI) based pathology diagnosis. However, the current MIL methods are usually based on independent and identical distribution hypothesis, thus neglect the correlation among different instances. To address this problem, we proposed a new framework, called correlated MIL, and provided a proof for convergence. Based on this framework, we devised a Transformer based MIL (TransMIL), which explored both morphological and spatial information. The proposed TransMIL can effectively deal with unbalanced/balanced and binary/multiple classification with great visualization and interpretability. We conducted various experiments for three different computational pathology problems and achieved better performance and faster convergence compared with state-of-the-art methods. The test AUC for the binary tumor classification can be up to 93.09% over CAMELYON16 dataset. And the AUC over the cancer subtypes classification can be up to 96.03% and 98.82% over TCGA-NSCLC dataset and TCGA-RCC dataset, respectively. Implementation is available at: https://github.com/szc19990412/TransMIL."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Evolution Gym", "Title": "A Large-Scale Benchmark for Evolving Soft Robots", "Abstract": "Both the design and control of a robot play equally important roles in its task performance. However, while optimal control is well studied in the machine learning and robotics community, less attention is placed on finding the optimal robot design. This is mainly because co-optimizing design and control in robotics is characterized as a challenging problem, and more importantly, a comprehensive evaluation benchmark for co-optimization does not exist. In this paper, we propose Evolution Gym, the first large-scale benchmark for co-optimizing the design and control of soft robots. In our benchmark, each robot is composed of different types of voxels (e.g., soft, rigid, actuators), resulting in a modular and expressive robot design space. Our benchmark environments span a wide range of tasks, including locomotion on various types of terrains and manipulation. Furthermore, we develop several robot co-evolution algorithms by combining state-of-the-art design optimization methods and deep reinforcement learning techniques. Evaluating the algorithms on our benchmark platform, we observe robots exhibiting increasingly complex behaviors as evolution progresses, with the best evolved designs solving many of our proposed tasks. Additionally, even though robot designs are evolved autonomously from scratch without prior knowledge, they often grow to resemble existing natural creatures while outperforming hand-designed robots. Nevertheless, all tested algorithms fail to find robots that succeed in our hardest environments. This suggests that more advanced algorithms are required to explore the high-dimensional design space and evolve increasingly intelligent robots -- an area of research in which we hope Evolution Gym will accelerate progress. Our website with code, environments, documentation, and tutorials is available at http://evogym.csail.mit.edu/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Circa", "Title": "Stochastic ReLUs for Private Deep Learning", "Abstract": "The simultaneous rise of machine learning as a service and concerns over user privacy have increasingly motivated the need for private inference (PI). While recent work demonstrates PI is possible using cryptographic primitives, the computational overheads render it impractical. State-of-art deep networks are inadequate in this context because the source of slowdown in PI stems from the ReLU operations whereas optimizations for plaintext inference focus on reducing FLOPs. In this paper we re-think ReLU computations and propose optimizations for PI tailored to properties of neural networks. Specifically, we reformulate ReLU as an approximate sign test and introduce a novel truncation method for the sign test that significantly reduces the cost per ReLU. These optimizations result in a specific type of stochastic ReLU. The key observation is that the stochastic fault behavior is well suited for the fault-tolerant properties of neural network inference. Thus, we provide significant savings without impacting accuracy. We collectively call the optimizations Circa and demonstrate improvements of up to 4.7$\\times$ storage and 3$\\times$ runtime over baseline implementations; we further show that Circa can be used on top of recent PI optimizations to obtain 1.8$\\times$ additional speedup."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Luna", "Title": "Linear Unified Nested Attention", "Abstract": "The quadratic computational and memory complexities of the Transformer's attention mechanism have limited its scalability for modeling long sequences.  In this paper, we propose Luna, a linear unified nested attention mechanism that approximates softmax attention with two nested linear attention functions, yielding only linear (as opposed to quadratic) time and space complexity. Specifically, with the first attention function, Luna packs the input sequence into a sequence of fixed length. Then, the packed sequence is unpacked using the second attention function. As compared to a more traditional attention mechanism, Luna introduces an additional sequence with a fixed length as input and an additional corresponding output, which allows Luna to perform attention operation linearly, while also storing adequate contextual information. We perform extensive evaluations on three benchmarks of sequence modeling tasks: long-context sequence modelling, neural machine translation and masked language modeling for large-scale pretraining. Competitive or even better experimental results demonstrate both the effectiveness and efficiency of Luna compared to a variety of strong baseline methods including the full-rank attention and other efficient sparse and dense attention methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hindsight Task Relabelling", "Title": "Experience Replay for Sparse Reward Meta-RL", "Abstract": "Meta-reinforcement learning (meta-RL) has proven to be a successful framework for leveraging experience from prior tasks to rapidly learn new related tasks, however, current meta-RL approaches struggle to learn in sparse reward environments. Although existing meta-RL algorithms can learn strategies for adapting to new sparse reward tasks, the actual adaptation strategies are learned using hand-shaped reward functions, or require simple environments where random exploration is sufficient to encounter sparse reward. In this paper we present a formulation of hindsight relabelling for meta-RL, which relabels experience during meta-training to enable learning to learn entirely using sparse reward. We demonstrate the effectiveness of our approach on a suite of challenging sparse reward environments that previously required dense reward during meta-training to solve. Our approach solves these environments using the true sparse reward function, with performance comparable to training with a proxy dense reward function."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Zero Time Waste", "Title": "Recycling Predictions in Early Exit Neural Networks", "Abstract": "The problem of reducing processing time of large deep learning models is a fundamental challenge in many real-world applications. Early exit methods strive towards this goal by attaching additional Internal Classifiers (ICs) to intermediate layers of a neural network. ICs can quickly return predictions for easy examples and, as a result, reduce the average inference time of the whole model. However, if a particular IC does not decide to return an answer early, its predictions are discarded, with its computations effectively being wasted. To solve this issue, we introduce Zero Time Waste (ZTW), a novel approach in which each IC reuses predictions returned by its predecessors by (1) adding direct connections between ICs and (2) combining previous outputs in an ensemble-like manner. We conduct extensive experiments across various datasets and architectures to demonstrate that ZTW achieves a significantly better accuracy vs. inference time trade-off than other recently proposed early exit methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ReSSL", "Title": "Relational Self-Supervised Learning with Weak Augmentation", "Abstract": "Self-supervised Learning (SSL) including the mainstream contrastive learning has achieved great success in learning visual representations without data annotations. However, most of methods mainly focus on the instance level information (\\ie, the different augmented images of the same instance should have the same feature or cluster into the same class), but there is a lack of attention on the relationships between different instances. In this paper, we introduced a novel SSL paradigm, which we term as relational self-supervised learning  (ReSSL) framework that learns representations by modeling the relationship between different instances. Specifically, our proposed method employs sharpened distribution of pairwise similarities among different instances as \\textit{relation} metric, which is thus utilized to match the feature embeddings of different augmentations. Moreover, to boost the performance, we argue that weak augmentations matter to represent a more reliable relation, and leverage momentum strategy for practical efficiency. Experimental results show that our proposed ReSSL significantly outperforms the previous state-of-the-art algorithms in terms of both performance and training efficiency."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bias Out-of-the-Box", "Title": "An Empirical Analysis of Intersectional Occupational Biases in Popular Generative Language Models", "Abstract": "The capabilities of natural language models trained on large-scale data have increased immensely over the past few years. Open source libraries such as HuggingFace have made these models easily available and accessible. While prior research has identified biases in large language models, this paper considers biases contained in the most popular versions of these models when applied `out-of-the-box' for downstream tasks. We focus on generative language models as they are well-suited for extracting biases inherited from training data. Specifically, we conduct an in-depth analysis of GPT-2, which is the most downloaded text generation model on HuggingFace, with over half a million downloads per month. We assess biases related to occupational associations for different protected categories by intersecting gender with religion, sexuality, ethnicity, political affiliation, and continental name origin. Using a template-based data collection pipeline, we collect 396K sentence completions made by GPT-2 and find: (i) The machine-predicted jobs are less diverse and more stereotypical for women than for men, especially for intersections; (ii) Intersectional interactions are highly relevant for occupational associations, which we quantify by fitting 262 logistic models; (iii) For most occupations, GPT-2 reflects the skewed gender and ethnicity distribution found in US Labor Bureau data, and even pulls the societally-skewed distribution towards gender parity in cases where its predictions deviate from real labor market observations. This raises the normative question of what language models \\textit{should} learn - whether they should reflect or correct for existing inequalities."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Weisfeiler and Lehman Go Cellular", "Title": "CW Networks", "Abstract": "Graph Neural Networks (GNNs) are limited in their expressive power, struggle with long-range interactions and lack a principled way to model higher-order structures. These problems can be attributed to the strong coupling between the computational graph and the input graph structure. The recently proposed Message Passing Simplicial Networks naturally decouple these elements by performing message passing on the clique complex of the graph. Nevertheless, these models can be severely constrained by the rigid combinatorial structure of Simplicial Complexes (SCs). In this work, we extend recent theoretical results on SCs to regular Cell Complexes, topological objects that flexibly subsume SCs and graphs. We show that this generalisation provides a powerful set of graph \"lifting\" transformations, each leading to a unique hierarchical message passing procedure. The resulting methods, which we collectively call CW Networks (CWNs), are strictly more powerful than the WL test and not less powerful than the 3-WL test. In particular, we demonstrate the effectiveness of one such scheme, based on rings, when applied to molecular graph problems. The proposed architecture benefits from provably larger expressivity than commonly used GNNs, principled modelling of higher-order signals and from compressing the distances between nodes. We demonstrate that our model achieves state-of-the-art results on a variety of molecular datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pay Better Attention to Attention", "Title": "Head Selection in Multilingual and Multi-Domain Sequence Modeling", "Abstract": "Multi-head attention has each of the attention heads collect salient information from different parts of an input sequence, making it a powerful mechanism for sequence modeling. Multilingual and multi-domain learning are common scenarios for sequence modeling, where the key challenge is to maximize positive transfer and mitigate negative interference across languages and domains. In this paper, we find that non-selective attention sharing is sub-optimal for achieving good generalization across all languages and domains. We further propose attention sharing strategies to facilitate parameter sharing and specialization in multilingual and multi-domain sequence modeling. Our approach automatically learns shared and specialized attention heads for different languages and domains. Evaluated in various tasks including speech recognition, text-to-text and speech-to-text translation, the proposed attention sharing strategies consistently bring gains to sequence models built upon multi-head attention. For speech-to-text translation, our approach yields an average of $+2.0$ BLEU over $13$ language directions in multilingual setting and $+2.0$ BLEU over $3$ domains in multi-domain setting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Non-convex Distributionally Robust Optimization", "Title": "Non-asymptotic Analysis", "Abstract": "Distributionally robust optimization (DRO) is a widely-used approach to learn models that are robust against distribution shift. Compared with the standard optimization setting, the objective function in DRO is more difficult to optimize, and most of the existing theoretical results make strong assumptions on the loss function. In this work we bridge the gap by studying DRO algorithms for general smooth non-convex losses. By carefully exploiting the specific form of the DRO objective, we are able to provide non-asymptotic convergence guarantees even though the objective function is possibly non-convex, non-smooth and has unbounded gradient noise. In particular, we prove that a special algorithm called the mini-batch normalized gradient descent with momentum, can find an $\\epsilon$-first-order stationary point within $\\mathcal O(\\epsilon^{-4})$ gradient complexity. We also discuss the conditional value-at-risk (CVaR) setting, where we propose a penalized DRO objective based on a smoothed version of the CVaR that allows us to obtain a similar convergence guarantee. We finally verify our theoretical results in a number of tasks and find that the proposed algorithm can consistently achieve prominent acceleration."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MetaAvatar", "Title": "Learning Animatable Clothed Human Models from Few Depth Images", "Abstract": "In this paper, we aim to create generalizable and controllable neural signed distance fields (SDFs) that represent clothed humans from monocular depth observations. Recent advances in deep learning, especially neural implicit representations, have enabled human shape reconstruction and controllable avatar generation from different sensor inputs. However, to generate realistic cloth deformations from novel input poses, watertight meshes or dense full-body scans are usually needed as inputs. Furthermore, due to the difficulty of effectively modeling pose-dependent cloth deformations for diverse body shapes and cloth types, existing approaches resort to per-subject/cloth-type optimization from scratch, which is computationally expensive. In contrast, we propose an approach that can quickly generate realistic clothed human avatars, represented as controllable neural SDFs, given only monocular depth images. We achieve this by using meta-learning to learn an initialization of a hypernetwork that predicts the parameters of neural SDFs. The hypernetwork is conditioned on human poses and represents a clothed neural avatar that deforms non-rigidly according to the input poses. Meanwhile, it is meta-learned to effectively incorporate priors of diverse body shapes and cloth types and thus can be much faster to fine-tune, compared to models trained from scratch. We qualitatively and quantitatively show that our approach outperforms state-of-the-art approaches that require complete meshes as inputs while our approach requires only depth frames as inputs and runs orders of magnitudes faster. Furthermore, we demonstrate that our meta-learned hypernetwork is very robust, being the first to generate avatars with realistic dynamic cloth deformations given as few as 8 monocular depth frames."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Newton-LESS", "Title": "Sparsification without Trade-offs for the Sketched Newton Update", "Abstract": "In second-order optimization, a potential bottleneck can be computing the Hessian matrix of the optimized function at every iteration. Randomized sketching has emerged as a powerful technique for constructing estimates of the Hessian which can be used to perform approximate Newton steps. This involves multiplication by a random sketching matrix, which introduces a trade-off between the computational cost of sketching and the convergence rate of the optimization. A theoretically desirable but practically much too expensive choice is to use a dense Gaussian sketching matrix, which produces unbiased estimates of the exact Newton step and offers strong problem-independent convergence guarantees. We show that the Gaussian matrix can be drastically sparsified, substantially reducing the computational cost, without affecting its convergence properties in any way. This approach, called Newton-LESS, is based on a recently introduced sketching technique: LEverage Score Sparsified (LESS) embeddings. We prove that Newton-LESS enjoys nearly the same problem-independent local convergence rate as Gaussian embeddings for a large class of functions. In particular, this leads to a new state-of-the-art convergence result for an iterative least squares solver. Finally, we substantially extend LESS embeddings to include uniformly sparsified random sign matrices which can be implemented efficiently and perform well in numerical experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Word2Fun", "Title": "Modelling Words as Functions for Diachronic Word Representation", "Abstract": "Word meaning may change over time as a reflection of changes in human society. Therefore, modeling time in word representation is necessary for some diachronic tasks. Most existing diachronic word representation approaches train the embeddings separately for each pre-grouped time-stamped corpus and align these embeddings, e.g., by orthogonal projections, vector initialization, temporal referencing, and compass. However, not only does word meaning change in a short time, word meaning may also be subject to evolution over long timespans, thus resulting in a unified continuous process. A recent approach called `DiffTime'  models semantic evolution as functions parameterized by multiple-layer nonlinear neural networks over time. In this paper, we will carry on this line of work by learning explicit functions over time  for each word. Our approach, called `Word2Fun', reduces the space complexity from $\\mathcal{O}(TVD)$ to $\\mathcal{O}(kVD)$ where $k$  is a small constant ($k \\ll T $). In particular, a specific instance based on polynomial functions could provably approximate any function modeling word evolution with a given negligible error thanks to the Weierstrass Approximation Theorem. The effectiveness of the proposed approach is evaluated in diverse tasks including time-aware word clustering, temporal analogy, and semantic change detection. Code at: {\\url{https://github.com/wabyking/Word2Fun.git}}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Derivative-Free Policy Optimization for Linear Risk-Sensitive and Robust Control Design", "Title": "Implicit Regularization and Sample Complexity", "Abstract": "Direct policy search serves as one of the workhorses in modern reinforcement learning (RL), and its applications in continuous control tasks have recently attracted increasing attention. In this work, we investigate the convergence theory of policy gradient (PG) methods for learning the linear risk-sensitive and robust controller. In particular, we develop PG methods that can be implemented in a derivative-free fashion by sampling system trajectories, and establish both global convergence and sample complexity results in the solutions of two fundamental settings in risk-sensitive and robust control: the finite-horizon linear exponential quadratic Gaussian, and the finite-horizon linear-quadratic disturbance attenuation problems. As a by-product, our results also provide the first sample complexity for the global convergence of PG methods on solving zero-sum linear-quadratic dynamic games, a nonconvex-nonconcave minimax optimization problem that serves as a baseline setting in multi-agent reinforcement learning (MARL) with continuous spaces. One feature of our algorithms is that during the learning phase, a certain level of robustness/risk-sensitivity of the controller is preserved, which we termed as the implicit regularization property, and is an essential requirement in safety-critical control systems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "G-PATE", "Title": "Scalable Differentially Private Data Generator via Private Aggregation of Teacher Discriminators", "Abstract": "Recent advances in machine learning have largely benefited from the massive accessible training data. However, large-scale data sharing has raised great privacy concerns. In this work, we propose a novel privacy-preserving data Generative model based on the PATE framework (G-PATE), aiming to train a scalable differentially private data generator that preserves high generated data utility. Our approach leverages generative adversarial nets to generate data, combined with private aggregation among different discriminators to ensure strong privacy guarantees. Compared to existing approaches, G-PATE significantly improves the use of privacy budgets. In particular, we train a student data generator with an ensemble of teacher discriminators and propose a novel private gradient aggregation mechanism to ensure differential privacy on all information that flows from teacher discriminators to the student generator. In addition, with random projection and gradient discretization, the proposed gradient aggregation mechanism is able to effectively deal with high-dimensional gradient vectors. Theoretically, we prove that G-PATE ensures differential privacy for the data generator.  Empirically, we demonstrate the superiority of G-PATE over prior work through extensive experiments. We show that G-PATE is the first work being able to generate high-dimensional image data with high data utility under limited privacy budgets ($\\varepsilon \\le 1$). Our code is available at https://github.com/AI-secure/G-PATE."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Framing RNN as a kernel method", "Title": "A neural ODE approach", "Abstract": "Building on the interpretation of a recurrent neural network (RNN) as a continuous-time neural differential equation, we show, under appropriate conditions, that the solution of a RNN can be viewed as a linear function of a specific feature set of the input sequence, known as the signature. This connection allows us to frame a RNN as a kernel method in a suitable reproducing kernel Hilbert space. As a consequence, we obtain theoretical guarantees on generalization and stability for a large class of recurrent networks. Our results are illustrated on simulated datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoBalance", "Title": "Optimized Loss Functions for Imbalanced Data", "Abstract": "Imbalanced datasets are commonplace in modern machine learning problems. The presence of under-represented classes or groups with sensitive attributes results in concerns about generalization and fairness. Such concerns are further exacerbated by the fact that large capacity deep nets can perfectly fit the training data and appear to achieve perfect accuracy and fairness during training, but perform poorly during test. To address these challenges, we propose AutoBalance, a bi-level optimization framework that automatically designs a training loss function to optimize a blend of accuracy and fairness-seeking objectives. Specifically, a lower-level problem trains the model weights, and an upper-level problem tunes the loss function by monitoring and optimizing the desired objective over the validation data. Our loss design enables personalized treatment for classes/groups by employing a parametric cross-entropy loss and individualized data augmentation schemes. We evaluate the benefits and performance of our approach for the application scenarios of imbalanced and group-sensitive classification. Extensive empirical evaluations demonstrate the benefits of AutoBalance over state-of-the-art approaches. Our experimental findings are complemented with theoretical insights on loss function design and the benefits of the train-validation split. All code is available open-source."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SyncTwin", "Title": "Treatment Effect Estimation with Longitudinal Outcomes", "Abstract": "Most of the medical observational studies estimate the causal treatment effects using electronic health records (EHR), where a patient's covariates and outcomes are both observed longitudinally. However, previous methods focus only on adjusting for the covariates while neglecting the temporal structure in the outcomes. To bridge the gap, this paper develops a new method, SyncTwin, that learns a patient-specific time-constant representation from the pre-treatment observations. SyncTwin issues counterfactual prediction of a target patient by constructing a synthetic twin that closely matches the target in representation. The reliability of the estimated treatment effect can be assessed by comparing the observed and synthetic pre-treatment outcomes. The medical experts can interpret the estimate by examining the most important contributing individuals to the synthetic twin. In the real-data experiment, SyncTwin successfully reproduced the findings of a randomized controlled clinical trial using observational data, which demonstrates its usability in the complex real-world EHR."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VigDet", "Title": "Knowledge Informed Neural Temporal Point Process for Coordination Detection on Social Media", "Abstract": "Recent years have witnessed an increasing use of coordinated accounts on social media, operated by misinformation campaigns to influence public opinion and manipulate social outcomes. Consequently, there is an urgent need to develop an effective methodology for coordinated group detection to combat the misinformation on social media. However, existing works suffer from various drawbacks, such as, either limited performance due to extreme reliance on predefined signatures of coordination, or instead an inability to address the natural sparsity of account activities on social media with useful prior domain knowledge. Therefore, in this paper, we propose a coordination detection framework incorporating neural temporal point process with prior knowledge such as temporal logic or pre-defined filtering functions. Specifically, when modeling the observed data from social media with neural temporal point process, we jointly learn a Gibbs-like distribution of group assignment based on how consistent an assignment is to (1) the account embedding space and (2) the prior knowledge. To address the challenge that the distribution is hard to be efficiently computed and sampled from, we design a theoretically guaranteed variational inference approach to learn a mean-field approximation for it. Experimental results on a real-world dataset show the effectiveness of our proposed method compared to the SOTA model in both unsupervised and semi-supervised settings. We further apply our model on a COVID-19 Vaccine Tweets dataset. The detection result suggests the presence of suspicious coordinated efforts on spreading misinformation about COVID-19 vaccines."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Limitations of Large Width in Neural Networks", "Title": "A Deep Gaussian Process Perspective", "Abstract": "Large width limits have been a recent focus of deep learning research: modulo computational practicalities, do wider networks outperform narrower ones? Answering this question has been challenging, as conventional networks gain representational power with width, potentially masking any negative effects. Our analysis in this paper decouples capacity and width via the generalization of neural networks to Deep Gaussian Processes (Deep GP), a class of nonparametric hierarchical models that subsume neural nets. In doing so, we aim to understand how width affects (standard) neural networks once they have sufficient capacity for a given modeling task. Our theoretical and empirical results on Deep GP suggest that large width can be detrimental to hierarchical models. Surprisingly, we prove that even nonparametric Deep GP converge to Gaussian processes, effectively becoming shallower without any increase in representational power. The posterior, which corresponds to a mixture of data-adaptable basis functions, becomes less data-dependent with width. Our tail analysis demonstrates that width and depth have opposite effects: depth accentuates a model’s non-Gaussianity, while width makes models increasingly Gaussian. We find there is a “sweet spot” that maximizes test performance before the limiting GP behavior prevents adaptability, occurring at width = 1 or width = 2 for nonparametric Deep GP. These results make strong predictions about the same phenomenon in conventional neural networks trained with L2 regularization (analogous to a Gaussian prior on parameters): we show that such neural networks may need up to 500 − 1000 hidden units for sufficient capacity - depending on the dataset - but further width degrades performance."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ResNEsts and DenseNEsts", "Title": "Block-based DNN Models with Improved Representation Guarantees", "Abstract": "Models recently used in the literature proving residual networks (ResNets) are better than linear predictors are actually different from standard ResNets that have been widely used in computer vision. In addition to the assumptions such as scalar-valued output or single residual block, the models fundamentally considered in the literature have no nonlinearities at the final residual representation that feeds into the final affine layer. To codify such a difference in nonlinearities and reveal a linear estimation property, we define ResNEsts, i.e., Residual Nonlinear Estimators, by simply dropping nonlinearities at the last residual representation from standard ResNets. We show that wide ResNEsts with bottleneck blocks can always guarantee a very desirable training property that standard ResNets aim to achieve, i.e., adding more blocks does not decrease performance given the same set of basis elements. To prove that, we first recognize ResNEsts are basis function models that are limited by a coupling problem in basis learning and linear prediction. Then, to decouple prediction weights from basis learning, we construct a special architecture termed augmented ResNEst (A-ResNEst) that always guarantees no worse performance with the addition of a block. As a result, such an A-ResNEst establishes empirical risk lower bounds for a ResNEst using corresponding bases. Our results demonstrate ResNEsts indeed have a problem of diminishing feature reuse; however, it can be avoided by sufficiently expanding or widening the input space, leading to the above-mentioned desirable property. Inspired by the densely connected networks (DenseNets) that have been shown to outperform ResNets, we also propose a corresponding new model called Densely connected Nonlinear Estimator (DenseNEst). We show that any DenseNEst can be represented as a wide ResNEst with bottleneck blocks. Unlike ResNEsts, DenseNEsts exhibit the desirable property without any special architectural re-design."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BayesIMP", "Title": "Uncertainty Quantification for Causal Data Fusion", "Abstract": "While causal models are becoming one of the mainstays of machine learning, the problem of uncertainty quantification in causal inference remains challenging. In this paper, we study the causal data fusion problem, where data arising from multiple causal graphs are combined to estimate the average treatment effect of a target variable. As data arises from multiple sources and can vary in quality and sample size, principled uncertainty quantification becomes essential. To that end, we introduce \\emph{Bayesian Causal Mean Processes}, the framework which combines ideas from probabilistic integration and kernel mean embeddings to represent interventional distributions in the reproducing kernel Hilbert space, while taking into account the uncertainty within each causal graph. To demonstrate the informativeness of our uncertainty estimation, we apply our method to the Causal Bayesian Optimisation task and show improvements over state-of-the-art methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RMM", "Title": "Reinforced Memory Management for Class-Incremental Learning", "Abstract": "Class-Incremental Learning (CIL) [38] trains classifiers under a strict memory budget: in each incremental phase, learning is done for new data, most of which is abandoned to free space for the next phase. The preserved data are exemplars used for replaying. However, existing methods use a static and ad hoc strategy for memory allocation, which is often sub-optimal. In this work, we propose a dynamic memory management strategy that is optimized for the incremental phases and different object classes. We call our method reinforced memory management (RMM), leveraging reinforcement learning. RMM training is not naturally compatible with CIL as the past, and future data are strictly non-accessible during the incremental phases. We solve this by training the policy function of RMM on pseudo CIL tasks, e.g., the tasks built on the data of the zeroth phase, and then applying it to target tasks. RMM propagates two levels of actions: Level-1 determines how to split the memory between old and new classes, and Level-2 allocates memory for each specific class. In essence, it is an optimizable and general method for memory management that can be used in any replaying-based CIL method. For evaluation, we plug RMM into two top-performing baselines (LUCIR+AANets and POD+AANets [28]) and conduct experiments on three benchmarks (CIFAR-100, ImageNet-Subset, and ImageNet-Full). Our results show clear improvements, e.g., boosting POD+AANets by 3.6%, 4.4%, and 1.9% in the 25-Phase settings of the above benchmarks, respectively.  The code is available at https://class-il.mpi-inf.mpg.de/rmm/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ImageBART", "Title": "Bidirectional Context with Multinomial Diffusion for Autoregressive Image Synthesis", "Abstract": "Autoregressive models and their sequential factorization of the data likelihood have recently demonstrated great potential for image representation and synthesis. Nevertheless, they incorporate image context in a linear 1D order by attending only to previously synthesized image patches above or to the left. Not only is this unidirectional, sequential bias of attention unnatural for images as it disregards large parts of a scene until synthesis is almost complete. It also processes the entire image on a single scale, thus ignoring more global contextual information up to the gist of the entire scene. As a remedy we incorporate a coarse-to-fine hierarchy of context by combining the autoregressive formulation with a multinomial diffusion process: Whereas a multistage diffusion process successively compresses and removes information to coarsen an image, we train a Markov chain to invert this process. In each stage, the resulting autoregressive ImageBART model progressively incorporates context from previous stages in a coarse-to-fine manner. Experiments demonstrate the gain over current autoregressive models, continuous diffusion probabilistic models, and latent variable models. Moreover, the approach enables to control the synthesis process and to trade compression rate against reconstruction accuracy, while still guaranteeing visually plausible results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "QuPeD", "Title": "Quantized Personalization via Distillation with Applications to Federated Learning", "Abstract": "Traditionally, federated learning (FL) aims to train a single global model while collaboratively using multiple clients and a server. Two natural challenges that FL algorithms face are heterogeneity in data across clients and collaboration of clients with diverse resources. In this work, we introduce a quantized and personalized FL algorithm QuPeD that facilitates collective (personalized model compression) training via knowledge distillation (KD)  among clients who have access to heterogeneous data and resources. For personalization, we allow clients to learn compressed personalized models with different quantization parameters and model dimensions/structures. Towards this, first we propose an algorithm for learning quantized models through a relaxed optimization problem, where quantization values are also optimized over. When each client participating in the (federated) learning process has different requirements of the compressed model (both in model dimension and precision), we formulate a compressed personalization framework by introducing knowledge distillation loss for local client objectives collaborating through a global model. We develop an alternating proximal gradient update for solving this compressed personalization problem, and analyze its convergence properties. Numerically, we validate that QuPeD outperforms competing personalized FL methods, FedAvg, and local training of clients in various heterogeneous settings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Model Adaptation", "Title": "Historical Contrastive Learning for Unsupervised Domain Adaptation without Source Data", "Abstract": "Unsupervised domain adaptation aims to align a labeled source domain and an unlabeled target domain, but it requires to access the source data which often raises concerns in data privacy, data portability and data transmission efficiency. We study unsupervised model adaptation (UMA), or called Unsupervised Domain Adaptation without Source Data, an alternative setting that aims to adapt source-trained models towards target distributions without accessing source data. To this end, we design an innovative historical contrastive learning (HCL) technique that exploits historical source hypothesis to make up for the absence of source data in UMA. HCL addresses the UMA challenge from two perspectives. First, it introduces historical contrastive instance discrimination (HCID) that learns from target samples by contrasting their embeddings which are generated by the currently adapted model and the historical models. With the historical models, HCID encourages UMA to learn instance-discriminative target representations while preserving the source hypothesis. Second, it introduces historical contrastive category discrimination (HCCD) that pseudo-labels target samples to learn category-discriminative target representations. Specifically, HCCD re-weights pseudo labels according to their prediction consistency across the current and historical models. Extensive experiments show that HCL outperforms and state-of-the-art methods consistently across a variety of visual tasks and setups."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Damped Anderson Mixing for Deep Reinforcement Learning", "Title": "Acceleration, Convergence, and Stabilization", "Abstract": "Anderson mixing has been heuristically applied to reinforcement learning (RL) algorithms for accelerating convergence and improving the sampling efficiency of deep RL. Despite its heuristic improvement of convergence, a rigorous mathematical justification for the benefits of Anderson mixing in RL has not yet been put forward. In this paper, we provide deeper insights into a class of acceleration schemes built on Anderson mixing that improve the convergence of deep RL algorithms. Our main results establish a connection between Anderson mixing and quasi-Newton methods and prove that Anderson mixing increases the convergence radius of policy iteration schemes by an extra contraction factor. The key focus of the analysis roots in the fixed-point iteration nature of RL. We further propose a stabilization strategy by introducing a stable regularization term in Anderson mixing and a differentiable, non-expansive MellowMax operator that can allow both faster convergence and more stable behavior. Extensive experiments demonstrate that our proposed method enhances the convergence, stability, and performance of RL algorithms."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Two Sides of Meta-Learning Evaluation", "Title": "In vs. Out of Distribution", "Abstract": "We categorize meta-learning evaluation into two settings: $\\textit{in-distribution}$ [ID], in which the train and test tasks are sampled $\\textit{iid}$ from the same underlying task distribution, and $\\textit{out-of-distribution}$ [OOD], in which they are not. While most meta-learning theory and some FSL applications follow the ID setting, we identify that most existing few-shot classification benchmarks instead reflect OOD evaluation, as they use disjoint sets of train (base) and test (novel) classes for task generation. This discrepancy is problematic because -- as we show on numerous benchmarks -- meta-learning methods that perform better on existing OOD datasets may perform significantly worse in the ID setting. In addition, in the OOD setting, even though current FSL benchmarks seem befitting, our study highlights concerns in 1) reliably performing model selection for a given meta-learning method, and 2) consistently comparing the performance of different methods. To address these concerns, we provide suggestions on how to construct FSL benchmarks to allow for ID evaluation as well as more reliable OOD evaluation. Our work aims to inform the meta-learning community about the importance and distinction of ID vs. OOD evaluation, as well as the subtleties of OOD evaluation with current benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Exploiting Local Convergence of Quasi-Newton Methods Globally", "Title": "Adaptive Sample Size Approach", "Abstract": "In this paper, we study the application of quasi-Newton methods for solving empirical risk minimization (ERM) problems defined over a large dataset. Traditional deterministic and stochastic quasi-Newton methods can be executed to solve such problems; however, it is known that their global convergence rate may not be better than first-order methods, and their local superlinear convergence only appears towards the end of the learning process. In this paper, we use an adaptive sample size scheme that exploits the superlinear convergence of quasi-Newton methods globally and throughout the entire learning process. The main idea of the proposed adaptive sample size algorithms is to start with a small subset of data points and solve their corresponding ERM problem within its statistical accuracy, and then enlarge the sample size geometrically and use the optimal solution of the problem corresponding to the smaller set as an initial point for solving the subsequent ERM problem with more samples. We show that if the initial sample size is sufficiently large and we use quasi-Newton methods to solve each subproblem, the subproblems can be solved superlinearly fast (after at most three iterations), as we guarantee that the iterates always stay within a neighborhood that quasi-Newton methods converge superlinearly. Numerical experiments on various datasets confirm our theoretical results and demonstrate the computational advantages of our method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PDE-GCN", "Title": "Novel Architectures for Graph Neural Networks Motivated by Partial Differential Equations", "Abstract": "Graph neural networks are increasingly becoming the go-to approach in various fields such as computer vision, computational biology and chemistry, where data are naturally explained by graphs. However, unlike traditional convolutional neural networks, deep graph networks do not necessarily yield better performance than shallow graph networks. This behavior usually stems from the over-smoothing phenomenon. In this work, we propose a family of architecturesto control this behavior by design. Our networks are motivated by numerical methods for solving Partial Differential Equations (PDEs) on manifolds, and as such, their behavior can be explained by similar analysis. Moreover, as we demonstrate using an extensive set of experiments, our PDE-motivated networks can generalize and be effective for various types of problems from different fields. Our architectures obtain better or on par with the current state-of-the-art results for problems that are typically approached using different architectures."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SSMF", "Title": "Shifting Seasonal Matrix Factorization", "Abstract": "Given taxi-ride counts information between departure and destination locations, how can we forecast their future demands? In general, given a data stream of events with seasonal patterns that innovate over time, how can we effectively and efficiently forecast future events? In this paper, we propose Shifting Seasonal Matrix Factorization approach, namely SSMF, that can adaptively learn multiple seasonal patterns (called regimes), as well as switching between them. Our proposed method has the following properties: (a) it accurately forecasts future events by detecting regime shifts in seasonal patterns as the data stream evolves; (b) it works in an online setting, i.e., processes each observation in constant time and memory; (c) it effectively realizes regime shifts without human intervention by using a lossless data compression scheme. We demonstrate that our algorithm outperforms state-of-the-art baseline methods by accurately forecasting upcoming events on three real-world data streams."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoAtNet", "Title": "Marrying Convolution and Attention for All Data Sizes", "Abstract": "Transformers have attracted increasing interests in computer vision, but they still fall behind state-of-the-art convolutional networks. In this work, we show that while Transformers tend to have larger model capacity, their generalization can be worse than convolutional networks due to the lack of the right inductive bias. To effectively combine the strengths from both architectures, we present CoAtNets(pronounced \"coat\" nets), a family of hybrid models built from two key insights: (1) depthwise Convolution and self-Attention can be naturally unified via simple relative attention; (2) vertically stacking convolution layers and attention layers in a principled way is surprisingly effective in improving generalization, capacity and efficiency. Experiments show that our CoAtNets achieve state-of-the-art performance under different resource constraints across various datasets: Without extra data, CoAtNet achieves 86.0% ImageNet top-1 accuracy; When pre-trained with 13M images from ImageNet-21K, our CoAtNet achieves 88.56% top-1 accuracy, matching ViT-huge pre-trained with 300M images from JFT-300M while using 23x less data; Notably, when we further scale up CoAtNet with JFT-3B, it achieves 90.88% top-1 accuracy on ImageNet, establishing a new state-of-the-art result."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sample Complexity of Tree Search Configuration", "Title": "Cutting Planes and Beyond", "Abstract": "Cutting-plane methods have enabled remarkable successes in integer programming over the last few decades. State-of-the-art solvers integrate a myriad of cutting-plane techniques to speed up the underlying tree-search algorithm used to find optimal solutions. In this paper we provide sample complexity bounds for cut-selection in branch-and-cut (B&C). Given a training set of integer programs sampled from an application-specific input distribution and a family of cut selection policies, these guarantees bound the number of samples sufficient to ensure that using any policy in the family, the size of the tree B&C builds on average over the training set is close to the expected size of the tree B&C builds. We first bound the sample complexity of learning cutting planes from the canonical family of Chvátal-Gomory cuts. Our bounds handle any number of waves of any number of cuts and are fine tuned to the magnitudes of the constraint coefficients. Next, we prove sample complexity bounds for more sophisticated cut selection policies that use a combination of scoring rules to choose from a family of cuts. Finally, beyond the realm of cutting planes for integer programming, we develop a general abstraction of tree search that captures key components such as node selection and variable selection. For this abstraction, we bound the sample complexity of learning a good policy for building the search tree."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "IQ-Learn", "Title": "Inverse soft-Q Learning for Imitation", "Abstract": "In many sequential decision-making problems (e.g., robotics control, game playing, sequential prediction), human or expert data is available containing useful information about the task. However, imitation learning (IL) from a small amount of expert data can be challenging in high-dimensional environments with complex dynamics. Behavioral cloning is a simple method that is widely used due to its simplicity of implementation and stable convergence but doesn't utilize any information involving the environment’s dynamics. Many existing methods that exploit dynamics information are difficult to train in practice due to an adversarial optimization process over reward and policy approximators or biased, high variance gradient estimators. We introduce a method for dynamics-aware IL which avoids adversarial training by learning a single Q-function, implicitly representing both reward and policy. On standard benchmarks, the implicitly learned rewards show a high positive correlation with the ground-truth rewards, illustrating our method can also be used for inverse reinforcement learning (IRL). Our method, Inverse soft-Q learning (IQ-Learn) obtains state-of-the-art results in offline and online imitation learning settings, significantly outperforming existing methods both in the number of required environment interactions and scalability in high-dimensional spaces, often by more than 3x."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "An Analysis of Constant Step Size SGD in the Non-convex Regime", "Title": "Asymptotic Normality and Bias", "Abstract": "Structured non-convex learning problems, for which critical points have favorable statistical properties, arise frequently in statistical machine learning. Algorithmic convergence and statistical estimation rates are well-understood for such problems. However, quantifying the uncertainty associated with the underlying training algorithm is not well-studied in the non-convex setting. In order to address this shortcoming, in this work, we establish an asymptotic normality result for the constant step size stochastic gradient descent (SGD)  algorithm---a widely used algorithm in practice. Specifically, based on the relationship between SGD and Markov Chains  [DDB19], we show that the average of SGD iterates is asymptotically normally distributed around the expected value of their unique invariant distribution, as long as the non-convex and non-smooth objective function satisfies a dissipativity property. We also characterize the bias between this expected value and the critical points of the objective function under various local regularity conditions. Together, the above two results could be leveraged to construct confidence intervals for non-convex problems that are trained using the SGD algorithm."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Invertible Tabular GANs", "Title": "Killing Two Birds with One Stone for Tabular Data Synthesis", "Abstract": "Tabular data synthesis has received wide attention in the literature. This is because available data is often limited, incomplete, or cannot be obtained easily, and data privacy is becoming increasingly important. In this work, we present a generalized GAN framework for tabular synthesis, which combines the adversarial training of GANs and the negative log-density regularization of invertible neural networks. The proposed framework can be used for two distinctive objectives. First,  we can further improve the synthesis quality, by decreasing the negative log-density of real records in the process of adversarial training. On the other hand, by increasing the negative log-density of real records, realistic fake records can be synthesized in a way that they are not too much close to real records and reduce the chance of potential information leakage. We conduct experiments with real-world datasets for classification, regression, and privacy attacks. In general, the proposed method demonstrates the best synthesis quality (in terms of task-oriented evaluation metrics, e.g., F1) when decreasing the negative log-density during the adversarial training. If increasing the negative log-density, our experimental results show that the distance between real and fake records increases, enhancing robustness against privacy attacks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Recursive Bayesian Networks", "Title": "Generalising and Unifying Probabilistic Context-Free Grammars and Dynamic Bayesian Networks", "Abstract": "Probabilistic context-free grammars (PCFGs) and dynamic Bayesian networks (DBNs) are widely used sequence models with complementary strengths and limitations. While PCFGs allow for nested hierarchical dependencies (tree structures), their latent variables (non-terminal symbols) have to be discrete. In contrast, DBNs allow for continuous latent variables, but the dependencies are strictly sequential (chain structure). Therefore, neither can be applied if the latent variables are assumed to be continuous and also to have a nested hierarchical dependency structure. In this paper, we present Recursive Bayesian Networks (RBNs), which generalise and unify PCFGs and DBNs, combining their strengths and containing both as special cases. RBNs define a joint distribution over tree-structured Bayesian networks with discrete or continuous latent variables. The main challenge lies in performing joint inference over the exponential number of possible structures and the continuous variables. We provide two solutions: 1) For arbitrary RBNs, we generalise inside and outside probabilities from PCFGs to the mixed discrete-continuous case, which allows for maximum posterior estimates of the continuous latent variables via gradient descent, while marginalising over network structures. 2) For Gaussian RBNs, we additionally derive an analytic approximation of the marginal data likelihood (evidence) and marginal posterior distribution, allowing for robust parameter optimisation and Bayesian inference. The capacity and diverse applications of RBNs are illustrated on two examples: In a quantitative evaluation on synthetic data, we demonstrate and discuss the advantage of RBNs for segmentation and tree induction from noisy sequences, compared to change point detection and hierarchical clustering. In an application to musical data, we approach the unsolved problem of hierarchical music analysis from the raw note level and compare our results to expert annotations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EF21", "Title": "A New, Simpler, Theoretically Better, and Practically Faster Error Feedback", "Abstract": "Error feedback (EF), also known as error compensation, is an immensely popular convergence stabilization mechanism in the context of distributed training of supervised machine learning models enhanced by the use of contractive communication compression mechanisms, such as Top-$k$. First proposed by Seide et al [2014] as a heuristic, EF resisted any theoretical understanding until recently [Stich et al., 2018, Alistarh et al., 2018]. While these early breakthroughs were followed by a steady stream of works offering various improvements and generalizations, the current theoretical understanding of EF is still very limited. Indeed, to the best of our knowledge, all existing analyses either i) apply to the single node setting only, ii) rely on very strong and often unreasonable assumptions, such as global boundedness of the gradients, or iterate-dependent assumptions that cannot be checked a-priori and may not hold in practice, or iii) circumvent these issues via the introduction of additional unbiased compressors, which increase the communication cost. In this work we fix all these deficiencies by proposing and analyzing a new EF mechanism, which we call EF21, which consistently and substantially outperforms EF in practice. Moreover, our theoretical analysis relies on standard assumptions only, works in the distributed heterogeneous data setting, and leads to better and more meaningful rates. In particular, we prove that EF21 enjoys a fast $\\mathcal{O}(1/T)$  convergence rate for smooth nonconvex problems, beating the previous bound of $\\mathcal{O}(1/T^{2/3})$, which was shown under a strong bounded gradients assumption. We further improve this to a fast linear rate for Polyak-Lojasiewicz functions, which is the first linear convergence result for an error feedback method not relying on unbiased compressors. Since EF has a large number of applications where it reigns supreme, we believe that our 2021 variant, EF21, will have a large impact on the practice of communication efficient distributed learning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "$\\texttt{LeadCache}$", "Title": "Regret-Optimal Caching in Networks", "Abstract": "We consider an online prediction problem in the context of network caching. Assume that multiple users are connected to several caches via a bipartite network. At any time slot, each user may request an arbitrary file chosen from a large catalog. A user's request at a slot is met if the requested file is cached in at least one of the caches connected to the user. Our objective is to predict, prefetch, and optimally distribute the files on the caches at each slot to maximize the total number of cache hits. The problem is non-trivial due to the non-convex and non-smooth nature of the objective function. In this paper, we propose $\\texttt{LeadCache}$ - an efficient online caching policy based on the Follow-the-Perturbed-Leader paradigm. We show that $\\texttt{LeadCache}$ is regret-optimal up to a factor of $\\tilde{O}(n^{3/8}),$ where $n$ is the number of users. We design two efficient implementations of the $\\texttt{LeadCache}$ policy, one based on Pipage rounding and the other based on Madow's sampling, each of which makes precisely one call to an LP-solver per iteration. Furthermore, with a Strong-Law-type assumption, we show that the total number of file fetches under $\\texttt{LeadCache}$ remains almost surely finite over an infinite horizon. Finally, we derive an approximately tight regret lower bound using results from graph coloring. We conclude that the learning-based $\\texttt{LeadCache}$ policy decisively outperforms the state-of-the-art caching policies both theoretically and empirically."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Robust Regression Revisited", "Title": "Acceleration and Improved Estimation Rates", "Abstract": "We study fast algorithms for statistical regression problems under the strong contamination model, where the goal is to approximately optimize a generalized linear model (GLM) given adversarially corrupted samples. Prior works in this line of research were based on the \\emph{robust gradient descent} framework of \\cite{PrasadSBR20}, a first-order method using biased gradient queries, or the \\emph{Sever} framework of \\cite{DiakonikolasKK019}, an iterative outlier-removal method calling a stationary point finder. We present nearly-linear time algorithms for robust regression problems with improved runtime or estimation guarantees compared to the state-of-the-art. For the general case of smooth GLMs (e.g.\\ logistic regression), we show that the robust gradient descent framework of \\cite{PrasadSBR20} can be \\emph{accelerated}, and show our algorithm extends to optimizing the Moreau envelopes of Lipschitz GLMs (e.g.\\ support vector machines), answering several open questions in the literature. For the well-studied case of robust linear regression, we present an alternative approach obtaining improved estimation rates over prior nearly-linear time algorithms. Interestingly, our algorithm starts with an identifiability proof introduced in the context of the sum-of-squares algorithm of \\cite{BakshiP21}, which achieved optimal error rates while requiring large polynomial runtime and sample complexity. We reinterpret their proof within the Sever framework and obtain a dramatically faster and more sample-efficient algorithm under fewer distributional assumptions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probing Inter-modality", "Title": "Visual Parsing with Self-Attention for Vision-and-Language Pre-training", "Abstract": "Vision-Language Pre-training (VLP) aims to learn multi-modal representations from image-text pairs and serves for downstream vision-language tasks in a fine-tuning fashion. The dominant VLP models adopt a CNN-Transformer architecture, which embeds images with a CNN, and then aligns images and text with a Transformer.  Visual relationship between visual contents plays an important role in image understanding and is the basic for inter-modal alignment learning. However, CNNs have limitations in visual relation learning due to local receptive field's weakness in modeling long-range dependencies. Thus the two objectives of learning visual relation and inter-modal alignment are encapsulated in the same Transformer network. Such design might restrict the inter-modal alignment learning in the Transformer by ignoring the specialized characteristic of each objective. To tackle this, we propose a fully Transformer visual embedding for VLP to better learn visual relation and further promote inter-modal alignment. Specifically, we propose a metric named Inter-Modality Flow (IMF) to measure the interaction between vision and language modalities (i.e., inter-modality). We also design a novel masking optimization mechanism named Masked Feature Regression (MFR) in Transformer to further promote the inter-modality learning. To the best of our knowledge, this is the first study to explore the benefit of Transformer for visual feature learning in VLP.  We verify our method on a wide range of vision-language tasks, including Visual Question Answering (VQA), Visual Entailment and Visual Reasoning. Our approach not only outperforms the state-of-the-art VLP performance, but also shows benefits on the IMF metric."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MixACM", "Title": "Mixup-Based Robustness Transfer via Distillation of Activated Channel Maps", "Abstract": "Deep neural networks are susceptible to adversarially crafted, small, and imperceptible changes in the natural inputs. The most effective defense mechanism against these examples is adversarial training which constructs adversarial examples during training by iterative maximization of loss. The model is then trained to minimize the loss on these constructed examples. This min-max optimization requires more data, larger capacity models, and additional computing resources. It also degrades the standard generalization performance of a model. Can we achieve robustness more efficiently? In this work, we explore this question from the perspective of knowledge transfer. First, we theoretically show the transferability of robustness from an adversarially trained teacher model to a student model with the help of mixup augmentation. Second, we propose a novel robustness transfer method called Mixup-Based Activated Channel Maps (MixACM) Transfer. MixACM transfers robustness from a robust teacher to a student by matching activated channel maps generated without expensive adversarial perturbations. Finally, extensive experiments on multiple datasets and different learning scenarios show our method can transfer robustness while also improving generalization on natural images."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RoMA", "Title": "Robust Model Adaptation for Offline Model-based Optimization", "Abstract": "We consider the problem of searching an input maximizing a black-box objective function given a static dataset of input-output queries. A popular approach to solving this problem is maintaining a proxy model, e.g., a deep neural network (DNN), that approximates the true objective function. Here, the main challenge is how to avoid adversarially optimized inputs during the search, i.e., the inputs where the DNN highly overestimates the true objective function. To handle the issue, we propose a new framework, coined robust model adaptation (RoMA), based on gradient-based optimization of inputs over the DNN. Specifically, it consists of two steps: (a) a pre-training strategy to robustly train the proxy model and (b) a novel adaptation procedure of the proxy model to have robust estimates for a specific set of candidate solutions. At a high level, our scheme utilizes the local smoothness prior to overcome the brittleness of the DNN. Experiments under various tasks show the effectiveness of RoMA compared with previous methods, obtaining state-of-the-art results, e.g., RoMA outperforms all at 4 out of 6 tasks and achieves runner-up results at the remaining tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Additive Models", "Title": "Interpretable Machine Learning with Neural Nets", "Abstract": "Deep neural networks (DNNs) are powerful black-box predictors that have achieved impressive performance on a wide variety of tasks. However, their accuracy comes at the cost of intelligibility: it is usually unclear how they make their decisions. This hinders their applicability to high stakes decision-making domains such as healthcare. We propose Neural Additive Models (NAMs) which combine some of the expressivity of DNNs with the inherent intelligibility of generalized additive models. NAMs learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. Our experiments on regression and classification datasets show that NAMs are more accurate than widely used intelligible models such as logistic regression and shallow decision trees. They perform similarly to existing state-of-the-art generalized additive models in accuracy, but are more flexible because they are based on neural nets instead of boosted trees. To demonstrate this, we show how NAMs can be used for multitask learning on synthetic data and on the COMPAS recidivism data due to their composability, and demonstrate that the differentiability of NAMs allows them to train more complex interpretable models for COVID-19."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond BatchNorm", "Title": "Towards a Unified Understanding of Normalization in Deep Learning", "Abstract": "Inspired by BatchNorm, there has been an explosion of normalization layers in deep learning. Recent works have identified a multitude of beneficial properties in BatchNorm to explain its success. However, given the pursuit of alternative normalization layers, these properties need to be generalized so that any given layer's success/failure can be accurately predicted. In this work, we take a first step towards this goal by extending known properties of BatchNorm in randomly initialized deep neural networks (DNNs) to several recently proposed normalization layers. Our primary findings follow: (i) similar to BatchNorm, activations-based normalization layers can prevent exponential growth of activations in ResNets, but parametric techniques require explicit remedies; (ii) use of GroupNorm can ensure an informative forward propagation, with different samples being assigned dissimilar activations, but increasing group size results in increasingly indistinguishable activations for different samples, explaining slow convergence speed in models with LayerNorm; and (iii) small group sizes result in large gradient norm in earlier layers, hence explaining training instability issues in Instance Normalization and illustrating a speed-stability tradeoff in GroupNorm. Overall, our analysis reveals a unified set of mechanisms that underpin the success of normalization methods in deep learning, providing us with a compass to systematically explore the vast design space of DNN normalization layers."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MAUVE", "Title": "Measuring the Gap Between Neural Text and Human Text using Divergence Frontiers", "Abstract": "As major progress is made in open-ended text generation, measuring how close machine-generated text is to human language remains a critical open problem. We introduce Mauve, a comparison measure for open-ended text generation, which directly compares the learnt distribution from a text generation model to the distribution of human-written text using divergence frontiers. Mauve scales up to modern text generation models by computing information divergences in a quantized embedding space. Through an extensive empirical study on three open-ended generation tasks, we find that Mauve identifies known properties of generated text, scales naturally with model size, and correlates with human judgments, with fewer restrictions than existing distributional evaluation metrics."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CrypTen", "Title": "Secure Multi-Party Computation Meets Machine Learning", "Abstract": "Secure multi-party computation (MPC) allows parties to perform computations on data while keeping that data private. This capability has great potential for machine-learning applications: it facilitates training of machine-learning models on private data sets owned by different parties, evaluation of one party's private model using another party's private data, etc. Although a range of studies implement machine-learning models via secure MPC, such implementations are not yet mainstream. Adoption of secure MPC is hampered by the absence of flexible software frameworks that `\"speak the language\" of machine-learning researchers and engineers. To foster adoption of secure MPC in machine learning, we present CrypTen: a software framework that exposes popular secure MPC primitives via abstractions that are common in modern machine-learning frameworks, such as tensor computations, automatic differentiation, and modular neural networks. This paper describes the design of CrypTen and measure its performance on state-of-the-art models for text classification, speech recognition, and image classification. Our benchmarks show that CrypTen's GPU support and high-performance communication between (an arbitrary number of) parties allows it to perform efficient private evaluation of modern machine-learning models under a semi-honest threat model. For example, two parties using CrypTen can securely predict phonemes in speech recordings using Wav2Letter faster than real-time. We hope that CrypTen will spur adoption of secure MPC in the machine-learning community."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "See More for Scene", "Title": "Pairwise Consistency Learning for Scene Classification", "Abstract": "Scene classification is a valuable classification subtask and has its own characteristics which still needs more in-depth studies. Basically, scene characteristics are distributed over the whole image, which cause the need of “seeing” comprehensive and informative regions. Previous works mainly focus on region discovery and aggregation, while rarely involves the inherent properties of CNN along with its potential ability to satisfy the requirements of scene classification. In this paper, we propose to understand scene images and the scene classification CNN models in terms of the focus area. From this new perspective, we find that large focus area is preferred in scene classification CNN models as a consequence of learning scene characteristics. Meanwhile, the analysis about existing training schemes helps us to understand the effects of focus area, and also raises the question about optimal training method for scene classification. Pursuing the better usage of scene characteristics, we propose a new learning scheme with a tailored loss in the goal of activating larger focus area on scene images. Since the supervision of the target regions to be enlarged is usually lacked, our alternative learning scheme is to erase already activated area, and allow the CNN models to activate more area during training. The proposed scheme is implemented by keeping the pairwise consistency between the output of  the erased image and its original one. In particular, a tailored loss is proposed to keep such pairwise consistency by leveraging category-relevance information. Experiments on Places365 show the significant improvements of our method with various CNNs. Our method shows an inferior result on the object-centric dataset, ImageNet, which experimentally indicates that it captures the unique characteristics of scenes."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "When False Positive is Intolerant", "Title": "End-to-End  Optimization with Low FPR for Multipartite Ranking", "Abstract": "Multipartite ranking is a basic task in machine learning, where the Area Under the receiver operating characteristics Curve (AUC) is generally applied as the evaluation metric. Despite that AUC reflects the overall performance of the model, it is inconsistent with the expected performance in some application scenarios, where only a low False Positive Rate (FPR) is meaningful. To leverage high performance under low FPRs, we consider an alternative metric for multipartite ranking evaluating the True Positive Rate (TPR) at a given FPR, denoted as TPR@FPR. Unfortunately, the key challenge of direct  TPR@FPR optimization is two-fold: \\textbf{a)} the original objective function is not differentiable, making gradient backpropagation impossible; \\textbf{b)} the loss function could not be written as a sum of independent instance-wise terms, making mini-batch based optimization infeasible.      To address these issues, we propose a novel framework on top of the deep learning framework named \\textit{Cross-Batch Approximation for Multipartite Ranking (CBA-MR)}. In face of \\textbf{a)},  we propose a differentiable surrogate optimization problem where the instances having a short-time effect on FPR are rendered with different weights based on the random walk hypothesis. To tackle \\textbf{b)}, we propose a fast ranking estimation method, where the full-batch loss evaluation is replaced by a delayed update scheme with the help of an embedding cache. Finally, experimental results on four real-world benchmarks are provided to demonstrate the effectiveness of the proposed method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SketchGen", "Title": "Generating Constrained CAD Sketches", "Abstract": "Computer-aided design (CAD) is the most widely used modeling approach for technical design. The typical starting point in these designs is 2D sketches which can later be extruded and combined to obtain complex three-dimensional assemblies. Such sketches are typically composed of parametric primitives, such as points, lines, and circular arcs, augmented with geometric constraints linking the primitives, such as coincidence, parallelism, or orthogonality. Sketches can be represented as graphs, with the primitives as nodes and the constraints as edges. Training a model to automatically generate CAD sketches can enable several novel workflows, but is challenging due to the complexity of the graphs and the heterogeneity of the primitives and constraints. In particular, each type of primitive and constraint may require a record of different size and parameter types.We propose SketchGen as a generative model based on a transformer architecture to address the heterogeneity problem by carefully designing a sequential language for the primitives and constraints that allows distinguishing between different primitive or constraint types and their parameters, while encouraging our model to re-use information across related parameters, encoding shared structure. A particular highlight of our work is the ability to produce primitives linked via constraints that enables the final output to be further regularized via a constraint solver. We evaluate our model by demonstrating constraint prediction for given sets of primitives and full sketch generation from scratch, showing that our approach significantly out performs the state-of-the-art in CAD sketch generation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CLDA", "Title": "Contrastive Learning for Semi-Supervised Domain Adaptation", "Abstract": "Unsupervised Domain Adaptation (UDA) aims to align the labeled source distribution with the unlabeled target distribution to obtain domain invariant predictive models. However, the application of well-known UDA approaches does not generalize well in Semi-Supervised Domain Adaptation (SSDA) scenarios where few labeled samples from the target domain are available.This paper proposes a simple Contrastive Learning framework for semi-supervised Domain Adaptation (CLDA) that attempts to bridge the intra-domain gap between the labeled and unlabeled target distributions and the inter-domain gap between source and unlabeled target distribution in SSDA. We suggest employing class-wise contrastive learning to reduce the inter-domain gap and instance-level contrastive alignment between the original(input image) and strongly augmented unlabeled target images to minimize the intra-domain discrepancy. We have empirically shown that both of these modules complement each other to achieve superior performance. Experiments on three well-known domain adaptation benchmark datasets, namely DomainNet, Office-Home, and Office31, demonstrate the effectiveness of our approach. CLDA achieves state-of-the-art results on all the above datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SPANN", "Title": "Highly-efficient Billion-scale Approximate Nearest Neighborhood Search", "Abstract": "The in-memory algorithms for approximate nearest neighbor search (ANNS) have achieved great success for fast high-recall search, but are extremely expensive when handling very large scale database. Thus, there is an increasing request for the hybrid ANNS solutions with small memory and inexpensive solid-state drive (SSD). In this paper, we present a simple but efficient memory-disk hybrid indexing and search system, named SPANN, that follows the inverted index methodology. It stores the centroid points of the posting lists in the memory and the large posting lists in the disk. We guarantee both disk-access efficiency (low  latency) and high recall by effectively reducing the disk-access number and retrieving high-quality posting lists. In the index-building stage, we adopt a hierarchical balanced clustering algorithm to balance the length of posting lists and augment the posting list by adding the points in the closure of the corresponding clusters. In the search stage, we use a query-aware scheme to dynamically prune the access of unnecessary posting lists.  Experiment results demonstrate that SPANN is 2X faster than the state-of-the-art ANNS solution DiskANN to reach the same recall quality 90% with same memory cost in three billion-scale datasets. It can reach 90% recall@1 and recall@10 in just around one millisecond with only about 10% of original memory cost.  Code is available at: https://github.com/microsoft/SPTAG."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning where to learn", "Title": "Gradient sparsity in meta and continual learning", "Abstract": "Finding neural network weights that generalize well from small datasets is difficult. A promising approach is to learn a weight initialization such that a small number of weight changes results in low generalization error. We show that this form of meta-learning can be improved by letting the learning algorithm decide which weights to change, i.e., by learning where to learn. We find that patterned sparsity emerges from this process, with the pattern of sparsity varying on a problem-by-problem basis. This selective sparsity results in better generalization and less interference in a range of few-shot and continual learning problems. Moreover, we find that sparse learning also emerges in a more expressive model where learning rates are meta-learned. Our results shed light on an ongoing debate on whether meta-learning can discover adaptable features and suggest that learning by sparse gradient descent is a powerful inductive bias for meta-learning systems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PlayVirtual", "Title": "Augmenting Cycle-Consistent Virtual Trajectories for Reinforcement Learning", "Abstract": "Learning good feature representations is important for deep reinforcement learning (RL). However, with limited experience, RL often suffers from data inefficiency for training. For un-experienced or less-experienced trajectories (i.e., state-action sequences), the lack of data limits the use of them for better feature learning. In this work, we propose a novel method, dubbed PlayVirtual, which augments cycle-consistent virtual trajectories to enhance the data efficiency for RL feature representation learning. Specifically, PlayVirtual predicts future states in a latent space based on the current state and action by a dynamics model and then predicts the previous states by a backward dynamics model, which forms a trajectory cycle. Based on this, we augment the actions to generate a large amount of virtual state-action trajectories. Being free of groudtruth state supervision, we enforce a trajectory to meet the cycle consistency constraint, which can significantly enhance the data efficiency. We validate the effectiveness of our designs on the Atari and DeepMind Control Suite benchmarks. Our method achieves the state-of-the-art performance on both benchmarks. Our code is available at https://github.com/microsoft/Playvirtual."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Even your Teacher Needs Guidance", "Title": "Ground-Truth Targets Dampen Regularization Imposed by Self-Distillation", "Abstract": "Knowledge distillation is classically a procedure where a neural network is trained on the output of another network along with the original targets in order to transfer knowledge between the architectures. The special case of self-distillation, where the network architectures are identical, has been observed to improve generalization accuracy. In this paper, we consider an iterative variant of self-distillation in a kernel regression setting, in which successive steps incorporate both model outputs and the ground-truth targets. This allows us to provide the first theoretical results on the importance of using the weighted ground-truth targets in self-distillation. Our focus is on fitting nonlinear functions to training data with a weighted mean square error objective function suitable for distillation, subject to $\\ell_2$ regularization of the model parameters. We show that any such function obtained with self-distillation can be calculated directly as a function of the initial fit, and that infinite distillation steps yields the same optimization problem as the original with amplified regularization. Furthermore, we provide a closed form solution for the optimal choice of weighting parameter at each step, and show how to efficiently estimate this weighting parameter for deep learning and significantly reduce the computational requirements compared to a grid search."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Compressing Neural Networks", "Title": "Towards Determining the Optimal Layer-wise Decomposition", "Abstract": "We present a novel global compression framework for deep neural networks that automatically analyzes each layer to identify the optimal per-layer compression ratio, while simultaneously achieving the desired overall compression. Our algorithm hinges on the idea of compressing each convolutional (or fully-connected) layer by slicing its channels into multiple groups and decomposing each group via low-rank decomposition. At the core of our algorithm is the derivation of layer-wise error bounds from the Eckart–Young–Mirsky theorem. We then leverage these bounds to frame the compression problem as an optimization problem where we wish to minimize the maximum compression error across layers and propose an efficient algorithm towards a solution. Our experiments indicate that our method outperforms existing low-rank compression approaches across a wide range of networks and data sets. We believe that our results open up new avenues for future research into the global performance-size trade-offs of modern neural networks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Simple steps are all you need", "Title": "Frank-Wolfe and generalized self-concordant functions", "Abstract": "Generalized self-concordance is a key property present in the objective function of many important learning problems.  We establish the convergence rate of a simple Frank-Wolfe variant that uses the open-loop step size strategy $\\gamma_t = 2/(t+2)$, obtaining a $\\mathcal{O}(1/t)$ convergence rate for this class of functions in terms of primal gap and Frank-Wolfe gap, where $t$ is the iteration count. This avoids the use of second-order information or the need to estimate local smoothness parameters of previous work. We also show improved convergence rates for various common cases, e.g., when the feasible region under consideration is uniformly convex or polyhedral."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization of Model-Agnostic Meta-Learning Algorithms", "Title": "Recurring and Unseen Tasks", "Abstract": "In this paper, we study the generalization properties of Model-Agnostic Meta-Learning (MAML) algorithms for supervised learning problems. We focus on the setting in which we train the MAML model over $m$ tasks, each with $n$ data points, and characterize its generalization error from two points of view: First, we assume the new task at test time is one of the training tasks, and we show that, for strongly convex objective functions, the expected excess population loss is bounded by $\\mathcal{O}(1/mn)$. Second, we consider the MAML algorithm's generalization to an unseen task and show that the resulting generalization error depends on the total variation distance between the underlying distributions of the new task and the tasks observed during the training process. Our proof techniques rely on the connections between algorithmic stability and generalization bounds of algorithms. In particular, we propose a new definition of stability for meta-learning algorithms, which allows us to capture the role of both the number of tasks $m$ and number of samples per task $n$ on the generalization error of MAML."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Factored Policy Gradients", "Title": "Leveraging Structure for Efficient Learning in MOMDPs", "Abstract": "Policy gradient methods can solve complex tasks but often fail when the dimensionality of the action-space or objective multiplicity grow very large. This occurs, in part, because the variance on score-based gradient estimators scales quadratically. In this paper, we address this problem through a factor baseline which exploits independence structure encoded in a novel action-target influence network. Factored policy gradients (FPGs), which follow, provide a common framework for analysing key state-of-the-art algorithms, are shown to generalise traditional policy gradients, and yield a principled way of incorporating prior knowledge of a problem domain's generative processes. We provide an analysis of the proposed estimator and identify the conditions under which variance is reduced. The algorithmic aspects of FPGs are discussed, including optimal policy factorisation, as characterised by minimum biclique coverings, and the implications for the bias variance trade-off of incorrectly specifying the network. Finally, we demonstrate the performance advantages of our algorithm on large-scale bandit and traffic intersection problems,  providing a novel contribution to the latter in the form of a spatial approximation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MarioNette", "Title": "Self-Supervised Sprite Learning", "Abstract": "Artists and video game designers often construct 2D animations using libraries of sprites---textured patches of objects and characters. We propose a deep learning approach that decomposes sprite-based video animations into a disentangled representation of recurring graphic elements in a self-supervised manner. By jointly learning a dictionary of possibly transparent patches and training a network that places them onto a canvas, we deconstruct sprite-based content into a sparse, consistent, and explicit representation that can be easily used in downstream tasks, like editing or analysis. Our framework offers a promising approach for discovering recurring visual patterns in image collections without supervision."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RLlib Flow", "Title": "Distributed Reinforcement Learning is a Dataflow Problem", "Abstract": "Researchers and practitioners in the field of reinforcement learning (RL) frequently leverage parallel computation, which has led to a plethora of new algorithms and systems in the last few years. In this paper, we re-examine the challenges posed by distributed RL and try to view it through the lens of an old idea: distributed dataflow. We show that viewing RL as a dataflow problem leads to highly composable and performant implementations. We propose RLlib Flow, a hybrid actor-dataflow programming model for distributed RL, and validate its practicality by porting the full suite of algorithms in RLlib, a widely adopted distributed RL library. Concretely, RLlib Flow provides 2-9$\\times$ code savings in real production code and enables the composition of multi-agent algorithms not possible by end users before. The open-source code is available as part of RLlib at https://github.com/ray-project/ray/tree/master/rllib."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Improve Agents without Retraining", "Title": "Parallel Tree Search with Off-Policy Correction", "Abstract": "Tree Search (TS) is crucial to some of the most influential successes in reinforcement learning. Here, we tackle two major challenges with TS that limit its usability: \\textit{distribution shift} and \\textit{scalability}. We first discover and analyze a counter-intuitive phenomenon: action selection through TS and a pre-trained value function often leads to lower performance compared to the original pre-trained agent, even when having access to the exact state and reward in future steps. We show this is due to a distribution shift to areas where value estimates are highly inaccurate and analyze this effect using Extreme Value theory. To overcome this problem, we introduce a novel off-policy correction term that accounts for the mismatch between the pre-trained value and its corresponding TS policy by penalizing under-sampled trajectories. We prove that our correction eliminates the above mismatch and bound the probability of sub-optimal action selection. Our correction significantly improves pre-trained Rainbow agents without any further training, often more than doubling their scores on Atari games. Next, we address the scalability issue given by the computational complexity of exhaustive TS that scales exponentially with the tree depth. We introduce Batch-BFS: a GPU breadth-first search that advances all nodes in each depth of the tree simultaneously. Batch-BFS reduces runtime by two orders of magnitude and, beyond inference, enables also training with TS of depths that were not feasible before. We train DQN agents from scratch using TS and show improvement in several Atari games compared to both the original DQN and the more advanced Rainbow. We will share the code upon publication."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Center Smoothing", "Title": "Certified Robustness for Networks with Structured Outputs", "Abstract": "The study of provable adversarial robustness has mostly been limited to classification tasks and models with one-dimensional real-valued outputs. We extend the scope of certifiable robustness to problems with more general and structured outputs like sets, images, language, etc. We model the output space as a metric space under a distance/similarity function, such as intersection-over-union, perceptual similarity, total variation distance, etc. Such models are used in many machine learning problems like image segmentation, object detection, generative models, image/audio-to-text systems, etc. Based on a robustness technique called randomized smoothing, our center smoothing procedure can produce models with the guarantee that the change in the output, as measured by the distance metric, remains small for any norm-bounded adversarial perturbation of the input. We apply our method to create certifiably robust models with disparate output spaces -- from sets to images -- and show that it yields meaningful certificates without significantly degrading the performance of the base model."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DOCTOR", "Title": "A Simple Method for Detecting Misclassification Errors", "Abstract": "Deep neural networks (DNNs) have shown to perform very well on large scale object recognition problems and lead to widespread use for real-world applications, including situations where DNN are implemented as “black boxes”.  A promising approach to secure their use is to accept decisions that are likely to be correct while discarding the others.  In this work, we propose DOCTOR, a simple method that aims to identify whether the prediction of a DNN classifier should (or should not) be trusted so that, consequently, it would be possible to accept it or to reject it. Two scenarios are investigated: Totally Black Box (TBB) where only the soft-predictions are available and Partially Black Box (PBB) where gradient-propagation to perform input pre-processing is allowed. Empirically, we show that DOCTOR outperforms all state-of-the-art methods on various well-known images and sentiment analysis datasets. In particular, we observe a reduction of up to 4% of the false rejection rate (FRR) in the PBB scenario. DOCTOR can be applied to any pre-trained model, it does not require prior information about the underlying dataset and is as simple as the simplest available methods in the literature."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A$^2$-Net", "Title": "Learning Attribute-Aware Hash Codes for Large-Scale Fine-Grained Image Retrieval", "Abstract": "Our work focuses on tackling large-scale fine-grained image retrieval as ranking the images depicting the concept of interests (i.e., the same sub-category labels) highest based on the fine-grained details in the query. It is desirable to alleviate the challenges of both fine-grained nature of small inter-class variations with large intra-class variations and explosive growth of fine-grained data for such a practical task. In this paper, we propose an Attribute-Aware hashing Network (A$^2$-Net) for generating attribute-aware hash codes to not only make the retrieval process efficient, but also establish explicit correspondences between hash codes and visual attributes. Specifically, based on the captured visual representations by attention, we develop an encoder-decoder structure network of a reconstruction task to unsupervisedly distill high-level attribute-specific vectors from the appearance-specific visual representations without attribute annotations. A$^2$-Net is also equipped with a feature decorrelation constraint upon these attribute vectors to enhance their representation abilities. Finally, the required hash codes are generated by the attribute vectors driven by preserving original similarities. Qualitative experiments on five benchmark fine-grained datasets show our superiority over competing methods. More importantly, quantitative results demonstrate the obtained hash codes can strongly correspond to certain kinds of crucial properties of fine-grained objects."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Brick-by-Brick", "Title": "Combinatorial Construction with Deep Reinforcement Learning", "Abstract": "Discovering a solution in a combinatorial space is prevalent in many real-world problems but it is also challenging due to diverse complex constraints and the vast number of possible combinations. To address such a problem, we introduce a novel formulation, combinatorial construction, which requires a building agent to assemble unit primitives (i.e., LEGO bricks) sequentially -- every connection between two bricks must follow a fixed rule, while no bricks mutually overlap. To construct a target object, we provide incomplete knowledge about the desired target (i.e., 2D images) instead of exact and explicit volumetric information to the agent. This problem requires a comprehensive understanding of partial information and long-term planning to append a brick sequentially, which leads us to employ reinforcement learning. The approach has to consider a variable-sized action space where a large number of invalid actions, which would cause overlap between bricks, exist. To resolve these issues, our model, dubbed Brick-by-Brick, adopts an action validity prediction network that efficiently filters invalid actions for an actor-critic network. We demonstrate that the proposed method successfully learns to construct an unseen object conditioned on a single image or multiple views of a target object."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "iFlow", "Title": "Numerically Invertible Flows for Efficient Lossless Compression via a Uniform Coder", "Abstract": "It was estimated that the world produced $59 ZB$ ($5.9 \\times 10^{13} GB$) of data in 2020, resulting in the enormous costs of both data storage and transmission. Fortunately, recent advances in deep generative models have spearheaded a new class of so-called \"neural compression\" algorithms, which significantly outperform traditional codecs in terms of compression ratio. Unfortunately, the application of neural compression garners little commercial interest due to its limited bandwidth; therefore, developing highly efficient frameworks is of critical practical importance. In this paper, we discuss lossless compression using normalizing flows which have demonstrated a great capacity for achieving high compression ratios. As such, we introduce iFlow, a new method for achieving efficient lossless compression. We first propose Modular Scale Transform (MST) and a novel family of numerically invertible flow transformations based on MST. Then we introduce the Uniform Base Conversion System (UBCS), a fast uniform-distribution codec incorporated into iFlow, enabling efficient compression. iFlow achieves state-of-the-art compression ratios and is $5 \\times$ quicker than other high-performance schemes. Furthermore, the techniques presented in this paper can be used to accelerate coding time for a broad class of flow-based algorithms."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Meta Two-Sample Testing", "Title": "Learning Kernels for Testing with Limited Data", "Abstract": "Modern kernel-based two-sample tests have shown great success in distinguishing complex, high-dimensional distributions by learning appropriate kernels (or, as a special case, classifiers). Previous work, however, has assumed that many samples are observed from both of the distributions being distinguished. In realistic scenarios with very limited numbers of data samples, it can be challenging to identify a kernel powerful enough to distinguish complex distributions. We address this issue by introducing the problem of meta two-sample testing (M2ST), which aims to exploit (abundant) auxiliary data on related tasks to find an algorithm that can quickly identify a powerful test on new target tasks. We propose two specific algorithms for this task: a generic scheme which improves over baselines, and a more tailored approach which performs even better. We provide both theoretical justification and empirical evidence that our proposed meta-testing schemes outperform learning kernel-based tests directly from scarce observations, and identify when such schemes will be successful."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COHESIV", "Title": "Contrastive Object and Hand Embedding Segmentation In Video", "Abstract": "In this paper we learn to segment hands and hand-held objects from motion. Our system takes a single RGB image and hand location as input to segment the hand and hand-held object. For learning, we generate responsibility maps that show how well a hand's motion explains other pixels' motion in video. We use these responsibility maps as pseudo-labels to train a weakly-supervised neural network using an attention-based similarity loss and contrastive loss. Our system outperforms alternate methods, achieving good performance on the 100DOH, EPIC-KITCHENS, and HO3D datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ByPE-VAE", "Title": "Bayesian Pseudocoresets Exemplar VAE", "Abstract": "Recent studies show that advanced priors play a major role in deep generative models. Exemplar VAE, as a variant of VAE with an exemplar-based prior, has achieved impressive results. However, due to the nature of model design, an exemplar-based model usually requires vast amounts of data to participate in training, which leads to huge computational complexity. To address this issue, we propose Bayesian Pseudocoresets Exemplar VAE (ByPE-VAE), a new variant of VAE with a prior based on Bayesian pseudocoreset. The proposed prior is conditioned on a small-scale pseudocoreset rather than the whole dataset for reducing the computational cost and avoiding overfitting. Simultaneously, we obtain the optimal pseudocoreset via a stochastic optimization algorithm during VAE training aiming to minimize the Kullback-Leibler divergence between the prior based on the pseudocoreset and that based on the whole dataset. Experimental results show that ByPE-VAE can achieve competitive improvements over the state-of-the-art VAEs in the tasks of density estimation, representation learning, and generative data augmentation. Particularly, on a basic VAE architecture, ByPE-VAE is up to 3 times faster than Exemplar VAE while almost holding the performance. Code is available at \\url{https://github.com/Aiqz/ByPE-VAE}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "No Fear of Heterogeneity", "Title": "Classifier Calibration for Federated Learning with Non-IID Data", "Abstract": "A central challenge in training classification models in the real-world federated system is learning with non-IID data. To cope with this, most of the existing works involve enforcing regularization in local optimization or improving the model aggregation scheme at the server. Other works also share public datasets or synthesized samples to supplement the training of under-represented classes or introduce a certain level of personalization. Though effective, they lack a deep understanding of how the data heterogeneity affects each layer of a deep classification model. In this paper, we bridge this gap by performing an experimental analysis of the representations learned by different layers. Our observations are surprising: (1) there exists a greater bias in the classifier than other layers, and (2) the classification performance can be significantly improved by post-calibrating the classifier after federated training. Motivated by the above findings, we propose a novel and simple algorithm called Classifier Calibration with Virtual Representations (CCVR), which adjusts the classifier using virtual representations sampled from an approximated gaussian mixture model. Experimental results demonstrate that CCVR achieves state-of-the-art performance on popular federated learning benchmarks including CIFAR-10, CIFAR-100, and CINIC-10. We hope that our simple yet effective method can shed some light on the future research of federated learning with non-IID data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STEM", "Title": "A Stochastic Two-Sided Momentum Algorithm Achieving Near-Optimal Sample and Communication Complexities for Federated Learning", "Abstract": "Federated Learning (FL) refers to the paradigm where multiple worker nodes (WNs) build a joint model by using local data. Despite extensive research, for a generic non-convex FL problem, it is not clear, how to choose the WNs' and the server's update directions, the minibatch sizes, and the local update frequency, so that the WNs use the minimum number of samples and communication rounds to achieve the desired solution. This work addresses the above question and considers a class of stochastic algorithms where the WNs perform a few local updates before communication. We show that when both the WN's and the server's directions are chosen based on certain stochastic momentum estimator, the algorithm requires $\\tilde{\\mathcal{O}}(\\epsilon^{-3/2})$ samples and $\\tilde{\\mathcal{O}}(\\epsilon^{-1})$ communication rounds to compute an $\\epsilon$-stationary solution. To the best of our knowledge, this is the first FL algorithm that achieves such {\\it near-optimal} sample and communication complexities simultaneously.  Further, we show that there is a trade-off curve between local update frequencies and local minibatch sizes, on which the above sample and communication complexities can be maintained. {Finally,   we show that for the classical FedAvg (a.k.a. Local SGD, which is a momentum-less special case of the STEM), a similar trade-off curve exists, albeit with worse sample and communication complexities. Our insights on this trade-off provides guidelines for choosing the four important design elements for FL algorithms, the update frequency, directions, and minibatch sizes to achieve the best performance.}"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bubblewrap", "Title": "Online tiling and real-time flow prediction on neural manifolds", "Abstract": "While most classic studies of function in experimental neuroscience have focused on the coding properties of individual neurons, recent developments in recording technologies have resulted in an increasing emphasis on the dynamics of neural populations. This has given rise to a wide variety of models for analyzing population activity in relation to experimental variables, but direct testing of many neural population hypotheses requires intervening in the system based on current neural state, necessitating models capable of inferring neural state online. Existing approaches, primarily based on dynamical systems, require strong parametric assumptions that are easily violated in the noise-dominated regime and do not scale well to the thousands of data channels in modern experiments. To address this problem, we propose a method that combines fast, stable dimensionality reduction with a soft tiling of the resulting neural manifold, allowing dynamics to be approximated as a probability flow between tiles. This method can be fit efficiently using online expectation maximization, scales to tens of thousands of tiles, and outperforms existing methods when dynamics are noise-dominated or feature multi-modal transition probabilities. The resulting model can be trained at kiloHertz data rates, produces accurate approximations of neural dynamics within minutes, and generates predictions on submillisecond time scales. It retains predictive performance throughout many time steps into the future and is fast enough to serve as a component of closed-loop causal experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Marching Tetrahedra", "Title": "a Hybrid Representation for High-Resolution 3D Shape Synthesis", "Abstract": "We introduce DMTet, a deep 3D conditional generative model that can synthesize high-resolution 3D shapes using simple user guides such as coarse voxels. It marries the merits of implicit and explicit 3D representations by leveraging a novel hybrid 3D representation. Compared to the current implicit approaches, which are trained to regress the signed distance values, DMTet directly optimizes for the reconstructed surface, which enables us to synthesize finer geometric details with fewer artifacts. Unlike deep 3D generative models that directly generate explicit representations such as meshes, our model can synthesize shapes with arbitrary topology. The core of DMTet includes a deformable tetrahedral grid that encodes a discretized signed distance function and a differentiable marching tetrahedra layer that converts the implicit signed distance representation to the explicit surface mesh representation. This combination allows joint optimization of the surface geometry and topology as well as generation of the hierarchy of subdivisions using reconstruction and adversarial losses defined explicitly on the surface mesh. Our approach significantly outperforms existing work on conditional shape synthesis from coarse voxel inputs, trained on a dataset of complex 3D animal shapes. Project page: https://nv-tlabs.github.io/DMTet/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Success and Simplicity", "Title": "A Second Look at Transferable Targeted Attacks", "Abstract": "Achieving transferability of targeted attacks is reputed to be remarkably difficult. The current state of the art has resorted to resource-intensive solutions that necessitate training model(s) for each target class with additional data. In our investigation, we find, however, that simple transferable attacks which require neither model training nor additional data can achieve surprisingly strong targeted transferability. This insight has been overlooked until now, mainly because the widespread practice of attacking with only few iterations has largely limited the attack convergence to optimal targeted transferability. In particular, we, for the first time, identify that a very simple logit loss can largely surpass the commonly adopted cross-entropy loss, and yield even better results than the resource-intensive state of the art. Our analysis spans a variety of transfer scenarios, especially including three new, realistic scenarios: an ensemble transfer scenario with little model similarity, a worse-case scenario with low-ranked target classes, and also a real-world attack on the Google Cloud Vision API. Results in these new transfer scenarios demonstrate that the commonly adopted, easy scenarios cannot fully reveal the actual strength of different attacks and may cause misleading comparative results. We also show the usefulness of the simple logit loss for generating targeted universal adversarial perturbations in a data-free manner. Overall, the aim of our analysis is to inspire a more meaningful evaluation on targeted transferability. Code is available at https://github.com/ZhengyuZhao/Targeted-Tansfer."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Ising Model Selection Using $\\ell_{1}$-Regularized Linear Regression", "Title": "A Statistical Mechanics Analysis", "Abstract": "We theoretically analyze the typical learning performance of $\\ell_{1}$-regularized linear regression ($\\ell_1$-LinR) for Ising model selection using the replica method from statistical mechanics. For typical random regular graphs in the paramagnetic phase, an accurate estimate of the typical sample complexity of $\\ell_1$-LinR is obtained.   Remarkably, despite the model misspecification, $\\ell_1$-LinR is model selection consistent with the same order of sample complexity as $\\ell_{1}$-regularized logistic regression ($\\ell_1$-LogR), i.e., $M=\\mathcal{O}\\left(\\log N\\right)$,  where $N$ is the number of variables of the Ising model. Moreover, we provide an efficient method to accurately predict the non-asymptotic behavior of $\\ell_1$-LinR for moderate $M, N$, such as precision and recall. Simulations show a fairly good agreement between theoretical predictions and experimental results, even for graphs with many loops, which supports our findings. Although this paper mainly focuses on $\\ell_1$-LinR, our method is readily applicable for precisely characterizing the typical learning performances of a wide class of  $\\ell_{1}$-regularized $M$-estimators including $\\ell_1$-LogR and interaction screening."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Contrastive Graph Poisson Networks", "Title": "Semi-Supervised Learning with Extremely Limited Labels", "Abstract": "Graph Neural Networks (GNNs) have achieved remarkable performance in the task of semi-supervised node classification. However, most existing GNN models require sufficient labeled data for effective network training. Their performance can be seriously degraded when labels are extremely limited. To address this issue, we propose a new framework termed Contrastive Graph Poisson Networks (CGPN) for node classification under extremely limited labeled data. Specifically, our CGPN derives from variational inference; integrates a newly designed Graph Poisson Network (GPN) to effectively propagate the limited labels to the entire graph and a normal GNN, such as Graph Attention Network, that flexibly guides the propagation of GPN; applies a contrastive objective to further exploit the supervision information from the learning process of GPN and GNN models. Essentially, our CGPN can enhance the learning performance of GNNs under extremely limited labels by contrastively propagating the limited labels to the entire graph. We conducted extensive experiments on different types of datasets to demonstrate the superiority of CGPN."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Network-to-Network Regularization", "Title": "Enforcing Occam's Razor to Improve Generalization", "Abstract": "What makes a classifier have the ability to generalize? There have been a lot of important attempts to address this question, but a clear answer is still elusive. Proponents of complexity theory find that the complexity of the classifier's function space is key to deciding generalization, whereas other recent work reveals that classifiers which extract invariant feature representations are likely to generalize better. Recent theoretical and empirical studies, however, have shown that even within a classifier's function space, there can be significant differences in the ability to generalize. Specifically, empirical studies have shown that among functions which have a good training data fit, functions with lower Kolmogorov complexity (KC) are likely to generalize better, while the opposite is true for functions of higher KC. Motivated by these findings, we propose, in this work, a novel measure of complexity called Kolmogorov Growth (KG), which we use to derive new generalization error bounds that only depend on the final choice of the classification function. Guided by the bounds, we propose a novel way of regularizing neural networks by constraining the network trajectory to remain in the low KG zone during training. Minimizing KG while learning is akin to applying the Occam's razor to neural networks. The proposed approach, called network-to-network regularization, leads to clear improvements in the generalization ability of classifiers. We verify this for three popular image datasets (MNIST, CIFAR-10, CIFAR-100) across varying training data sizes. Empirical studies find that conventional training of neural networks, unlike network-to-network regularization, leads to networks of high KG and lower test accuracies. Furthermore, we present the benefits of N2N regularization in the scenario where the training data labels are noisy. Using N2N regularization, we achieve competitive performance on MNIST, CIFAR-10 and CIFAR-100 datasets with corrupted training labels, significantly improving network performance compared to standard cross-entropy baselines in most cases. These findings illustrate the many benefits obtained from imposing a function complexity prior like Kolmogorov Growth during the training process."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spherical Motion Dynamics", "Title": "Learning Dynamics of Normalized Neural Network using SGD and Weight Decay", "Abstract": "In this paper, we comprehensively reveal the learning dynamics of normalized neural network using Stochastic Gradient Descent (with momentum) and Weight Decay (WD), named as Spherical Motion Dynamics (SMD). Most related works focus on studying behavior of effective learning rate\" inequilibrium\" state, i.e. assuming weight norm remains unchanged. However, their discussion on why this equilibrium can be reached is either absent or less convincing. Our work directly explores the cause of equilibrium, as a special state of SMD. Specifically, 1) we introduce the assumptions that can lead to equilibrium state in SMD, and prove equilibrium can be reached in a linear rate regime under given assumptions; 2) we propose ``angular update\" as a substitute for effective learning rate to depict the state of SMD, and derive the theoretical value of angular update in equilibrium state; 3) we verify our assumptions and theoretical results on various large-scale computer vision tasks including ImageNet and MSCOCO with standard settings. Experiment results show our theoretical findings agree well with empirical observations. We also show that the behavior of angular update in SMD can produce interesting effect to the optimization of neural network in practice."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Probabilistic Forecasting", "Title": "A Level-Set Approach", "Abstract": "Large-scale time series panels have become ubiquitous over the last years in areas such as retail, operational metrics, IoT, and medical domain (to name only a few). This has resulted in a need for forecasting techniques that effectively leverage all available data by learning across all time series in each panel. Among the desirable properties of forecasting techniques, being able to generate probabilistic predictions ranks among the top. In this paper, we therefore present Level Set Forecaster (LSF), a simple yet effective general approach to transform a point estimator into a probabilistic one. By recognizing the connection of our algorithm to random forests (RFs) and quantile regression forests (QRFs), we are able to prove consistency guarantees of our approach under mild assumptions on the underlying point estimator. As a byproduct, we prove the first consistency results for QRFs under the CART-splitting criterion. Empirical experiments show that our approach, equipped with tree-based models as the point estimator, rivals state-of-the-art deep learning models in terms of forecasting accuracy."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ParK", "Title": "Sound and Efficient Kernel Ridge Regression by Feature Space Partitions", "Abstract": "We introduce ParK, a new large-scale solver for kernel ridge regression. Our approach combines partitioning with random projections and iterative optimization to reduce space and time complexity while provably maintaining the same statistical accuracy. In particular, constructing suitable partitions directly in the feature space rather than in the input space, we promote orthogonality between the local estimators, thus ensuring that key quantities such as local effective dimension and bias remain under control. We characterize the statistical-computational tradeoff of our model, and demonstrate the effectiveness of our method by numerical experiments on large-scale datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Retiring Adult", "Title": "New Datasets for Fair Machine Learning", "Abstract": "Although the fairness community has recognized the importance of data, researchers in the area primarily rely on UCI Adult when it comes to tabular data. Derived from a 1994 US Census survey, this dataset has appeared in hundreds of research papers where it served as the basis for the development and comparison of many algorithmic fairness interventions. We reconstruct a superset of the UCI Adult data from available US Census sources and reveal idiosyncrasies of the UCI Adult dataset that limit its external validity. Our primary contribution is a suite of new datasets derived from US Census surveys that extend the existing data ecosystem for research on fair machine learning. We create prediction tasks relating to income, employment, health, transportation, and housing. The data span multiple years and all states of the United States, allowing researchers to study temporal shift and geographic variation. We highlight a broad initial sweep of new empirical insights relating to trade-offs between fairness criteria, performance of algorithmic interventions, and the role of distribution shift based on our new datasets. Our findings inform ongoing debates, challenge some existing narratives, and point to future research directions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Grad2Task", "Title": "Improved Few-shot Text Classification Using Gradients for Task Representation", "Abstract": "Large pretrained language models (LMs) like BERT have improved performance in many disparate natural language processing (NLP) tasks. However, fine tuning such models requires a large number of training examples for each target task. Simultaneously, many realistic NLP problems are \"few shot\", without a sufficiently large training set. In this work, we propose a novel conditional neural process-based approach for few-shot text classification that learns to transfer from other diverse tasks with rich annotation. Our key idea is to represent each task using gradient information from a base model and to train an adaptation network that modulates a text classifier conditioned on the task representation. While previous task-aware few-shot learners represent tasks by input encoding, our novel task representation is more powerful, as the gradient captures input-output relationships of a task. Experimental results show that our approach outperforms traditional fine-tuning, sequential transfer learning, and state-of-the-art meta learning approaches on a collection of diverse few-shot tasks. We further conducted analysis and ablations to justify our design choices."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Speech-T", "Title": "Transducer for Text to Speech and Beyond", "Abstract": "Neural Transducer (e.g., RNN-T) has been widely used in automatic speech recognition (ASR) due to its capabilities of efficiently modeling monotonic alignments between input and output sequences and naturally supporting streaming inputs. Considering that monotonic alignments are also critical to text to speech (TTS) synthesis and streaming TTS is also an important application scenario, in this work, we explore the possibility of applying Transducer to TTS and more. However, it is challenging because it is difficult to trade off the emission (continuous mel-spectrogram prediction) probability and transition (ASR Transducer predicts blank token to indicate transition to next input) probability when calculating the output probability lattice in Transducer, and it is not easy to learn the alignments between text and speech through the output probability lattice. We propose SpeechTransducer (Speech-T for short), a Transformer based Transducer model that 1) uses a new forward algorithm to separate the transition prediction from the continuous mel-spectrogram prediction when calculating the output probability lattice, and uses a diagonal constraint in the probability lattice to help the alignment learning; 2) supports both full-sentence or streaming TTS by adjusting the look-ahead context; and 3) further supports both TTS and ASR together for the first time, which enjoys several advantages including fewer parameters as well as streaming synthesis and recognition in a single model. Experiments on LJSpeech datasets demonstrate that Speech-T 1) is more robust than the attention based autoregressive TTS model due to its inherent monotonic alignments between text and speech; 2) naturally supports streaming TTS with good voice quality; and 3) enjoys the benefit of joint modeling TTS and ASR in a single network."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sub-Linear Memory", "Title": "How to Make Performers SLiM", "Abstract": "Transformer architectures have become very popular yet the original implementation requires  $O(L^2)$ in serial time and memory as functions of input length $L$. Recent works proposed various linear self-attention mechanisms, scaling only as $O(L)$ for serial computation. We conduct a thorough complexity analysis of Performers, a class which includes most recent linear Transformer mechanisms. We note a remarkable computational flexibility: the gradient computation can be performed with no approximations using sublinear memory as a function of $L$ (in addition to negligible storage for the input sequence), at a cost of greater time complexity in the parallel setting. In the extreme case, a Performer consumes only $O(1)$ memory, and still requires $O(L)$ time. Due to complete backward-compatibility, this discovered time-memory tradeoff can be used for fine-tuning on low-memory devices in a decentralized fashion without any server computations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VQ-GNN", "Title": "A Universal Framework to Scale up Graph Neural Networks using Vector Quantization", "Abstract": "Most state-of-the-art Graph Neural Networks (GNNs) can be defined as a form of graph convolution which can be realized by message passing between direct neighbors or beyond. To scale such GNNs to large graphs, various neighbor-, layer-, or subgraph-sampling techniques are proposed to alleviate the \"neighbor explosion\" problem by considering only a small subset of messages passed to the nodes in a mini-batch. However, sampling-based methods are difficult to apply to GNNs that utilize many-hops-away or global context each layer, show unstable performance for different tasks and datasets, and do not speed up model inference. We propose a principled and fundamentally different approach, VQ-GNN, a universal framework to scale up any convolution-based GNNs using Vector Quantization (VQ) without compromising the performance. In contrast to sampling-based techniques, our approach can effectively preserve all the messages passed to a mini-batch of nodes by learning and updating a small number of quantized reference vectors of global node representations, using VQ within each GNN layer. Our framework avoids the \"neighbor explosion\" problem of GNNs using quantized representations combined with a low-rank version of the graph convolution matrix. We show that such a compact low-rank version of the gigantic convolution matrix is sufficient both theoretically and experimentally. In company with VQ, we design a novel approximated message passing algorithm and a nontrivial back-propagation rule for our framework. Experiments on various types of GNN backbones demonstrate the scalability and competitive performance of our framework on large-graph node classification and link prediction benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GemNet", "Title": "Universal Directional Graph Neural Networks for Molecules", "Abstract": "Effectively predicting molecular interactions has the potential to accelerate molecular dynamics by multiple orders of magnitude and thus revolutionize chemical simulations. Graph neural networks (GNNs) have recently shown great successes for this task, overtaking classical methods based on fixed molecular kernels. However, they still appear very limited from a theoretical perspective, since regular GNNs cannot distinguish certain types of graphs. In this work we close this gap between theory and practice. We show that GNNs with directed edge embeddings and two-hop message passing are indeed universal approximators for predictions that are invariant to translation, and equivariant to permutation and rotation. We then leverage these insights and multiple structural improvements to propose the geometric message passing neural network (GemNet). We demonstrate the benefits of the proposed changes in multiple ablation studies. GemNet outperforms previous models on the COLL, MD17, and OC20 datasets by 34%, 41%, and 20%, respectively, and performs especially well on the most challenging molecules. Our implementation is available online."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Shortest Path", "Title": "Minimax, Parameter-Free and Towards Horizon-Free Regret", "Abstract": "We study the problem of learning in the stochastic shortest path (SSP) setting, where an agent seeks to minimize the expected cost accumulated before reaching a goal state. We design a novel model-based algorithm EB-SSP that carefully skews the empirical transitions and perturbs the empirical costs with an exploration bonus to induce an optimistic SSP problem whose associated value iteration scheme is guaranteed to converge. We prove that EB-SSP achieves the minimax regret rate $\\widetilde{O}(B_{\\star} \\sqrt{S A K})$, where $K$ is the number of episodes, $S$ is the number of states, $A$ is the number of actions and $B_{\\star}$ bounds the expected cumulative cost of the optimal policy from any state, thus closing the gap with the lower bound. Interestingly, EB-SSP obtains this result while being parameter-free, i.e., it does not require any prior knowledge of $B_{\\star}$, nor of $T_{\\star}$, which bounds the expected time-to-goal of the optimal policy from any state. Furthermore, we illustrate various cases (e.g., positive costs, or general costs when an order-accurate estimate of $T_{\\star}$ is available) where the regret only contains a logarithmic dependence on $T_{\\star}$, thus yielding the first (nearly) horizon-free regret bound beyond the finite-horizon MDP setting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sim and Real", "Title": "Better Together", "Abstract": "Simulation is used extensively in autonomous systems, particularly in robotic manipulation. By far, the most common approach is to train a controller in simulation, and then use it as an initial starting point for the real system. We demonstrate how to learn simultaneously from both simulation and interaction with the real environment. We propose an algorithm for balancing the large number of samples from the high throughput but less accurate simulation and the low-throughput, high-fidelity and costly samples from the real environment. We achieve that by maintaining a replay buffer for each environment the agent interacts with. We analyze such multi-environment interaction theoretically, and provide convergence properties, through a novel theoretical replay buffer analysis.  We demonstrate the efficacy of our method on a sim-to-real environment."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Antipodes of Label Differential Privacy", "Title": "PATE and ALIBI", "Abstract": "We consider the privacy-preserving machine learning (ML) setting where the trained model must satisfy differential privacy (DP) with respect to the labels of the training examples. We propose two novel approaches based on, respectively, the Laplace mechanism and the PATE framework, and demonstrate their effectiveness on standard benchmarks.While recent work by Ghazi et al. proposed Label DP schemes based on a randomized response mechanism, we argue that additive Laplace noise coupled with Bayesian inference (ALIBI) is a better fit for typical ML tasks. Moreover, we show how to achieve very strong privacy levels in some regimes, with our adaptation of the PATE framework that builds on recent advances in semi-supervised learning.We complement theoretical analysis of our algorithms' privacy guarantees with empirical evaluation of their memorization properties. Our evaluation suggests that comparing different algorithms according to their provable DP guarantees can be misleading and favor a less private algorithm with a tighter analysis.Code for implementation of algorithms and memorization attacks is available from https://github.com/facebookresearch/labeldpantipodes."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Visual Search Asymmetry", "Title": "Deep Nets and Humans Share Similar Inherent Biases", "Abstract": "Visual search is a ubiquitous and often challenging daily task, exemplified by looking for the car keys at home or a friend in a crowd. An intriguing property of some classical search tasks is an asymmetry such that finding a target A among distractors B can be easier than finding B among A. To elucidate the mechanisms responsible for asymmetry in visual search, we propose a computational model that takes a target and a search image as inputs and produces a sequence of eye movements until the target is found. The model integrates eccentricity-dependent visual recognition with target-dependent top-down cues. We compared the model against human behavior in six paradigmatic search tasks that show asymmetry in humans. Without prior exposure to the stimuli or task-specific training, the model provides a plausible mechanism for search asymmetry. We hypothesized that the polarity of search asymmetry arises from experience with the natural environment. We tested this hypothesis by training the model on augmented versions of ImageNet where the biases of natural images were either removed or reversed. The polarity of search asymmetry disappeared or was altered depending on the training protocol. This study highlights how classical perceptual properties can emerge in neural network models, without the need for task-specific training, but rather as a consequence of the statistical properties of the developmental diet fed to the model. All source code and data are publicly available at https://github.com/kreimanlab/VisualSearchAsymmetry."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BooVI", "Title": "Provably Efficient Bootstrapped Value Iteration", "Abstract": "Despite the tremendous success of reinforcement learning (RL) with function approximation, efficient exploration remains a significant challenge, both practically and theoretically. In particular, existing theoretically grounded RL algorithms based on upper confidence bounds (UCBs), such as optimistic least-squares value iteration (LSVI), are often incompatible with practically powerful function approximators, such as neural networks. In this paper, we develop a variant of \\underline{boo}tstrapped LS\\underline{VI}, namely BooVI, which bridges such a gap between practice and theory. Practically, BooVI drives exploration through (re)sampling, making it compatible with general function approximators. Theoretically, BooVI inherits the worst-case $\\tilde{O}(\\sqrt{d^3 H^3 T})$-regret of optimistic LSVI in the episodic linear setting. Here $d$ is the feature dimension, $H$ is the episode horizon, and $T$ is the total number of steps."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ABC", "Title": "Auxiliary Balanced Classifier for Class-imbalanced Semi-supervised Learning", "Abstract": "Existing semi-supervised learning (SSL) algorithms typically assume class-balanced datasets, although the class distributions of many real world datasets are imbalanced. In general, classifiers trained on a class-imbalanced dataset are biased toward the majority classes. This issue becomes more problematic for SSL algorithms because they utilize the biased prediction of unlabeled data for training. However, traditional class-imbalanced learning techniques, which are designed for labeled data, cannot be readily combined with SSL algorithms. We propose a scalable class-imbalanced SSL algorithm that can effectively use unlabeled data, while mitigating class imbalance by introducing an auxiliary balanced classifier (ABC) of a single layer, which is attached to a representation layer of an existing SSL algorithm. The ABC is trained with a class-balanced loss of a minibatch, while using high-quality representations learned from all data points in the minibatch using the backbone SSL algorithm to avoid overfitting and information loss. Moreover, we use consistency regularization, a recent SSL technique for utilizing unlabeled data in a modified way, to train the ABC to be balanced among the classes by selecting unlabeled data with the same probability for each class. The proposed algorithm achieves state-of-the-art performance in various class-imbalanced SSL experiments using four benchmark datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BCD Nets", "Title": "Scalable Variational Approaches for Bayesian Causal Discovery", "Abstract": "A structural equation model (SEM) is an effective framework to reason over causal relationships represented via a directed acyclic graph (DAG).Recent advances have enabled effective maximum-likelihood point estimation of DAGs from observational data. However, a point estimate may not accurately capture the uncertainty in inferring the underlying graph in practical scenarios, wherein the true DAG is non-identifiable and/or the observed dataset is limited.We propose Bayesian Causal Discovery Nets (BCD Nets), a variational inference framework for estimating a distribution over DAGs characterizing a linear-Gaussian SEM.Developing a full Bayesian posterior over DAGs is challenging due to the the discrete and combinatorial nature of graphs.We analyse key design choices for scalable VI over DAGs, such as 1) the parametrization of DAGs via an expressive variational family, 2) a continuous relaxation that enables low-variance stochastic optimization, and 3) suitable priors over the latent variables.We provide a series of experiments on real and synthetic data showing that BCD Nets outperform maximum-likelihood methods on standard causal discovery metrics such as structural Hamming distance in low data regimes."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Information-constrained optimization", "Title": "can adaptive processing of gradients help?", "Abstract": "We revisit first-order optimization under local information constraints such as local privacy, gradient quantization, and computational constraints limiting access to a few coordinates of the gradient. In this setting, the optimization algorithm is not allowed to directly access the complete output of the gradient oracle, but only gets limited information about it subject to the local information constraints.   We study the role of adaptivity in processing the gradient output to obtain this limited information from it, and obtain tight or nearly tight bounds for both convex and strongly convex optimization when adaptive gradient processing is allowed."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning to Draw", "Title": "Emergent Communication through Sketching", "Abstract": "Evidence that visual communication preceded written language and provided a basis for it goes back to prehistory, in forms such as cave and rock paintings depicting traces of our distant ancestors. Emergent communication research has sought to explore how agents can learn to communicate in order to collaboratively solve tasks. Existing research has focused on language, with a learned communication channel transmitting sequences of discrete tokens between the agents. In this work, we explore a visual communication channel between agents that are allowed to draw with simple strokes. Our agents are parameterised by deep neural networks, and the drawing procedure is differentiable, allowing for end-to-end training. In the framework of a referential communication game, we demonstrate that agents can not only successfully learn to communicate by drawing, but with appropriate inductive biases, can do so in a fashion that humans can interpret. We hope to encourage future research to consider visual communication as a more flexible and directly interpretable alternative of training collaborative agents."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HRFormer", "Title": "High-Resolution Vision Transformer for Dense Predict", "Abstract": "We present a High-Resolution Transformer (HRFormer) that learns high-resolution representations for dense prediction tasks, in contrast to the original Vision Transformer that produces low-resolution representations and has high memory and computational cost. We take advantage of the multi-resolution parallel design introduced in high-resolution convolutional networks (HRNet [45]), along with local-window self-attention that performs self-attention over small non-overlapping image windows [21], for improving the memory and computation efficiency. In addition, we introduce a convolution into the FFN to exchange information across the disconnected image windows. We demonstrate the effectiveness of the HighResolution Transformer on both human pose estimation and semantic segmentation tasks, e.g., HRFormer outperforms Swin transformer [27] by 1.3 AP on COCO pose estimation with 50% fewer parameters and 30% fewer FLOPs. Code is available at: https://github.com/HRNet/HRFormer"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Manifold Topology Divergence", "Title": "a Framework for Comparing Data Manifolds.", "Abstract": "We propose a framework for comparing data manifolds, aimed, in particular, towards the evaluation of deep generative models. We describe a novel tool, Cross-Barcode(P,Q), that, given a pair of distributions in a high-dimensional space, tracks multiscale topology spacial discrepancies between manifolds on which the distributions are concentrated. Based on the Cross-Barcode, we introduce the Manifold Topology Divergence score (MTop-Divergence) and apply it to assess the performance of deep generative models in various domains: images, 3D-shapes, time-series, and on different datasets: MNIST, Fashion MNIST, SVHN, CIFAR10, FFHQ, market stock data, ShapeNet. We demonstrate that the MTop-Divergence accurately detects various degrees of mode-dropping, intra-mode collapse, mode invention, and image disturbance. Our algorithm scales well (essentially linearly) with the increase of the dimension of the ambient high-dimensional space. It is one of the first TDA-based methodologies that can be applied universally to datasets of different sizes and dimensions, including the ones on which the most recent GANs in the visual domain are trained. The proposed method is domain agnostic and does not rely on pre-trained networks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shape your Space", "Title": "A Gaussian Mixture Regularization Approach to Deterministic Autoencoders", "Abstract": "Variational Autoencoders (VAEs) are powerful probabilistic models to learn representations of complex data distributions. One important limitation of VAEs is the strong prior assumption that latent representations learned by the model follow a simple uni-modal Gaussian distribution. Further, the variational training procedure poses considerable practical challenges. Recently proposed regularized autoencoders offer a deterministic autoencoding framework, that simplifies the original VAE objective and is significantly easier to train. Since these models only provide weak control over the learned latent distribution, they require an ex-post density estimation step to generate samples comparable to those of VAEs. In this paper, we propose a simple and end-to-end trainable deterministic autoencoding framework, that efficiently shapes the latent space of the model during training and utilizes the capacity of expressive multi-modal latent distributions. The proposed training procedure provides direct evidence if the latent distribution adequately captures complex aspects of the encoded data. We show in experiments the expressiveness and sample quality of our model in various challenging continuous and discrete domains. An implementation is available at https://github.com/boschresearch/GMM_DAE."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "An Even More Optimal Stochastic Optimization Algorithm", "Title": "Minibatching and Interpolation Learning", "Abstract": "We present and analyze an algorithm for optimizing smooth and convex or strongly convex objectives using minibatch stochastic gradient estimates. The algorithm is optimal with respect to its dependence on both the minibatch size and minimum expected loss simultaneously. This improves over the optimal method of Lan, which is insensitive to the minimum expected loss; over the optimistic acceleration of Cotter et al., which has suboptimal dependence on the minibatch size; and over the algorithm of Liu and Belkin, which is limited to least squares problems and is also similarly suboptimal.  Applied to interpolation learning, the improvement over Cotter et al.~and Liu and Belkin translates to a linear, rather than square-root, parallelization speedup."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SOAT", "Title": "A Scene- and Object-Aware Transformer for Vision-and-Language Navigation", "Abstract": "Natural language instructions for visual navigation often use scene descriptions (e.g., bedroom) and object references (e.g., green chairs) to provide a breadcrumb trail to a goal location. This work presents a transformer-based vision-and-language navigation (VLN) agent that uses two different visual encoders -- a scene classification network and an object detector -- which produce features that match these two distinct types of visual cues. In our method, scene features contribute high-level contextual information that supports object-level processing. With this design, our model is able to use vision-and-language pretraining (i.e., learning the alignment between images and text from large-scale web data) to substantially improve performance on the Room-to-Room (R2R) and Room-Across-Room (RxR) benchmarks. Specifically, our approach leads to improvements of 1.8% absolute in SPL on R2R and 3.7% absolute in SR on RxR. Our analysis reveals even larger gains for navigation instructions that contain six or more object references, which further suggests that our approach is better able to use object features and align them to references in the instructions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distribution-free inference for regression", "Title": "discrete, continuous, and in between", "Abstract": "In data analysis problems where we are not able to rely on distributional assumptions, what types of inference guarantees can still be obtained? Many popular methods, such as holdout methods, cross-validation methods, and conformal prediction, are able to provide distribution-free guarantees for predictive inference, but the problem of providing inference for the underlying regression function (for example, inference on the conditional mean $\\mathbb{E}[Y|X]$) is more challenging. In the setting where the features $X$ are continuously distributed, recent work has established that any confidence interval for $\\mathbb{E}[Y|X]$ must have non-vanishing width, even as sample size tends to infinity. At the other extreme, if $X$ takes only a small number of possible values, then inference on $\\mathbb{E}[Y|X]$ is trivial to achieve. In this work, we study the problem in settings in between these two extremes. We find that there are several distinct regimes in between the finite setting and the continuous setting, where vanishing-width confidence intervals are achievable if and only if the effective support size of the distribution of $X$ is smaller than the square of the sample size."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeuroLKH", "Title": "Combining Deep Learning Model with Lin-Kernighan-Helsgaun Heuristic for Solving the Traveling Salesman Problem", "Abstract": "We present NeuroLKH, a novel algorithm that combines deep learning with the strong traditional heuristic Lin-Kernighan-Helsgaun (LKH) for solving Traveling Salesman Problem. Specifically, we train a Sparse Graph Network (SGN) with supervised learning for edge scores and unsupervised learning for node penalties, both of which are critical for improving the performance of LKH. Based on the output of SGN, NeuroLKH creates the edge candidate set and transforms edge distances to guide the searching process of LKH. Extensive experiments firmly demonstrate that, by training one model on a wide range of problem sizes, NeuroLKH significantly outperforms LKH and generalizes well to much larger sizes. Also, we show that NeuroLKH can be applied to other routing problems such as Capacitated Vehicle Routing Problem (CVRP), Pickup and Delivery Problem (PDP), and CVRP with Time Windows (CVRPTW)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LSH-SMILE", "Title": "Locality Sensitive Hashing Accelerated Simulation and Learning", "Abstract": "The advancement of deep neural networks over the last decade has enabled progress in scientific knowledge discovery in the form of learning Partial Differential Equations (PDEs) directly from experiment data. Nevertheless, forward simulation and backward learning of large-scale dynamic systems require handling billions of mutually interacting elements, the scale of which overwhelms current computing architectures. We propose Locality Sensitive Hashing Accelerated Simulation and Learning (LSH-SMILE), a unified framework to scale up both forward simulation and backward learning of physics systems. LSH-SMILE takes advantage of (i) the locality of PDE updates, (ii) similar temporal dynamics shared by multiple elements. LSH-SMILE hashes elements with similar dynamics into a single hash bucket and handles their updates at once. This allows LSH-SMILE to scale with respect to the number of non-empty hash buckets, a drastic improvement over conventional approaches. Theoretically, we prove a novel bound on the errors introduced by LSH-SMILE. Experimentally, we demonstrate that LSH-SMILE simulates physics systems at comparable quality with exact approaches, but with way less time and space complexity. Such savings also translate to better learning performance due to LSH-SMILE's ability to propagate gradients over a long duration."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LEADS", "Title": "Learning Dynamical Systems that Generalize Across Environments", "Abstract": "When modeling dynamical systems from real-world data samples, the distribution of data often changes according to the environment in which they are captured, and the dynamics of the system itself vary from one environment to another. Generalizing across environments thus challenges the conventional frameworks. The classical settings suggest either considering data as i.i.d and learning a single model to cover all situations or learning environment-specific models. Both are sub-optimal: the former disregards the discrepancies between environments leading to biased solutions, while the latter does not exploit their potential commonalities and is prone to scarcity problems. We propose LEADS, a novel framework that leverages the commonalities and discrepancies among known environments to improve model generalization. This is achieved with a tailored training formulation aiming at capturing common dynamics within a shared model while additional terms capture environment-specific dynamics. We ground our approach in theory, exhibiting a decrease in sample complexity w.r.t classical alternatives.  We show how theory and practice coincides on the simplified case of linear dynamics. Moreover, we instantiate this framework for neural networks and evaluate it experimentally on representative families of nonlinear dynamics. We show that this new setting can exploit knowledge extracted from environment-dependent data and improves generalization for both known and novel environments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Storchastic", "Title": "A Framework for General Stochastic Automatic Differentiation", "Abstract": "Modelers use automatic differentiation (AD) of computation graphs to implement complex Deep Learning models without defining gradient computations. Stochastic AD extends AD to stochastic computation graphs with sampling steps, which arise when modelers handle the intractable expectations common in Reinforcement Learning and Variational Inference. However, current methods for stochastic AD are limited: They are either only applicable to continuous random variables and differentiable functions, or can only use simple but high variance score-function estimators. To overcome these limitations, we introduce Storchastic, a new framework for AD of stochastic computation graphs. Storchastic allows the modeler to choose from a wide variety of gradient estimation methods at each sampling step, to optimally reduce the variance of the gradient estimates. Furthermore, Storchastic is provably unbiased for estimation of any-order gradients, and generalizes variance reduction techniques to higher-order gradient estimates. Finally, we implement Storchastic as a PyTorch library at github.com/HEmile/storchastic."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SADGA", "Title": "Structure-Aware Dual Graph Aggregation Network for Text-to-SQL", "Abstract": "The Text-to-SQL task, aiming to translate the natural language of the questions into SQL queries, has drawn much attention recently.  One of the most challenging problems of Text-to-SQL is how to generalize the trained model to the unseen database schemas, also known as the cross-domain Text-to-SQL task. The key lies in the generalizability of (i) the encoding method to model the question and the database schema and (ii) the question-schema linking method to learn the mapping between words in the question and tables/columns in the database schema. Focusing on the above two key issues, we propose a \\emph{Structure-Aware Dual Graph Aggregation Network} (SADGA) for cross-domain Text-to-SQL. In SADGA, we adopt the graph structure to provide a unified encoding model for both the natural language question and database schema. Based on the proposed unified modeling, we further devise a structure-aware aggregation method to learn the mapping between the question-graph and schema-graph. The structure-aware aggregation method is featured with \\emph{Global Graph Linking}, \\emph{Local Graph Linking} and \\emph{Dual-Graph Aggregation Mechanism}. We not only study the performance of our proposal empirically but also achieved 3rd place on the challenging Text-to-SQL benchmark Spider at the time of writing."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "To The Point", "Title": "Correspondence-driven monocular 3D category reconstruction", "Abstract": "We present To The Point (TTP), a method for reconstructing 3D objects from a single image using 2D to 3D correspondences given only foreground masks, a category specific template and optionally sparse keypoints for supervision.  We recover a 3D shape from a 2D image by first regressing the 2D positions corresponding to the 3D template vertices and then jointly estimating a rigid camera transform and non-rigid template deformation that optimally explain the 2D positions through the 3D shape projection. By relying on correspondences we use a simple per-sample optimization problem to replace CNN-based regression of camera pose and non-rigid deformation and thereby obtain substantially more accurate 3D reconstructions. We treat this optimization as a differentiable layer and train the whole system in an end-to-end manner using geometry-driven losses. We report systematic quantitative improvements on multiple categories and provide qualitative results comprising diverse shape, poses and texture prediction examples."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One More Step Towards Reality", "Title": "Cooperative Bandits with Imperfect Communication", "Abstract": "The cooperative bandit problem is increasingly becoming relevant due to its applications in large-scale decision-making. However, most research for this problem focuses exclusively on the setting with perfect communication, whereas in most real-world distributed settings, communication is often over stochastic networks, with arbitrary corruptions and delays. In this paper, we study cooperative bandit learning under three typical real-world communication scenarios, namely, (a) message-passing over stochastic time-varying networks, (b) instantaneous reward-sharing over a network with random delays, and (c) message-passing with adversarially corrupted rewards, including byzantine communication. For each of these environments, we propose decentralized algorithms that achieve competitive performance, along with near-optimal guarantees on the incurred group regret as well. Furthermore, in the setting with perfect  communication, we present an improved delayed-update algorithm that outperforms the existing state-of-the-art on various network topologies. Finally, we present tight network-dependent minimax lower bounds on the group regret. Our proposed algorithms are straightforward to implement and obtain competitive empirical performance."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The future is log-Gaussian", "Title": "ResNets and their infinite-depth-and-width limit at initialization", "Abstract": "Theoretical results show that neural networks can be approximated by Gaussian processes in the infinite-width limit. However, for fully connected networks, it has been previously shown that for any fixed network width, $n$, the Gaussian approximation gets worse as the network depth, $d$, increases. Given that modern networks are deep, this raises the question of how well modern architectures, like ResNets, are captured by the infinite-width limit. To provide a better approximation, we study ReLU ResNets in the infinite-depth-and-width limit, where \\emph{both} depth and width tend to infinity as their ratio, $d/n$, remains constant. In contrast to the Gaussian infinite-width limit, we show theoretically that the network exhibits log-Gaussian behaviour at initialization in the infinite-depth-and-width limit, with parameters depending on the ratio $d/n$. Using Monte Carlo simulations, we demonstrate that even basic properties of standard ResNet architectures are poorly captured by the Gaussian limit, but remarkably well captured by our log-Gaussian limit. Moreover, our analysis reveals that ReLU ResNets at initialization are hypoactivated: fewer than half of the ReLUs are activated. Additionally, we calculate the interlayer correlations, which have the effect of exponentially increasing the variance of the network output. Based on our analysis, we introduce \\emph{Balanced ResNets}, a simple architecture modification, which eliminates hypoactivation and interlayer correlations and is more amenable to theoretical analysis."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Proxy Convexity", "Title": "A Unified Framework for the Analysis of Neural Networks Trained by Gradient Descent", "Abstract": "Although the optimization objectives for learning neural networks are highly non-convex, gradient-based methods have been wildly successful at learning neural networks in practice. This juxtaposition has led to a number of recent studies on provable guarantees for neural networks trained by gradient descent. Unfortunately, the techniques in these works are often highly specific to the particular setup in each problem, making it difficult to generalize across different settings. To address this drawback in the literature, we propose a unified non-convex optimization framework for the analysis of neural network training. We introduce the notions of proxy convexity and proxy Polyak-Lojasiewicz (PL) inequalities, which are satisfied if the original objective function induces a proxy objective function that is implicitly minimized when using gradient methods. We show that stochastic gradient descent (SGD) on objectives satisfying proxy convexity or the proxy PL inequality leads to efficient guarantees for proxy objective functions. We further show that many existing guarantees for neural networks trained by gradient descent can be unified through proxy convexity and proxy PL inequalities."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "KALE Flow", "Title": "A Relaxed KL Gradient Flow for Probabilities with Disjoint Support", "Abstract": "We study the gradient flow for a relaxed approximation to the Kullback-Leibler (KL) divergencebetween a moving source and a fixed target distribution.This approximation, termed theKALE (KL approximate lower-bound estimator), solves a regularized version ofthe Fenchel dual problem defining the KL over a restricted class of functions.When using a Reproducing Kernel Hilbert Space (RKHS) to define the functionclass, we show that the KALE continuously interpolates between the KL and theMaximum Mean Discrepancy (MMD). Like the MMD and other Integral ProbabilityMetrics, the KALE remains well defined for mutually singulardistributions. Nonetheless, the KALE inherits from the limiting KL a greater sensitivity to mismatch in the support of the distributions, compared with the MMD. These two properties make theKALE gradient flow particularly well suited when the target distribution is supported on a low-dimensional manifold. Under an assumption of sufficient smoothness of the trajectories, we show the global convergence of the KALE flow. We propose a particle implementation of the flow given initial samples from the source and the target distribution, which we use to empirically confirm the KALE's properties."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Relational Self-Attention", "Title": "What's Missing in Attention for Video Understanding", "Abstract": "Convolution has been arguably the most important feature transform for modern neural networks, leading to the advance of deep learning.  Recent emergence of Transformer networks, which replace convolution layers with self-attention blocks,  has revealed the limitation of stationary convolution kernels and opened the door to the era of dynamic feature transforms. The existing dynamic transforms, including self-attention, however, are all limited for video understanding where correspondence relations in space and time, i.e., motion information, are crucial for effective representation. In this work, we introduce a relational feature transform, dubbed the relational self-attention (RSA), that leverages rich structures of spatio-temporal relations in videos by dynamically generating relational kernels and aggregating relational contexts. Our experiments and ablation studies show that the RSA network substantially outperforms convolution and self-attention counterparts, achieving the state of the art on the standard motion-centric benchmarks for video action recognition, such as Something-Something-V1&V2, Diving48, and FineGym."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GENESIS-V2", "Title": "Inferring Unordered Object Representations without Iterative Refinement", "Abstract": "Advances in unsupervised learning of object-representations have culminated in the development of a broad range of methods for unsupervised object segmentation and interpretable object-centric scene generation. These methods, however, are limited to simulated and real-world datasets with limited visual complexity. Moreover, object representations are often inferred using RNNs which do not scale well to large images or iterative refinement which avoids imposing an unnatural ordering on objects in an image but requires the a priori initialisation of a fixed number of object representations. In contrast to established paradigms, this work proposes an embedding-based approach in which embeddings of pixels are clustered in a differentiable fashion using a stochastic stick-breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-v2, which can infer a variable number of object representations without using RNNs or iterative refinement. We show that GENESIS-v2 performs strongly in comparison to recent baselines in terms of unsupervised image segmentation and object-centric scene generation on established synthetic datasets as well as more complex real-world datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mixture Proportion Estimation and PU Learning", "Title": "A Modern Approach", "Abstract": "Given only positive examples and unlabeled examples (from both positive and negative classes), we might hope nevertheless to estimate an accurate positive-versus-negative classifier. Formally, this task is broken down into two subtasks: (i) Mixture Proportion Estimation (MPE)---determining the fraction of positive examples in the unlabeled data; and (ii) PU-learning---given such an estimate, learning the desired positive-versus-negative classifier. Unfortunately, classical methods for both problems break down in high-dimensional settings. Meanwhile, recently proposed heuristics lack theoretical coherence and depend precariously on hyperparameter tuning. In this paper, we propose two simple techniques: Best Bin Estimation (BBE) (for MPE); and Conditional Value Ignoring Risk (CVIR), a simple objective for PU-learning. Both methods dominate previous approaches empirically, and for BBE, we establish formal guarantees that hold whenever we can train a model to cleanly separate out a small subset of positive examples. Our final algorithm (TED)$^n$, alternates between the two procedures, significantly improving both our mixture proportion estimator and classifier"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AC/DC", "Title": "Alternating Compressed/DeCompressed Training of Deep Neural Networks", "Abstract": "The increasing computational requirements of deep neural networks (DNNs) have led to significant interest in obtaining DNN models that are sparse, yet accurate. Recent work has investigated the even harder case of sparse training, where the DNN weights are, for as much as possible, already sparse to reduce computational costs during training. Existing sparse training methods are often empirical and can have lower accuracy relative to the dense baseline. In this paper, we present a general approach called Alternating Compressed/DeCompressed (AC/DC) training of DNNs, demonstrate convergence for a variant of the algorithm,  and show that AC/DC outperforms existing sparse training methods in accuracy at similar computational budgets; at high sparsity levels, AC/DC even outperforms existing methods that rely on accurate pre-trained dense models. An important property of AC/DC is that it allows co-training of dense and sparse models, yielding accurate sparse-dense model pairs at the end of the training process. This is useful in practice, where compressed variants may be desirable for deployment in resource-constrained settings without re-doing the entire training flow, and also provides us with insights into the accuracy gap between dense and compressed models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HyperSPNs", "Title": "Compact and Expressive Probabilistic Circuits", "Abstract": "Probabilistic circuits (PCs) are a family of generative models which allows for the computation of exact likelihoods and marginals of its probability distributions. PCs are both expressive and tractable, and serve as popular choices for discrete density estimation tasks. However, large PCs are susceptible to overfitting, and only a few regularization strategies (e.g., dropout, weight-decay) have been explored. We propose HyperSPNs: a new paradigm of generating the mixture weights of large PCs using a small-scale neural network. Our framework can be viewed as a soft weight-sharing strategy, which combines the greater expressiveness of large models with the better generalization and memory-footprint properties of small models.  We show the merits of our regularization strategy on two state-of-the-art PC families introduced in recent literature -- RAT-SPNs and EiNETs -- and demonstrate generalization improvements in both models on a suite of density estimation benchmarks in both discrete and continuous domains."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "L2ight", "Title": "Enabling On-Chip Learning for Optical Neural Networks via Efficient in-situ Subspace Optimization", "Abstract": "Silicon-photonics-based optical neural network (ONN) is a promising hardware platform that could represent a paradigm shift in efficient AI with its CMOS-compatibility, flexibility, ultra-low execution latency, and high energy efficiency. In-situ training on the online programmable photonic chips is appealing but still encounters challenging issues in on-chip implementability, scalability, and efficiency. In this work, we propose a closed-loop ONN on-chip learning framework L2ight to enable scalable ONN mapping and efficient in-situ learning. L2ight adopts a three-stage learning flow that first calibrates the complicated photonic circuit states under challenging physical constraints, then performs photonic core mapping via combined analytical solving and zeroth-order optimization. A subspace learning procedure with multi-level sparsity is integrated into L2ight to enable in-situ gradient evaluation and fast adaptation, unleashing the power of optics for real on-chip intelligence. Extensive experiments demonstrate our proposed L2ight outperforms prior ONN training protocols with 3-order-of-magnitude higher scalability and over 30x better efficiency, when benchmarked on various models and learning tasks. This synergistic framework is the first scalable on-chip learning solution that pushes this emerging field from intractable to scalable and further to efficient for next-generation self-learnable photonic neural chips. From a co-design perspective, L2ight also provides essential insights for hardware-restricted unitary subspace optimization and efficient sparse training. We open-source our framework at the link."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Synthetic Design", "Title": "An Optimization Approach to Experimental Design with Synthetic Controls", "Abstract": "We investigate the optimal design of experimental studies that have pre-treatment outcome data available.  The average treatment effect is estimated as the difference between the weighted average outcomes of the treated and control units. A number of commonly used approaches fit this formulation, including the difference-in-means estimator and a variety of synthetic-control techniques. We propose several methods for choosing the set of treated units in conjunction with the weights. Observing the NP-hardness of the problem, we introduce a mixed-integer programming formulation which selects both the treatment and control sets and unit weightings. We prove that these proposed approaches lead to qualitatively different experimental units being selected for treatment. We use simulations based on publicly available data from the US Bureau of Labor Statistics that show improvements in terms of mean squared error and statistical power when compared to simple and commonly used alternatives such as randomized trials."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Unbalanced Gromov Wasserstein Distance", "Title": "Conic Formulation and Relaxation", "Abstract": "Comparing metric measure spaces (i.e. a metric space endowed with a probability distribution) is at the heart of many machine learning problems. The most popular distance between such metric measure spaces is the Gromov-Wasserstein (GW) distance, which is the solution of a quadratic assignment problem. The GW distance is however limited to the comparison of metric measure spaces endowed with a \\emph{probability} distribution. To alleviate this issue, we introduce two Unbalanced Gromov-Wasserstein formulations: a distance and a more tractable upper-bounding relaxation.  They both allow the comparison of metric spaces equipped with arbitrary positive measures up to isometries. The first formulation is a positive and definite divergence based on a relaxation of the mass conservation constraint using a novel type of quadratically-homogeneous divergence. This divergence works hand in hand with the entropic regularization approach which is popular to solve large scale optimal transport problems. We show that the underlying non-convex optimization problem can be efficiently tackled using a highly parallelizable and GPU-friendly iterative scheme. The second formulation is a distance between mm-spaces up to isometries based on a conic lifting.  Lastly, we provide numerical experiments on synthetic and domain adaptation data with a Positive-Unlabeled learning task to highlight the salient features of the unbalanced divergence and its potential applications in ML."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning MDPs from Features", "Title": "Predict-Then-Optimize for Sequential Decision Making by Reinforcement Learning", "Abstract": "In the predict-then-optimize framework, the objective is to train a predictive model, mapping from environment features to parameters of an optimization problem, which maximizes decision quality when the optimization is subsequently solved. Recent work on decision-focused learning shows that embedding the optimization problem in the training pipeline can improve decision quality and help generalize better to unseen tasks compared to relying on an intermediate loss function for evaluating prediction quality. We study the predict-then-optimize framework in the context of sequential decision problems (formulated as MDPs) that are solved via reinforcement learning. In particular, we are given environment features and a set of trajectories from training MDPs, which we use to train a predictive model that generalizes to unseen test MDPs without trajectories. Two significant computational challenges arise in applying decision-focused learning to MDPs: (i) large state and action spaces make it infeasible for existing techniques to differentiate through MDP problems, and (ii) the high-dimensional policy space, as parameterized by a neural network, makes differentiating through a policy expensive. We resolve the first challenge by sampling provably unbiased derivatives to approximate and differentiate through optimality conditions, and the second challenge by using a low-rank approximation to the high-dimensional sample-based derivatives. We implement both Bellman-based and policy gradient-based decision-focused learning on three different MDP problems with missing parameters, and show that decision-focused learning performs better in generalization to unseen tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SAPE", "Title": "Spatially-Adaptive Progressive Encoding for Neural Optimization", "Abstract": "Multilayer-perceptrons (MLP)  are known to struggle learning functions of high-frequencies, and in particular, instances of wide frequency bands.We present a progressive mapping scheme for input signals of MLP networks, enabling them to better fit a wide range of frequencies without sacrificing training stability or requiring any domain specific preprocessing. We introduce Spatially Adaptive Progressive Encoding (SAPE) layers, which gradually unmask signal components with increasing frequencies as a function of time and space. The progressive exposure of frequencies is monitored by a feedback loop throughout the neural optimization process, allowing changes to propagate at different rates among local spatial portions of the signal space. We demonstrate the advantage of our method on variety of domains and applications: regression of low dimensional signals and images, representation learning of occupancy networks, and a geometric task of mesh transfer between 3D shapes."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Equilibrium Refinement for the Age of Machines", "Title": "The One-Sided Quasi-Perfect Equilibrium", "Abstract": "In two-player zero-sum extensive-form games, Nash equilibrium prescribes optimal strategies against perfectly rational opponents. However, it does not guarantee rational play in parts of the game tree that can only be reached by the players making mistakes. This can be problematic when operationalizing equilibria in the real world among imperfect players. Trembling-hand refinements are a sound remedy to this issue, and are subsets of Nash equilibria that are designed to handle the possibility that any of the players may make mistakes. In this paper, we initiate the study of equilibrium refinements for settings where one of the players is perfectly rational (the ``machine'') and the other may make mistakes. As we show, this endeavor has many pitfalls: many intuitively appealing approaches to refinement fail in various ways. On the positive side, we introduce a modification of the classical quasi-perfect equilibrium (QPE) refinement, which we call the one-sided quasi-perfect equilibrium. Unlike QPE, one-sided QPE only accounts for mistakes from one player and assumes that no mistakes will be made by the machine. We present experiments on standard benchmark games and an endgame from the famous man-machine match where the AI Libratus was the first to beat top human specialist professionals in heads-up no-limit Texas hold'em poker. We show that one-sided QPE can be computed more efficiently than all known prior refinements, paving the way to wider adoption of Nash equilibrium refinements in settings with perfectly rational machines (or humans perfectly actuating machine-generated strategies) that interact with players prone to mistakes. We also show that one-sided QPE tends to play better than a Nash equilibrium strategy against imperfect opponents."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multiple Descent", "Title": "Design Your Own Generalization Curve", "Abstract": "This paper explores the generalization loss of linear regression in variably parameterized families of models, both under-parameterized and over-parameterized. We show that the generalization curve can have an arbitrary number of peaks, and moreover, the locations of those peaks can be explicitly controlled. Our results highlight the fact that both the classical U-shaped generalization curve and the recently observed double descent curve are not intrinsic properties of the model family. Instead, their emergence is due to the interaction between the properties of the data and the inductive biases of learning algorithms."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gone Fishing", "Title": "Neural Active Learning with Fisher Embeddings", "Abstract": "There is an increasing need for effective active learning algorithms that are compatible with deep neural networks. This paper motivates and revisits a classic, Fisher-based active selection objective, and proposes BAIT, a practical, tractable, and high-performing algorithm that makes it viable for use with neural models. BAIT draws inspiration from the theoretical analysis of maximum likelihood estimators (MLE) for parametric models. It selects batches of samples by optimizing a bound on the MLE error in terms of the Fisher information, which we show can be implemented efficiently at scale by exploiting linear-algebraic structure especially amenable to execution on modern hardware. Our experiments demonstrate that BAIT outperforms the previous state of the art on both classification and regression problems, and is flexible enough to be used with a variety of model architectures."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Going Beyond Linear RL", "Title": "Sample Efficient Neural Function Approximation", "Abstract": "Deep Reinforcement Learning (RL) powered by neural net approximation of the Q function has had enormous empirical success. While the theory of RL has traditionally focused on linear function approximation (or eluder dimension) approaches, little is known about nonlinear RL with neural net approximations of the Q functions. This is the focus of this work, where we study function approximation with two-layer neural networks (considering both ReLU and polynomial activation functions).  Our first result is a computationally and statistically efficient algorithm in the generative model setting under completeness for two-layer neural networks. Our second result considers this setting but under only realizability of the neural net function class.  Here, assuming deterministic dynamics, the sample complexity scales linearly in the algebraic dimension. In all cases, our results significantly improve upon what can be attained with linear (or eluder dimension) methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scalable Neural Data Server", "Title": "A Data Recommender for Transfer Learning", "Abstract": "Absence of large-scale labeled data in the practitioner's target domain can be a bottleneck to applying machine learning algorithms in practice. Transfer learning is a popular strategy for leveraging additional data to improve the downstream performance, but finding the most relevant data to transfer from can be challenging. Neural Data Server (NDS), a search engine that recommends relevant data for a given downstream task, has been previously proposed to address this problem (Yan et al., 2020). NDS uses a mixture of experts trained on data sources to estimate similarity between each source and the downstream task. Thus, the computational cost to each user grows with the number of sources and requires an expensive training step for each data provider.To address these issues, we propose Scalable Neural Data Server (SNDS), a large-scale search engine that can theoretically index thousands of datasets to serve relevant ML data to end users. SNDS trains the mixture of experts on intermediary datasets during initialization, and represents both data sources and downstream tasks by their proximity to the intermediary datasets. As such, computational cost incurred by users of SNDS remains fixed as new datasets are added to the server, without pre-training for the data providers.We validate SNDS on a plethora of real world tasks and find that data recommended by SNDS improves downstream task performance over baselines. We also demonstrate the scalability of our system by demonstrating its ability to select relevant data for transfer outside of the natural image setting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CATs", "Title": "Cost Aggregation Transformers for Visual Correspondence", "Abstract": "We propose a novel cost aggregation network, called Cost Aggregation Transformers (CATs), to find dense correspondences between semantically similar images with additional challenges posed by large intra-class appearance and geometric variations. Cost aggregation is a highly important process in matching tasks, which the matching accuracy depends on the quality of its output. Compared to hand-crafted or CNN-based methods addressing the cost aggregation, in that either lacks robustness to severe deformations or inherit the limitation of CNNs that fail to discriminate incorrect matches due to limited receptive fields, CATs explore global consensus among initial correlation map with the help of some architectural designs that allow us to fully leverage self-attention mechanism. Specifically, we include appearance affinity modeling to aid the cost aggregation process in order to disambiguate the noisy initial correlation maps and propose multi-level aggregation to efficiently capture different semantics from hierarchical feature representations. We then combine with swapping self-attention technique and residual connections not only to enforce consistent matching, but also to ease the learning process, which we find that these result in an apparent performance boost. We conduct experiments to demonstrate the effectiveness of the proposed model over the latest methods and provide extensive ablation studies. Code and trained models are available at https://sunghwanhong.github.io/CATs/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Labeling Trick", "Title": "A Theory of Using Graph Neural Networks for Multi-Node Representation Learning", "Abstract": "In this paper, we provide a theory of using graph neural networks (GNNs) for multi-node representation learning (where we are interested in learning a representation for a set of more than one node, such as link). We know that GNN is designed to learn single-node representations. When we want to learn a node set representation involving multiple nodes, a common practice in previous works is to directly aggregate the single-node representations obtained by a GNN into a joint node set representation. In this paper, we show a fundamental constraint of such an approach, namely the inability to capture the dependence between nodes in the node set, and argue that directly aggregating individual node representations does not lead to an effective joint representation for multiple nodes. Then, we notice that a few previous successful works for multi-node representation learning, including SEAL, Distance Encoding, and ID-GNN, all used node labeling. These methods first label nodes in the graph according to their relationships with the target node set before applying a GNN. Then, the node representations obtained in the labeled graph are aggregated into a node set representation. By investigating their inner mechanisms, we unify these node labeling techniques into a single and most general form---labeling trick. We prove that with labeling trick a sufficiently expressive GNN learns the most expressive node set representations, thus in principle solves any joint learning tasks over node sets. Experiments on one important two-node representation learning task, link prediction, verified our theory. Our work explains the superior performance of previous node-labeling-based methods, and establishes a theoretical foundation of using GNNs for multi-node representation learning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SUPER-ADAM", "Title": "Faster and Universal Framework of Adaptive Gradients", "Abstract": "Adaptive gradient methods have shown excellent performances for solving many machine learning problems. Although multiple adaptive gradient  methods were recently studied, they mainly focus on either empirical or theoretical aspects and also only work for specific problems by using some  specific adaptive learning rates. Thus, it is desired to design  a  universal  framework for practical algorithms of adaptive gradients with theoretical guarantee to solve general problems. To fill this gap, we propose a faster and universal framework of adaptive gradients (i.e., SUPER-ADAM) by introducing a universal adaptive matrix that includes most existing adaptive gradient forms. Moreover, our framework can flexibly integrate the momentum and variance reduced techniques. In particular, our novel framework provides the convergence analysis support for adaptive gradient methods under the nonconvex setting. In theoretical analysis, we prove that our SUPER-ADAM algorithm can achieve the best known gradient (i.e., stochastic first-order oracle (SFO)) complexity of $\\tilde{O}(\\epsilon^{-3})$ for finding an $\\epsilon$-stationary point of nonconvex optimization, which matches the lower bound for stochastic smooth nonconvex optimization. In numerical experiments, we employ various deep learning tasks to validate that our algorithm consistently outperforms the existing adaptive algorithms. Code is available at https://github.com/LIJUNYI95/SuperAdam"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "When Expressivity Meets Trainability", "Title": "Fewer than $n$ Neurons Can Work", "Abstract": "Modern neural networks are often quite wide, causing large memory and computation costs. It is thus of great interest to train a narrower network. However, training narrow neural nets remains a challenging task. We ask two theoretical questions: Can narrow networks have as strong expressivity as wide ones? If so, does the loss function exhibit a  benign optimization landscape? In this work, we provide partially affirmative answers to both questions for 1-hidden-layer networks with fewer than $n$ (sample size) neurons when the activation is smooth.  First, we prove that as long as the width $m \\geq 2n/d$ (where $d$ is the input dimension), its expressivity is strong, i.e., there exists at least one global minimizer with zero training loss. Second, we identify a nice local region with no local-min or saddle points. Nevertheless, it is not clear whether gradient descent can stay in this nice region. Third, we consider a constrained optimization formulation where the feasible region is the nice local region, and prove that every KKT point is a nearly global minimizer. It is expected that projected gradient methods converge to KKT points under mild technical conditions, but we leave the rigorous convergence analysis to future work. Thorough numerical results show that projected gradient methods on this constrained formulation significantly outperform SGD for training narrow neural nets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "An Image is Worth More Than a Thousand Words", "Title": "Towards Disentanglement in The Wild", "Abstract": "Unsupervised disentanglement has been shown to be theoretically impossible without inductive biases on the models and the data. As an alternative approach, recent methods rely on limited supervision to disentangle the factors of variation and allow their identifiability. While annotating the true generative factors is only required for a limited number of observations, we argue that it is infeasible to enumerate all the factors of variation that describe a real-world image distribution. To this end, we propose a method for disentangling a set of factors which are only partially labeled, as well as separating the complementary set of residual factors that are never explicitly specified. Our success in this challenging setting, demonstrated on synthetic benchmarks, gives rise to leveraging off-the-shelf image descriptors to partially annotate a subset of attributes in real image domains (e.g. of human faces) with minimal manual effort. Specifically, we use a recent language-image embedding model (CLIP) to annotate a set of attributes of interest in a zero-shot manner and demonstrate state-of-the-art disentangled image manipulation results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Hierarchical Clustering", "Title": "$O(1)$-Approximation for Well-Clustered Graphs", "Abstract": "Hierarchical clustering  studies a recursive partition of a data set into clusters of successively smaller size, and is a fundamental problem in data analysis. In this work we study the cost function for hierarchical clustering introduced by Dasgupta, and present two polynomial-time approximation algorithms: Our first result is an $O(1)$-approximation algorithm for graphs of high conductance. Our simple construction bypasses complicated recursive routines of finding sparse cuts known in the literature. Our second and main result is an $O(1)$-approximation algorithm for a wide family of graphs that exhibit a well-defined structure of clusters. This result generalises the previous state-of-the-art, which holds only for graphs generated from stochastic models. The significance of our work is demonstrated by the empirical analysis on both synthetic and real-world data sets, on which our presented algorithm outperforms  the previously proposed algorithm for graphs with a well-defined cluster structure."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Qu-ANTI-zation", "Title": "Exploiting Quantization Artifacts for Achieving Adversarial Outcomes", "Abstract": "Quantization is a popular technique that transforms the parameter representation of a neural network from floating-point numbers into lower-precision ones (e.g., 8-bit integers). It reduces the memory footprint and the computational cost at inference, facilitating the deployment of resource-hungry models. However, the parameter perturbations caused by this transformation result in behavioral disparities between the model before and after quantization. For example, a quantized model can misclassify some test-time samples that are otherwise classified correctly. It is not known whether such differences lead to a new security vulnerability. We hypothesize that an adversary may control this disparity to introduce specific behaviors that activate upon quantization. To study this hypothesis, we weaponize quantization-aware training and propose a new training framework to implement adversarial quantization outcomes. Following this framework, we present three attacks we carry out with quantization: (i) an indiscriminate attack for significant accuracy loss; (ii) a targeted attack against specific samples; and (iii) a backdoor attack for controlling the model with an input trigger. We further show that a single compromised model defeats multiple quantization schemes, including robust quantization techniques. Moreover, in a federated learning scenario, we demonstrate that a set of malicious participants who conspire can inject our quantization-activated backdoor. Lastly, we discuss potential counter-measures and show that only re-training consistently removes the attack artifacts. Our code is available at https://github.com/Secure-AI-Systems-Group/Qu-ANTI-zation"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Differentially Private Stochastic Optimization", "Title": "New Results in Convex and Non-Convex Settings", "Abstract": "We study differentially private stochastic optimization in convex and non-convex settings. For the convex case, we focus on the family of non-smooth generalized linear losses (GLLs). Our algorithm for the $\\ell_2$ setting achieves optimal excess population risk in near-linear time, while the best known differentially private algorithms for general convex losses run in super-linear time. Our algorithm for the $\\ell_1$ setting has nearly-optimal excess population risk $\\tilde{O}\\big(\\sqrt{\\frac{\\log{d}}{n}}\\big)$, and circumvents the dimension dependent lower bound of \\cite{Asi:2021} for general non-smooth convex losses. In the differentially private non-convex setting, we provide several new algorithms for approximating stationary points of the population risk. For the $\\ell_1$-case with smooth losses and polyhedral constraint, we provide the first nearly dimension independent rate, $\\tilde O\\big(\\frac{\\log^{2/3}{d}}{{n^{1/3}}}\\big)$ in linear time. For the constrained $\\ell_2$-case, with smooth losses, we obtain a linear-time algorithm with rate $\\tilde O\\big(\\frac{1}{n^{3/10}d^{1/10}}+\\big(\\frac{d}{n^2}\\big)^{1/5}\\big)$.   Finally, for the $\\ell_2$-case we provide the first method  for {\\em non-smooth weakly convex} stochastic optimization with rate $\\tilde O\\big(\\frac{1}{n^{1/4}}+\\big(\\frac{d}{n^2}\\big)^{1/6}\\big)$ which matches the best existing non-private algorithm when $d= O(\\sqrt{n})$. We also extend all our results above for the non-convex $\\ell_2$ setting to the $\\ell_p$ setting, where $1 < p \\leq 2$, with only polylogarithmic (in the dimension) overhead in the rates."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TacticZero", "Title": "Learning to Prove Theorems from Scratch with Deep Reinforcement Learning", "Abstract": "We propose a novel approach to interactive theorem-proving (ITP) using deep reinforcement learning. The proposed framework is able to learn proof search strategies as well as tactic and arguments prediction in an end-to-end manner. We formulate the process of ITP as a Markov decision process (MDP) in which each state represents a set of potential derivation paths. This structure allows us to introduce a novel backtracking mechanism which enables the agent to efficiently discard (predicted) dead-end derivations and restart the derivation from promising alternatives. We implement the framework in the HOL theorem prover. Experimental results show that the framework using learned search strategies outperforms existing automated theorem provers (i.e., hammers) available in HOL when evaluated on unseen problems. We further elaborate the role of key components of the framework using ablation studies."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Twins", "Title": "Revisiting the Design of Spatial Attention in Vision Transformers", "Abstract": "Very recently, a variety of vision transformer architectures for dense prediction tasks have been proposed and they show that the design of spatial attention is critical to their success in these tasks. In this work, we revisit the design of the spatial attention and demonstrate that a carefully devised yet simple spatial attention mechanism performs favorably against the state-of-the-art schemes. As a result, we propose two vision transformer architectures, namely, Twins- PCPVT and Twins-SVT. Our proposed architectures are highly efficient and easy to implement, only involving matrix multiplications that are highly optimized in modern deep learning frameworks. More importantly, the proposed architectures achieve excellent performance on a wide range of visual tasks including image-level classification as well as dense detection and segmentation. The simplicity and strong performance suggest that our proposed architectures may serve as stronger backbones for many vision tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reliable Post hoc Explanations", "Title": "Modeling Uncertainty in Explainability", "Abstract": "As black box explanations are increasingly being employed to establish model credibility in high stakes settings, it is important to ensure that these explanations are accurate and reliable. However, prior work demonstrates that explanations generated by state-of-the-art techniques are inconsistent, unstable, and provide very little insight into their correctness and reliability. In addition, these methods are also computationally inefficient, and require significant hyper-parameter tuning. In this paper, we address the aforementioned challenges by developing a novel Bayesian framework for generating local explanations along with their associated uncertainty. We instantiate this framework to obtain Bayesian versions of LIME and KernelSHAP which  output credible intervals for the feature importances, capturing the associated uncertainty. The resulting explanations not only enable us to make concrete inferences about their quality (e.g., there is a 95% chance that the feature importance lies within the given range), but are also highly consistent and stable. We carry out a detailed theoretical analysis that leverages the aforementioned uncertainty to estimate how many perturbations to sample, and how to sample for faster convergence.  This work makes the first attempt at addressing several critical issues with popular explanation methods in one shot, thereby generating consistent, stable, and reliable explanations with guarantees in a computationally efficient manner. Experimental evaluation with multiple real world datasets and user studies demonstrate that the efficacy of the proposed framework."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Combating Noise", "Title": "Semi-supervised Learning by Region Uncertainty Quantification", "Abstract": "Semi-supervised learning aims to leverage a large amount of unlabeled data for performance boosting. Existing works primarily focus on image classification. In this paper, we delve into semi-supervised learning for object detection, where labeled data are more labor-intensive to collect. Current methods are easily distracted by noisy regions generated by pseudo labels. To combat the noisy labeling, we propose noise-resistant semi-supervised learning by quantifying the region uncertainty. We first investigate the adverse effects brought by different forms of noise associated with pseudo labels. Then we propose to quantify the uncertainty of regions by identifying the noise-resistant properties of regions over different strengths. By importing the region uncertainty quantification and promoting multi-peak probability distribution output, we introduce uncertainty into training and further achieve noise-resistant learning. Experiments on both PASCAL VOC and MS COCO demonstrate the extraordinary performance of our method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Conic Blackwell Algorithm", "Title": "Parameter-Free Convex-Concave Saddle-Point Solving", "Abstract": "We develop new parameter-free and scale-free algorithms for solving convex-concave saddle-point problems. Our results are based on a new simple regret minimizer, the Conic Blackwell Algorithm$^+$ (CBA$^+$), which attains $O(1/\\sqrt{T})$ average regret. Intuitively, our approach generalizes to other decision sets of interest ideas from the Counterfactual Regret minimization (CFR$^+$) algorithm, which has very strong practical performance for solving sequential games on simplexes.We show how to implement CBA$^+$ for the simplex, $\\ell_{p}$ norm balls, and ellipsoidal confidence regions in the simplex, and we present numerical experiments for solving matrix games and distributionally robust optimization problems.Our empirical results show that CBA$^+$ is a simple algorithm that outperforms state-of-the-art methods on synthetic data and real data instances, without the need for any choice of step sizes or other algorithmic parameters."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "3DP3", "Title": "3D Scene Perception via Probabilistic Programming", "Abstract": "We present 3DP3, a framework for inverse graphics that uses inference in a structured generative model of objects, scenes, and images. 3DP3 uses (i) voxel models to represent the 3D shape of objects, (ii) hierarchical scene graphs to decompose scenes into objects and the contacts between them, and (iii) depth image likelihoods based on real-time graphics. Given an observed RGB-D image, 3DP3's inference algorithm infers the underlying latent 3D scene, including the object poses and a parsimonious joint parametrization of these poses, using fast bottom-up pose proposals, novel involutive MCMC updates of the scene graph structure, and, optionally, neural object detectors and pose estimators. We show that 3DP3 enables scene understanding that is aware of 3D shape, occlusion, and contact structure. Our results demonstrate that 3DP3 is more accurate at 6DoF object pose estimation from real images than deep learning baselines and shows better generalization to challenging scenes with novel viewpoints, contact, and partial observability."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Why Spectral Normalization Stabilizes GANs", "Title": "Analysis and Improvements", "Abstract": "Spectral normalization (SN) is a widely-used technique for improving the stability and sample quality of Generative Adversarial Networks (GANs). However, current understanding of SN's efficacy is limited. In this work, we show that SN controls two important failure modes of GAN training: exploding and vanishing gradients. Our proofs illustrate a (perhaps unintentional) connection with the successful LeCun initialization. This connection helps to explain why the most popular implementation of SN for GANs requires no hyper-parameter tuning, whereas stricter implementations of SN have poor empirical performance out-of-the-box. Unlike LeCun initialization which only controls gradient vanishing at the beginning of training, SN preserves this property throughout training. Building on this theoretical understanding, we propose a new spectral normalization technique: Bidirectional Scaled Spectral Normalization (BSSN), which incorporates insights from later improvements to LeCun initialization: Xavier initialization and Kaiming initialization. Theoretically, we show that BSSN gives better gradient control than SN. Empirically, we demonstrate that it outperforms SN in sample quality and training stability on several benchmark datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "$(\\textrm{Implicit})^2$", "Title": "Implicit Layers for Implicit Representations", "Abstract": "Recent research in deep learning has investigated two very different forms of ''implicitness'': implicit representations model high-frequency data such as images or 3D shapes directly via a low-dimensional neural network (often using e.g., sinusoidal bases or nonlinearities); implicit layers, in contrast, refer to techniques where the forward pass of a network is computed via non-linear dynamical systems, such as fixed-point or differential equation solutions, with the backward pass computed via the implicit function theorem.  In this work, we demonstrate that these two seemingly orthogonal concepts are remarkably well-suited for each other. In particular, we show that by exploiting fixed-point implicit layer to model implicit representations, we can substantially improve upon the performance of the conventional explicit-layer-based approach. Additionally, as implicit representation networks are typically trained in large-batch settings, we propose to leverage the property of implicit layers to amortize the cost of fixed-point forward/backward passes over training steps -- thereby addressing one of the primary challenges with implicit layers (that many iterations are required for the black-box fixed-point solvers). We empirically evaluated our method on learning multiple implicit representations for images, videos and audios, showing that our $(\\textrm{Implicit})^2$ approach substantially improve upon existing models while being both faster to train and much more memory efficient."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MADE", "Title": "Exploration via Maximizing Deviation from Explored Regions", "Abstract": "In online reinforcement learning (RL), efficient exploration remains particularly challenging in high-dimensional environments with sparse rewards. In low-dimensional environments, where tabular parameterization is possible, count-based upper confidence bound (UCB) exploration methods achieve minimax near-optimal rates. However, it remains unclear how to efficiently implement UCB in realistic RL tasks that involve non-linear function approximation. To address this, we propose a new exploration approach via maximizing the deviation of the occupancy of the next policy from the explored regions. We add this term as an adaptive regularizer to the standard RL objective to balance exploration vs. exploitation.  We pair the new objective with a provably convergent algorithm, giving rise to a new intrinsic reward that adjusts existing bonuses. The proposed intrinsic reward is easy to implement and combine with other existing RL algorithms to conduct exploration. As a proof of concept, we evaluate the new intrinsic reward on tabular examples across a variety of model-based and model-free algorithms, showing improvements over count-only exploration strategies. When tested on navigation and locomotion tasks from MiniGrid and DeepMind Control Suite benchmarks, our approach significantly improves sample efficiency over state-of-the-art methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Align before Fuse", "Title": "Vision and Language Representation Learning with Momentum Distillation", "Abstract": "Large-scale vision and language representation learning has shown promising improvements on various vision-language tasks. Most existing methods employ a transformer-based multimodal encoder to jointly model visual tokens (region-based image features) and word tokens. Because the visual tokens and word tokens are unaligned, it is challenging for the multimodal encoder to learn image-text interactions. In this paper, we introduce a contrastive loss to ALign the image and text representations BEfore Fusing (ALBEF) them through cross-modal attention, which enables more grounded vision and language representation learning. Unlike most existing methods, our method does not require bounding box annotations nor high-resolution images. In order to improve learning from noisy web data, we propose momentum distillation, a self-training method which learns from pseudo-targets produced by a momentum model. We provide a theoretical analysis of ALBEF from a mutual information maximization perspective, showing that different training tasks can be interpreted as different ways to generate views for an image-text pair. ALBEF achieves state-of-the-art performance on multiple downstream vision-language tasks. On image-text retrieval, ALBEF outperforms methods that are pre-trained on orders of magnitude larger datasets. On VQA and NLVR$^2$, ALBEF achieves absolute improvements of 2.37% and 3.84% compared to the state-of-the-art, while enjoying faster inference speed. Code and models are available at https://github.com/salesforce/ALBEF."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A Little Robustness Goes a Long Way", "Title": "Leveraging Robust Features for Targeted Transfer Attacks", "Abstract": "Adversarial examples for neural network image classifiers are known to be transferable: examples optimized to be misclassified by a source classifier are often misclassified as well by classifiers with different architectures. However, targeted adversarial examples—optimized to be classified as a chosen target class—tend to be less transferable between architectures. While prior research on constructing transferable targeted attacks has focused on improving the optimization procedure, in this work we examine the role of the source classifier. Here, we show that training the source classifier to be \"slightly robust\"—that is, robust to small-magnitude adversarial examples—substantially improves the transferability of class-targeted and representation-targeted adversarial attacks, even between architectures as different as convolutional neural networks and transformers. The results we present provide insight into the nature of adversarial examples as well as the mechanisms underlying so-called \"robust\" classifiers."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TriBERT", "Title": "Human-centric Audio-visual Representation Learning", "Abstract": "The recent success of transformer models in language, such as BERT, has motivated the use of such architectures for multi-modal feature learning and tasks. However, most multi-modal variants (e.g., ViLBERT) have limited themselves to visual-linguistic data. Relatively few have explored its use in audio-visual modalities, and none, to our knowledge, illustrate them in the context of granular audio-visual detection or segmentation tasks such as sound source separation and localization. In this work, we introduce TriBERT -- a transformer-based architecture, inspired by ViLBERT, which enables contextual feature learning across three modalities: vision, pose, and audio, with the use of flexible co-attention. The use of pose keypoints is inspired by recent works that illustrate that such representations can significantly boost performance in many audio-visual scenarios where often one or more persons are responsible for the sound explicitly (e.g., talking) or implicitly (e.g., sound produced as a function of human manipulating an object). From a technical perspective, as part of the TriBERT architecture, we introduce a learned visual tokenization scheme based on spatial attention and leverage weak-supervision to allow granular cross-modal interactions for visual and pose modalities. Further, we supplement learning with sound-source separation loss formulated across all three streams. We pre-train our model on the large MUSIC21 dataset and demonstrate improved performance in audio-visual sound source separation on that dataset as well as other datasets through fine-tuning. In addition, we show that the learned TriBERT representations are generic and significantly improve performance on other audio-visual tasks such as cross-modal audio-visual-pose retrieval by as much as 66.7% in top-1 accuracy."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Baby Intuitions Benchmark (BIB)", "Title": "Discerning the goals, preferences, and actions of others", "Abstract": "To achieve human-like common sense about everyday life, machine learning systems must understand and reason about the goals, preferences, and actions of other agents in the environment. By the end of their first year of life, human infants intuitively achieve such common sense, and these cognitive achievements lay the foundation for humans' rich and complex understanding of the mental states of others. Can machines achieve generalizable, commonsense reasoning about other agents like human infants? The Baby Intuitions Benchmark (BIB) challenges machines to predict the plausibility of an agent's behavior based on the underlying causes of its actions. Because BIB's content and paradigm are adopted from developmental cognitive science, BIB allows for direct comparison between human and machine performance. Nevertheless, recently proposed, deep-learning-based agency reasoning models fail to show infant-like reasoning, leaving BIB an open challenge."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Hybrid Automata", "Title": "Learning Dynamics With Multiple Modes and Stochastic Transitions", "Abstract": "Effective control and prediction of dynamical systems require appropriate handling of continuous-time and discrete, event-triggered processes. Stochastic hybrid systems (SHSs), common across engineering domains, provide a formalism for dynamical systems subject to discrete, possibly stochastic, state jumps and multi-modal continuous-time flows. Despite the versatility and importance of SHSs across applications, a general procedure for the explicit learning of both discrete events and multi-mode continuous dynamics remains an open problem. This work introduces Neural Hybrid Automata (NHAs), a recipe for learning SHS dynamics without a priori knowledge on the number, mode parameters, and inter-modal transition dynamics. NHAs provide a systematic inference method based on normalizing flows, neural differential equations, and self-supervision. We showcase NHAs on several tasks, including mode recovery and flow learning in systems with stochastic transitions, and end-to-end learning of hierarchical robot controllers."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Meta-Adaptive Nonlinear Control", "Title": "Theory and Algorithms", "Abstract": "We present an online multi-task learning approach for adaptive nonlinear control, which we call Online Meta-Adaptive Control (OMAC). The goal is to control a nonlinear system subject to adversarial disturbance and unknown \\emph{environment-dependent} nonlinear dynamics, under the assumption that the environment-dependent dynamics can be well captured with some shared representation. Our approach is motivated by robot control, where a robotic system encounters a sequence of new environmental conditions that it must quickly adapt to. A key emphasis is to integrate online representation learning with established methods from control theory, in order to arrive at a unified framework that yields both control-theoretic and learning-theoretic guarantees. We provide instantiations of our approach under varying conditions, leading to the first non-asymptotic end-to-end convergence guarantee for multi-task nonlinear control. OMAC can also be integrated with deep representation learning. Experiments show that OMAC significantly outperforms conventional adaptive control approaches which do not learn the shared representation, in inverted pendulum and 6-DoF drone control tasks under varying wind conditions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization Error Rates in Kernel Regression", "Title": "The Crossover from the Noiseless to Noisy Regime", "Abstract": "In this manuscript we consider Kernel Ridge Regression (KRR) under the Gaussian design. Exponents for the decay of the excess generalization error of KRR have been reported in various works under the assumption of power-law decay of eigenvalues of the features co-variance. These decays were, however, provided for sizeably different setups, namely in the noiseless case with constant regularization and in the noisy optimally regularized case. Intermediary settings have been left substantially uncharted. In this work, we unify and extend this line of work, providing characterization of all regimes and excess error decay rates that can be observed in terms of the interplay of noise and regularization. In particular, we show the existence of a transition in the noisy setting between the noiseless exponents to its noisy values as the sample complexity is increased. Finally, we illustrate how this crossover can also be observed on real data sets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Gaussian Mixtures with Generalized Linear Models", "Title": "Precise Asymptotics in High-dimensions", "Abstract": "Generalised linear models for multi-class classification problems are one of the fundamental building blocks of modern machine learning tasks. In this manuscript, we characterise the learning of a mixture of $K$ Gaussians with generic means and covariances via empirical risk minimisation (ERM) with any convex loss and regularisation. In particular, we prove exact asymptotics characterising the ERM estimator in high-dimensions, extending several previous results about Gaussian mixture classification in the literature. We exemplify our result in two tasks of interest in statistical learning: a) classification for a mixture with sparse means, where we study the efficiency of $\\ell_1$ penalty with respect to $\\ell_2$; b) max-margin multi-class classification, where we characterise the phase transition on the existence of the multi-class logistic maximum likelihood estimator for $K>2$. Finally, we discuss how our theory can be applied beyond the scope of synthetic data, showing that in different cases Gaussian mixtures capture closely the learning curve of classification tasks in real data sets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Latent Matters", "Title": "Learning Deep State-Space Models", "Abstract": "Deep state-space models (DSSMs) enable temporal predictions by learning the underlying dynamics of observed sequence data. They are often trained by maximising the evidence lower bound. However, as we show, this does not ensure the model actually learns the underlying dynamics. We therefore propose a constrained optimisation framework as a general approach for training DSSMs. Building upon this, we introduce the extended Kalman VAE (EKVAE), which combines amortised variational inference with classic Bayesian filtering/smoothing to model dynamics more accurately than RNN-based DSSMs. Our results show that the constrained optimisation framework significantly improves system identification and prediction accuracy on the example of established state-of-the-art DSSMs. The EKVAE outperforms previous models w.r.t. prediction accuracy, achieves remarkable results in identifying dynamical systems, and can furthermore successfully learn state-space representations where static and dynamic features are disentangled."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Believe What You See", "Title": "Implicit Constraint Approach for Offline Multi-Agent Reinforcement Learning", "Abstract": "Learning from datasets without interaction with environments (Offline Learning) is an essential step to apply Reinforcement Learning (RL) algorithms in real-world scenarios.However, compared with the single-agent counterpart, offline multi-agent RL introduces more agents with the larger state and action space, which is more challenging but attracts little attention. We demonstrate current offline RL algorithms are ineffective in multi-agent systems due to the accumulated extrapolation error. In this paper, we propose a novel offline RL algorithm, named Implicit Constraint Q-learning (ICQ), which effectively alleviates the extrapolation error by only trusting the state-action pairs given in the dataset for value estimation.  Moreover, we extend ICQ to multi-agent tasks by decomposing the joint-policy under the implicit constraint.  Experimental results demonstrate that the extrapolation error is successfully controlled within a reasonable range and insensitive to the number of agents. We further show that ICQ achieves the state-of-the-art performance in the challenging multi-agent offline tasks (StarCraft II). Our code is public online at https://github.com/YiqinYang/ICQ."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "K-Net", "Title": "Towards Unified Image Segmentation", "Abstract": "Semantic, instance, and panoptic segmentations have been addressed using different and specialized frameworks despite their underlying connections. This paper presents a unified, simple, and effective framework for these essentially similar tasks. The framework, named K-Net, segments both instances and semantic categories consistently by a group of learnable kernels, where each kernel is responsible for generating a mask for either a potential instance or a stuff class. To remedy the difficulties of distinguishing various instances, we propose a kernel update strategy that enables each kernel dynamic and conditional on its meaningful group in the input image. K-Net can be trained in an end-to-end manner with bipartite matching, and its training and inference are naturally NMS-free and box-free. Without bells and whistles, K-Net surpasses all previous published state-of-the-art single-model results of panoptic segmentation on MS COCO test-dev split and semantic segmentation on ADE20K val split with 55.2% PQ and 54.3% mIoU, respectively. Its instance segmentation performance is also on par with Cascade Mask R-CNN on MS COCO with 60%-90% faster inference speeds. Code and models will be released at https://github.com/ZwwWayne/K-Net/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dynaboard", "Title": "An Evaluation-As-A-Service Platform for Holistic Next-Generation Benchmarking", "Abstract": "We introduce Dynaboard, an evaluation-as-a-service framework for hosting benchmarks and conducting holistic model comparison, integrated with the Dynabench platform. Our platform evaluates NLP models directly instead of relying on self-reported metrics or predictions on a single dataset. Under this paradigm, models are submitted to be evaluated in the cloud, circumventing the issues of reproducibility, accessibility, and backwards compatibility that often hinder benchmarking in NLP. This allows users to interact with uploaded models in real time to assess their quality, and permits the collection of additional metrics such as memory use, throughput, and robustness, which -- despite their importance to practitioners -- have traditionally been absent from leaderboards. On each task, models are ranked according to the Dynascore, a novel utility-based aggregation of these statistics, which users can customize to better reflect their preferences, placing more/less weight on a particular axis of evaluation or dataset. As state-of-the-art NLP models push the limits of traditional benchmarks, Dynaboard offers a standardized solution for a more diverse and comprehensive evaluation of model quality."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NTopo", "Title": "Mesh-free Topology Optimization using Implicit Neural Representations", "Abstract": "Recent advances in implicit neural representations show great promise when it comes to generating numerical solutions to partial differential equations. Compared to conventional alternatives, such representations employ parameterized neural networks to define, in a mesh-free manner, signals that are highly-detailed, continuous, and fully differentiable. In this work, we present a novel machine learning approach for topology optimization---an important class of inverse problems with high-dimensional parameter spaces and highly nonlinear objective landscapes. To effectively leverage neural representations in the context of mesh-free topology optimization, we use multilayer perceptrons to parameterize both density and displacement fields. Our experiments indicate that our method is highly competitive for minimizing  structural compliance objectives, and it enables self-supervised learning of continuous solution spaces for topology optimization problems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CO-PILOT", "Title": "COllaborative Planning and reInforcement Learning On sub-Task curriculum", "Abstract": "Goal-conditioned reinforcement learning (RL) usually suffers from sparse reward and inefficient exploration in long-horizon tasks. Planning can find the shortest path to a distant goal that provides dense reward/guidance but is inaccurate without a precise environment model. We show that RL and planning can collaboratively learn from each other to overcome their own drawbacks. In ''CO-PILOT'', a learnable path-planner and an RL agent produce dense feedback to train each other on a curriculum of tree-structured sub-tasks. Firstly, the planner recursively decomposes a long-horizon task to a tree of sub-tasks in a top-down manner, whose layers construct coarse-to-fine sub-task sequences as plans to complete the original task. The planning policy is trained to minimize the RL agent's cost of completing the sequence in each layer from top to bottom layers, which gradually increases the sub-tasks and thus forms an easy-to-hard curriculum for the planner.  Next, a bottom-up traversal of the tree trains the RL agent from easier sub-tasks with denser rewards on bottom layers to harder ones on top layers and collects its cost on each sub-task train the planner in the next episode. CO-PILOT repeats this mutual training for multiple episodes before switching to a new task, so the RL agent and planner are fully optimized to facilitate each other's training. We compare CO-PILOT with RL (SAC, HER, PPO), planning (RRT*, NEXT, SGT), and their combination (SoRB) on navigation and continuous control tasks. CO-PILOT significantly improves the success rate and sample efficiency."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Curriculum Design for Teaching via Demonstrations", "Title": "Theory and Applications", "Abstract": "We consider the problem of teaching via demonstrations in sequential decision-making settings. In particular, we study how to design a personalized curriculum over demonstrations to speed up the learner's convergence. We provide a unified curriculum strategy for two popular learner models: Maximum Causal Entropy Inverse Reinforcement Learning (MaxEnt-IRL) and Cross-Entropy Behavioral Cloning (CrossEnt-BC). Our unified strategy induces a ranking over demonstrations based on a notion of difficulty scores computed w.r.t. the teacher's optimal policy and the learner's current policy. Compared to the state of the art, our strategy doesn't require access to the learner's internal dynamics and still enjoys similar convergence guarantees under mild technical conditions. Furthermore, we adapt our curriculum strategy to the setting where no teacher agent is present using task-specific difficulty scores. Experiments on a synthetic car driving environment and navigation-based environments demonstrate the effectiveness of our curriculum strategy."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Drop, Swap, and Generate", "Title": "A Self-Supervised Approach for Generating Neural Activity", "Abstract": "Meaningful and simplified representations of neural activity can yield insights into how and what information is being processed within a neural circuit. However, without labels, finding representations that reveal the link between the brain and behavior can be challenging. Here, we introduce a novel unsupervised approach for learning disentangled representations of neural activity called Swap-VAE. Our approach combines a generative modeling framework with an instance-specific alignment loss that tries to maximize the representational similarity between transformed views of the input (brain state). These transformed (or augmented) views are created by dropping out neurons and jittering samples in time, which intuitively should lead the network to a representation that maintains both temporal consistency and invariance to the specific neurons used to represent the neural state. Through evaluations on both synthetic data and neural recordings from hundreds of neurons in different primate brains, we show that it is possible to build representations that disentangle neural datasets along relevant latent dimensions linked to behavior."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Recurrence along Depth", "Title": "Deep Convolutional Neural Networks with Recurrent Layer Aggregation", "Abstract": "This paper introduces a concept of layer aggregation to describe how information from previous layers can be reused to better extract features at the current layer. While DenseNet is a typical example of the layer aggregation mechanism, its redundancy has been commonly criticized in the literature. This motivates us to propose a very light-weighted module, called recurrent layer aggregation (RLA), by making use of the sequential structure of layers in a deep CNN. Our RLA module is compatible with many mainstream deep CNNs, including ResNets, Xception and MobileNetV2, and its effectiveness is verified by our extensive experiments on image classification, object detection and instance segmentation tasks. Specifically, improvements can be uniformly observed on CIFAR, ImageNet and MS COCO datasets, and the corresponding RLA-Nets can surprisingly boost the performances by 2-3% on the object detection task. This evidences the power of our RLA module in helping main CNNs better learn structural information in images."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural-PIL", "Title": "Neural Pre-Integrated Lighting for Reflectance Decomposition", "Abstract": "Decomposing a scene into its shape, reflectance and illumination is a fundamental problem in computer vision and graphics. Neural approaches such as NeRF have achieved remarkable success in view synthesis, but do not explicitly perform decomposition and instead operate exclusively on radiance (the product of reflectance and illumination). Extensions to NeRF, such as NeRD, can perform decomposition but struggle to accurately recover detailed illumination, thereby significantly limiting realism. We propose a novel reflectance decomposition network that can estimate shape, BRDF, and per-image illumination given a set of object images captured under varying illumination. Our key technique is a novel illumination integration network called Neural-PIL that replaces a costly illumination integral operation in the rendering with a simple network query. In addition, we also learn deep low-dimensional priors on BRDF and illumination representations using novel smooth manifold auto-encoders. Our decompositions can result in considerably better BRDF and light estimates enabling more accurate novel view-synthesis and relighting compared to prior art. Project page: https://markboss.me/publication/2021-neural-pil/"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Information is Power", "Title": "Intrinsic Control via Information Capture", "Abstract": "Humans and animals explore their environment and acquire useful skills even in the absence of clear goals, exhibiting intrinsic motivation. The study of intrinsic motivation in artificial agents is concerned with the following question: what is a good general-purpose objective for an agent? We study this question in dynamic partially-observed environments, and argue that a compact and general learning objective is to minimize the entropy of the agent's state visitation estimated using a latent state-space model. This objective induces an agent to both gather information about its environment, corresponding to reducing uncertainty, and to gain control over its environment, corresponding to reducing the unpredictability of future world states. We instantiate this approach as a deep reinforcement learning agent equipped with a deep variational Bayes filter. We find that our agent learns to discover, represent, and exercise control of dynamic objects in a variety of partially-observed environments sensed with visual observations without extrinsic reward."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Causal-Neural Connection", "Title": "Expressiveness, Learnability, and Inference", "Abstract": "One of the central elements of any causal inference is an object called structural causal model (SCM), which represents a collection of mechanisms and exogenous sources of random variation of the system under investigation (Pearl, 2000). An important property of many kinds of neural networks is universal approximability: the ability to approximate any function to arbitrary precision. Given this property, one may be tempted to surmise that a collection of neural nets is capable of learning any SCM by training on data generated by that SCM. In this paper, we show this is not the case by disentangling the notions of expressivity and learnability. Specifically, we show that the causal hierarchy theorem (Thm. 1, Bareinboim et al., 2020), which describes the limits of what can be learned from data, still holds for neural models. For instance, an arbitrarily complex and expressive neural net is unable to predict the effects of interventions given observational data alone. Given this result, we introduce a special type of SCM called a neural causal model (NCM), and formalize a new type of inductive bias to encode structural constraints necessary for performing causal inferences. Building on this new class of models, we focus on solving two canonical tasks found in the literature known as causal  identification and estimation. Leveraging the neural toolbox, we develop an algorithm that is both sufficient and necessary to determine whether a causal effect can be learned from data (i.e., causal identifiability); it then estimates the effect whenever identifiability holds (causal estimation). Simulations corroborate the proposed approach."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "R-Drop", "Title": "Regularized Dropout for Neural Networks", "Abstract": "Dropout is a powerful and widely used technique to regularize the training of deep neural networks. Though effective and performing well, the randomness introduced by dropout causes unnegligible inconsistency between training and inference. In this paper, we introduce a simple consistency training strategy to regularize dropout, namely R-Drop, which forces the output distributions of different sub models generated by dropout to be consistent with each other. Specifically, for each training sample, R-Drop minimizes the bidirectional KL-divergence between the output distributions of two sub models sampled by dropout. Theoretical analysis reveals that R-Drop reduces the above inconsistency. Experiments on $\\bf{5}$ widely used deep learning tasks ($\\bf{18}$ datasets in total), including neural machine translation, abstractive summarization, language understanding, language modeling, and image classification, show that R-Drop is universally effective. In particular, it yields substantial improvements when applied to fine-tune large-scale pre-trained models, e.g., ViT, RoBERTa-large, and BART, and achieves state-of-the-art (SOTA) performances with the vanilla Transformer model on WMT14 English$\\to$German translation ($\\bf{30.91}$ BLEU) and WMT14 English$\\to$French translation ($\\bf{43.95}$ BLEU), even surpassing models trained with extra large-scale data and expert-designed advanced variants of Transformer models. Our code is available at GitHub\\footnote{\\url{https://github.com/dropreg/R-Drop}}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SSUL", "Title": "Semantic Segmentation with Unknown Label for Exemplar-based Class-Incremental Learning", "Abstract": "We consider a class-incremental semantic segmentation (CISS) problem. While some recently proposed algorithms utilized variants of knowledge distillation (KD) technique to tackle the problem, they only partially addressed the key additional challenges in CISS that causes the catastrophic forgetting; \\textit{i.e.}, the semantic drift of the background class and multi-label prediction issue. To better address these challenges, we propose a new method, dubbed as SSUL-M (Semantic Segmentation with Unknown Label with Memory), by carefully combining several techniques tailored for semantic segmentation. More specifically, we make three main contributions; (1) modeling \\textit{unknown} class within the background class to help learning future classes (help plasticity), (2) \\textit{freezing} backbone network and past classifiers with binary cross-entropy loss and pseudo-labeling to overcome catastrophic forgetting (help stability), and (3) utilizing \\textit{tiny exemplar memory} for the first time in CISS to improve \\textit{both} plasticity and stability. As a result, we show our method achieves significantly better performance than the recent state-of-the-art baselines on the standard benchmark datasets. Furthermore, we justify our contributions with thorough and extensive ablation analyses and discuss different natures of the CISS problem compared to the standard class-incremental learning for classification. The official code is available at https://github.com/clovaai/SSUL."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Pinball Loss", "Title": "Quantile Methods for Calibrated Uncertainty Quantification", "Abstract": "Among the many ways of quantifying uncertainty in a regression setting, specifying the full quantile function is attractive, as quantiles are amenable to interpretation and evaluation. A model that predicts the true conditional quantiles for each input, at all quantile levels, presents a correct and efficient representation of the underlying uncertainty. To achieve this, many current quantile-based methods focus on optimizing the pinball loss. However, this loss restricts the scope of applicable regression models, limits the ability to target many desirable properties (e.g. calibration, sharpness, centered intervals), and may produce poor conditional quantiles. In this work, we develop new quantile methods that address these shortcomings. In particular, we propose methods that can apply to any class of regression model, select an explicit balance between calibration and sharpness, optimize for calibration of centered intervals, and produce more accurate conditional quantiles. We provide a thorough experimental evaluation of our methods, which includes a high dimensional uncertainty quantification task in nuclear fusion."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Make Sure You're Unsure", "Title": "A Framework for Verifying Probabilistic Specifications", "Abstract": "Most real world applications require dealing with stochasticity like sensor noise or predictive uncertainty, where formal specifications of desired behavior are inherently probabilistic.  Despite the promise of formal verification in ensuring the reliability of neural networks, progress in the direction of probabilistic specifications has been limited. In this direction, we first introduce a general formulation of probabilistic specifications for neural networks, which captures both probabilistic networks (e.g., Bayesian neural networks, MC-Dropout networks) and uncertain inputs (distributions over inputs arising from sensor noise or other perturbations). We then propose a general technique to verify such specifications by generalizing the notion of Lagrangian duality, replacing standard Lagrangian multipliers with \"functional multipliers\" that can be arbitrary functions of the activations at a given layer. We show that an optimal choice of functional multipliers leads to exact verification (i.e.,  sound and complete verification),  and for specific forms of multipliers, we develop tractable practical verification algorithms. We empirically validate our algorithms by applying them to Bayesian Neural Networks (BNNs) and MC Dropout Networks, and certifying properties such as adversarial robustness and robust detection of out-of-distribution (OOD) data. On these tasks we are able to provide significantly stronger guarantees when compared to prior work -- for instance, for a VGG-64 MC-Dropout CNN trained on CIFAR-10 in a verification-agnostic manner,  we improve the certified AUC (a verified lower bound on the true AUC) for robust OOD detection (on CIFAR-100) from $0 \\% \\rightarrow 29\\%$. Similarly, for a BNN trained on MNIST, we improve on the $\\ell_\\infty$ robust accuracy from $60.2 \\% \\rightarrow 74.6\\%$. Further, on a novel specification -- distributionally robust OOD detection -- we improve on the certified AUC from $5\\% \\rightarrow 23\\%$."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Making the most of your day", "Title": "online learning for optimal allocation of time", "Abstract": "We study online learning for optimal allocation when the resource to be allocated is time. An agent receives task proposals sequentially according to a Poisson process and can either accept or reject a proposed task. If she accepts the proposal, she is busy for the duration of the task and obtains a reward that depends on the task duration. If she rejects it, she remains on hold until a new task proposal arrives. We study the regret incurred by the agent first when she knows her reward function but does not know the distribution of the task duration, and then when she does not know her reward function, either. Faster rates are finally obtained by adding structural assumptions on the distribution of rides or on the reward function. This natural setting bears similarities with contextual (one-armed) bandits, but with the crucial difference that the normalized reward associated to a context depends on the whole distribution of contexts."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Federated Reconstruction", "Title": "Partially Local Federated Learning", "Abstract": "Personalization methods in federated learning aim to balance the benefits of federated and local training for data availability, communication cost, and robustness to client heterogeneity. Approaches that require clients to communicate all model parameters can be undesirable due to privacy and communication constraints. Other approaches require always-available or stateful clients, impractical in large-scale cross-device settings. We introduce Federated Reconstruction, the first model-agnostic framework for partially local federated learning suitable for training and inference at scale. We motivate the framework via a connection to model-agnostic meta learning, empirically demonstrate its performance over existing approaches for collaborative filtering and next word prediction, and release an open-source library for evaluating approaches in this setting. We also describe the successful deployment of this approach at scale for federated collaborative filtering in a mobile keyboard application."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One Explanation is Not Enough", "Title": "Structured Attention Graphs for Image Classification", "Abstract": "Attention maps are popular tools for explaining the decisions of convolutional neural networks (CNNs) for image classification. Typically, for each image of interest, a single attention map is produced, which assigns weights to pixels based on their importance to the classification. We argue that a single attention map provides an incomplete understanding since there are often many other maps that explain a classification equally well. In this paper, we propose to utilize a beam search algorithm to systematically search for multiple explanations for each image. Results show that there are indeed multiple relatively localized explanations for many images. However, naively showing multiple explanations to users can be overwhelming and does not reveal their common and distinct structures. We introduce structured attention graphs (SAGs), which compactly represent sets of attention maps for an image by visualizing how different combinations of image regions impact the confidence of a classifier. An approach to computing a compact and representative SAG for visualization is proposed via diverse sampling. We conduct a user study comparing the use of SAGs to traditional attention maps for answering comparative counterfactual questions about image classifications. Our results show that the users are significantly more accurate when presented with SAGs compared to standard attention map baselines."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Integrating Expert ODEs into Neural ODEs", "Title": "Pharmacology and Disease Progression", "Abstract": "Modeling a system's temporal behaviour in reaction to external stimuli is a fundamental problem in many areas. Pure Machine Learning (ML) approaches often fail in the small sample regime and cannot provide actionable insights beyond predictions. A promising modification has been to incorporate expert domain knowledge into ML models. The application we consider is predicting the patient health status and disease progression over time, where a wealth of domain knowledge is available from pharmacology. Pharmacological models describe the dynamics of carefully-chosen medically meaningful variables in terms of systems of Ordinary Differential Equations (ODEs). However, these models only describe a limited collection of variables, and these variables are often not observable in clinical environments. To close this gap, we propose the latent hybridisation model (LHM) that integrates a system of expert-designed ODEs with machine-learned Neural ODEs to fully describe the dynamics of the system and to link the expert and latent variables to observable quantities. We evaluated LHM on synthetic data as well as real-world intensive care data of COVID-19 patients. LHM consistently outperforms previous works, especially when few training samples are available such as at the beginning of the pandemic."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Decrypting Cryptic Crosswords", "Title": "Semantically Complex Wordplay Puzzles as a Target for NLP", "Abstract": "Cryptic crosswords, the dominant crossword variety in the UK, are a promising target for advancing NLP systems that seek to process semantically complex, highly compositional language. Cryptic clues read like fluent natural language but are adversarially composed of two parts: a definition and a wordplay cipher requiring character-level manipulations. Expert humans use creative intelligence to solve cryptics, flexibly combining linguistic, world, and domain knowledge. In this paper, we make two main contributions. First, we present a dataset of cryptic clues as a challenging new benchmark for NLP systems that seek to process compositional language in more creative, human-like ways. After showing that three non-neural approaches and T5, a state-of-the-art neural language model, do not achieve good performance, we make our second main contribution: a novel curriculum approach, in which the model is first fine-tuned on related tasks such as unscrambling words. We also introduce a challenging data split, examine the meta-linguistic capabilities of subword-tokenized models, and investigate model systematicity by perturbing the wordplay part of clues, showing that T5 exhibits behavior partially consistent with human solving strategies. Although our curricular approach considerably improves on the T5 baseline, our best-performing model still fails to generalize to the extent that humans can. Thus, cryptic crosswords remain an unsolved challenge for NLP systems and a potential source of future innovation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Replacing Rewards with Examples", "Title": "Example-Based Policy Search via Recursive Classification", "Abstract": "Reinforcement learning (RL) algorithms assume that users specify tasks by manually writing down a reward function. However, this process can be laborious and demands considerable technical expertise. Can we devise RL algorithms that instead enable users to specify tasks simply by providing examples of successful outcomes? In this paper, we derive a control algorithm that maximizes the future probability of these successful outcome examples. Prior work has approached similar problems with a two-stage process, first learning a reward function and then optimizing this reward function using another reinforcement learning algorithm. In contrast, our method directly learns a value function from transitions and successful outcomes, without learning this intermediate reward function. Our method therefore requires fewer hyperparameters to tune and lines of code to debug. We show that our method satisfies a new data-driven Bellman equation, where examples take the place of the typical reward function term. Experiments show that our approach outperforms prior methods that learn explicit reward functions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepGEM", "Title": "Generalized Expectation-Maximization for Blind Inversion", "Abstract": "Typically, inversion algorithms assume that a forward model, which relates a source to its resulting measurements, is known and fixed. Using collected indirect measurements and the forward model, the goal becomes to recover the source. When the forward model is unknown, or imperfect, artifacts due to model mismatch occur in the recovery of the source. In this paper, we study the problem of blind inversion: solving an inverse problem with unknown or imperfect knowledge of the forward model parameters. We propose DeepGEM, a variational Expectation-Maximization (EM) framework that can be used to solve for the unknown parameters of the forward model in an unsupervised manner. DeepGEM makes use of a normalizing flow generative network to efficiently capture complex posterior distributions, which leads to more accurate evaluation of the source's posterior distribution used in EM. We showcase the effectiveness of our DeepGEM approach by achieving strong performance on the challenging problem of blind seismic tomography, where we significantly outperform the standard method used in seismology.  We also demonstrate the generality of DeepGEM by applying it to a simple case of blind deconvolution."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bridging Offline Reinforcement Learning and Imitation Learning", "Title": "A Tale of Pessimism", "Abstract": "Offline (or batch) reinforcement learning (RL) algorithms seek to learn an optimal policy from a fixed dataset without active data collection. Based on the composition of the offline dataset, two main methods are used: imitation learning which is suitable for expert datasets, and vanilla offline RL which often requires uniform coverage datasets. From a practical standpoint, datasets often deviate from these two extremes and the exact data composition is usually unknown. To bridge this gap, we present a new offline RL framework that smoothly interpolates between the two extremes of data composition, hence unifying imitation learning and vanilla offline RL. The new framework is centered around a weak version of the concentrability coefficient that measures the deviation of the behavior policy from the expert policy alone. Under this new framework, we ask: can one develop an algorithm that achieves a minimax optimal rate adaptive to unknown data composition? To address this question, we consider a lower confidence bound (LCB) algorithm developed based on pessimism in the face of uncertainty in offline RL. We study finite-sample properties of LCB as well as information-theoretic limits in multi-armed bandits, contextual bandits, and Markov decision processes (MDPs). Our analysis reveals surprising facts about optimality rates. In particular, in both contextual bandits and RL, LCB achieves a faster rate of $1/N$ for nearly-expert datasets compared to the usual rate of $1/\\sqrt{N}$ in offline RL, where $N$ is the batch dataset sample size. In contextual bandits with at least two contexts, we prove that LCB is adaptively optimal for the entire data composition range, achieving a smooth transition from imitation learning to offline RL. We further show that LCB is almost adaptively optimal in MDPs."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Impression learning", "Title": "Online representation learning with synaptic plasticity", "Abstract": "Understanding how the brain constructs statistical models of the sensory world remains a longstanding challenge for computational neuroscience. Here, we derive an unsupervised local synaptic plasticity rule that trains neural circuits to infer latent structure from sensory stimuli via a novel loss function for approximate online Bayesian inference. The learning algorithm is driven by a local error signal computed between two factors that jointly contribute to neural activity: stimulus drive and internal predictions --- the network's 'impression' of the stimulus. Physiologically, we associate these two components with the basal and apical dendrites of pyramidal neurons, respectively. We show that learning can be implemented online, is capable of capturing temporal dependencies in continuous input streams, and generalizes to hierarchical architectures. Furthermore, we demonstrate both analytically and empirically that the algorithm is more data-efficient than a three-factor plasticity alternative, enabling it to learn statistics of high-dimensional, naturalistic inputs. Overall, the model provides a bridge from mechanistic accounts of synaptic plasticity to algorithmic descriptions of unsupervised probabilistic learning and inference."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fixes That Fail", "Title": "Self-Defeating Improvements in Machine-Learning Systems", "Abstract": "Machine-learning systems such as self-driving cars or virtual assistants are composed of a large number of machine-learning models that recognize image content, transcribe speech, analyze natural language, infer preferences, rank options, etc. Models in these systems are often developed and trained independently, which raises an obvious concern: Can improving a machine-learning model make the overall system worse? We answer this question affirmatively by showing that improving a model can deteriorate the performance of downstream models, even after those downstream models are retrained. Such self-defeating improvements are the result of entanglement between the models in the system. We perform an error decomposition of systems with multiple machine-learning models, which sheds light on the types of errors that can lead to self-defeating improvements. We also present the results of experiments which show that self-defeating improvements emerge in a realistic stereo-based detection system for cars and pedestrians."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking Calibration of Deep Neural Networks", "Title": "Do Not Be Afraid of Overconfidence", "Abstract": "Capturing accurate uncertainty quantification of the prediction from deep neural networks is important in many real-world decision-making applications. A reliable predictor is expected to be accurate when it is confident about its predictions and indicate high uncertainty when it is likely to be inaccurate. However, modern neural networks have been found to be poorly calibrated, primarily in the direction of overconfidence. In recent years, there is a surge of research on model calibration by leveraging implicit or explicit regularization techniques during training, which obtain well calibration by avoiding overconfident outputs. In our study, we empirically found that despite the predictions obtained from these regularized models are better calibrated, they suffer from not being as calibratable, namely, it is harder to further calibrate their predictions with post-hoc calibration methods like temperature scaling and histogram binning. We conduct a series of empirical studies showing that overconfidence may not hurt final calibration performance if post-hoc calibration is allowed, rather, the penalty of confident outputs will compress the room of potential improvements in post-hoc calibration phase. Our experimental findings point out a new direction to improve calibration of DNNs by considering main training and post-hoc calibration as a unified framework."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic optimization under time drift", "Title": "iterate averaging, step-decay schedules, and high probability guarantees", "Abstract": "We consider the problem of minimizing a convex function that is evolving in time according to unknown and possibly stochastic dynamics. Such problems abound in the machine learning and signal processing literature, under the names of concept drift and stochastic tracking. We provide novel non-asymptotic convergence guarantees for stochastic algorithms with iterate averaging, focusing on bounds valid both in expectation and with high probability. Notably, we show that the tracking efficiency of the proximal stochastic gradient method depends only logarithmically on the initialization quality when equipped with a step-decay schedule."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mosaicking to Distill", "Title": "Knowledge Distillation from Out-of-Domain Data", "Abstract": "Knowledge distillation~(KD) aims to craft a compact student model that imitates the behavior of a pre-trained teacher in a target domain. Prior KD approaches, despite their gratifying results, have largely relied on the premise that \\emph{in-domain} data is available to carry out the knowledge transfer. Such an assumption, unfortunately, in many cases violates the practical setting, since the original training data or even the data domain is often unreachable due to privacy or copyright reasons. In this paper, we attempt to tackle an ambitious task, termed as \\emph{out-of-domain} knowledge distillation~(OOD-KD), which allows us to conduct KD using only OOD data that can be readily obtained at a very low cost. Admittedly,  OOD-KD is by nature a highly challenging task due to the agnostic domain gap. To this end, we introduce a handy yet surprisingly efficacious approach, dubbed as~\\textit{MosaicKD}. The key insight behind MosaicKD lies in that, samples from various domains share common local patterns, even though their global semantic may vary significantly; these shared local patterns, in turn, can be re-assembled analogous to mosaic tiling, to approximate the in-domain data and to further alleviating the domain discrepancy. In MosaicKD, this is achieved through a four-player min-max game, in which a generator, a discriminator, a student network,  are collectively trained in an adversarial manner, partially under the guidance of a pre-trained teacher. We validate MosaicKD over {classification and semantic segmentation tasks} across various benchmarks, and demonstrate that it yields results much superior to the state-of-the-art counterparts on OOD data. Our code is available at \\url{https://github.com/zju-vipa/MosaicKD}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Not All Images are Worth 16x16 Words", "Title": "Dynamic Transformers for Efficient Image Recognition", "Abstract": "Vision Transformers (ViT) have achieved remarkable success in large-scale image recognition. They split every 2D image into a fixed number of patches, each of which is treated as a token. Generally, representing an image with more tokens would lead to higher prediction accuracy, while it also results in drastically increased computational cost. To achieve a decent trade-off between accuracy and speed, the number of tokens is empirically set to 16x16 or 14x14. In this paper, we argue that every image has its own characteristics, and ideally the token number should be conditioned on each individual input. In fact, we have observed that there exist a considerable number of “easy” images which can be accurately predicted with a mere number of 4x4 tokens, while only a small fraction of “hard” ones need a finer representation. Inspired by this phenomenon, we propose a Dynamic Transformer to automatically configure a proper number of tokens for each input image. This is achieved by cascading multiple Transformers with increasing numbers of tokens, which are sequentially activated in an adaptive fashion at test time, i.e., the inference is terminated once a sufficiently confident prediction is produced. We further design efficient feature reuse and relationship reuse mechanisms across different components of the Dynamic Transformer to reduce redundant computations. Extensive empirical results on ImageNet, CIFAR-10, and CIFAR-100 demonstrate that our method significantly outperforms the competitive baselines in terms of both theoretical computational efficiency and practical inference speed. Code and pre-trained models (based on PyTorch and MindSpore) are available at https://github.com/blackfeather-wang/Dynamic-Vision-Transformer and https://github.com/blackfeather-wang/Dynamic-Vision-Transformer-MindSpore."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ATISS", "Title": "Autoregressive Transformers for Indoor Scene Synthesis", "Abstract": "The ability to synthesize realistic and diverse indoor furniture layouts automatically or based on partial input, unlocks many applications, from better interactive 3D tools to data synthesis for training and simulation. In this paper, we present ATISS, a novel autoregressive transformer architecture for creating diverse and plausible synthetic indoor environments, given only the room type and its floor plan. In contrast to prior work, which poses scene synthesis as sequence generation, our model generates rooms as unordered sets of objects. We argue that this formulation is more natural, as it makes ATISS generally useful beyond fully automatic room layout synthesis. For example, the same trained model can be used in interactive applications for general scene completion, partial room re-arrangement with any objects specified by the user, as well as object suggestions for any partial room. To enable this, our model leverages the permutation equivariance of the transformer when conditioning on the partial scene, and is trained to be permutation-invariant across object orderings. Our model is trained end-to-end as an autoregressive generative model using only labeled 3D bounding boxes as supervision. Evaluations on four room types in the 3D-FRONT dataset demonstrate that our model consistently generates plausible room layouts that are more realistic than existing methods.In addition, it has fewer parameters, is simpler to implement and train and runs up to 8 times faster than existing methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SegFormer", "Title": "Simple and Efficient Design for Semantic Segmentation with Transformers", "Abstract": "We present SegFormer, a simple, efficient yet powerful semantic segmentation framework which unifies Transformers with lightweight multilayer perceptron (MLP) decoders. SegFormer has two appealing features: 1) SegFormer comprises a novel hierarchically structured Transformer encoder which outputs multiscale features. It does not need positional encoding, thereby avoiding the interpolation of positional codes which leads to decreased performance when the testing resolution differs from training. 2) SegFormer avoids complex decoders. The proposed MLP decoder aggregates information from different layers, and thus combining both local attention and global attention to render powerful representations. We show that this simple and lightweight design is the key to efficient segmentation on Transformers.  We scale our approach up to obtain a series of models from SegFormer-B0 to Segformer-B5, which reaches much better performance and efficiency than previous counterparts.For example, SegFormer-B4 achieves 50.3% mIoU on ADE20K with 64M parameters, being 5x smaller and 2.2% better than the previous best method. Our best model, SegFormer-B5, achieves 84.0% mIoU on Cityscapes validation set and shows excellent zero-shot robustness on Cityscapes-C."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Delayed Propagation Transformer", "Title": "A Universal Computation Engine towards Practical Control in Cyber-Physical Systems", "Abstract": "Multi-agent control is a central theme in the Cyber-Physical Systems (CPS). However, current control methods either receive non-Markovian states due to insufficient sensing and decentralized design, or suffer from poor convergence. This paper presents the Delayed Propagation Transformer (DePT), a new transformer-based model that specializes in the global modeling of CPS while taking into account the immutable constraints from the physical world. DePT induces a cone-shaped spatial-temporal attention prior, which injects the information propagation and aggregation principles and enables a global view. With physical constraint inductive bias baked into its design, our DePT is ready to plug and play for a broad class of multi-agent systems. The experimental results on one of the most challenging CPS -- network-scale traffic signal control system in the open world -- show that our model outperformed the state-of-the-art expert methods on synthetic and real-world datasets. Our codes are released at: https://github.com/VITA-Group/DePT."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Smoothness", "Title": "Incorporating Low-Rank Analysis into Nonparametric Density Estimation", "Abstract": "The construction and theoretical analysis of the most popular universally consistent nonparametric density estimators hinge on one functional property: smoothness. In this paper we investigate the theoretical implications of incorporating a multi-view latent variable model, a type of low-rank model, into nonparametric density estimation. To do this we perform extensive analysis on histogram-style estimators that integrate a multi-view model. Our analysis culminates in showing that there exists a universally consistent histogram-style estimator that converges to any multi-view model with a finite number of Lipschitz continuous components at a rate of $\\widetilde{O}(1/\\sqrt[3]{n})$ in $L^1$ error. In contrast, the standard histogram estimator can converge at a rate slower than $1/\\sqrt[d]{n}$ on the same class of densities. We also introduce a new nonparametric latent variable model based on the Tucker decomposition. A rudimentary implementation of our estimators experimentally demonstrates a considerable performance improvement over the standard histogram estimator. We also provide a thorough analysis of the sample complexity of our Tucker decomposition-based model and a variety of other results. Thus, our paper provides solid theoretical foundations for extending low-rank techniques to the nonparametric setting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FACMAC", "Title": "Factored Multi-Agent Centralised Policy Gradients", "Abstract": "We propose FACtored Multi-Agent Centralised policy gradients (FACMAC), a new method for cooperative multi-agent reinforcement learning in both discrete and continuous action spaces. Like MADDPG, a popular multi-agent actor-critic method, our approach uses deep deterministic policy gradients to learn policies. However, FACMAC learns a centralised but factored critic, which combines per-agent utilities into the joint action-value function via a non-linear monotonic function, as in QMIX, a popular multi-agent $Q$-learning algorithm. However, unlike QMIX, there are no inherent constraints on factoring the critic. We thus also employ a nonmonotonic factorisation and empirically demonstrate that its increased representational capacity allows it to solve some tasks that cannot be solved with monolithic, or monotonically factored critics. In addition, FACMAC uses a centralised policy gradient estimator that optimises over the entire joint action space, rather than optimising over each agent's action space separately as in MADDPG. This allows for more coordinated policy changes and fully reaps the benefits of a centralised critic. We evaluate FACMAC on variants of the multi-agent particle environments, a novel multi-agent MuJoCo benchmark, and a challenging set of StarCraft II micromanagement tasks. Empirical results demonstrate FACMAC's superior performance over MADDPG and other baselines on all three domains."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EDGE", "Title": "Explaining Deep Reinforcement Learning Policies", "Abstract": "With the rapid development of deep reinforcement learning (DRL) techniques, there is an increasing need to understand and interpret DRL policies. While recent research has developed explanation methods to interpret how an agent determines its moves, they cannot capture the importance of actions/states to a game's final result. In this work, we propose a novel self-explainable model that augments a Gaussian process with a customized kernel function and an interpretable predictor. Together with the proposed model, we also develop a parameter learning procedure that leverages inducing points and variational inference to improve learning efficiency. Using our proposed model, we can predict an agent's final rewards from its game episodes and extract time step importance within episodes as strategy-level explanations for that agent. Through experiments on Atari and MuJoCo games, we verify the explanation fidelity of our method and demonstrate how to employ interpretation to understand agent behavior, discover policy vulnerabilities, remediate policy errors, and even defend against adversarial attacks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "A-NeRF", "Title": "Articulated Neural Radiance Fields for Learning Human Shape, Appearance, and Pose", "Abstract": "While deep learning reshaped the classical motion capture pipeline with feed-forward networks, generative models are required to recover fine alignment via iterative refinement. Unfortunately, the existing models are usually hand-crafted or learned in controlled conditions, only applicable to limited domains. We propose a method to learn a generative neural body model from unlabelled monocular videos by extending Neural Radiance Fields (NeRFs). We equip them with a skeleton to apply to time-varying and articulated motion. A key insight is that implicit models require the inverse of the forward kinematics used in explicit surface models. Our reparameterization defines spatial latent variables relative to the pose of body parts and thereby overcomes ill-posed inverse operations with an overparameterization. This enables learning volumetric body shape and appearance from scratch while jointly refining the articulated pose; all without ground truth labels for appearance, pose, or 3D shape on the input videos. When used for novel-view-synthesis and motion capture, our neural model improves accuracy on diverse datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Argmax Flows and Multinomial Diffusion", "Title": "Learning Categorical Distributions", "Abstract": "Generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. This paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. To optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. Multinomial Diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. We demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Don’t Generate Me", "Title": "Training Differentially Private Generative Models with Sinkhorn Divergence", "Abstract": "Although machine learning models trained on massive data have led to breakthroughs in several areas, their deployment in privacy-sensitive domains remains limited due to restricted access to data. Generative models trained with privacy constraints on private data can sidestep this challenge, providing indirect access to private data instead. We propose DP-Sinkhorn, a novel optimal transport-based generative method for learning data distributions from private data with differential privacy. DP-Sinkhorn minimizes the Sinkhorn divergence, a computationally efficient approximation to the exact optimal transport distance, between the model and data in a differentially private manner and uses a novel technique for controlling the bias-variance trade-off of gradient estimates. Unlike existing approaches for training differentially private generative models, which are mostly based on generative adversarial networks, we do not rely on adversarial objectives, which are notoriously difficult to optimize, especially in the presence of noise imposed by privacy constraints. Hence, DP-Sinkhorn is easy to train and deploy. Experimentally, we improve upon the state-of-the-art on multiple image modeling benchmarks and show differentially private synthesis of informative RGB images."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Keeping Your Eye on the Ball", "Title": "Trajectory Attention in Video Transformers", "Abstract": "In video transformers, the time dimension is often treated in the same way as the two spatial dimensions. However, in a scene where objects or the camera may move, a physical point imaged at one location in frame $t$ may be entirely unrelated to what is found at that location in frame $t+k$. These temporal correspondences should be modeled to facilitate learning about dynamic scenes. To this end, we propose a new drop-in block for video transformers - trajectory attention - that aggregates information along implicitly determined motion paths. We additionally propose a new method to address the quadratic dependence of computation and memory on the input size, which is particularly important for high resolution or long videos. While these ideas are useful in a range of settings, we apply them to the specific task of video action recognition with a transformer model and obtain state-of-the-art results on the Kinetics, Something-Something V2, and Epic-Kitchens datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "D2C", "Title": "Diffusion-Decoding Models for Few-Shot Conditional Generation", "Abstract": "Conditional generative models of high-dimensional images have many applications, but supervision signals from conditions to images can be expensive to acquire. This paper describes Diffusion-Decoding models with Contrastive representations (D2C), a paradigm for training unconditional variational autoencoders (VAE) for few-shot conditional image generation. D2C uses a learned diffusion-based prior over the latent representations to improve generation and contrastive self-supervised learning to improve representation quality. D2C can adapt to novel generation tasks, conditioned on labels or manipulation constraints, by learning from as few as 100 labeled examples. On conditional generation from new labels, D2C achieves superior performance over state-of-the-art VAEs and diffusion models. On conditional image manipulation, D2C generations are two orders of magnitude faster to produce over StyleGAN2 ones and are preferred by 50% - 60% of the human evaluators in a double-blind study. We release our code at https://github.com/jiamings/d2c."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SQALER", "Title": "Scaling Question Answering by Decoupling Multi-Hop and Logical Reasoning", "Abstract": "State-of-the-art approaches to reasoning and question answering over knowledge graphs (KGs) usually scale with the number of edges and can only be applied effectively on small instance-dependent subgraphs. In this paper, we address this issue by showing that multi-hop and more complex logical reasoning can be accomplished separately without losing expressive power. Motivated by this insight, we propose an approach to multi-hop reasoning that scales linearly with the number of relation types in the graph, which is usually significantly smaller than the number of edges or nodes. This produces a set of candidate solutions that can be provably refined to recover the solution to the original problem. Our experiments on knowledge-based question answering show that our approach solves the multi-hop MetaQA dataset, achieves a new state-of-the-art on the more challenging WebQuestionsSP, is orders of magnitude more scalable than competitive approaches, and can achieve compositional generalization out of the training distribution."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FL-WBC", "Title": "Enhancing Robustness against Model Poisoning Attacks in Federated Learning from a Client Perspective", "Abstract": "Federated learning (FL) is a popular distributed learning framework that trains a global model through iterative communications between a central server and edge devices. Recent works have demonstrated that FL is vulnerable to model poisoning attacks. Several server-based defense approaches (e.g. robust aggregation), have been proposed to mitigate such attacks. However, we empirically show that under extremely strong attacks, these defensive methods fail to guarantee the robustness of FL. More importantly, we observe that as long as the global model is polluted, the impact of attacks on the global model will remain in subsequent rounds even if there are no subsequent attacks. In this work, we propose a client-based defense, named White Blood Cell for Federated Learning (FL-WBC), which can mitigate model poisoning attacks that have already polluted the global model. The key idea of FL-WBC is to identify the parameter space where long-lasting attack effect on parameters resides and perturb that space during local training. Furthermore, we derive a certified robustness guarantee against model poisoning attacks and a convergence guarantee to FedAvg after applying our FL-WBC. We conduct experiments on FasionMNIST and CIFAR10 to evaluate the defense against state-of-the-art model poisoning attacks. The results demonstrate that our method can effectively mitigate model poisoning attack impact on the global model within 5 communication rounds with nearly no accuracy drop under both IID and Non-IID settings. Our defense is also complementary to existing server-based robust aggregation approaches and can further improve the robustness of FL under extremely strong attacks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OctField", "Title": "Hierarchical Implicit Functions for 3D Modeling", "Abstract": "Recent advances in localized implicit functions have enabled neural implicit representation to be scalable to large scenes.However, the regular subdivision of 3D space employed by these approaches fails to take into account the sparsity of the surface occupancy and the varying granularities of geometric details. As a result, its memory footprint grows cubically with the input volume, leading to a prohibitive computational cost even at a moderately dense decomposition. In this work, we present a learnable hierarchical implicit representation for 3D surfaces, coded OctField, that allows high-precision encoding of intricate surfaces with low memory and computational budget. The key to our approach is an adaptive decomposition of 3D scenes that only distributes local implicit functions around the surface of interest. We achieve this goal by introducing a hierarchical octree structure to adaptively subdivide the 3D space according to the surface occupancy and the richness of part geometry. As octree is discrete and non-differentiable, we further propose a novel hierarchical network that models the subdivision of octree cells as a probabilistic process and recursively encodes and decodes both octree structure and surface geometry in a differentiable manner. We demonstrate the value of OctField for a range of shape modeling and reconstruction tasks, showing superiority over alternative approaches."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sanity Checks for Lottery Tickets", "Title": "Does Your Winning Ticket Really Win the Jackpot?", "Abstract": "There have been long-standing controversies and inconsistencies over the experiment setup and criteria for identifying the \"winning ticket\" in literature. To reconcile such, we revisit the definition of lottery ticket hypothesis, with comprehensive and more rigorous conditions. Under our new definition, we show concrete evidence to clarify whether the winning ticket exists across the major DNN architectures and/or applications. Through extensive experiments, we perform quantitative analysis on the correlations between winning tickets and various experimental factors, and empirically study the patterns of our observations. We find that the key training hyperparameters, such as learning rate and training epochs, as well as the architecture characteristics such as capacities and residual connections, are all highly correlated with whether and when the winning tickets can be identified. Based on our analysis, we summarize a guideline for parameter settings in regards of specific architecture characteristics, which we hope to catalyze the research progress on the topic of lottery ticket hypothesis. Our codes are publicly available at: https://github.com/boone891214/sanity-check-LTH."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TokenLearner", "Title": "Adaptive Space-Time Tokenization for Videos", "Abstract": "In this paper, we introduce a novel visual representation learning which relies on a handful of adaptively learned tokens, and which is applicable to both image and video understanding tasks. Instead of relying on hand-designed splitting strategies to obtain visual tokens and processing a large number of densely sampled patches for attention, our approach learns to mine important tokens in visual data. This results in efficiently and effectively finding a few important visual tokens and enables modeling of pairwise attention between such tokens, over a longer temporal horizon for videos, or the spatial content in image frames. Our experiments demonstrate strong performance on several challenging benchmarks for video recognition tasks. Importantly, due to our tokens being adaptive, we accomplish competitive results at significantly reduced computational cost. We establish new state-of-the-arts on multiple video datasets, including Kinetics-400, Kinetics-600, Charades, and AViD."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adversarial Robustness without Adversarial Training", "Title": "A Teacher-Guided Curriculum Learning Approach", "Abstract": "Current SOTA adversarially robust models are mostly based on adversarial training (AT) and differ only by some regularizers either at inner maximization or outer minimization steps. Being repetitive in nature during the inner maximization step, they take a huge time to train. We propose a non-iterative method that enforces the following ideas during training. Attribution maps are more aligned to the actual object in the image for adversarially robust models compared to naturally trained models. Also, the allowed set of pixels to perturb an image (that changes model decision) should be restricted to the object pixels only, which reduces the attack strength by limiting the attack space. Our method achieves significant performance gains with a little extra effort (10-20%) over existing AT models and outperforms all other methods in terms of adversarial as well as natural accuracy. We have performed extensive experimentation with CIFAR-10, CIFAR-100, and TinyImageNet datasets and reported results against many popular strong adversarial attacks to prove the effectiveness of our method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FjORD", "Title": "Fair and Accurate Federated Learning under heterogeneous targets with Ordered Dropout", "Abstract": "Federated Learning (FL) has been gaining significant traction across different ML tasks, ranging from vision to keyboard predictions. In large-scale deployments, client heterogeneity is a fact and constitutes a primary problem for fairness, training performance and accuracy. Although significant efforts have been made into tackling statistical data heterogeneity, the diversity in the processing capabilities and network bandwidth of clients, termed system heterogeneity, has remained largely unexplored. Current solutions either disregard a large portion of available devices or set a uniform limit on the model's capacity, restricted by the least capable participants.In this work, we introduce Ordered Dropout, a mechanism that achieves an ordered, nested representation of knowledge in Neural Networks and enables the extraction of lower footprint submodels without the need for retraining. We further show that for linear maps our Ordered Dropout is equivalent to SVD.  We employ this technique, along with a self-distillation methodology, in the realm of FL in a framework called FjORD. FjORD alleviates the problem of client system heterogeneity by tailoring the model width to the client's capabilities. Extensive evaluation on both CNNs and RNNs across diverse modalities shows that FjORD consistently leads to significant performance gains over state-of-the-art baselines while maintaining its nested structure."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MixSeq", "Title": "Connecting Macroscopic Time Series Forecasting with Microscopic Time Series Data", "Abstract": "Time series forecasting is widely used in business intelligence, e.g., forecast stock market price, sales, and help the analysis of data trend. Most time series of interest are macroscopic time series that are aggregated from microscopic data. However, instead of directly modeling the macroscopic time series, rare literature studied the forecasting of macroscopic time series by leveraging data on the microscopic level. In this paper, we assume that the microscopic time series follow some unknown mixture probabilistic distributions. We theoretically show that as we identify the ground truth latent mixture components, the estimation of time series from each component could be improved because of lower variance, thus benefitting the estimation of macroscopic time series as well. Inspired by the power of Seq2seq and its variants on the modeling of time series data, we propose Mixture of Seq2seq (MixSeq), an end2end mixture model to cluster microscopic time series, where all the components come from a family of Seq2seq models parameterized by different parameters. Extensive experiments on both synthetic and real-world data show the superiority of our approach."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Divergence Frontiers for Generative Models", "Title": "Sample Complexity, Quantization Effects, and Frontier Integrals", "Abstract": "The spectacular success of deep generative models calls for quantitative tools to measure their statistical performance. Divergence frontiers have recently been proposed as an evaluation framework for generative models, due to their ability to measure the quality-diversity trade-off inherent to deep generative modeling. We establish non-asymptotic bounds on the sample complexity of divergence frontiers. We also introduce frontier integrals which provide summary statistics of divergence frontiers. We show how smoothed estimators such as Good-Turing or Krichevsky-Trofimov can overcome the missing mass problem and lead to faster rates of convergence. We illustrate the theoretical results with numerical examples from natural language processing and computer vision."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Gradient Descent on Two-layer Nets", "Title": "Margin Maximization and Simplicity Bias", "Abstract": "The generalization mystery of overparametrized deep nets has motivated efforts to understand how gradient descent (GD) converges to low-loss solutions that generalize well. Real-life neural networks are initialized from small random values and trained with cross-entropy loss for classification (unlike the \"lazy\" or \"NTK\" regime of training where analysis was more successful), and a recent sequence of results (Lyu and Li, 2020; Chizat and Bach, 2020; Ji and Telgarsky, 2020) provide theoretical evidence that GD may converge to the \"max-margin\" solution with zero loss, which presumably generalizes well. However, the global optimality of margin is proved only in some settings where neural nets are infinitely or exponentially wide. The current paper is able to establish this global optimality for two-layer Leaky ReLU nets trained with gradient flow on linearly separable and symmetric data, regardless of the width. The analysis also gives some theoretical justification for recent empirical findings (Kalimeris et al., 2019) on the so-called simplicity bias of GD towards linear or other \"simple\" classes of solutions, especially early in training. On the pessimistic side, the paper suggests that such results are fragile. A simple data manipulation can make gradient flow converge to a linear classifier with suboptimal margin."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shape As Points", "Title": "A Differentiable Poisson Solver", "Abstract": "In recent years, neural implicit representations gained popularity in 3D reconstruction due to their expressiveness and flexibility. However, the implicit nature of neural implicit representations results in slow inference times and requires careful initialization. In this paper, we revisit the classic yet ubiquitous point cloud representation and introduce a differentiable point-to-mesh layer using a differentiable formulation of Poisson Surface Reconstruction (PSR) which allows for a GPU-accelerated fast solution of the indicator function given an oriented point cloud. The differentiable PSR layer allows us to efficiently and differentiably bridge the explicit 3D point representation with the 3D mesh via the implicit indicator field, enabling end-to-end optimization of surface reconstruction metrics such as Chamfer distance. This duality between points and meshes hence allows us to represent shapes as oriented point clouds, which are explicit, lightweight and expressive. Compared to neural implicit representations, our Shape-As-Points (SAP) model is more interpretable, lightweight, and accelerates inference time by one order of magnitude. Compared to other explicit representations such as points, patches, and meshes, SAP produces topology-agnostic, watertight manifold surfaces. We demonstrate the effectiveness of SAP on the task of surface reconstruction from unoriented point clouds and learning-based reconstruction."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Drawing Robust Scratch Tickets", "Title": "Subnetworks with Inborn Robustness Are Found within Randomly Initialized Networks", "Abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to adversarial attacks, i.e., an imperceptible perturbation to the input can mislead DNNs trained on clean images into making erroneous predictions. To tackle this, adversarial training is currently the most effective defense method, by augmenting the training set with adversarial samples generated on the fly. \\textbf{Interestingly, we discover for the first time that there exist subnetworks with inborn robustness, matching or surpassing the robust accuracy of the adversarially trained networks with comparable model sizes, within randomly initialized networks without any model training}, indicating that adversarial training on model weights is not indispensable towards adversarial robustness. We name such subnetworks Robust Scratch Tickets (RSTs), which are also by nature efficient. Distinct from the popular lottery ticket hypothesis, neither the original dense networks nor the identified RSTs need to be trained. To validate and understand this fascinating finding, we further conduct extensive experiments to study the existence and properties of RSTs under different models, datasets, sparsity patterns, and attacks, drawing insights regarding the relationship between DNNs’ robustness and their initialization/overparameterization. Furthermore, we identify the poor adversarial transferability between RSTs of different sparsity ratios drawn from the same randomly initialized dense network, and propose a Random RST Switch (R2S) technique, which randomly switches between different RSTs, as a novel defense method built on top of RSTs. We believe our findings about RSTs have opened up a new perspective to study model robustness and extend the lottery ticket hypothesis."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SEAL", "Title": "Self-supervised Embodied Active Learning using Exploration and 3D Consistency", "Abstract": "In this paper, we explore how we can build upon the data and models of Internet images and use them to adapt to robot vision without requiring any extra labels. We present a framework called Self-supervised Embodied Active Learning (SEAL). It utilizes perception models trained on internet images to learn an active exploration policy. The observations gathered by this exploration policy are labelled using 3D consistency and used to improve the perception model. We build and utilize 3D semantic maps to learn both action and perception in a completely self-supervised manner. The semantic map is used to compute an intrinsic motivation reward for training the exploration policy and for labelling the agent observations using spatio-temporal 3D consistency and label propagation. We demonstrate that the SEAL framework can be used to close the action-perception loop: it improves object detection and instance segmentation performance of a pretrained perception model by just moving around in training environments and the improved perception model can be used to improve Object Goal Navigation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sifting through the noise", "Title": "Universal first-order methods for stochastic variational inequalities", "Abstract": "We examine a flexible algorithmic framework for solving monotone variational inequalities in the presence of randomness and uncertainty. The proposed template encompasses a wide range of popular first-order methods, including dual averaging, dual extrapolation and optimistic gradient algorithms – both adaptive and non-adaptive. Our first result is that the algorithm achieves the optimal rates of convergence for cocoercive problems when the profile of the randomness is known to the optimizer: $\\mathcal{O}(1/\\sqrt{T})$ for absolute noise profiles, and $\\mathcal{O}(1/T)$ for relative ones. Subsequently, we drop all prior knowledge requirements (the absolute/relative variance of the randomness affecting the problem, the operator's cocoercivity constant, etc.), and we analyze an adaptive instance of the method that gracefully interpolates between the above rates – i.e. it achieves $\\mathcal{O}(1/\\sqrt{T})$ and $\\mathcal{O}(1/T)$ in the absolute and relative cases, respectively. To our knowledge, this is the first universality result of its kind in the literature and, somewhat surprisingly, it shows that an extra-gradient proxy step is not required to achieve optimal rates."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accommodating Picky Customers", "Title": "Regret Bound and Exploration Complexity for Multi-Objective Reinforcement Learning", "Abstract": "In this paper we consider multi-objective reinforcement learning where the objectives are balanced using preferences. In practice, the preferences are often given in an adversarial manner, e.g., customers can be picky in many applications. We formalize this problem as an episodic learning problem on a Markov decision process, where transitions are unknown and a reward function is the inner product of a preference vector with pre-specified multi-objective reward functions. We consider two settings. In the online setting, the agent receives a (adversarial) preference every episode and proposes policies to interact with the environment. We provide a model-based algorithm that achieves a nearly minimax optimal regret bound $\\widetilde{\\mathcal{O}}\\bigl(\\sqrt{\\min\\{d,S\\}\\cdot H^2 SAK}\\bigr)$, where $d$ is the number of objectives, $S$ is the number of states, $A$ is the number of actions, $H$ is the length of the horizon, and $K$ is the number of episodes. Furthermore, we consider preference-free exploration, i.e., the agent first interacts with the environment without specifying any preference and then is able to accommodate arbitrary preference vector up to $\\epsilon$ error. Our proposed algorithm is provably efficient with a nearly optimal trajectory complexity $\\widetilde{\\mathcal{O}}\\bigl({\\min\\{d,S\\}\\cdot H^3 SA}/{\\epsilon^2}\\bigr)$. This result partly resolves an open problem raised by \\citet{jin2020reward}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Emergence of Objectness", "Title": "Learning Zero-shot Segmentation from Videos", "Abstract": "Humans can easily detect and segment moving objects simply by observing how they move, even without knowledge of object semantics. Inspired by this, we develop a zero-shot unsupervised approach for learning object segmentations. The model comprises two visual pathways: an appearance pathway that segments individual RGB images into coherent object regions, and a motion pathway that predicts the flow vector for each region between consecutive video frames. The two pathways jointly reconstruct a new representation called segment flow. This decoupled representation of appearance and motion is trained in a self-supervised manner to reconstruct one frame from another.When pretrained on an unlabeled video corpus, the model can be useful for a variety of applications, including 1) primary object segmentation from a single image in a zero-shot fashion; 2) moving object segmentation from a video with unsupervised test-time adaptation; 3) image semantic segmentation by supervised fine-tuning on a labeled image dataset. We demonstrate encouraging experimental results on all of these tasks using  pretrained models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MST", "Title": "Masked Self-Supervised Transformer for Visual Representation", "Abstract": "Transformer has been widely used for self-supervised pre-training in Natural Language Processing (NLP) and achieved great success. However, it has not been fully explored in visual self-supervised learning. Meanwhile, previous methods only consider the high-level feature and learning representation from a global perspective, which may fail to transfer to the downstream dense prediction tasks focusing on local features. In this paper, we present a novel Masked Self-supervised Transformer approach named MST, which can explicitly capture the local context of an image while preserving the global semantic information. Specifically, inspired by the Masked Language Modeling (MLM) in NLP, we propose a masked token strategy based on the multi-head self-attention map, which dynamically masks some tokens of local patches without damaging the crucial structure for self-supervised learning. More importantly, the masked tokens together with the remaining tokens are further recovered by a global image decoder, which preserves the spatial information of the image and is more friendly to the downstream dense prediction tasks. The experiments on multiple datasets demonstrate the effectiveness and generality of the proposed method. For instance, MST achieves Top-1 accuracy of 76.9% with DeiT-S only using 300-epoch pre-training by linear evaluation, which outperforms supervised methods with the same epoch by 0.4% and its comparable variant DINO by 1.0%. For dense prediction tasks, MST also achieves 42.7% mAP on MS COCO object detection and 74.04% mIoU on Cityscapes segmentation only with 100-epoch pre-training."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CARMS", "Title": "Categorical-Antithetic-REINFORCE Multi-Sample Gradient Estimator", "Abstract": "Accurately backpropagating the gradient through categorical variables is a challenging task that arises in various domains, such as training discrete latent variable models. To this end, we propose CARMS, an unbiased estimator for categorical random variables based on multiple mutually negatively correlated (jointly antithetic) samples. CARMS combines REINFORCE with copula based sampling to avoid duplicate samples and reduce its variance, while keeping the estimator unbiased using importance sampling. It generalizes both the ARMS antithetic estimator for binary variables, which is CARMS for two categories, as well as LOORF/VarGrad, the leave-one-out REINFORCE estimator, which is CARMS with independent samples.  We evaluate CARMS on several benchmark datasets on a generative modeling task, as well as a structured output prediction task, and find it to outperform competing methods including a strong self-control baseline. The code is publicly available."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Channel Permutations for N", "Title": "M Sparsity", "Abstract": "We introduce channel permutations as a method to maximize the accuracy of N:M sparse networks. N:M sparsity requires N out of M consecutive elements to be zero and has been shown to maintain accuracy for many models and tasks with a simple prune and fine-tune workflow. By permuting weight matrices along their channel dimension and adjusting the surrounding layers appropriately, we demonstrate accuracy recovery for even small, parameter-efficient networks, without affecting inference run-time. We also present both a quality metric to simplify judging permutations as well as efficient methods to search for high-quality permutations, including two optimizations to escape local minima. Finally, we share an ablation study to show the importance of each part of our search algorithm, experimental results showing correlation between our quality metric and final network accuracy, improved sparse network accuracy using our techniques with insignificant overhead to training time, and the transformation of unstructured to structured sparse workloads. Code to use these techniques when generating a 2:4 sparse network is available at https://github.com/NVIDIA/apex/tree/master/apex/contrib/sparsity."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bellman Eluder Dimension", "Title": "New Rich Classes of RL Problems, and Sample-Efficient Algorithms", "Abstract": "Finding the minimal structural assumptions that empower sample-efficient learning is one of the most important research directions in Reinforcement Learning (RL). This paper advances our understanding of this fundamental question by introducing a new complexity measure—Bellman Eluder (BE) dimension. We show that the family of RL problems of low BE dimension is remarkably rich, which subsumes a vast majority of existing tractable RL problems including but not limited to tabular MDPs, linear MDPs, reactive POMDPs, low Bellman rank problems as well as low Eluder dimension problems. This paper further designs a new optimization-based algorithm— GOLF, and reanalyzes a hypothesis elimination-based algorithm—OLIVE (proposed in Jiang et al. (2017)). We prove that both algorithms learn the near-optimal policies of low BE dimension problems in a number of samples that is polynomial in all relevant parameters, but independent of the size of state-action space. Our regret and sample complexity results match or improve the best existing results for several well-known subclasses of low BE dimension problems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HNPE", "Title": "Leveraging Global Parameters for Neural Posterior Estimation", "Abstract": "Inferring the parameters of a stochastic model based on experimental observations is central to the scientific method. A particularly challenging setting is when the model is strongly indeterminate, i.e. when distinct sets of parameters yield identical observations. This arises in many practical situations, such as when inferring the distance and power of a radio source (is the source close and weak or far and strong?) or when estimating the amplifier gain and underlying brain activity of an electrophysiological experiment. In this work, we present hierarchical neural posterior estimation (HNPE), a novel method for cracking such indeterminacy by exploiting additional information conveyed by an auxiliary set of observations sharing global parameters. Our method extends recent developments in simulation-based inference (SBI) based on normalizing flows to Bayesian hierarchical models. We validate quantitatively our proposal on a motivating example amenable to analytical solutions and then apply it to invert a well known non-linear model from computational neuroscience, using both simulated and real EEG data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neo-GNNs", "Title": "Neighborhood Overlap-aware Graph Neural Networks for Link Prediction", "Abstract": "Graph Neural Networks (GNNs) have been widely applied to various fields for learning over graph-structured data. They have shown significant improvements over traditional heuristic methods in various tasks such as node classification and graph classification. However, since GNNs heavily rely on smoothed node features rather than graph structure, they often show poor performance than simple heuristic methods in link prediction where the structural information, e.g., overlapped neighborhoods, degrees, and shortest paths, is crucial. To address this limitation, we propose Neighborhood Overlap-aware Graph Neural Networks (Neo-GNNs) that learn useful structural features from an adjacency matrix and estimate overlapped neighborhoods for link prediction. Our Neo-GNNs generalize neighborhood overlap-based heuristic methods and handle overlapped multi-hop neighborhoods. Our extensive experiments on Open Graph Benchmark datasets (OGB) demonstrate that Neo-GNNs consistently achieve state-of-the-art performance in link prediction."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tree in Tree", "Title": "from Decision Trees to Decision Graphs", "Abstract": "Decision trees have been widely used as classifiers in many machine learning applications thanks to their lightweight and interpretable decision process. This paper introduces Tree in Tree decision graph (TnT), a framework that extends the conventional decision tree to a more generic and powerful directed acyclic graph. TnT constructs decision graphs by recursively growing decision trees inside the internal or leaf nodes instead of greedy training. The time complexity of TnT is linear to the number of nodes in the graph, therefore it can construct decision graphs on large datasets. Compared to decision trees, we show that TnT achieves better classification performance with reduced model size, both as a stand-alone classifier and as a base-estimator in bagging/AdaBoost ensembles. Our proposed model is a novel, more efficient and accurate alternative to the widely-used decision trees."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GeoMol", "Title": "Torsional Geometric Generation of Molecular 3D Conformer Ensembles", "Abstract": "Prediction of a molecule’s 3D conformer ensemble from the molecular graph holds a key role in areas of cheminformatics and drug discovery. Existing generative models have several drawbacks including lack of modeling important molecular geometry elements (e.g., torsion angles), separate optimization stages prone to error accumulation, and the need for structure fine-tuning based on approximate classical force-fields or computationally expensive methods. We propose GEOMOL --- an end-to-end, non-autoregressive, and SE(3)-invariant machine learning approach to generate distributions of low-energy molecular 3D conformers. Leveraging the power of message passing neural networks (MPNNs) to capture local and global graph information, we predict local atomic 3D structures and torsion angles, avoid- ing unnecessary over-parameterization of the geometric degrees of freedom (e.g., one angle per non-terminal bond). Such local predictions suffice both for both the training loss computation and for the full deterministic conformer assembly (at test time). We devise a non-adversarial optimal transport based loss function to promote diverse conformer generation. GEOMOL predominantly outperforms popular open-source, commercial, or state-of-the-art machine learning (ML) models, while achieving significant speed-ups. We expect such differentiable 3D structure generators to significantly impact molecular modeling and related applications."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CANITA", "Title": "Faster Rates for Distributed Convex Optimization with Communication Compression", "Abstract": "Due to the high communication cost in distributed and federated learning, methods relying on compressed communication are becoming increasingly popular. Besides, the best theoretically and practically performing gradient-type methods invariably rely on some form of acceleration/momentum to reduce the number of communications (faster convergence), e.g., Nesterov's accelerated gradient descent [31, 32] and Adam [14]. In order to combine the benefits of communication compression and convergence acceleration, we propose a \\emph{compressed and accelerated} gradient method based on ANITA [20] for distributed optimization, which we call CANITA. Our CANITA achieves the \\emph{first accelerated rate} $O\\bigg(\\sqrt{\\Big(1+\\sqrt{\\frac{\\omega^3}{n}}\\Big)\\frac{L}{\\epsilon}} + \\omega\\big(\\frac{1}{\\epsilon}\\big)^{\\frac{1}{3}}\\bigg)$, which improves upon the state-of-the-art non-accelerated rate  $O\\left((1+\\frac{\\omega}{n})\\frac{L}{\\epsilon} + \\frac{\\omega^2+\\omega}{\\omega+n}\\frac{1}{\\epsilon}\\right)$ of DIANA [12] for distributed general convex problems, where $\\epsilon$ is the target error,  $L$ is the smooth parameter of the objective, $n$ is the number of machines/devices, and $\\omega$ is the compression parameter (larger $\\omega$ means more compression can be applied, and no compression implies $\\omega=0$). Our results show that as long as the number of devices $n$ is large (often true in distributed/federated learning), or the compression $\\omega$ is not very high,  CANITA achieves the faster convergence rate $O\\Big(\\sqrt{\\frac{L}{\\epsilon}}\\Big)$, i.e., the number of communication rounds is $O\\Big(\\sqrt{\\frac{L}{\\epsilon}}\\Big)$ (vs. $O\\big(\\frac{L}{\\epsilon}\\big)$ achieved by previous works). As a result, CANITA enjoys the advantages of both compression (compressed communication in each round) and acceleration (much fewer communication rounds)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Drop-DTW", "Title": "Aligning Common Signal Between Sequences While Dropping Outliers", "Abstract": "In this work, we consider the problem of sequence-to-sequence alignment for signals containing outliers.  Assuming the absence of outliers, the standard Dynamic Time Warping (DTW) algorithm efficiently computes the optimal alignment between two (generally) variable-length sequences.  While DTW is robust to temporal shifts and dilations of the signal, it fails to align sequences in a meaningful way in the presence of outliers that can be arbitrarily interspersed in the sequences.  To address this problem, we introduce Drop-DTW, a novel algorithm that aligns the common signal between the sequences while automatically dropping the outlier elements from the matching.  The entire procedure is implemented as a single dynamic program that is efficient and fully differentiable.  In our experiments, we show that Drop-DTW is a robust similarity measure for sequence retrieval and demonstrate its effectiveness as a training loss on diverse applications. With Drop-DTW, we address temporal step localization on instructional videos, representation learning from noisy videos, and cross-modal representation learning for audio-visual retrieval and localization. In all applications, we take a weakly- or unsupervised approach and demonstrate state-of-the-art results under these settings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ToAlign", "Title": "Task-Oriented Alignment for Unsupervised Domain Adaptation", "Abstract": "Unsupervised domain adaptive classifcation intends to improve the classifcation performance on unlabeled target domain. To alleviate the adverse effect of domain shift, many approaches align the source and target domains in the feature space. However, a feature is usually taken as a whole for alignment without explicitly making domain alignment proactively serve the classifcation task, leading to sub-optimal solution. In this paper, we propose an effective Task-oriented Alignment (ToAlign) for unsupervised domain adaptation (UDA). We study what features should be aligned across domains and propose to make the domain alignment proactively serve classifcation by performing feature decomposition and alignment under the guidance of the prior knowledge induced from the classifcation task itself. Particularly, we explicitly decompose a feature in the source domain into a task-related/discriminative feature that should be aligned, and a task-irrelevant feature that should be avoided/ignored, based on the classifcation meta-knowledge. Extensive experimental results on various benchmarks (e.g., Offce-Home, Visda-2017, and DomainNet) under different domain adaptation settings demonstrate the effectiveness of ToAlign which helps achieve the state-of-the-art performance. The code is publicly available at https://github.com/microsoft/UDA."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DynamicViT", "Title": "Efficient Vision Transformers with Dynamic Token Sparsification", "Abstract": "Attention is sparse in vision transformers. We observe the final prediction in vision transformers is only based on a subset of most informative tokens, which is sufficient for accurate image recognition. Based on this observation, we propose a dynamic token sparsification framework to prune redundant tokens progressively and dynamically based on the input. Specifically, we devise a lightweight prediction module to estimate the importance score of each token given the current features. The module is added to different layers to prune redundant tokens hierarchically. To optimize the prediction module in an end-to-end manner, we propose an attention masking strategy to differentiably prune a token by blocking its interactions with other tokens. Benefiting from the nature of self-attention, the unstructured sparse tokens are still hardware friendly, which makes our framework easy to achieve actual speed-up. By hierarchically pruning 66% of the input tokens, our method greatly reduces 31% $\\sim$ 37%  FLOPs and improves the throughput by over 40% while the drop of accuracy is within 0.5% for various vision transformers. Equipped with the dynamic token sparsification framework,  DynamicViT models can achieve very competitive complexity/accuracy trade-offs compared to state-of-the-art CNNs and vision transformers on ImageNet. Code is available at https://github.com/raoyongming/DynamicViT"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PortaSpeech", "Title": "Portable and High-Quality Generative Text-to-Speech", "Abstract": "Non-autoregressive text-to-speech (NAR-TTS) models such as FastSpeech 2 and Glow-TTS can synthesize high-quality speech from the given text in parallel. After analyzing two kinds of generative NAR-TTS models (VAE and normalizing flow), we find that: VAE is good at capturing the long-range semantics features (e.g., prosody) even with small model size but suffers from blurry and unnatural results; and normalizing flow is good at reconstructing the frequency bin-wise details but performs poorly when the number of model parameters is limited. Inspired by these observations, to generate diverse speech with natural details and rich prosody using a lightweight architecture, we propose PortaSpeech, a portable and high-quality generative text-to-speech model. Specifically, 1) to model both the prosody and mel-spectrogram details accurately, we adopt a lightweight VAE with an enhanced prior followed by a flow-based post-net with strong conditional inputs as the main architecture. 2) To further compress the model size and memory footprint, we introduce the grouped parameter sharing mechanism to the affine coupling layers in the post-net. 3) To improve the expressiveness of synthesized speech and reduce the dependency on accurate fine-grained alignment between text and speech, we propose a linguistic encoder with mixture alignment combining hard word-level alignment and soft phoneme-level alignment, which explicitly extracts word-level semantic information.  Experimental results show that PortaSpeech outperforms other TTS models in both voice quality and prosody modeling in terms of subjective and objective evaluation metrics, and shows only a slight performance degradation when reducing the model parameters to 6.7M (about 4x model size and 3x runtime memory compression ratio compared with FastSpeech 2). Our extensive ablation studies demonstrate that each design in PortaSpeech is effective."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "From Optimality to Robustness", "Title": "Adaptive Re-Sampling Strategies in Stochastic Bandits", "Abstract": "The stochastic multi-arm bandit problem has been extensively studied under standard assumptions on the arm's distribution (e.g bounded with known support, exponential family, etc). These assumptions are suitable for many real-world problems but sometimes they require knowledge (on tails for instance) that may not be precisely accessible to the practitioner, raising the question of the robustness of bandit algorithms to model misspecification. In this paper we study a generic \\emph{Dirichlet Sampling} (DS) algorithm, based on pairwise comparisons of empirical indices computed with \\textit{re-sampling} of the arms' observations and a data-dependent \\textit{exploration bonus}. We show that different variants of this strategy achieve provably optimal regret guarantees when the distributions are bounded and logarithmic regret for semi-bounded distributions with a mild quantile condition. We also show that a  simple tuning achieve robustness with respect to a large class of unbounded distributions, at the cost of slightly worse than logarithmic asymptotic regret. We finally provide numerical experiments showing the merits of DS in a decision-making problem on synthetic agriculture data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CCVS", "Title": "Context-aware Controllable Video Synthesis", "Abstract": "This presentation introduces a self-supervised learning approach to the synthesis of new videos clips from old ones, with several new key elements for improved spatial resolution and realism: It conditions the synthesis process on contextual information for temporal continuity and ancillary information for fine control. The prediction model is doubly autoregressive, in the latent space of an autoencoder for forecasting, and in image space for updating contextual information, which is also used to enforce spatio-temporal consistency through a learnable optical flow module. Adversarial training of the autoencoder in the appearance and temporal domains is used to further improve the realism of its output. A quantizer inserted between the encoder and the transformer in charge of forecasting future frames in latent space (and its inverse inserted between the transformer and the decoder) adds even more flexibility by affording simple mechanisms for handling multimodal ancillary information for controlling the synthesis process (e.g., a few sample frames, an audio track, a trajectory in image space) and taking into account the intrinsically uncertain nature of the future by allowing multiple predictions. Experiments with an implementation of the proposed approach give very good qualitative and quantitative results on multiple tasks and standard benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predify", "Title": "Augmenting deep neural networks with brain-inspired predictive coding dynamics", "Abstract": "Deep neural networks excel at image classification, but their performance is far less robust to input perturbations than human perception. In this work we explore whether this shortcoming may be partly addressed by incorporating brain-inspired recurrent dynamics in deep convolutional networks. We take inspiration from a popular framework in neuroscience: \"predictive coding\". At each layer of the hierarchical model, generative feedback \"predicts\" (i.e., reconstructs) the pattern of activity in the previous layer. The reconstruction errors are used to iteratively update the network’s representations across timesteps, and to optimize the network's feedback weights over the natural image dataset--a form of unsupervised training. We show that implementing this strategy into two popular networks, VGG16 and EfficientNetB0, improves their robustness against various corruptions and adversarial attacks. We hypothesize that other feedforward networks could similarly benefit from the proposed framework. To promote research in this direction, we provide an open-sourced PyTorch-based package called \\textit{Predify}, which can be used to implement and investigate the impacts of the predictive coding dynamics in any convolutional neural network."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Slow Learning and Fast Inference", "Title": "Efficient Graph Similarity Computation via Knowledge Distillation", "Abstract": "Graph Similarity Computation (GSC) is essential to wide-ranging graph applications such as retrieval, plagiarism/anomaly detection, etc. The exact computation of graph similarity, e.g., Graph Edit Distance (GED), is an NP-hard problem that cannot be exactly solved within an adequate time given large graphs. Thanks to the strong representation power of graph neural network (GNN), a variety of GNN-based inexact methods emerged. To capture the subtle difference across graphs, the key success is designing the dense interaction with features fusion at the early stage, which, however, is a trade-off between speed and accuracy. For slow learning of graph similarity, this paper proposes a novel early-fusion approach by designing a co-attention-based feature fusion network on multilevel GNN features. To further improve the speed without much accuracy drop, we introduce an efficient GSC solution by distilling the knowledge from the slow early-fusion model to the student one for fast inference. Such a student model also enables the offline collection of individual graph embeddings, speeding up the inference time in orders. To address the instability through knowledge transfer, we decompose the dynamic joint embedding into the static pseudo individual ones for precise teacher-student alignment. The experimental analysis on the real-world datasets demonstrates the superiority of our approach over the state-of-the-art methods on both accuracy and efficiency. Particularly, we speed up the prior art by more than 10x on the benchmark AIDS data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BernNet", "Title": "Learning Arbitrary Graph Spectral Filters via Bernstein Approximation", "Abstract": "Many representative graph neural networks, $e.g.$, GPR-GNN and ChebNet, approximate graph convolutions with graph spectral filters. However, existing work either applies predefined filter weights or learns them without necessary constraints, which may lead to oversimplified or ill-posed filters. To overcome these issues, we propose $\\textit{BernNet}$, a novel graph neural network with theoretical support that provides a simple but effective scheme for designing and learning arbitrary graph spectral filters. In particular, for any filter over the normalized Laplacian spectrum of a graph, our BernNet estimates it by an order-$K$ Bernstein polynomial approximation and designs its spectral property by setting the coefficients of the Bernstein basis. Moreover, we can learn the coefficients (and the corresponding filter weights) based on observed graphs and their associated signals and thus achieve the BernNet specialized for the data. Our experiments demonstrate that BernNet can learn arbitrary spectral filters, including complicated band-rejection and comb filters, and it achieves superior performance in real-world graph modeling tasks. Code is available at https://github.com/ivam-he/BernNet."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking and Reweighting the Univariate Losses for Multi-Label Ranking", "Title": "Consistency and Generalization", "Abstract": "The (partial) ranking loss is a commonly used evaluation measure for multi-label classification, which is usually optimized with convex surrogates for computational efficiency. Prior theoretical efforts on multi-label ranking mainly focus on (Fisher) consistency analyses. However, there is a gap between existing theory and practice --- some inconsistent pairwise losses can lead to promising performance, while some consistent univariate losses usually have no clear superiority in practice. To take a step towards filling up this gap, this paper presents a systematic study from two complementary perspectives of consistency and generalization error bounds of learning algorithms. We theoretically find two key factors of the distribution (or dataset) that affect the learning guarantees of algorithms: the instance-wise class imbalance and the label size $c$. Specifically, in an extremely imbalanced case, the algorithm with the consistent univariate loss has an error bound of $O(c)$, while the one with the inconsistent pairwise loss depends on $O(\\sqrt{c})$ as shown in prior work. This may shed light on the superior performance of pairwise methods in practice, where real datasets are usually highly imbalanced. Moreover, we present an inconsistent reweighted univariate loss-based algorithm that enjoys an error bound of $O(\\sqrt{c})$ for promising performance as well as the computational efficiency of univariate losses. Finally, experimental results confirm our theoretical findings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spot the Difference", "Title": "Detection of Topological Changes via Geometric Alignment", "Abstract": "Geometric alignment appears in a variety of applications, ranging from domain adaptation, optimal transport, and normalizing flows in machine learning; optical flow and learned augmentation in computer vision and deformable registration within biomedical imaging. A recurring challenge is the alignment of domains whose topology is not the same; a problem that is routinely ignored, potentially introducing bias in downstream analysis. As a first step towards solving such alignment problems, we propose an unsupervised algorithm for the detection of changes in image topology. The model is based on a conditional variational auto-encoder and detects topological changes between two images during the registration step. We account for both topological changes in the image under spatial variation and unexpected transformations. Our approach is validated on two tasks and datasets: detection of topological changes in microscopy images of cells, and unsupervised anomaly detection brain imaging."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Linear and Kernel Classification in the Streaming Model", "Title": "Improved Bounds for Heavy Hitters", "Abstract": "We study linear and kernel classification in the streaming model. For linear classification, we improve upon the algorithm of (Tai, et al. 2018), which solves the $\\ell_1$ point query problem on the optimal weight vector $w_* \\in \\mathbb{R}^d$ in sublinear space. We first give an algorithm solving the more difficult $\\ell_2$ point query problem on $w_*$, also in sublinear space. We also give an algorithm which solves the $\\ell_2$ heavy hitter problem on $w_*$, in sublinear space and running time. Finally, we give an algorithm which can $\\textit{deterministically}$ solve the $\\ell_1$ point query problem on $w_*$, with sublinear space improving upon that of (Tai, et al. 2018). For kernel classification, if $w_* \\in \\mathbb{R}^{d^p}$ is the optimal weight vector classifying points in the stream according to their $p^{th}$-degree polynomial kernel, then we give an algorithm solving the $\\ell_2$ point query problem on $w_*$ in $\\text{poly}(\\frac{p \\log d}{\\varepsilon})$ space, and an algorithm solving the $\\ell_2$ heavy hitter problem in $\\text{poly}(\\frac{p \\log d}{\\varepsilon})$ space and running time. Note that our space and running time are polynomial in $p$, making our algorithms well-suited to high-degree polynomial kernels and the Gaussian kernel (approximated by the polynomial kernel of degree $p = \\Theta(\\log T)$)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Look at What I’m Doing", "Title": "Self-Supervised Spatial Grounding of Narrations in Instructional Videos", "Abstract": "We introduce the task of spatially localizing narrated interactions in videos. Key to our approach is the ability to learn to spatially localize interactions with self-supervision on a large corpus of videos with accompanying transcribed narrations. To achieve this goal, we propose a multilayer cross-modal attention network that enables effective optimization of a contrastive loss during training. We introduce a divided strategy that alternates between computing inter- and intra-modal attention across the visual and natural language modalities, which allows effective training via directly contrasting the two modalities' representations. We demonstrate the effectiveness of our approach by self-training on the HowTo100M instructional video dataset and evaluating on a newly collected dataset of localized described interactions in the YouCook2 dataset. We show that our approach outperforms alternative baselines, including shallow co-attention and full cross-modal attention. We also apply our approach to grounding phrases in images with weak supervision on Flickr30K and show that stacking multiple attention layers is effective and, when combined with a word-to-region loss, achieves state of the art on recall-at-one and pointing hand accuracies."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RETRIEVE", "Title": "Coreset Selection for Efficient and Robust Semi-Supervised Learning", "Abstract": "Semi-supervised learning (SSL) algorithms have had great success in recent years in limited labeled data regimes. However, the current state-of-the-art SSL algorithms are computationally expensive and entail significant compute time and energy requirements. This can prove to be a huge limitation for many smaller companies and academic groups. Our main insight is that training on a subset of unlabeled data instead of entire unlabeled data enables the current SSL algorithms to converge faster, significantly reducing computational costs. In this work, we propose RETRIEVE, a coreset selection framework for efficient and robust semi-supervised learning. RETRIEVE selects the coreset by solving a mixed discrete-continuous bi-level optimization problem such that the selected coreset minimizes the labeled set loss. We use a one-step gradient approximation and show that the discrete optimization problem is approximately submodular, enabling simple greedy algorithms to obtain the coreset. We empirically demonstrate on several real-world datasets that existing SSL algorithms like VAT, Mean-Teacher, FixMatch, when used with RETRIEVE, achieve a) faster training times,  b) better performance when unlabeled data consists of Out-of-Distribution (OOD) data and imbalance. More specifically, we show that with minimal accuracy degradation, RETRIEVE achieves a speedup of around $3\\times$ in the traditional SSL setting and achieves a speedup of $5\\times$ compared to state-of-the-art (SOTA) robust SSL algorithms in the case of imbalance and OOD data. RETRIEVE is available as a part of the CORDS toolkit: https://github.com/decile-team/cords."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "S$^3$", "Title": "Sign-Sparse-Shift Reparametrization for Effective Training of Low-bit Shift Networks", "Abstract": "Shift neural networks reduce computation complexity by removing expensive multiplication operations and quantizing continuous weights into low-bit discrete values, which are fast and energy-efficient compared to conventional neural networks. However, existing shift networks are sensitive to the weight initialization and yield a degraded performance caused by vanishing gradient and weight sign freezing problem. To address these issues, we propose S$^3$ re-parameterization, a novel technique for training low-bit shift networks. Our method decomposes a discrete parameter in a sign-sparse-shift 3-fold manner. This way, it efficiently learns a low-bit network with weight dynamics similar to full-precision networks and insensitive to weight initialization. Our proposed training method pushes the boundaries of shift neural networks and shows 3-bit shift networks compete with their full-precision counterparts in terms of top-1 accuracy on ImageNet."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Implicit MLE", "Title": "Backpropagating Through Discrete Exponential Family Distributions", "Abstract": "Combining discrete probability distributions and combinatorial optimization problems with neural network components has numerous applications but poses several challenges. We propose Implicit Maximum Likelihood Estimation (I-MLE), a framework for end-to-end learning of models combining discrete exponential family distributions and differentiable neural components. I-MLE is widely applicable as it only requires the ability to compute the most probable states and does not rely on smooth relaxations. The framework encompasses several approaches such as perturbation-based implicit differentiation and recent methods to differentiate through black-box combinatorial solvers. We introduce a novel class of noise distributions for approximating marginals via perturb-and-MAP. Moreover, we show that I-MLE simplifies to maximum likelihood estimation when used in some recently studied learning settings that involve combinatorial solvers. Experiments on several datasets suggest that I-MLE is competitive with and often outperforms existing approaches which rely on problem-specific relaxations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Linear Convergence in Federated Learning", "Title": "Tackling Client Heterogeneity and Sparse Gradients", "Abstract": "We consider a standard federated learning (FL) setup where a group of clients periodically coordinate with a central server to train a statistical model. We develop a general algorithmic framework called FedLin to tackle some of the key challenges intrinsic to FL, namely objective heterogeneity, systems heterogeneity, and infrequent and imprecise communication. Our framework is motivated by the observation that under these challenges, various existing FL algorithms suffer from a fundamental speed-accuracy conflict: they either guarantee linear convergence but to an incorrect point, or convergence to the global minimum but at a sub-linear rate, i.e., fast convergence comes at the expense of accuracy. In contrast, when the clients' local loss functions are smooth and strongly convex, we show that FedLin guarantees linear convergence to the global minimum, despite arbitrary objective and systems heterogeneity. We then establish matching upper and lower bounds on the convergence rate of FedLin that highlight the effects of infrequent, periodic communication. Finally, we show that FedLin preserves linear convergence rates under aggressive gradient sparsification, and quantify the effect of the compression level on the convergence rate. Notably, our work is the first to provide tight linear convergence rate guarantees, and constitutes the first comprehensive analysis of gradient sparsification in FL."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dynamic Sasvi", "Title": "Strong Safe Screening for Norm-Regularized Least Squares", "Abstract": "A recently introduced technique, called safe screening,'' for a sparse optimization problem allows us to identify irrelevant variables in the early stages of optimization. In this paper, we first propose a flexible framework for safe screening based on the Fenchel--Rockafellar duality and then derive a strong safe screening rule for norm-regularized least squares using the proposed framework. We refer to the proposed screening rule for norm-regularized least squares asdynamic Sasvi'' because it can be interpreted as a generalization of Sasvi. Unlike the original Sasvi, it does not require the exact solution of a more strongly regularized problem; hence, it works safely in practice. We show that our screening rule always eliminates more features compared with the existing state-of-the-art methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Topic Modeling Revisited", "Title": "A Document Graph-based Neural Network Perspective", "Abstract": "Most topic modeling approaches are based on the bag-of-words assumption, where each word is required to be conditionally independent in the same document. As a result, both of the generative story and the topic formulation have totally ignored the semantic dependency among words, which is important for improving the semantic comprehension and model interpretability. To this end, in this paper, we revisit the task of topic modeling by transforming each document into a directed graph with word dependency as edges between word nodes, and develop a novel approach, namely Graph Neural Topic Model (GNTM). Specifically, in GNTM, a well-defined probabilistic generative story is designed to model both the graph structure and word sets with multinomial distributions on the vocabulary and word dependency edge set as the topics. Meanwhile, a Neural Variational Inference (NVI) approach is proposed to learn our model with graph neural networks to encode the document graphs. Besides, we theoretically demonstrate that Latent Dirichlet Allocation (LDA) can be derived from GNTM as a special case with similar objective functions. Finally, extensive experiments on four benchmark datasets have clearly demonstrated the effectiveness and interpretability of GNTM compared with state-of-the-art baselines."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fast Routing under Uncertainty", "Title": "Adaptive Learning in Congestion Games via Exponential Weights", "Abstract": "We examine an adaptive learning framework for nonatomic congestion games where the players' cost functions may be subject to exogenous fluctuations (e.g., due to disturbances in the network, variations in the traffic going through a link). In this setting, the popular multiplicative/ exponential weights algorithm enjoys an $\\mathcal{O}(1/\\sqrt{T})$ equilibrium convergence rate; however, this rate is suboptimal in static environments---i.e., when the network is not subject to randomness. In this static regime, accelerated algorithms achieve an $\\mathcal{O}(1/T^{2})$ convergence speed, but they fail to converge altogether in stochastic problems. To fill this gap, we propose a novel,  adaptive exponential weights method---dubbed AdaWeight---that seamlessly interpolates between the $\\mathcal{O}(1/T^{2})$  and $\\mathcal{O}(1/\\sqrt{T})$ rates in the static and stochastic regimes respectively. Importantly, this \"best-of-both-worlds\" guarantee does not require any prior knowledge of the problem's parameters or tuning by the optimizer; in addition, the method's convergence speed depends subquadratically on the size of the network (number of vertices and edges), so it scales gracefully to large, real-life urban networks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MAP Propagation Algorithm", "Title": "Faster Learning with a Team of Reinforcement Learning Agents", "Abstract": "Nearly all state-of-the-art deep learning algorithms rely on error backpropagation, which is generally regarded as biologically implausible. An alternative way of training an artificial neural network is through treating each unit in the network as a reinforcement learning agent, and thus the network is considered as a team of agents. As such, all units can be trained by REINFORCE, a local learning rule modulated by a global signal that is more consistent with biologically observed forms of synaptic plasticity. Although this learning rule follows the gradient of return in expectation, it suffers from high variance and thus the low speed of learning, rendering it impractical to train deep networks. We therefore propose a novel algorithm called MAP propagation to reduce this variance significantly while retaining the local property of the learning rule. Experiments demonstrated that MAP propagation could solve common reinforcement learning tasks at a similar speed to backpropagation when applied to an actor-critic network. Our work thus allows for the broader application of teams of agents in deep reinforcement learning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TransGAN", "Title": "Two Pure Transformers Can Make One Strong GAN, and That Can Scale Up", "Abstract": "The recent explosive interest on transformers has suggested their potential to become powerful ``universal\" models for computer vision tasks, such as classification, detection, and segmentation. While those attempts mainly study the discriminative models, we explore transformers on some more notoriously difficult vision tasks, e.g., generative adversarial networks (GANs).  Our goal is to conduct the first pilot study in building a GAN \\textit{completely free of convolutions}, using only pure transformer-based architectures. Our vanilla GAN architecture, dubbed \\textbf{TransGAN}, consists of a memory-friendly transformer-based generator that progressively increases feature resolution, and correspondingly a multi-scale discriminator to capture simultaneously semantic contexts and low-level textures. On top of them, we introduce the new module of grid self-attention for alleviating the memory bottleneck further, in order to scale up TransGAN to high-resolution generation. We also develop a unique training recipe including a series of techniques that can mitigate the training instability issues of TransGAN, such as data augmentation, modified normalization, and relative position encoding. Our best architecture achieves highly competitive performance compared to current state-of-the-art GANs using convolutional backbones. Specifically, TransGAN sets \\textbf{new state-of-the-art} inception score of 10.43 and FID of 18.28 on STL-10. It also reaches the inception score of 9.02 and FID of 9.26  on CIFAR-10, and 5.28 FID on CelebA $\\mathbf{128} \\times \\mathbf{128}$, respectively: both on par with the current best results and outperforming StyleGAN-V2. When it comes to higher-resolution (e.g. $\\mathbf{256} \\times \\mathbf{256}$) generation tasks, such as on CelebA-HQ and LSUN-Church, TransGAN continues to produce diverse visual examples with high fidelity and impressive texture details. In addition, we dive deep into the transformer-based generation models to understand how their behaviors differ from convolutional ones, by visualizing training dynamics. The code is available at: https://github.com/VITA-Group/TransGAN."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Qimera", "Title": "Data-free Quantization with Synthetic Boundary Supporting Samples", "Abstract": "Model quantization is known as a promising method to compress deep neural networks, especially for inferences on lightweight mobile or edge devices. However, model quantization usually requires access to the original training data to maintain the accuracy of the full-precision models, which is often infeasible in real-world scenarios for security and privacy issues.A popular approach to perform quantization without access to the original data is to use synthetically generated samples, based on batch-normalization statistics or adversarial learning.However, the drawback of such approaches is that they primarily rely on random noise input to the generator to attain diversity of the synthetic samples. We find that this is often insufficient to capture the distribution of the original data, especially around the decision boundaries.To this end, we propose Qimera, a method that uses superposed latent embeddings to generate synthetic boundary supporting samples.For the superposed embeddings to better reflect the original distribution, we also propose using an additional disentanglement mapping layer and extracting information from the full-precision model.The experimental results show that Qimera achieves state-of-the-art performances for various settings on data-free quantization. Code is available at https://github.com/iamkanghyunchoi/qimera."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "M-FAC", "Title": "Efficient Matrix-Free Approximations of Second-Order Information", "Abstract": "Efficiently approximating local curvature information of the loss function is a useful tool for the optimization and compression of deep neural networks. Yet, most existing methods to approximate second-order information have high computational or storage costs, limiting their practicality. In this work, we investigate matrix-free approaches for estimating Inverse-Hessian Vector Products (IHVPs) for the case when the Hessian can be approximated as a sum of rank-one matrices, as in the classic approximation of the Hessian by the empirical Fisher matrix. The first algorithm we propose is tailored towards network compression and can compute the IHVP for dimension $d$ given a fixed set of $m$ rank-one matrices using $O(dm^2)$ precomputation, $O(dm)$ cost for computing the IHVP and query cost $O(m)$ for computing any single element of the inverse Hessian approximation. The second algorithm targets an optimization setting, where we wish to compute the product between the inverse Hessian, estimated over a sliding  window of optimization steps, and a given gradient direction. We give an algorithm with cost $O(dm + m^2)$ for computing the IHVP and $O(dm + m^3)$ for adding or removing any gradient from the sliding window. We show that both algorithms yield competitive results for network pruning and optimization, respectively, with significantly lower computational overhead relative to existing second-order methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Anti-Backdoor Learning", "Title": "Training Clean Models on Poisoned Data", "Abstract": "Backdoor attack has emerged as a major security threat to deep neural networks (DNNs). While existing defense methods have demonstrated promising results on detecting or erasing backdoors, it is still not clear whether robust training methods can be devised to prevent the backdoor triggers being injected into the trained model in the first place. In this paper, we introduce the concept of \\emph{anti-backdoor learning}, aiming to train \\emph{clean} models given backdoor-poisoned data. We frame the overall learning process as a dual-task of learning the \\emph{clean} and the \\emph{backdoor} portions of data. From this view, we identify two inherent characteristics of backdoor attacks as their weaknesses: 1) the models learn backdoored data much faster than learning with clean data, and the stronger the attack the faster the model converges on backdoored data; 2) the backdoor task is tied to a specific class (the backdoor target class). Based on these two weaknesses, we propose a general learning scheme, Anti-Backdoor Learning (ABL), to automatically prevent backdoor attacks during training. ABL introduces a two-stage \\emph{gradient ascent} mechanism for standard training to 1) help isolate backdoor examples at an early training stage, and 2) break the correlation between backdoor examples and the target class at a later training stage. Through extensive experiments on multiple benchmark datasets against 10 state-of-the-art attacks, we empirically show that ABL-trained models on backdoor-poisoned data achieve the same performance as they were trained on purely clean data. Code is available at \\url{https://github.com/bboylyg/ABL}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "H-NeRF", "Title": "Neural Radiance Fields for Rendering and Temporal Reconstruction of Humans in Motion", "Abstract": "We present neural radiance fields for rendering and temporal (4D) reconstruction of humans in motion (H-NeRF), as captured by a sparse set of cameras or even from a monocular video. Our approach combines ideas from neural scene representation, novel-view synthesis, and implicit statistical geometric human representations, coupled using novel loss functions. Instead of learning a radiance field with a uniform occupancy prior, we constrain it by a structured implicit human body model, represented using signed distance functions. This allows us to robustly fuse information from sparse views and generalize well beyond the poses or views observed in training. Moreover, we apply geometric constraints to co-learn the structure of the observed subject -- including both body and clothing -- and to regularize the radiance field to geometrically plausible solutions. Extensive experiments on multiple datasets demonstrate the robustness and the accuracy of our approach, its generalization capabilities significantly outside a small training set of poses and views, and statistical extrapolation beyond the observed shape."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DOBF", "Title": "A Deobfuscation Pre-Training Objective for Programming Languages", "Abstract": "Recent advances in self-supervised learning have dramatically improved the state of the art on a wide variety of tasks. However, research in language model pre-training has mostly focused on natural languages, and it is unclear whether models like BERT and its variants provide the best pre-training when applied to other modalities, such as source code. In this paper, we introduce a new pre-training objective, DOBF, that leverages the structural aspect of programming languages and pre-trains a model to recover the original version of obfuscated source code. We show that models pre-trained with DOBF significantly outperform existing approaches on multiple downstream tasks, providing relative improvements of up to 12.2% in unsupervised code translation, and 5.3% in natural language code search. Incidentally, we found that our pre-trained model is able to deobfuscate fully obfuscated source files, and to suggest descriptive variable names."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interventional Sum-Product Networks", "Title": "Causal Inference with Tractable Probabilistic Models", "Abstract": "While probabilistic models are an important tool for studying causality, doing so suffers from the intractability of inference. As a step towards tractable causal models, we consider the problem of learning interventional distributions using sum-product networks (SPNs) that are over-parameterized by gate functions, e.g., neural networks. Providing an arbitrarily intervened causal graph as input, effectively subsuming Pearl's do-operator, the gate function predicts the parameters of the SPN. The resulting interventional SPNs are motivated and illustrated by a structural causal model themed around personal health. Our empirical evaluation against competing methods from both generative and causal modelling demonstrates that interventional SPNs indeed are both expressive and causally adequate."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PettingZoo", "Title": "Gym for Multi-Agent Reinforcement Learning", "Abstract": "This paper introduces the PettingZoo library and the accompanying Agent Environment Cycle (\"AEC\") games model. PettingZoo is a library of diverse sets of multi-agent environments with a universal, elegant Python API. PettingZoo was developed with the goal of accelerating research in Multi-Agent Reinforcement Learning (\"MARL\"), by making work more interchangeable, accessible and reproducible akin to what OpenAI's Gym library did for single-agent reinforcement learning. PettingZoo's API, while inheriting many features of Gym, is unique amongst MARL APIs in that it's based around the novel AEC games model. We argue, in part through case studies on major problems in popular MARL environments, that the popular game models are poor conceptual models of the games commonly used with MARL, that they promote severe bugs that are hard to detect, and that the AEC games model addresses these problems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Decision Transformer", "Title": "Reinforcement Learning via Sequence Modeling", "Abstract": "We introduce a framework that abstracts Reinforcement Learning (RL) as a sequence modeling problem. This allows us to draw upon the simplicity and scalability of the Transformer architecture, and associated advances in language modeling such as GPT-x and BERT. In particular, we present Decision Transformer, an architecture that casts the problem of RL as conditional sequence modeling. Unlike prior approaches to RL that fit value functions or compute policy gradients, Decision Transformer simply outputs the optimal actions by leveraging a causally masked Transformer. By conditioning an autoregressive model on the desired return (reward), past states, and actions, our Decision Transformer model can generate future actions that achieve the desired return. Despite its simplicity, Decision Transformer matches or exceeds the performance of state-of-the-art model-free offline RL baselines on Atari, OpenAI Gym, and Key-to-Door tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TNASP", "Title": "A Transformer-based NAS Predictor with a Self-evolution Framework", "Abstract": "Predictor-based Neural Architecture Search (NAS) continues to be an important topic because it aims to mitigate the time-consuming search procedure of traditional NAS methods. A promising performance predictor determines the quality of final searched models in predictor-based NAS methods. Most existing predictor-based methodologies train model-based predictors under a proxy dataset setting, which may suffer from the accuracy decline and the generalization problem, mainly due to their poor abilities to represent spatial topology information of the graph structure data. Besides the poor encoding for spatial topology information, these works did not take advantage of the temporal information such as historical evaluations during training. Thus, we propose a Transformer-based NAS performance predictor, associated with a Laplacian matrix based positional encoding strategy, which better represents topology information and achieves better performance than previous state-of-the-art methods on NAS-Bench-101, NAS-Bench-201, and DARTS search space. Furthermore, we also propose a self-evolution framework that can fully utilize temporal information as guidance. This framework iteratively involves the evaluations of previously predicted results as constraints into current optimization iteration, thus further improving the performance of our predictor. Such framework is model-agnostic, thus can enhance performance on various backbone structures for the prediction task. Our proposed method helped us rank 2nd among all teams in CVPR 2021 NAS Competition Track 2: Performance Prediction Track."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analytic Study of Families of Spurious Minima in Two-Layer ReLU Neural Networks", "Title": "A Tale of Symmetry II", "Abstract": "We study the optimization problem associated with fitting two-layer ReLU neural networks with respect to the squared loss, where labels are generated by a target network. We make use of the rich symmetry structure to develop a novel set of tools for studying families of spurious minima. In contrast to existing approaches which operate in limiting regimes, our technique directly addresses the nonconvex loss landscape for finite number of inputs $d$ and neurons $k$, and provides analytic, rather than heuristic, information. In particular, we derive analytic estimates for the loss at different minima, and prove that, modulo $O(d^{-1/2})$-terms, the Hessian spectrum concentrates near small positive constants, with the exception of $\\Theta(d)$ eigenvalues which grow linearly with~$d$. We further show that the Hessian spectrum at global and spurious minima coincide to $O(d^{-1/2})$-order, thus challenging our ability to argue about statistical generalization through local curvature. Lastly, our technique provides the exact \\emph{fractional} dimensionality at which families of critical points turn from saddles into spurious minima. This makes possible the study of the creation and the annihilation of spurious minima using powerful tools from equivariant bifurcation theory."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CAM-GAN", "Title": "Continual Adaptation Modules for Generative Adversarial Networks", "Abstract": "We present a continual learning approach for generative adversarial networks (GANs), by designing and leveraging parameter-efficient feature map transformations. Our approach is based on learning a set of global and task-specific parameters. The global parameters are fixed across tasks whereas the task-specific parameters act as local adapters for each task, and help in efficiently obtaining task-specific feature maps. Moreover, we propose an element-wise addition of residual bias in the transformed feature space, which further helps stabilize GAN training in such settings. Our approach also leverages task similarities based on the Fisher information matrix. Leveraging this knowledge from previous tasks significantly improves the model performance. In addition, the similarity measure also helps reduce the parameter growth in continual adaptation and helps to learn a compact model. In contrast to the recent approaches for continually-learned GANs, the proposed approach provides a memory-efficient way to perform effective continual data generation. Through extensive experiments on challenging and diverse datasets, we show that the feature-map-transformation approach outperforms state-of-the-art methods for continually-learned GANs, with substantially fewer parameters. The proposed method generates high-quality samples that can also improve the generative-replay-based continual learning for discriminative tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unadversarial Examples", "Title": "Designing Objects for Robust Vision", "Abstract": "We study a class of computer vision settings wherein one can modify the design of the objects being recognized. We develop a framework that leverages this capability---and deep networks' unusual sensitivity to input perturbations---to design ``robust objects,'' i.e., objects that are explicitly optimized to be confidently classified. Our framework yields improved performance on standard benchmarks, a simulated robotics environment, and physical-world experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ResT", "Title": "An Efficient Transformer for Visual Recognition", "Abstract": "This paper presents an efficient multi-scale vision Transformer, called ResT, that capably served as a general-purpose backbone for image recognition. Unlike existing Transformer methods, which employ standard Transformer blocks to tackle raw images with a fixed resolution, our ResT have several advantages: (1) A memory-efficient multi-head self-attention is built, which compresses the memory by a simple depth-wise convolution, and projects the interaction across the attention-heads dimension while keeping the diversity ability of multi-heads; (2) Positional encoding is constructed as spatial attention, which is more flexible and can tackle with input images of arbitrary size without interpolation or fine-tune; (3) Instead of the straightforward tokenization at the beginning of each stage, we design the patch embedding as a stack of overlapping convolution operation with stride on the token map. We comprehensively validate ResT on image classification and downstream tasks. Experimental results show that the proposed ResT can outperform the recently state-of-the-art backbones by a large margin, demonstrating the potential of ResT as strong backbones. The code and models will be made publicly available at https://github.com/wofmanaf/ResT."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CROCS", "Title": "Clustering and Retrieval of Cardiac Signals Based on Patient Disease Class, Sex, and Age", "Abstract": "The process of manually searching for relevant instances in, and extracting information from, clinical databases underpin a multitude of clinical tasks. Such tasks include disease diagnosis, clinical trial recruitment, and continuing medical education. This manual search-and-extract process, however, has been hampered by the growth of large-scale clinical databases and the increased prevalence of unlabelled instances. To address this challenge, we propose a supervised contrastive learning framework, CROCS, where representations of cardiac signals associated with a set of patient-specific attributes (e.g., disease class, sex, age) are attracted to learnable embeddings entitled clinical prototypes. We exploit such prototypes for both the clustering and retrieval of unlabelled cardiac signals based on multiple patient attributes. We show that CROCS outperforms the state-of-the-art method, DTC, when clustering and also retrieves relevant cardiac signals from a large database. We also show that clinical prototypes adopt a semantically meaningful arrangement based on patient attributes and thus confer a high degree of interpretability."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Combinatorial Optimization for Panoptic Segmentation", "Title": "A Fully Differentiable Approach", "Abstract": "We propose a fully differentiable architecture for simultaneous semantic and instance segmentation (a.k.a. panoptic segmentation) consisting of a convolutional neural network and an asymmetric multiway cut problem solver. The latter solves a combinatorial optimization problem that elegantly incorporates semantic and boundary predictions to produce a panoptic labeling. Our formulation allows to directly maximize a smooth surrogate of the panoptic quality metric by backpropagating the gradient through the optimization problem. Experimental evaluation shows improvement by backpropagating through the optimization problem w.r.t. comparable approaches on Cityscapes and COCO datasets. Overall, our approach of combinatorial optimization for panoptic segmentation (COPS) shows the utility of using optimization in tandem with deep learning in a challenging large scale real-world problem and showcases benefits and insights into training such an architecture."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Breaking the Moments Condition Barrier", "Title": "No-Regret Algorithm for Bandits with Super Heavy-Tailed Payoffs", "Abstract": "Despite a large amount of effort in dealing with heavy-tailed error in machine learning, little is known when moments of the error can become non-existential: the random noise $\\eta$ satisfies Pr$\\left[|\\eta| > |y|\\right] \\le 1/|y|^{\\alpha}$ for some $\\alpha > 0$. We make the first attempt to actively handle such super heavy-tailed noise in bandit learning problems:  We propose a novel robust statistical estimator, mean of medians, which estimates a random variable by computing the empirical mean of a sequence of empirical medians. We then present a generic reductionist algorithmic framework for solving bandit learning problems (including multi-armed and linear bandit problem): the mean of medians estimator can be applied to nearly any bandit learning algorithm as a black-box filtering for its reward signals and obtain similar regret bound as if the reward is sub-Gaussian. We show that the regret bound is near-optimal even with very heavy-tailed noise. We also empirically demonstrate the effectiveness of the proposed algorithm, which further corroborates our theoretical results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FLEX", "Title": "Unifying Evaluation for Few-Shot NLP", "Abstract": "Few-shot NLP research is highly active, yet conducted in disjoint research threads with evaluation suites that lack challenging-yet-realistic testing setups and fail to employ careful experimental design. Consequently, the community does not know which techniques perform best or even if they outperform simple baselines. In response, we formulate the FLEX Principles, a set of requirements and best practices for unified, rigorous, valid, and cost-sensitive few-shot NLP evaluation. These principles include Sample Size Design, a novel approach to benchmark design that optimizes statistical accuracy and precision while keeping evaluation costs manageable. Following the principles, we release the FLEX benchmark, which includes four few-shot transfer settings, zero-shot evaluation, and a public leaderboard that covers diverse NLP tasks. In addition, we present UniFew, a prompt-based model for few-shot learning that unifies pretraining and finetuning prompt formats, eschewing complex machinery of recent prompt-based approaches in adapting downstream task formats to language model pretraining objectives. We demonstrate that despite simplicity, UniFew achieves results competitive with both popular meta-learning and prompt-based approaches."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DP-SSL", "Title": "Towards Robust Semi-supervised Learning with A Few Labeled Samples", "Abstract": "The scarcity of labeled data is a critical obstacle to deep learning. Semi-supervised learning (SSL) provides a promising way to leverage unlabeled data by pseudo labels. However, when the size of labeled data is very small (say a few labeled samples per class), SSL performs poorly and unstably, possibly due to the low quality of learned pseudo labels. In this paper, we propose a new SSL method called DP-SSL that adopts an innovative data programming (DP) scheme to generate probabilistic labels for unlabeled data. Different from existing DP methods that rely on human experts to provide initial labeling functions (LFs), we develop a multiple-choice learning~(MCL) based approach to automatically generate LFs from scratch in SSL style. With the noisy labels produced by the LFs, we design a label model to resolve the conflict and overlap among the noisy labels, and finally infer probabilistic labels for unlabeled samples. Extensive experiments on four standard SSL benchmarks show that DP-SSL can provide reliable labels for unlabeled data and achieve better classification performance on test sets than existing SSL methods, especially when only a small number of labeled samples are available. Concretely, for CIFAR-10 with only 40 labeled samples, DP-SSL achieves 93.82% annotation accuracy on unlabeled data and 93.46% classification accuracy on test data, which are higher than the SOTA results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Spatial Ensemble", "Title": "a Novel Model Smoothing Mechanism for Student-Teacher Framework", "Abstract": "Model smoothing is of central importance for obtaining a reliable teacher model in the student-teacher framework, where the teacher generates surrogate supervision signals to train the student. A popular model smoothing method is the Temporal Moving Average (TMA), which continuously averages the teacher parameters with the up-to-date student parameters. In this paper, we propose ''Spatial Ensemble'', a novel model smoothing mechanism in parallel with TMA. Spatial Ensemble randomly picks up a small fragment of the student model to directly replace the corresponding fragment of the teacher model. Consequentially, it stitches different fragments of historical student models into a unity, yielding the ''Spatial Ensemble'' effect. Spatial Ensemble obtains comparable student-teacher learning performance by itself and demonstrates valuable complementarity with temporal moving average. Their integration, named Spatial-Temporal Smoothing, brings general (sometimes significant) improvement to the student-teacher learning framework on a variety of state-of-the-art methods. For example, based on the self-supervised method BYOL, it yields +0.9% top-1 accuracy improvement on ImageNet, while based on the semi-supervised approach FixMatch, it increases the top-1 accuracy by around +6% on CIFAR-10 when only few training labels are available. Codes and models are available at: https://github.com/tengteng95/Spatial_Ensemble."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Wasserstein Flow Meets Replicator Dynamics", "Title": "A Mean-Field Analysis of Representation Learning in Actor-Critic", "Abstract": "Actor-critic  (AC) algorithms, empowered by neural networks, have had significant empirical success in recent years. However, most of the existing theoretical support for AC algorithms focuses on the case of linear function approximations, or linearized neural networks, where the feature representation is fixed throughout training. Such a limitation fails to capture the key aspect of representation learning in neural AC, which is pivotal in practical problems. In this work, we take a mean-field perspective on the evolution and convergence of feature-based neural AC. Specifically, we consider a version of  AC where the actor and critic are represented by overparameterized two-layer neural networks and are updated with two-timescale learning rates. The critic is updated by temporal-difference (TD) learning with a larger stepsize while the actor is updated via proximal policy optimization (PPO) with a smaller stepsize. In the continuous-time and infinite-width limiting regime, when the timescales are properly separated, we prove that neural AC finds the globally optimal policy at a sublinear rate. Additionally,  we prove that the feature representation induced by the critic network is allowed to evolve within a neighborhood of the initial one."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CAPE", "Title": "Encoding Relative Positions with Continuous Augmented Positional Embeddings", "Abstract": "Without positional information, attention-based Transformer neural networks are permutation-invariant. Absolute or relative positional embeddings are the most popular ways to feed Transformer models with positional information. Absolute positional embeddings are simple to implement, but suffer from generalization issues when evaluating on sequences longer than seen at training time. Relative positions are more robust to input length change, but are more complex to implement and yield inferior model throughput due to extra computational and memory costs. In this paper, we propose an augmentation-based approach (CAPE) for absolute positional embeddings, which keeps the advantages of both absolute (simplicity and speed) and relative positional embeddings (better generalization). In addition, our empirical evaluation on state-of-the-art models in machine translation, image and speech recognition demonstrates that CAPE leads to better generalization performance as well as increased stability with respect to training hyper-parameters."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DualNet", "Title": "Continual Learning, Fast and Slow", "Abstract": "According to Complementary Learning Systems (CLS) theory~\\cite{mcclelland1995there} in neuroscience, humans do effective \\emph{continual learning} through two complementary systems: a fast learning system centered on the hippocampus for rapid learning of the specifics and individual experiences, and a slow learning system located in the neocortex for the gradual acquisition of structured knowledge about the environment. Motivated by this theory, we propose a novel continual learning framework named ``DualNet\", which comprises a fast learning system for supervised learning of pattern-separated representation from specific tasks and a slow learning system for unsupervised representation learning of task-agnostic general representation via a Self-Supervised Learning (SSL) technique. The two fast and slow learning systems are complementary and work seamlessly in a holistic continual learning framework. Our extensive experiments on two challenging continual learning benchmarks of CORE50 and miniImageNet show that DualNet outperforms state-of-the-art continual learning methods by a large margin. We further conduct ablation studies of different SSL objectives to validate DualNet's efficacy, robustness, and scalability. Code is publicly available at \\url{https://github.com/phquang/DualNet}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deformable Butterfly", "Title": "A Highly Structured and Sparse Linear Transform", "Abstract": "We introduce a new kind of linear transform named Deformable Butterfly (DeBut) that generalizes the conventional butterfly matrices and can be adapted to various input-output dimensions. It inherits the fine-to-coarse-grained learnable hierarchy of traditional butterflies and when deployed to neural networks, the prominent structures and sparsity in a DeBut layer constitutes a new way for network compression. We apply DeBut as a drop-in replacement of standard fully connected and convolutional layers, and demonstrate its superiority in homogenizing a neural network and rendering it favorable properties such as light weight and low inference complexity, without compromising accuracy. The natural complexity-accuracy tradeoff arising from the myriad deformations of a DeBut layer also opens up new rooms for analytical and practical research. The codes and Appendix are publicly available at: https://github.com/ruilin0212/DeBut."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Better Safe Than Sorry", "Title": "Preventing Delusive Adversaries with Adversarial Training", "Abstract": "Delusive attacks aim to substantially deteriorate the test accuracy of the learning model by slightly perturbing the features of correctly labeled training examples. By formalizing this malicious attack as finding the worst-case training data within a specific $\\infty$-Wasserstein ball, we show that minimizing adversarial risk on the perturbed data is equivalent to optimizing an upper bound of natural risk on the original data. This implies that adversarial training can serve as a principled defense against delusive attacks. Thus, the test accuracy decreased by delusive attacks can be largely recovered by adversarial training. To further understand the internal mechanism of the defense, we disclose that adversarial training can resist the delusive perturbations by preventing the learner from overly relying on non-robust features in a natural setting. Finally, we complement our theoretical findings with a set of experiments on popular benchmark datasets, which show that the defense withstands six different practical attacks. Both theoretical and empirical results vote for adversarial training when confronted with delusive adversaries."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Analysis and Synthesis", "Title": "Reconstructing Speech from Self-Supervised Representations", "Abstract": "We present a neural analysis and synthesis (NANSY) framework that can manipulate the voice, pitch, and speed of an arbitrary speech signal.  Most of the previous works have focused on using information bottleneck to disentangle analysis features for controllable synthesis, which usually results in poor reconstruction quality. We address this issue by proposing a novel training strategy based on information perturbation. The idea is to perturb information in the original input signal (e.g., formant, pitch, and frequency response), thereby letting synthesis networks selectively take essential attributes to reconstruct the input signal. Because NANSY does not need any bottleneck structures, it enjoys both high reconstruction quality and controllability. Furthermore, NANSY does not require any labels associated with speech data such as text and speaker information, but rather uses a new set of analysis features, i.e., wav2vec feature and newly proposed pitch feature, Yingram, which allows for fully self-supervised training. Taking advantage of fully self-supervised training, NANSY can be easily extended to a multilingual setting by simply training it with a multilingual dataset. The experiments show that NANSY can achieve significant improvement in performance in several applications such as zero-shot voice conversion, pitch shift, and time-scale modification."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EditGAN", "Title": "High-Precision Semantic Image Editing", "Abstract": "Generative adversarial networks (GANs) have recently found applications in image editing. However, most GAN-based image editing methods often require large-scale datasets with semantic segmentation annotations for training, only provide high-level control, or merely interpolate between different images. Here, we propose EditGAN, a novel method for high-quality, high-precision semantic image editing, allowing users to edit images by modifying their highly detailed part segmentation masks, e.g., drawing a new mask for the headlight of a car. EditGAN builds on a GAN framework that jointly models images and their semantic segmentation, requiring only a handful of labeled examples – making it a scalable tool for editing. Specifically, we embed an image into the GAN’s latent space and perform conditional latent code optimization according to the segmentation edit, which effectively also modifies the image. To amortize optimization, we find “editing vectors” in latent space that realize the edits. The framework allows us to learn an arbitrary number of editing vectors, which can then be directly applied on other images at interactive rates. We experimentally show that EditGAN can manipulate images with an unprecedented level of detail and freedom while preserving full image quality. We can also easily combine multiple edits and perform plausible edits beyond EditGAN’s training data. We demonstrate EditGAN on a wide variety of image types and quantitatively outperform several previous editing methods on standard editing benchmark tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reinforcement Learning in Linear MDPs", "Title": "Constant Regret and Representation Selection", "Abstract": "We study the role of the representation of state-action value functions in regret minimization in finite-horizon Markov Decision Processes (MDPs) with linear structure. We first derive a necessary condition on the representation, called universally spanning optimal features (UNISOFT), to achieve constant regret in any MDP with linear reward function. This result encompasses the well-known settings of low-rank MDPs and, more generally, zero inherent Bellman error (also known as the Bellman closure assumption). We then demonstrate that this condition is also sufficient for these classes of problems by deriving a constant regret bound for two optimistic algorithms (LSVI-UCB and ELEANOR). Finally, we propose an algorithm for representation selection and we prove that it achieves constant regret when one of the given representations, or a suitable combination of them, satisfies the UNISOFT condition."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Noether Networks", "Title": "meta-learning useful conserved quantities", "Abstract": "Progress in machine learning (ML) stems from a combination of data availability, computational resources, and an appropriate encoding of inductive biases. Useful biases often exploit symmetries in the prediction problem, such as convolutional networks relying on translation equivariance. Automatically discovering these useful symmetries holds the potential to greatly improve the performance of ML systems, but still remains a challenge. In this work, we focus on sequential prediction problems and take inspiration from Noether's theorem to reduce the problem of finding inductive biases to meta-learning useful conserved quantities. We propose Noether Networks: a new type of architecture where a meta-learned conservation loss is optimized inside the prediction function. We show, theoretically and experimentally, that Noether Networks improve prediction quality, providing a general framework for discovering inductive biases in sequential problems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GradInit", "Title": "Learning to Initialize Neural Networks for Stable and Efficient Training", "Abstract": "Innovations in neural architectures have fostered significant breakthroughs in language modeling and computer vision. Unfortunately, novel architectures often result in challenging hyper-parameter choices and training instability if the network parameters are not properly initialized. A number of architecture-specific initialization schemes have been proposed, but these schemes are not always portable to new architectures. This paper presents GradInit, an automated and architecture agnostic method for initializing neural networks. GradInit is based on a simple heuristic; the norm of each network layer is adjusted so that a single step of SGD or Adam with prescribed hyperparameters results in the smallest possible loss value. This adjustment is done by introducing a scalar multiplier variable in front of each parameter block, and then optimizing these variables using a simple numerical scheme. GradInit accelerates the convergence and test performance of many convolutional architectures, both with or without skip connections, and even without normalization layers. It also improves the stability of the original Transformer architecture for machine translation, enabling training it without learning rate warmup using either Adam or SGD under a wide range of learning rates and momentum coefficients. Code is available at https://github.com/zhuchen03/gradinit."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DROID-SLAM", "Title": "Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras", "Abstract": "We introduce DROID-SLAM, a new deep learning based SLAM system. DROID-SLAM consists of recurrent iterative updates of camera pose and pixelwise depth through a Dense Bundle Adjustment layer. DROID-SLAM is accurate, achieving large improvements over prior work, and robust, suffering from substantially fewer catastrophic failures. Despite training on monocular video, it can leverage stereo or RGB-D video to achieve improved performance at test time. The URL to our open source code is https://github.com/princeton-vl/DROID-SLAM."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Dubber", "Title": "Dubbing for Videos According to Scripts", "Abstract": "Dubbing is a post-production process of re-recording actors’ dialogues, which is extensively used in filmmaking and video production. It is usually performed manually by professional voice actors who read lines with proper prosody, and in synchronization with the pre-recorded videos. In this work, we propose Neural Dubber, the first neural network model to solve a novel automatic video dubbing (AVD) task: synthesizing human speech synchronized with the given video from the text. Neural Dubber is a multi-modal text-to-speech (TTS) model that utilizes the lip movement in the video to control the prosody of the generated speech. Furthermore, an image-based speaker embedding (ISE) module is developed for the multi-speaker setting, which enables Neural Dubber to generate speech with a reasonable timbre according to the speaker’s face. Experiments on the chemistry lecture single-speaker dataset and LRS2 multi-speaker dataset show that Neural Dubber can generate speech audios on par with state-of-the-art TTS models in terms of speech quality. Most importantly, both qualitative and quantitative evaluations show that Neural Dubber can control the prosody of synthesized speech by the video, and generate high-fidelity speech temporally synchronized with the video."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "HSVA", "Title": "Hierarchical Semantic-Visual Adaptation for Zero-Shot Learning", "Abstract": "Zero-shot learning (ZSL) tackles the unseen class recognition problem,  transferring semantic knowledge from seen classes to unseen ones. Typically, to guarantee desirable knowledge transfer, a common (latent) space is adopted for associating the visual and semantic domains in ZSL.  However, existing common space learning methods align the semantic and visual domains by merely mitigating distribution disagreement through one-step adaptation. This strategy is usually ineffective due to the heterogeneous nature of the feature representations in the two domains, which intrinsically contain both distribution and structure variations. To address this and advance ZSL, we propose a novel hierarchical semantic-visual adaptation (HSVA) framework. Specifically, HSVA aligns the semantic and visual domains by adopting a hierarchical two-step adaptation, i.e., structure adaptation and distribution adaptation. In the structure adaptation step, we take two task-specific encoders to encode the source data (visual domain) and the target data (semantic domain) into a structure-aligned common space. To this end, a  supervised adversarial discrepancy (SAD)  module is proposed to adversarially minimize the discrepancy between the predictions of two task-specific classifiers, thus making the visual and semantic feature manifolds more closely aligned. In the distribution adaptation step, we directly minimize the Wasserstein distance between the latent multivariate Gaussian distributions to align the visual and semantic distributions using a common encoder. Finally, the structure and distribution adaptation are derived in a unified framework under two partially-aligned variational autoencoders. Extensive experiments on four benchmark datasets demonstrate that HSVA achieves superior performance on both conventional and generalized ZSL. The code is available at \\url{https://github.com/shiming-chen/HSVA}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Symplectic Form", "Title": "Learning Hamiltonian Equations on General Coordinate Systems", "Abstract": "In recent years, substantial research on the methods for learning Hamiltonian equations has been conducted. Although these approaches are very promising, the commonly used representation of the Hamilton equation uses the generalized momenta, which are generally unknown. Therefore, the training data must be represented in this unknown coordinate system, and this causes difficulty in applying the model to real data. Meanwhile, Hamiltonian equations also have a coordinate-free expression that is expressed by using the symplectic 2-form. In this study, we propose a model that learns the symplectic form from data using neural networks, thereby providing a method for learning Hamiltonian equations from data represented in general coordinate systems, which are not limited to the generalized coordinates and the generalized momenta. Consequently, the proposed method is capable not only of modeling target equations of both Hamiltonian and Lagrangian formalisms but also of extracting unknown Hamiltonian structures hidden in the data. For example, many polynomial ordinary differential equations such as the Lotka-Volterra equation are known to admit non-trivial Hamiltonian structures, and our numerical experiments show that such structures can be certainly learned from data. Technically, each symplectic 2-form is associated with a skew-symmetric matrix, but not all skew-symmetric matrices define the symplectic 2-form. In the proposed method, using the fact that symplectic 2-forms are derived as the exterior derivative of certain differential 1-forms, we model the differential 1-form by neural networks, thereby improving the efficiency of learning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse Steerable Convolutions", "Title": "An Efficient Learning of SE(3)-Equivariant Features for Estimation and Tracking of Object Poses in 3D Space", "Abstract": "As a basic component of SE(3)-equivariant deep feature learning, steerable convolution has recently demonstrated its advantages for 3D semantic analysis. The advantages are, however, brought by expensive computations on dense, volumetric data, which prevent its practical use for efficient processing of 3D data that are inherently sparse. In this paper, we propose a novel design of Sparse Steerable Convolution (SS-Conv) to address the shortcoming; SS-Conv greatly accelerates steerable convolution with sparse tensors, while strictly preserving the property of SE(3)-equivariance. Based on SS-Conv, we propose a general pipeline for precise estimation of object poses, wherein a key design is a Feature-Steering module that  takes the full advantage of SE(3)-equivariance and is able to conduct an efficient pose refinement. To verify our designs, we conduct thorough experiments on three tasks of 3D object semantic analysis, including instance-level 6D pose estimation, category-level 6D pose and size estimation, and category-level 6D pose tracking. Our proposed pipeline based on SS-Conv outperforms existing methods on almost all the metrics evaluated by the three tasks. Ablation studies also show the superiority of our SS-Conv over alternative convolutions in terms of both accuracy and efficiency. Our code is released publicly at https://github.com/Gorilla-Lab-SCUT/SS-Conv."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learned Robust PCA", "Title": "A Scalable Deep Unfolding Approach for High-Dimensional Outlier Detection", "Abstract": "Robust principal component analysis (RPCA) is a critical tool in modern machine learning, which detects outliers in the task of low-rank matrix reconstruction. In this paper, we propose a scalable and learnable non-convex approach for high-dimensional RPCA problems, which we call Learned Robust PCA (LRPCA). LRPCA is highly efficient, and its free parameters can be effectively learned to optimize via deep unfolding. Moreover, we extend deep unfolding from finite iterations to infinite iterations via a novel feedforward-recurrent-mixed neural network model. We establish the recovery guarantee of LRPCA under mild assumptions for RPCA. Numerical experiments show that LRPCA outperforms the state-of-the-art RPCA algorithms, such as ScaledGD and AltProj, on both synthetic datasets and real-world applications."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ProTo", "Title": "Program-Guided Transformer for Program-Guided Tasks", "Abstract": "Programs, consisting of semantic and structural information, play an important role in the communication between humans and agents. Towards learning general program executors to unify perception, reasoning, and decision making, we formulate program-guided tasks which require learning to execute a given program on the observed task specification. Furthermore, we propose Program-Guided Transformers (ProTo), which integrates both semantic and structural guidance of a program by leveraging cross-attention and masked self-attention to pass messages between the specification and routines in the program. ProTo executes a program in a learned latent space and enjoys stronger representation ability than previous neural-symbolic approaches. We demonstrate that ProTo significantly outperforms the previous state-of-the-art methods on GQA visual reasoning and 2D Minecraft policy learning datasets. Additionally, ProTo demonstrates better generalization to unseen, complex, and human-written programs."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NEO", "Title": "Non Equilibrium Sampling on the Orbits of a Deterministic Transform", "Abstract": "Sampling from a complex distribution $\\pi$ and approximating its intractable normalizing constant $\\mathrm{Z}$ are challenging problems. In this paper, a novel family of importance samplers (IS) and Markov chain Monte Carlo (MCMC) samplers is derived. Given an invertible map $\\mathrm{T}$, these schemes combine (with weights) elements from the forward and backward Orbits   through points sampled from a proposal distribution $\\rho$. The map $\\mathrm{T}$ does not leave the target $\\pi$ invariant, hence the name NEO, standing for Non-Equilibrium Orbits. NEO-IS provides unbiased estimators of the normalizing constant and self-normalized IS estimators of expectations under $\\pi$ while NEO-MCMC combines multiple NEO-IS estimates of the normalizing constant and an iterated sampling-importance resampling mechanism to sample from $\\pi$. For $\\mathrm{T}$ chosen as a discrete-time integrator of a conformal Hamiltonian system, NEO-IS achieves state-of-the art performance on difficult benchmarks and NEO-MCMC is able to explore highly multimodal targets. Additionally, we provide detailed theoretical results for both methods. In particular, we show that NEO-MCMC is uniformly geometrically ergodic and establish explicit mixing time estimates under mild conditions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scatterbrain", "Title": "Unifying Sparse and Low-rank Attention", "Abstract": "Recent advances in efficient Transformers have exploited either the sparsity or low-rank properties of attention matrices to reduce the computational and memory bottlenecks of modeling long sequences. However, it is still challenging to balance the trade-off between model quality and efficiency to perform a one-size-fits-all approximation for different tasks. To better understand this trade-off, we observe that sparse and low-rank approximations excel in different regimes, determined by the softmax temperature in attention, and sparse + low-rank can outperform each individually. Inspired by the classical robust-PCA algorithm for sparse and low-rank decomposition, we propose Scatterbrain, a novel way to unify sparse (via locality sensitive hashing) and low-rank (via kernel feature map) attention for accurate and efficient approximation. The estimation is unbiased with provably low error. We empirically show that Scatterbrain can achieve $2.1 \\times$ lower error than baselines when serving as a drop-in replacement in BigGAN image generation and pre-trained T2T-ViT. On a pre-trained T2T Vision transformer, even without fine-tuning, Scatterbrain can reduce $98\\%$ of attention memory at the cost of only $1\\%$ drop in accuracy. We demonstrate Scatterbrain for end-to-end training with up to $4$ points better perplexity and 5 points better average accuracy than sparse or low-rank efficient transformers on language modeling and long-range-arena tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PTR", "Title": "A Benchmark for Part-based Conceptual, Relational, and Physical Reasoning", "Abstract": "A critical aspect of human visual perception is the ability to parse visual scenes into individual objects and further into object parts, forming part-whole hierarchies. Such composite structures could induce a rich set of semantic concepts and relations, thus playing an important role in the interpretation and organization of visual signals as well as for the generalization of visual perception and reasoning. However, existing visual reasoning benchmarks mostly focus on objects rather than parts. Visual reasoning based on the full part-whole hierarchy is much more challenging than object-centric reasoning due to finer-grained concepts, richer geometry relations, and more complex physics. Therefore, to better serve for part-based conceptual, relational and physical reasoning, we introduce a new large-scale diagnostic visual reasoning dataset named PTR. PTR contains around 80k RGBD synthetic images with ground truth object and part level annotations regarding semantic instance segmentation, color attributes, spatial and geometric relationships, and certain physical properties such as stability. These images are paired with 800k machine-generated questions covering various types of reasoning types, making them a good testbed for visual reasoning models. We examine several state-of-the-art visual reasoning models on this dataset and observe that they still make many surprising mistakes in situations where humans can easily infer the correct answer. We believe this dataset will open up new opportunities for part-based reasoning. PTR dataset and baseline models are publicly available."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PreferenceNet", "Title": "Encoding Human Preferences in Auction Design with Deep Learning", "Abstract": "The design of optimal auctions is a problem of interest in economics, game theory and computer science. Despite decades of effort, strategyproof, revenue-maximizing auction designs are still not known outside of restricted settings. However, recent methods using deep learning have shown some success in approximating optimal auctions, recovering several known solutions and outperforming strong baselines when optimal auctions are not known. In addition to maximizing revenue, auction mechanisms may also seek to encourage socially desirable constraints such as allocation fairness or diversity. However, these philosophical notions neither have standardization nor do they have widely accepted formal definitions. In this paper, we propose PreferenceNet, an extension of existing neural-network-based auction mechanisms to encode constraints using (potentially human-provided) exemplars of desirable allocations. In addition, we introduce a new metric to evaluate an auction allocations' adherence to such socially desirable constraints and demonstrate that our proposed method is competitive with current state-of-the-art neural-network based auction designs. We validate our approach through human subject research and show that we are able to effectively capture real human preferences."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sliced Mutual Information", "Title": "A Scalable Measure of Statistical Dependence", "Abstract": "Mutual information (MI) is a fundamental measure of statistical dependence, with a myriad of applications to information theory, statistics, and machine learning. While it possesses many desirable structural properties, the estimation of high-dimensional MI from samples suffers from the curse of dimensionality. Motivated by statistical scalability to high dimensions, this paper proposes sliced MI (SMI) as a surrogate measure of dependence. SMI is defined as an average of MI terms between one-dimensional random projections. We show that it preserves many of the structural properties of classic MI, while gaining scalable computation and efficient estimation from samples. Furthermore, and in contrast to classic MI, SMI can grow as a result of deterministic transformations. This enables leveraging SMI for feature extraction by optimizing it over processing functions of raw data to identify useful representations thereof. Our theory is supported by numerical studies of independence testing and feature extraction, which demonstrate the potential gains SMI offers over classic MI for high-dimensional inference."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Bandits Show-Off", "Title": "Simple and Efficient Exploration with Deep Networks", "Abstract": "Designing efficient exploration is central to Reinforcement Learning due to the fundamental problem posed by the exploration-exploitation dilemma.  Bayesian exploration strategies like Thompson Sampling resolve this trade-off in a principled way by modeling and updating the distribution of the parameters of the action-value function, the outcome model of the environment.However, this technique becomes infeasible for complex environments due to the computational intractability of maintaining probability distributions over parameters of outcome models of corresponding complexity.Moreover, the approximation techniques introduced to mitigate this issue typically result in poor exploration-exploitation trade-offs, as observed in the case of deep neural network models with approximate posterior methods that have been shown to underperform in the deep bandit scenario.In this paper we introduce Sample Average Uncertainty (SAU), a simple and efficient uncertainty measure for contextual bandits.While Bayesian approaches like Thompson Sampling estimate outcomes uncertainty indirectly by first quantifying the variability over the parameters of the outcome model, SAU is a frequentist approach that directly estimates the uncertainty of the outcomes based on the value predictions.Importantly, we show theoretically that the uncertainty measure estimated by SAU asymptotically matches the uncertainty provided by Thompson Sampling, as well as its regret bounds.Because of its simplicity SAU can be seamlessly applied to deep contextual bandits as a very scalable drop-in replacement for epsilon-greedy exploration.We confirm empirically our theory by showing that SAU-based exploration outperforms current state-of-the-art deep Bayesian bandit methods on several real-world datasets at modest computation cost, and make the code to reproduce our results available at \\url{https://github.com/ibm/sau-explore}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TRS", "Title": "Transferability Reduced Ensemble via Promoting Gradient Diversity and Model Smoothness", "Abstract": "Adversarial Transferability is an intriguing property - adversarial perturbation crafted against one model is also effective against another model, while these models are from different model families or training processes. To better protect ML systems against adversarial attacks, several questions are raised: what are the sufficient conditions for adversarial transferability, and how to bound it? Is there a way to reduce the adversarial transferability in order to improve the robustness of an ensemble ML model? To answer these questions, in this work we first theoretically analyze and outline sufficient conditions for adversarial transferability between models; then propose a practical algorithm to reduce the transferability between base models within an ensemble to improve its robustness. Our theoretical analysis shows that only promoting the orthogonality between gradients of base models is not enough to ensure low transferability; in the meantime, the model smoothness is an important factor to control the transferability. We also provide the lower and upper bounds of adversarial transferability under certain conditions. Inspired by our theoretical analysis, we propose an effective Transferability Reduced Smooth (TRS) ensemble training strategy to train a robust ensemble with low transferability by enforcing both gradient orthogonality and model smoothness between base models. We conduct extensive experiments on TRS and compare with 6 state-of-the-art ensemble baselines against 8 whitebox attacks on different datasets, demonstrating that the proposed TRS outperforms all baselines significantly."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Moser Flow", "Title": "Divergence-based Generative Modeling on Manifolds", "Abstract": "We are interested in learning generative models for complex geometries described via manifolds, such as spheres, tori, and other implicit surfaces. Current extensions of existing (Euclidean) generative models are restricted to specific geometries and typically suffer from high computational costs. We introduce Moser Flow (MF), a new class of generative models within the family of continuous normalizing flows (CNF). MF also produces a CNF via a solution to the change-of-variable formula, however differently from other CNF methods, its model (learned) density is parameterized as the source (prior) density minus the divergence of a neural network (NN). The divergence is a local, linear differential operator, easy to approximate and calculate on manifolds. Therefore, unlike other CNFs, MF does not require invoking or backpropagating through an ODE solver during training. Furthermore, representing the model density explicitly as the divergence of a NN rather than as a solution of an ODE facilitates learning high fidelity densities. Theoretically, we prove that MF constitutes a universal density approximator under suitable assumptions. Empirically, we demonstrate for the first time the use of flow models for sampling from general curved surfaces and achieve significant improvements in density estimation, sample quality, and training complexity over existing CNFs on challenging synthetic geometries and real-world benchmarks from the earth and climate sciences."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Long-Short Transformer", "Title": "Efficient Transformers for Language and Vision", "Abstract": "Transformers have achieved success in both language and vision domains. However, it is prohibitively expensive to scale them to long sequences such as long documents or high-resolution images, because self-attention mechanism has quadratic time and memory complexities with respect to the input sequence length. In this paper, we propose Long-Short Transformer (Transformer-LS), an efficient self-attention mechanism for modeling long sequences with linear complexity for both language and vision tasks. It aggregates a novel long-range attention with dynamic projection to model distant correlations and a short-term attention to capture fine-grained local correlations. We propose a dual normalization strategy to account for the scale mismatch between the two attention mechanisms. Transformer-LS can be applied to both autoregressive and bidirectional models without additional complexity. Our method outperforms the state-of-the-art models on multiple tasks in language and vision domains, including the Long Range Arena benchmark, autoregressive language modeling, and ImageNet classification. For instance, Transformer-LS achieves 0.97 test BPC on enwik8 using half the number of parameters than previous method, while being faster and is able to handle 3x as long sequences compared to its full-attention version on the same hardware. On ImageNet, it can obtain the state-of-the-art results (e.g., a moderate size of 55.8M model solely trained on 224x224 ImageNet-1K can obtain Top-1 accuracy 84.1%), while being more scalable on high-resolution images. The source code and models are released at https://github.com/NVIDIA/transformer-ls."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Implicit Bias of Minima Stability", "Title": "A View from Function Space", "Abstract": "The loss terrains of over-parameterized neural networks have multiple global minima. However, it is well known that stochastic gradient descent (SGD) can stably converge only to minima that are sufficiently flat w.r.t. SGD's step size. In this paper we study the effect that this mechanism has on the function implemented by the trained model. First, we extend the existing knowledge on minima stability to non-differentiable minima, which are common in ReLU nets. We then use our stability results to study a single hidden layer univariate ReLU network. In this setting, we show that SGD is biased towards functions whose second derivative (w.r.t the input) has a bounded weighted $L_1$ norm, and this is regardless of the initialization. In particular, we show that the function implemented by the network upon convergence gets smoother as the learning rate increases. The weight multiplying the second derivative is larger around the center of the support of the training distribution, and smaller towards its boundaries, suggesting that a trained model tends to be smoother at the center of the training distribution."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Practical, Provably-Correct Interactive Learning in the Realizable Setting", "Title": "The Power of True Believers", "Abstract": "We consider interactive learning in the realizable setting and develop a general framework to handle problems ranging from best arm identification to active classification. We begin our investigation with the observation that agnostic algorithms \\emph{cannot} be minimax-optimal in the realizable setting. Hence, we design novel computationally efficient algorithms for the realizable setting that match the minimax lower bound up to logarithmic factors and are general-purpose, accommodating a wide variety of function classes including kernel methods, H{\\\"o}lder smooth functions, and convex functions. The sample complexities of our algorithms can be quantified in terms of well-known quantities like the extended teaching dimension and haystack dimension. However, unlike algorithms based directly on those combinatorial quantities, our algorithms are computationally efficient. To achieve computational efficiency, our algorithms sample from the version space using Monte Carlo ``hit-and-run'' algorithms instead of maintaining the version space explicitly. Our approach has two key strengths. First, it is simple, consisting of two unifying, greedy algorithms. Second, our algorithms have the capability to seamlessly leverage prior knowledge that is often available and useful in practice. In addition to our new theoretical results, we demonstrate empirically that our algorithms are competitive with Gaussian process UCB methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Latent Equilibrium", "Title": "A unified learning theory for arbitrarily fast computation with arbitrarily slow neurons", "Abstract": "The response time of physical computational elements is finite, and neurons are no exception. In hierarchical models of cortical networks each layer thus introduces a response lag. This inherent property of physical dynamical systems results in delayed processing of stimuli and causes a timing mismatch between network output and instructive signals, thus afflicting not only inference, but also learning. We introduce Latent Equilibrium, a new framework for inference and learning in networks of slow components which avoids these issues by harnessing the ability of biological neurons to phase-advance their output with respect to their membrane potential. This principle enables quasi-instantaneous inference independent of network depth and avoids the need for phased plasticity or computationally expensive network relaxation phases. We jointly derive disentangled neuron and synapse dynamics from a prospective energy function that depends on a network's generalized position and momentum. The resulting model can be interpreted as a biologically plausible approximation of error backpropagation in deep cortical networks with continuous-time, leaky neuronal dynamics and continuously active, local plasticity. We demonstrate successful learning of standard benchmark datasets, achieving competitive performance using both fully-connected and convolutional architectures, and show how our principle can be applied to detailed models of cortical microcircuitry. Furthermore, we study the robustness of our model to spatio-temporal substrate imperfections to demonstrate its feasibility for physical realization, be it in vivo or in silico."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Markov Factor Analysis", "Title": "Towards Concurrent Temporal and Spatial Analysis of fMRI Data", "Abstract": "Factor analysis methods have been widely used in neuroimaging to transfer high dimensional imaging data into low dimensional, ideally interpretable representations. However, most of these methods overlook the highly nonlinear and complex temporal dynamics of neural processes when factorizing their imaging data. In this paper, we present deep Markov factor analysis (DMFA), a generative model that employs Markov property in a chain of low dimensional temporal embeddings together with spatial inductive assumptions, all related through neural networks, to capture temporal dynamics in functional magnetic resonance imaging (fMRI) data, and tackle their high spatial dimensionality, respectively. Augmented with a discrete latent, DMFA is able to cluster fMRI data in its low dimensional temporal embedding with regard to subject and cognitive state variability, therefore, enables validation of a variety of fMRI-driven neuroscientific hypotheses. Experimental results on both synthetic and real fMRI data demonstrate the capacity of DMFA in revealing interpretable clusters and capturing nonlinear temporal dependencies in these high dimensional imaging data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BooVAE", "Title": "Boosting Approach for Continual Learning of VAE", "Abstract": "Variational autoencoder (VAE) is a deep generative model for unsupervised learning, allowing to encode observations into the meaningful latent space. VAE is prone to catastrophic forgetting when tasks arrive sequentially, and only the data for the current one is available. We address this problem of continual learning for VAEs. It is known that the choice of the prior distribution over the latent space is crucial for VAE in the non-continual setting. We argue that it can also be helpful to avoid catastrophic forgetting. We learn the approximation of the aggregated posterior as a prior for each task. This approximation is parametrised as an additive mixture of distributions induced by an encoder evaluated at trainable pseudo-inputs. We use a greedy boosting-like approach with entropy regularisation to learn the components. This method encourages components diversity, which is essential as we aim at memorising the current task with the fewest components possible. Based on the learnable prior, we introduce an end-to-end approach for continual learning of VAEs and provide empirical studies on commonly used benchmarks (MNIST, Fashion MNIST, NotMNIST) and CelebA datasets. For each dataset, the proposed method avoids catastrophic forgetting in a fully automatic way."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Pessimism Meets Invariance", "Title": "Provably Efficient Offline Mean-Field Multi-Agent RL", "Abstract": "Mean-Field Multi-Agent Reinforcement Learning (MF-MARL) is attractive in the applications involving a large population of homogeneous agents, as it exploits the permutation invariance of agents and avoids the curse of many agents. Most existing results only focus on online settings, in which agents can interact with the environment during training. In some applications such as social welfare optimization, however, the interaction during training can be prohibitive or even unethical in the societal systems. To bridge such a gap, we propose a SAFARI (peSsimistic meAn-Field vAlue iteRatIon) algorithm for off-line MF-MARL, which only requires a handful of pre-collected experience data. Theoretically, under a weak coverage assumption that the experience dataset contains enough information about the optimal policy, we prove that for an episodic mean-field MDP with a horizon $H$ and $N$ training trajectories, SAFARI attains a sub-optimality gap of $\\mathcal{O}(H^2d_{\\rm eff} /\\sqrt{N})$, where $d_{\\rm eff}$ is the effective dimension of the function class for parameterizing the value function, but independent on the number of agents. Numerical experiments are provided."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MOMA", "Title": "Multi-Object Multi-Actor Activity Parsing", "Abstract": "Complex activities often involve multiple humans utilizing different objects to complete actions (e.g., in healthcare settings, physicians, nurses, and patients interact with each other and various medical devices). Recognizing activities poses a challenge that requires a detailed understanding of actors' roles, objects' affordances, and their associated relationships. Furthermore, these purposeful activities are composed of multiple achievable steps, including sub-activities and atomic actions, which jointly define a hierarchy of action parts. This paper introduces Activity Parsing as the overarching task of temporal segmentation and classification of activities, sub-activities, atomic actions, along with an instance-level understanding of actors, objects, and their relationships in videos. Involving multiple entities (actors and objects), we argue that traditional pair-wise relationships, often used in scene or action graphs, do not appropriately represent the dynamics between them. Hence, we introduce Action Hypergraph, a spatial-temporal graph containing hyperedges (i.e., edges with higher-order relationships), as a new representation. In addition, we introduce Multi-Object Multi-Actor (MOMA), the first benchmark and dataset dedicated to activity parsing. Lastly, to parse a video, we propose the HyperGraph Activity Parsing (HGAP) network, which outperforms several baselines, including those based on regular graphs and raw video data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Graph Posterior Network", "Title": "Bayesian Predictive Uncertainty for Node Classification", "Abstract": "The interdependence between nodes in graphs is key to improve class prediction on nodes, utilized in approaches like Label Probagation (LP) or in Graph Neural Networks (GNNs). Nonetheless, uncertainty estimation for non-independent node-level predictions is under-explored.  In this work, we explore uncertainty quantification for node classification in three ways: (1) We derive three axioms explicitly characterizing the expected predictive uncertainty behavior in homophilic attributed graphs.(2) We propose a new model Graph Posterior Network (GPN) which explicitly performs Bayesian posterior updates for predictions on interdependent nodes. GPN provably obeys the proposed axioms. (3) We extensively evaluate GPN and a strong set of baselines on semi-supervised node classification including detection of anomalous features, and detection of left-out classes. GPN outperforms existing approaches for uncertainty estimation in the experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Remember What You Want to Forget", "Title": "Algorithms for Machine Unlearning", "Abstract": "We study the problem of unlearning datapoints from a learnt model. The learner first receives a dataset $S$ drawn i.i.d. from an unknown distribution, and outputs a model $\\widehat{w}$ that performs well on  unseen samples from the same distribution. However, at some point in the future, any training datapoint $z \\in S$ can request to be unlearned, thus prompting the learner to modify its output model while still ensuring the same accuracy guarantees.  We initiate a rigorous study of generalization in machine unlearning, where the goal is to perform well on previously unseen datapoints. Our focus is on both computational and storage complexity. For the setting of convex losses, we provide an unlearning algorithm that can unlearn up to $O(n/d^{1/4})$ samples, where $d$ is the problem dimension. In comparison, in general, differentially private learning (which implies unlearning) only guarantees deletion of $O(n/d^{1/2})$ samples. This demonstrates a novel separation between differential privacy and machine unlearning."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ErrorCompensatedX", "Title": "error compensation for variance reduced algorithms", "Abstract": "Communication cost is one major bottleneck for the scalability for distributed learning. One approach to reduce the communication cost is to compress the gradient during communication. However, directly compressing the gradient decelerates the convergence speed, and the resulting algorithm may diverge for biased compression. Recent work addressed this problem for stochastic gradient descent by adding back the compression error from the previous step. This idea was further extended to one class of variance reduced algorithms, where the variance of the stochastic gradient is reduced by taking a moving average over all history gradients. However, our analysis shows that just adding the previous step's compression error, as done in existing work, does not fully compensate the compression error. So, we propose ErrorCompensateX, which uses the compression error from the previous two steps. We show that ErrorCompensateX can achieve the same asymptotic convergence rate with the training without compression. Moreover, we  provide a unified theoretical analysis framework for this class of variance reduced algorithms, with or without error compensation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "It Has Potential", "Title": "Gradient-Driven Denoisers for Convergent Solutions to Inverse Problems", "Abstract": "In recent years there has been increasing interest in leveraging denoisers for solving general inverse problems. Two leading frameworks are regularization-by-denoising (RED) and plug-and-play priors (PnP) which incorporate explicit likelihood functions with priors induced by denoising algorithms.  RED and PnP have shown state-of-the-art performance in diverse imaging tasks when powerful denoisersare used, such as convolutional neural networks (CNNs). However, the study of their convergence remains an active line of research.  Recent works derive the convergence of RED and PnP methods by treating CNN denoisers as approximations for maximum a posteriori (MAP) or minimum mean square error (MMSE) estimators.  Yet, state-of-the-art denoisers cannot be interpreted as either MAPor MMSE estimators, since they typically do not exhibit symmetric Jacobians. Furthermore, obtaining stable inverse algorithms often requires controlling the Lipschitz constant of CNN denoisers during training.  Precisely enforcing this constraint is impractical, hence, convergence cannot be completely guaranteed. In this work, we introduce image denoisers derived as the gradients of smooth scalar-valued deep neural networks, acting as potentials. This ensures two things: (1) the proposed denoisers display symmetric Jacobians, allowing for MAP and MMSE estimators interpretation; (2) the denoisers may be integrated into RED and PnP schemes with backtracking step size, removing the need for enforcing their Lipschitz constant. To show the latter, we develop a simple inversion method that utilizes the proposed denoisers. We theoretically establish its convergence to stationary points of an underlying objective function consisting of the learned potentials. We numerically validate our method through various imaging experiments, showing improved results compared to standard RED and PnP methods, and with additional provable stability."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Moshpit SGD", "Title": "Communication-Efficient Decentralized Training on Heterogeneous Unreliable Devices", "Abstract": "Training deep neural networks on large datasets can often be accelerated by using multiple compute nodes. This approach, known as distributed training, can utilize hundreds of computers via specialized message-passing protocols such as Ring All-Reduce.However, running these protocols at scale requires reliable high-speed networking that is only available in dedicated clusters.In contrast, many real-world applications, such as federated learning and cloud-based distributed training, operate on unreliable devices with unstable network bandwidth.As a result, these applications are restricted to using parameter servers or gossip-based averaging protocols.In this work, we lift that restriction by proposing Moshpit All-Reduce — an iterative averaging protocol that exponentially converges to the global average.We demonstrate the efficiency of our protocol for distributed optimization with strong theoretical guarantees.The experiments show 1.3x speedup for ResNet-50 training on ImageNet compared to competitive gossip-based strategies and 1.5x speedup when training ALBERT-large on preemptible compute nodes."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "IRM—when it works and when it doesn't", "Title": "A test case of natural language inference", "Abstract": "Invariant Risk Minimization (IRM) is a recently proposed framework for out-of-distribution (o.o.d) generalization.  Most of the studies on IRM so far have focused on theoretical results, toy problems, and simple models. In this work, we investigate the applicability of IRM to bias mitigation-a special case of o.o.d generalization-in increasingly naturalistic settings and deep models. Using natural language inference (NLI) as a test case, we start with a setting where both the dataset and the bias are synthetic, continue with a natural dataset and synthetic bias, and end with a fully realistic setting with natural datasets and bias. Our results show that in naturalistic settings, learning complex features in place of the bias proves to be difficult, leading to a rather small improvement over empirical risk minimization. Moreover, we find that in addition to being sensitive to random seeds, the performance of IRM also depends on several critical factors, notably dataset size, bias prevalence, and bias strength, thus limiting IRM's advantage in practical scenarios. Our results  highlight key challenges in applying IRM to real-world scenarios, calling for a more naturalistic characterization of  the problem setup for o.o.d generalization."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SalKG", "Title": "Learning From Knowledge Graph Explanations for Commonsense Reasoning", "Abstract": "Augmenting pre-trained language models with knowledge graphs (KGs) has achieved success on various commonsense reasoning tasks. However, for a given task instance, the KG, or certain parts of the KG, may not be useful. Although KG-augmented models often use attention to focus on specific KG components, the KG is still always used, and the attention mechanism is never explicitly taught which KG components should be used. Meanwhile, saliency methods can measure how much a KG feature (e.g., graph, node, path) influences the model to make the correct prediction, thus explaining which KG features are useful. This paper explores how saliency explanations can be used to improve KG-augmented models' performance. First, we propose to create coarse (Is the KG useful?) and fine (Which nodes/paths in the KG are useful?) saliency explanations. Second, to motivate saliency-based supervision, we analyze oracle KG-augmented models which directly use saliency explanations as extra inputs for guiding their attention. Third, we propose SalKG, a framework for KG-augmented models to learn from coarse and/or fine saliency explanations. Given saliency explanations created from a task's training set, SalKG jointly trains the model to predict the explanations, then solve the task by attending to KG features highlighted by the predicted explanations. On three popular commonsense QA benchmarks (CSQA, OBQA, CODAH) and a range of KG-augmented models, we show that SalKG can yield considerable performance gains --- up to 2.76% absolute improvement on CSQA."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FlexMatch", "Title": "Boosting Semi-Supervised Learning with Curriculum Pseudo Labeling", "Abstract": "The recently proposed FixMatch achieved state-of-the-art results on most semi-supervised learning (SSL) benchmarks. However, like other modern SSL algorithms, FixMatch uses a pre-defined constant threshold for all classes to select unlabeled data that contribute to the training, thus failing to consider different learning status and learning difficulties of different classes. To address this issue, we propose Curriculum Pseudo Labeling (CPL), a curriculum learning approach to leverage unlabeled data according to the model's learning status. The core of CPL is to flexibly adjust thresholds for different classes at each time step to let pass informative unlabeled data and their pseudo labels. CPL does not introduce additional parameters or computations (forward or backward propagation). We apply CPL to FixMatch and call our improved algorithm FlexMatch. FlexMatch achieves state-of-the-art performance on a variety of SSL benchmarks, with especially strong performances when the labeled data are extremely limited or when the task is challenging. For example, FlexMatch achieves 13.96% and 18.96% error rate reduction over FixMatch on CIFAR-100 and STL-10 datasets respectively, when there are only 4 labels per class. CPL also significantly boosts the convergence speed, e.g., FlexMatch can use only 1/5 training time of FixMatch to achieve even better performance. Furthermore, we show that CPL can be easily adapted to other SSL algorithms and remarkably improve their performances. We open-source our code at https://github.com/TorchSSL/TorchSSL."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Behavior From the Void", "Title": "Unsupervised Active Pre-Training", "Abstract": "We introduce a new unsupervised pre-training method for reinforcement learning called APT, which stands for Active Pre-Training. APT learns behaviors and representations by actively searching for novel states in reward-free environments. The key novel idea is to explore the environment by maximizing a non-parametric entropy computed in an abstract representation space, which avoids challenging density modeling and consequently allows our approach to scale much better in environments that have high-dimensional observations (e.g., image observations). We empirically evaluate APT by exposing task-specific reward after a long unsupervised pre-training phase. In Atari games, APT achieves human-level performance on 12 games and obtains highly competitive performance compared to canonical fully supervised RL algorithms. On DMControl suite, APT beats all baselines in terms of asymptotic performance and data efficiency and dramatically improves performance on tasks that are extremely difficult to train from scratch."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BulletTrain", "Title": "Accelerating Robust Neural Network Training via Boundary Example Mining", "Abstract": "Neural network robustness has become a central topic in machine learning in recent years. Most training algorithms that improve the model's robustness to adversarial and common corruptions also introduce a large computational overhead, requiring as many as ten times the number of forward and backward passes in order to converge. To combat this inefficiency, we propose BulletTrain, a boundary example mining technique to drastically reduce the computational cost of robust training. Our key observation is that only a small fraction of examples are beneficial for improving robustness. BulletTrain dynamically predicts these important examples and optimizes robust training algorithms to focus on the important examples. We apply our technique to several existing robust training algorithms and achieve a 2.2x speed-up for TRADES and MART on CIFAR-10 and a 1.7x speed-up for AugMix on CIFAR-10-C and CIFAR-100-C without any reduction in clean and robust accuracy."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PerSim", "Title": "Data-Efficient Offline Reinforcement Learning with Heterogeneous Agents via Personalized Simulators", "Abstract": "We consider offline reinforcement learning (RL) with heterogeneous agents under severe data scarcity, i.e., we only observe a single historical trajectory for every agent under an unknown, potentially sub-optimal policy. We find that the performance of state-of-the-art offline and model-based RL methods degrade significantly given such limited data availability, even for commonly perceived \"solved\" benchmark settings such as \"MountainCar\" and \"CartPole\". To address this challenge, we propose PerSim, a model-based offline RL approach which first learns a personalized simulator for each agent by collectively using the historical trajectories across all agents, prior to learning a policy. We do so by positing that the transition dynamics across agents can be represented as a latent function of latent factors associated with agents, states, and actions; subsequently, we theoretically establish that this function is well-approximated by a \"low-rank\" decomposition of separable agent, state, and action latent functions. This representation suggests a simple, regularized neural network architecture to effectively learn the transition dynamics per agent, even with scarce, offline data. We perform extensive experiments across several benchmark environments and RL methods. The consistent improvement of our approach, measured in terms of both state dynamics prediction and eventual reward, confirms the efficacy of our framework in leveraging limited historical data to simultaneously learn personalized policies across agents."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Sign Identification", "Title": "Minimization of the Number of Errors in Thresholding Bandits", "Abstract": "In the fixed budget thresholding bandit problem, an algorithm sequentially allocates a budgeted number of samples to different distributions. It then predicts whether the mean of each distribution is larger or lower than a given threshold. We introduce a large family of algorithms (containing most existing relevant ones), inspired by the Frank-Wolfe algorithm, and provide a thorough yet generic analysis of their performance. This allowed us to construct new explicit algorithms, for a broad class of problems, whose losses are within a small constant factor of the non-adaptive oracle ones. Quite interestingly, we observed that adaptive methodsempirically greatly out-perform non-adaptive oracles, an uncommon behavior in standard online learning settings, such as regret minimization. We explain this surprising phenomenon on an insightful toy problem."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "All Tokens Matter", "Title": "Token Labeling for Training Better Vision Transformers", "Abstract": "In this paper, we present token labeling---a new training objective for training high-performance vision transformers (ViTs). Different from the standard training objective of ViTs that computes the classification loss on an additional trainable class token, our proposed one takes advantage of all the image patch tokens to compute the training loss in a dense manner. Specifically, token labeling reformulates the image classification problem into multiple token-level recognition problems and assigns each patch token with an individual location-specific supervision generated by a machine annotator. Experiments show that token labeling can clearly and consistently improve the performance of various ViT models across a wide spectrum. For a vision transformer with 26M learnable parameters serving as an example, with token labeling, the model can achieve 84.4% Top-1 accuracy on ImageNet. The result can be further increased to 86.4% by slightly scaling the model size up to 150M, delivering the minimal-sized model among previous models (250M+) reaching 86%. We also show that token labeling can clearly improve the generalization capability of the pretrained models on downstream tasks with dense prediction, such as semantic segmentation.  Our code and model are publiclyavailable at https://github.com/zihangJiang/TokenLabeling."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Partition and Code", "Title": "learning how to compress graphs", "Abstract": "Can we use machine learning to compress graph data? The absence of ordering in graphs poses a significant challenge to conventional compression algorithms, limiting their attainable gains as well as their ability to discover relevant patterns. On the other hand, most graph compression approaches rely on domain-dependent handcrafted representations and cannot adapt to different underlying graph distributions. This work aims to establish the necessary principles a lossless graph compression method should follow to approach the entropy storage lower bound. Instead of making rigid assumptions about the graph distribution, we formulate the compressor as a probabilistic model that can be learned from data and generalise to unseen instances. Our “Partition and Code” framework entails three steps: first, a partitioning algorithm decomposes the graph into subgraphs, then these are mapped to the elements of a small dictionary on which we learn a probability distribution, and finally,  an entropy encoder translates the representation into bits.  All the components (partitioning, dictionary and distribution) are parametric and can be trained with gradient descent. We theoretically compare the compression quality of several graph encodings and prove, under mild conditions, that PnC achieves compression gains that grow either linearly or quadratically with the number of vertices. Empirically, PnC yields significant compression improvements on diverse real-world networks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structure learning in polynomial time", "Title": "Greedy algorithms, Bregman information, and exponential families", "Abstract": "Greedy algorithms have long been a workhorse for learning graphical models, and more broadly for learning statistical models with sparse structure. In the context of learning directed acyclic graphs, greedy algorithms are popular despite their worst-case exponential runtime. In practice, however, they are very efficient. We provide new insight into this phenomenon by studying a general greedy score-based algorithm for learning DAGs. Unlike edge-greedy algorithms such as the popular GES and hill-climbing algorithms, our approach is vertex-greedy and requires at most a polynomial number of score evaluations. We then show how recent polynomial-time algorithms for learning DAG models are a special case of this algorithm, thereby illustrating how these order-based algorithms can be rigourously interpreted as score-based algorithms. This observation suggests new score functions and optimality conditions based on the duality between Bregman divergences and exponential families, which we explore in detail. Explicit sample and computational complexity bounds are derived. Finally, we provide extensive experiments suggesting that this algorithm indeed optimizes the score in a variety of settings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SIMILAR", "Title": "Submodular Information Measures Based Active Learning In Realistic Scenarios", "Abstract": "Active  learning  has  proven  to  be  useful  for  minimizing  labeling  costs  by selecting  the  most  informative  samples. However,  existing  active  learning methods do not work well in realistic scenarios such as imbalance or rare classes,out-of-distribution data in the unlabeled set, and redundancy.  In this work, we propose SIMILAR (Submodular Information Measures based actIve LeARning), a unified active learning framework using recently proposed submodular information measures (SIM) as acquisition functions. We argue that SIMILAR not only works in standard active learning but also easily extends to the realistic settings considered above and acts as a one-stop solution for active learning that is scalable to large real-world datasets. Empirically, we show that SIMILAR significantly outperforms existing active learning algorithms by as much as ~5%−18%in the case of rare classes and ~5%−10%in the case of out-of-distribution data on several image classification tasks like CIFAR-10, MNIST, and ImageNet."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EIGNN", "Title": "Efficient Infinite-Depth Graph Neural Networks", "Abstract": "Graph neural networks (GNNs) are widely used for modelling graph-structured data in numerous applications. However, with their inherently finite aggregation layers, existing GNN models may not be able to effectively capture long-range dependencies in the underlying graphs. Motivated by this limitation, we propose a GNN model with infinite depth, which we call Efficient Infinite-Depth Graph Neural Networks (EIGNN), to efficiently capture very long-range dependencies. We theoretically derive a closed-form solution of EIGNN which makes training an infinite-depth GNN model tractable. We then further show that we can achieve more efficient computation for training EIGNN by using eigendecomposition. The empirical results of comprehensive experiments on synthetic and real-world datasets show that EIGNN has a better ability to capture long-range dependencies than recent baselines, and consistently achieves state-of-the-art performance. Furthermore, we show that our model is also more robust against both noise and adversarial perturbations on node features."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SubTab", "Title": "Subsetting Features of Tabular Data for Self-Supervised Representation Learning", "Abstract": "Self-supervised learning has been shown to be very effective in learning useful representations, and yet much of the success is achieved in data types such as images, audio, and text. The success is mainly enabled by taking advantage of spatial, temporal, or semantic structure in the data through augmentation. However, such structure may not exist in tabular datasets commonly used in fields such as healthcare, making it difficult to design an effective augmentation method, and hindering a similar progress in tabular data setting. In this paper, we introduce a new framework, Subsetting features of Tabular data (SubTab), that turns the task of learning from tabular data into a multi-view representation learning problem by dividing the input features to multiple subsets. We argue that reconstructing the data from the subset of its features rather than its corrupted version in an autoencoder setting can better capture its underlying latent representation. In this framework, the joint representation can be expressed as the aggregate of latent variables of the subsets at test time, which we refer to as collaborative inference. Our experiments show that the SubTab achieves the state of the art (SOTA) performance of 98.31% on MNIST in tabular setting, on par with CNN-based SOTA models, and surpasses existing baselines on three other real-world datasets by a significant margin."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Efficient First-Order Contextual Bandits", "Title": "Prediction, Allocation, and Triangular Discrimination", "Abstract": "A recurring theme in statistical learning, online learning, and beyond is that faster convergence rates are possible for problems with low noise, often quantified by the performance of the best hypothesis; such results are known as first-order or small-loss guarantees. While first-order guarantees are relatively well understood in statistical and online learning, adapting to low noise in contextual bandits (and more broadly, decision making) presents major algorithmic challenges. In a COLT 2017 open problem, Agarwal, Krishnamurthy, Langford, Luo, and Schapire asked whether first-order guarantees are even possible for contextual bandits and---if so---whether they can be attained by efficient algorithms. We give a resolution to this question by providing an optimal and efficient reduction from contextual bandits to online regression with the logarithmic (or, cross-entropy) loss. Our algorithm is simple and practical, readily accommodates rich function classes, and requires no distributional assumptions beyond realizability. In a large-scale empirical evaluation, we find that our approach typically outperforms  comparable non-first-order methods.On the technical side, we show that the logarithmic loss and an information-theoretic quantity called the triangular discrimination play a fundamental role in obtaining first-order guarantees, and we combine this observation with new refinements to the regression oracle reduction framework of Foster and Rakhlin (2020). The use of triangular discrimination yields novel results even for the classical statistical learning model, and we anticipate that it will find broader use."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Distributed Estimation with Multiple Samples per User", "Title": "Sharp Rates and Phase Transition", "Abstract": "We obtain tight minimax rates for the problem of distributed estimation of discrete distributions under communication constraints, where $n$ users observing $m $ samples each can broadcast only $\\ell$  bits. Our main result is a tight characterization (up to logarithmic factors) of the error rate as a function of $m$, $\\ell$, the domain size, and the number of users under most regimes of interest. While previous work focused on the setting where each user only holds one sample, we show that as $m$ grows the $\\ell_1$ error rate gets reduced by a factor of $\\sqrt{m}$ for small $m$. However, for large $m$ we observe an interesting phase transition: the dependence of the error rate on the communication constraint $\\ell$ changes from $1/\\sqrt{2^{\\ell}}$ to $1/\\sqrt{\\ell}$."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SOPE", "Title": "Spectrum of Off-Policy Estimators", "Abstract": "Many sequential decision making problems are high-stakes and require off-policy evaluation (OPE) of a new policy using historical data collected using some other policy. One of the most common OPE techniques that provides unbiased estimates is trajectory based importance sampling (IS). However, due to the high variance of trajectory IS estimates, importance sampling methods based on state-action visitation distributions (SIS) have recently been adopted. Unfortunately, while SIS often provides lower variance estimates for long horizons, estimating the state-action distribution ratios can be challenging and lead to biased estimates. In this paper, we present a new perspective on this bias-variance trade-off and show the existence of a spectrum of estimators whose endpoints are SIS and IS. Additionally, we also establish a spectrum for doubly-robust and weighted version of these estimators. We provide empirical evidence that estimators in this spectrum can be used to trade-off between the bias and variance of IS and SIS and can achieve lower mean-squared error than both IS and SIS."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Strategic Behavior is Bliss", "Title": "Iterative Voting Improves Social Welfare", "Abstract": "Recent work in iterative voting has defined the additive dynamic price of anarchy (ADPoA) as the difference in social welfare between the truthful and worst-case equilibrium profiles resulting from repeated strategic manipulations. While iterative plurality has been shown to only return alternatives with at most one less initial votes than the truthful winner, it is less understood how agents' welfare changes in equilibrium. To this end, we differentiate agents' utility from their manipulation mechanism and determine iterative plurality's ADPoA in the worst- and average-cases. We first prove that the worst-case ADPoA is linear in the number of agents. To overcome this negative result, we study the average-case ADPoA and prove that equilibrium winners have a constant order welfare advantage over the truthful winner in expectation. Our positive results illustrate the prospect for social welfare to increase due to strategic manipulation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive First-Order Methods Revisited", "Title": "Convex Minimization without Lipschitz Requirements", "Abstract": "We propose a new family of adaptive first-order methods for a class of convex minimization problems that may fail to be Lipschitz continuous or smooth in the standard sense. Specifically, motivated by a recent flurry of activity on non-Lipschitz (NoLips) optimization, we consider problems that are continuous or smooth relative to a reference Bregman function – as opposed to a global, ambient norm (Euclidean or otherwise). These conditions encompass a wide range ofproblems with singular objective, such as Fisher markets, Poisson tomography, D-design, and the like. In this setting, the application of existing order-optimal adaptive methods – like UnixGrad or AcceleGrad – is not possible, especially in the presence of randomness and uncertainty. The proposed method, adaptive mirror descent (AdaMir), aims to close this gap by concurrently achieving min-max optimal rates in problems that are relatively continuous or smooth, including stochastic ones."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Gradient Descent-Ascent and Consensus Optimization for Smooth Games", "Title": "Convergence Analysis under Expected Co-coercivity", "Abstract": "Two of the most prominent algorithms for solving unconstrained smooth games are the classical stochastic gradient descent-ascent (SGDA) and the recently introduced stochastic consensus optimization (SCO) [Mescheder et al., 2017]. SGDA is known to converge to a stationary point for specific classes of games, but current convergence analyses require a bounded variance assumption. SCO is used successfully for solving large-scale adversarial problems, but its convergence guarantees are limited to its deterministic variant. In this work, we introduce the expected co-coercivity condition, explain its benefits, and provide the first last-iterate convergence guarantees of SGDA and SCO under this condition for solving a class of stochastic variational inequality problems that are potentially non-monotone. We prove linear convergence of both methods to a neighborhood of the solution when they use constant step-size, and we propose insightful stepsize-switching rules to guarantee convergence to the exact solution. In addition, our convergence guarantees hold under the arbitrary sampling paradigm, and as such, we give insights into the complexity of minibatching."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Container", "Title": "Context Aggregation Networks", "Abstract": "Convolutional neural networks (CNNs) are ubiquitous in computer vision, with a myriad of effective and efficient variations. Recently, Transformers -- originally introduced in natural language processing -- have been increasingly adopted in computer vision. While early adopters continued to employ CNN backbones, the latest networks are end-to-end CNN-free Transformer solutions. A recent surprising finding now shows that a simple MLP based solution without any traditional convolutional or Transformer components can produce effective visual representations. While CNNs, Transformers and MLP-Mixers may be considered as completely disparate architectures, we provide a unified view showing that they are in fact special cases of a more general method to aggregate spatial context in a neural network stack. We present the \\model (CONText AggregatIon NEtwoRk), a general-purpose building block for multi-head context aggregation that can exploit long-range interactions \\emph{a la} Transformers while still exploiting the inductive bias of the local convolution operation leading to faster convergence speeds, often seen in CNNs. Our \\model architecture achieves 82.7 \\% Top-1 accuracy on ImageNet using 22M parameters, +2.8 improvement compared with DeiT-Small, and can converge to 79.9 \\% Top-1 accuracy in just 200 epochs. In contrast to Transformer-based methods that do not scale well to downstream tasks that rely on larger input image resolutions, our efficient network, named \\modellight, can be employed in object detection and instance segmentation networks such as DETR, RetinaNet and Mask-RCNN to obtain an impressive detection mAP of 38.9, 43.8, 45.1 and mask mAP of 41.3, providing large improvements of 6.6, 7.3, 6.9 and 6.6 pts respectively, compared to a ResNet-50 backbone with a comparable compute and parameter size. Our method also achieves promising results on self-supervised learning compared to DeiT on the DINO framework. Code is released at https://github.com/allenai/container."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ConE", "Title": "Cone Embeddings for Multi-Hop Reasoning over Knowledge Graphs", "Abstract": "Query embedding (QE)---which aims to embed entities and first-order logical (FOL) queries in low-dimensional spaces---has shown great power in multi-hop reasoning over knowledge graphs. Recently, embedding entities and queries with geometric shapes becomes a promising direction, as geometric shapes can naturally represent answer sets of queries and logical relationships among them. However, existing geometry-based models have difficulty in modeling queries with negation, which significantly limits their applicability. To address this challenge, we propose a novel query embedding model, namely \\textbf{Con}e \\textbf{E}mbeddings (ConE), which is the first geometry-based QE model that can handle all the FOL operations, including conjunction, disjunction, and negation. Specifically, ConE represents entities and queries as Cartesian products of two-dimensional cones, where the intersection and union of cones naturally model the conjunction and disjunction operations. By further noticing that the closure of complement of cones remains cones, we design geometric complement operators in the embedding space for the negation operations. Experiments demonstrate that ConE significantly outperforms existing state-of-the-art methods on benchmark datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Federated Hyperparameter Tuning", "Title": "Challenges, Baselines, and Connections to Weight-Sharing", "Abstract": "Tuning hyperparameters is a crucial but arduous part of the machine learning pipeline. Hyperparameter optimization is even more challenging in federated learning, where models are learned over a distributed network of heterogeneous devices; here, the need to keep data on device and perform local training makes it difficult to efficiently train and evaluate configurations. In this work, we investigate the problem of federated hyperparameter tuning. We first identify key challenges and show how standard approaches may be adapted to form baselines for the federated setting. Then, by making a novel connection to the neural architecture search technique of weight-sharing, we introduce a new method, FedEx, to accelerate federated hyperparameter tuning that is applicable to widely-used federated optimization methods such as FedAvg and recent variants. Theoretically, we show that a FedEx variant correctly tunes the on-device learning rate in the setting of online convex optimization across devices. Empirically, we show that FedEx can outperform natural baselines for federated hyperparameter tuning by several percentage points on the Shakespeare, FEMNIST, and CIFAR-10 benchmarks—obtaining higher accuracy using the same training budget."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Training for the Future", "Title": "A Simple Gradient Interpolation Loss to Generalize Along Time", "Abstract": "In several real world applications, machine learning models are deployed to make predictions on data whose distribution changes gradually along time, leading to a drift between the train and test distributions. Such models are often re-trained on new data periodically, and they hence need to generalize to data not too far into the future. In this context, there is much prior work on enhancing temporal generalization, e.g. continuous transportation of past data, kernel smoothed time-sensitive parameters and more recently, adversarial learning of time-invariant features. However, these methods share several limitations, e.g, poor scalability, training instability, and dependence on unlabeled data from the future. Responding to the above limitations, we propose a simple method that starts with a model with time-sensitive parameters but regularizes its temporal complexity using a Gradient Interpolation  (GI) loss. GI allows the decision boundary to change along time and can still prevent overfitting to the limited training time snapshots  by allowing task-specific control over changes along time. We compare our method to existing baselines on multiple real-world datasets, which show that GI outperforms more complicated generative and adversarial approaches on the one hand, and simpler gradient regularization methods on the other."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Risk Minimization from Adaptively Collected Data", "Title": "Guarantees for Supervised and Policy Learning", "Abstract": "Empirical risk minimization (ERM) is the workhorse of machine learning, whether for classification and regression or for off-policy policy learning, but its model-agnostic guarantees can fail when we use adaptively collected data, such as the result of running a contextual bandit algorithm. We study a generic importance sampling weighted ERM algorithm for using adaptively collected data to minimize the average of a loss function over a hypothesis class and provide first-of-their-kind generalization guarantees and fast convergence rates. Our results are based on a new maximal inequality that carefully leverages the importance sampling structure to obtain rates with the good dependence on the exploration rate in the data. For regression, we provide fast rates that leverage the strong convexity of squared-error loss. For policy learning, we provide regret guarantees that close an open gap in the existing literature whenever exploration decays to zero, as is the case for bandit-collected data. An empirical investigation validates our theory."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Light Field Networks", "Title": "Neural Scene Representations with Single-Evaluation Rendering", "Abstract": "Inferring representations of 3D scenes from 2D observations is a fundamental problem of computer graphics, computer vision, and artificial intelligence. Emerging 3D-structured neural scene representations are a promising approach to 3D scene understanding. In this work, we propose a novel neural scene representation, Light Field Networks or LFNs, which represent both geometry and appearance of the underlying 3D scene in a 360-degree, four-dimensional light field parameterized via a neural implicit representation.  Rendering a ray from an LFN requires only a single network evaluation, as opposed to hundreds of evaluations per ray for ray-marching or volumetric based renderers in 3D-structured neural scene representations.  In the setting of simple scenes, we leverage meta-learning to learn a prior over LFNs that enables multi-view consistent light field reconstruction from as little as a single image observation. This results in dramatic reductions in time and memory complexity, and enables real-time rendering. The cost of storing a 360-degree light field via an LFN is two orders of magnitude lower than conventional methods such as the Lumigraph.  Utilizing the analytical differentiability of neural implicit representations and a novel parameterization of light space, we further demonstrate the extraction of sparse depth maps from LFNs."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ViSER", "Title": "Video-Specific Surface Embeddings for Articulated 3D Shape Reconstruction", "Abstract": "We introduce ViSER, a method for recovering articulated 3D shapes and dense3D trajectories from monocular videos.  Previous work on high-quality reconstruction of dynamic 3D shapes typically relies on multiple camera views, strong category-specific priors, or 2D keypoint supervision. We show that none of these are required if one can reliably estimate long-range correspondences in a video, making use of only 2D object masks and two-frame optical flow as inputs. ViSER infers correspondences by matching 2D pixels to a canonical,  deformable 3D mesh via video-specific surface embeddings that capture the pixel appearance of each surface point.  These embeddings behave as a continuous set of keypoint descriptors defined over the mesh surface, which can be used to establish dense long-range correspondences across pixels.  The surface embeddings are implemented as coordinate-based MLPs that are fit to each video via self-supervised losses.Experimental results show that ViSER compares favorably against prior work on challenging videos of humans with loose clothing and unusual poses as well as animals videos from DAVIS and YTVOS. Project page: viser-shape.github.io."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "REMIPS", "Title": "Physically Consistent 3D Reconstruction of Multiple Interacting People under Weak Supervision", "Abstract": "The three-dimensional reconstruction of multiple interacting humans given a monocular image is crucial for the general task of scene understanding, as capturing the subtleties of interaction is often the very reason for taking a picture. Current 3D human reconstruction methods either treat each person independently, ignoring most of the context, or reconstruct people jointly, but cannot recover interactions correctly when people are in close proximity. In this work, we introduce \\textbf{REMIPS}, a model for 3D \\underline{Re}construction of \\underline{M}ultiple \\underline{I}nteracting \\underline{P}eople under Weak \\underline{S}upervision. \\textbf{REMIPS} can reconstruct a variable number of people directly from monocular images. At the core of our methodology stands a novel transformer network that combines unordered person tokens (one for each detected human) with positional-encoded tokens from image features patches. We introduce a novel unified model for self- and interpenetration-collisions based on a mesh approximation computed by applying decimation operators. We rely on self-supervised losses for flexibility and generalisation in-the-wild and incorporate self-contact and interaction-contact losses directly into the learning process. With \\textbf{REMIPS}, we report state-of-the-art quantitative results on common benchmarks even in cases where no 3D supervision is used. Additionally, qualitative visual results show that our reconstructions are plausible in terms of pose and shape and coherent for challenging images, collected in-the-wild, where people are often interacting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Towards Open-World Feature Extrapolation", "Title": "An Inductive Graph Learning Approach", "Abstract": "We target open-world feature extrapolation problem where the feature space of input data goes through expansion and a model trained on partially observed features needs to handle new features in test data without further retraining. The problem is of much significance for dealing with features incrementally collected from different fields. To this end, we propose a new learning paradigm with graph representation and learning. Our framework contains two modules: 1) a backbone network (e.g., feedforward neural nets) as a lower model takes features as input and outputs predicted labels; 2) a graph neural network as an upper model learns to extrapolate embeddings for new features via message passing over a feature-data graph built from observed data. Based on our framework, we design two training strategies, a self-supervised approach and an inductive learning approach, to endow the model with extrapolation ability and alleviate feature-level over-fitting. We also provide theoretical analysis on the generalization error on test data with new features, which dissects the impact of training features and algorithms on generalization performance. Our experiments over several classification datasets and large-scale advertisement click prediction datasets demonstrate that our model can produce effective embeddings for unseen features and significantly outperforms baseline methods that adopt KNN and local aggregation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rethinking conditional GAN training", "Title": "An approach using geometrically structured latent manifolds", "Abstract": "Conditional GANs (cGAN), in their rudimentary form, suffer from critical drawbacks such as the lack of diversity in generated outputs and distortion between the latent and output manifolds.  Although efforts have been made to improve results, they can suffer from unpleasant side-effects such as the topology mismatch between latent and output spaces. In contrast, we tackle this problem from a geometrical perspective and propose a novel training mechanism that increases both the diversity and the visual quality of a vanilla cGAN, by systematically encouraging a bi-lipschitz mapping between the latent and the output manifolds. We validate the efficacy of our solution on a baseline cGAN (i.e., Pix2Pix) which lacks diversity, and show that by only modifying its training mechanism (i.e., with our proposed Pix2Pix-Geo), one can achieve more diverse and realistic outputs on a broad set of image-to-image translation tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OSOA", "Title": "One-Shot Online Adaptation of Deep Generative Models for Lossless Compression", "Abstract": "Explicit deep generative models (DGMs), e.g., VAEs and Normalizing Flows, have shown to offer an effective data modelling alternative for lossless compression. However, DGMs themselves normally require large storage space and thus contaminate the advantage brought by accurate data density estimation.To eliminate the requirement of saving separate models for different target datasets, we propose a novel setting that starts from a pretrained deep generative model and compresses the data batches while adapting the model with a dynamical system for only one epoch.We formalise this setting as that of One-Shot Online Adaptation (OSOA) of DGMs for lossless compression and propose a vanilla algorithm under this setting. Experimental results show that vanilla OSOA can save significant time versus training bespoke models and space versus using one model for all targets.With the same adaptation step number or adaptation time, it is shown vanilla OSOA can exhibit better space efficiency, e.g., $47\\%$ less space, than fine-tuning the pretrained model and saving the fine-tuned model.Moreover, we showcase the potential of OSOA and motivate more sophisticated OSOA algorithms by showing further space or time efficiency with multiple updates per batch and early stopping."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Multi-Armed Bandits with Bounded Arm-Memory", "Title": "Near-Optimal Guarantees for Best-Arm Identification and Regret Minimization", "Abstract": "We study the Stochastic Multi-armed Bandit problem under bounded arm-memory. In this setting, the arms arrive in a stream, and the number of arms that can be stored in the memory at any time, is bounded. The decision-maker can only pull arms that are present in the memory.  We address the problem from the perspective of two standard objectives: 1) regret minimization, and 2) best-arm identification. For regret minimization, we settle an important open question by showing an almost tight guarantee. We show $\\Omega(T^{2/3})$ cumulative regret in expectation for single-pass algorithms for arm-memory size of $(n-1)$, where $n$ is the number of arms. For best-arm identification, we provide an $(\\varepsilon, \\delta)$-PAC algorithm with arm memory size of $O(\\log^*n)$ and $O(\\frac{n}{\\varepsilon^2}\\cdot \\log(\\frac{1}{\\delta}))$ optimal sample complexity."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Grounding inductive biases in natural images", "Title": "invariance stems from variations in data", "Abstract": "To perform well on unseen and potentially out-of-distribution samples, it is desirable for machine learning models to have a predictable response with respect to transformations affecting the factors of variation of the input. Here, we study the relative importance of several types of inductive biases towards such predictable behavior: the choice of data, their augmentations, and model architectures. Invariance is commonly achieved through hand-engineered data augmentation, but do standard data augmentations address transformations that explain variations in real data? While prior work has focused on synthetic data, we attempt here to characterize the factors of variation in a real dataset, ImageNet, and study the invariance of both standard residual networks and the recently proposed vision transformer with respect to changes in these factors. We show standard augmentation relies on a precise combination of translation and scale, with translation recapturing most of the performance improvement---despite the (approximate) translation invariance built in to convolutional architectures, such as residual networks. In fact, we found that scale and translation invariance was similar across residual networks and vision transformer models despite their markedly different architectural inductive biases. We show the training data itself is the main source of invariance, and that data augmentation only further increases the learned invariances. Notably, the invariances learned during training align with the ImageNet factors of variation we found. Finally, we find that the main factors of variation in ImageNet mostly relate to appearance and are specific to each class."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Particle Dual Averaging", "Title": "Optimization of Mean Field Neural Network with Global Convergence Rate Analysis", "Abstract": "We propose the particle dual averaging (PDA) method, which generalizes the dual averaging method in convex optimization to the optimization over probability distributions with quantitative runtime guarantee. The algorithm consists of an inner loop and outer loop: the inner loop utilizes the Langevin algorithm to approximately solve for a stationary distribution, which is then optimized in the outer loop. The method can be interpreted as an extension of the Langevin algorithm to naturally handle nonlinear functional on the probability space. An important application of the proposed method is the optimization of neural network in the mean field regime, which is theoretically attractive due to the presence of nonlinear feature learning, but quantitative convergence rate can be challenging to obtain. By adapting finite-dimensional convex optimization theory into the space of measures, we not only establish global convergence of PDA for two-layer mean field neural networks under more general settings and simpler analysis, but also provide quantitative polynomial runtime guarantee. Our theoretical results are supported by numerical simulations on neural networks with reasonable size."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Only Train Once", "Title": "A One-Shot Neural Network Training And Pruning Framework", "Abstract": "Structured pruning is a commonly used technique in deploying deep neural networks (DNNs) onto resource-constrained devices. However, the existing pruning methods are usually heuristic, task-specified, and require an extra fine-tuning procedure. To overcome these limitations, we propose a framework that compresses DNNs into slimmer architectures with competitive performances and significant FLOPs reductions by Only-Train-Once (OTO). OTO contains two key steps: (i) we partition the parameters of DNNs into zero-invariant groups, enabling us to prune zero groups without affecting the output; and (ii) to promote zero groups, we then formulate a structured-sparsity optimization problem, and propose a novel optimization algorithm, Half-Space Stochastic Projected Gradient (HSPG), to solve it, which outperforms the standard proximal methods on group sparsity exploration, and maintains comparable convergence. To demonstrate the effectiveness of OTO, we train and compress full models simultaneously from scratch without fine-tuning for inference speedup and parameter reduction, and achieve state-of-the-art results on VGG16 for CIFAR10, ResNet50 for CIFAR10 and Bert for SQuAD and competitive result on ResNet50 for ImageNet. The source code is available at https://github.com/tianyic/onlytrainonce."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Referring Transformer", "Title": "A One-step Approach to Multi-task Visual Grounding", "Abstract": "As an important step towards visual reasoning, visual grounding (e.g., phrase localization, referring expression comprehension / segmentation) has been widely explored. Previous approaches to referring expression comprehension (REC) or segmentation (RES) either suffer from limited performance, due to a two-stage setup, or require the designing of complex task-specific one-stage architectures. In this paper, we propose a simple one-stage multi-task framework for visual grounding tasks. Specifically, we leverage a transformer architecture, where two modalities are fused in a visual-lingual encoder. In the decoder, the model learns to generate contextualized lingual queries which are then decoded and used to directly regress the bounding box and produce a segmentation mask for the corresponding referred regions. With this simple but highly contextualized model, we outperform state-of-the-art methods by a large margin on both REC and RES tasks. We also show that a simple pre-training schedule (on an external dataset) further improves the performance. Extensive experiments and ablations illustrate that our model benefits greatly from contextualized information and multi-task training."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "When in Doubt", "Title": "Neural Non-Parametric Uncertainty Quantification for Epidemic Forecasting", "Abstract": "Accurate and trustworthy epidemic forecasting is an important problem for public health planning and disease mitigation. Most existing epidemic forecasting models disregard uncertainty quantification, resulting in mis-calibrated predictions. Recent works in deep neural models for uncertainty-aware time-series forecasting also have several limitations; e.g., it is difficult to specify proper priors in Bayesian NNs, while methods like deep ensembling can be computationally expensive. In this paper, we propose to use neural functional processes to fill this gap. We model epidemic time-series with a probabilistic generative process and propose a functional neural process model called EpiFNP, which directly models the probability distribution of the forecast value in a non-parametric way. In EpiFNP, we use a dynamic stochastic correlation graph to model the correlations between sequences, and design different stochastic latent variables to capture functional uncertainty from different perspectives. Our experiments in a real-time flu forecasting setting show that EpiFNP significantly outperforms state-of-the-art models in both accuracy and calibration metrics, up to 2.5x in accuracy and 2.4x in calibration. Additionally, as EpiFNP learns the relations between the current season and similar patterns of historical seasons, it enables interpretable forecasts. Beyond epidemic forecasting, EpiFNP can be of independent interest for advancing uncertainty quantification in deep sequential models for predictive analytics."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Bounds all around", "Title": "training energy-based models with bidirectional bounds", "Abstract": "Energy-based models (EBMs) provide an elegant framework for density estimation, but they are notoriously difficult to train. Recent work has established links to generative adversarial networks, where the EBM is trained through a minimax game with a variational value function. We propose a bidirectional bound on the EBM log-likelihood, such that we maximize a lower bound and minimize an upper bound when solving the minimax game. We link one bound to a gradient penalty that stabilizes training, thereby provide grounding for best engineering practice. To evaluate the bounds we develop a new and efficient estimator of the Jacobi-determinant of the EBM generator. We demonstrate that these developments stabilize training and yield high-quality density estimation and sample generation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CogView", "Title": "Mastering Text-to-Image Generation via Transformers", "Abstract": "Text-to-Image generation in the general domain has long been an open problem, which requires both a powerful generative model and cross-modal understanding. We propose CogView, a 4-billion-parameter Transformer with VQ-VAE tokenizer to advance this problem. We also demonstrate the finetuning strategies for various downstream tasks, e.g. style learning, super-resolution, text-image ranking and fashion design, and methods to stabilize pretraining, e.g. eliminating NaN losses. CogView achieves the state-of-the-art FID on the blurred MS COCO dataset, outperforming previous GAN-based models and a recent similar work DALL-E."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Chasing Sparsity in Vision Transformers", "Title": "An End-to-End Exploration", "Abstract": "Vision transformers (ViTs) have recently received explosive popularity, but their enormous model sizes and training costs remain daunting. Conventional post-training pruning often incurs higher training budgets. In contrast, this paper aims to trim down both the training memory overhead and the inference complexity, without sacrificing the achievable accuracy. We carry out the first-of-its-kind comprehensive exploration, on taking a unified approach of integrating sparsity in ViTs \"from end to end''. Specifically, instead of training full ViTs, we dynamically extract and train sparse subnetworks, while sticking to a fixed small parameter budget. Our approach jointly optimizes model parameters and explores connectivity throughout training, ending up with one sparse network as the final output. The approach is seamlessly extended from unstructured to structured sparsity, the latter by considering to guide the prune-and-grow of self-attention heads inside ViTs. We further co-explore data and architecture sparsity for additional efficiency gains by plugging in a novel learnable token selector to adaptively determine the currently most vital patches. Extensive results on ImageNet with diverse ViT backbones validate the effectiveness of our proposals which obtain significantly reduced computational cost and almost unimpaired generalization. Perhaps most surprisingly, we find that the proposed sparse (co-)training can sometimes \\textit{improve the ViT accuracy} rather than compromising it, making sparsity a tantalizing \"free lunch''. For example, our sparsified DeiT-Small at ($5\\%$, $50\\%$) sparsity for (data, architecture), improves $\\mathbf{0.28\\%}$ top-1 accuracy, and meanwhile enjoys $\\mathbf{49.32\\%}$ FLOPs and $\\mathbf{4.40\\%}$ running time savings. Our codes are available at https://github.com/VITA-Group/SViTE."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "XCiT", "Title": "Cross-Covariance Image Transformers", "Abstract": "Following their success in natural language processing, transformers have recently shown much promise for computer vision. The self-attention operation underlying transformers yields global interactions between all tokens ,i.e. words or image patches, and enables flexible modelling of image data beyond the local interactions of convolutions. This flexibility, however, comes with a quadratic complexity in time and memory, hindering application to long sequences and high-resolution images. We propose a “transposed” version of self-attention that operates across feature channels rather than tokens, where the interactions are based on the cross-covariance matrix between keys and queries. The resulting cross-covariance attention (XCA) has linear complexity in the number of tokens, and allows efficient processing of high-resolution images.Our cross-covariance image transformer (XCiT) is built upon XCA. It combines the accuracy of conventional transformers with the scalability of convolutional architectures. We validate the effectiveness and generality of XCiT by reporting excellent results on multiple vision benchmarks, including image classification and self-supervised feature learning on ImageNet-1k, object detection and instance segmentation on COCO, and semantic segmentation on ADE20k.We will opensource our code and trained models to reproduce the reported results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SIMONe", "Title": "View-Invariant, Temporally-Abstracted Object Representations via Unsupervised Video Decomposition", "Abstract": "To help agents reason about scenes in terms of their building blocks, we wish to extract the compositional structure of any given scene (in particular, the configuration and characteristics of objects comprising the scene). This problem is especially difficult when scene structure needs to be inferred while also estimating the agent’s location/viewpoint, as the two variables jointly give rise to the agent’s observations. We present an unsupervised variational approach to this problem. Leveraging the shared structure that exists across different scenes, our model learns to infer two sets of latent representations from RGB video input alone: a set of \"object\" latents, corresponding to the time-invariant, object-level contents of the scene, as well as a set of \"frame\" latents, corresponding to global time-varying elements such as viewpoint. This factorization of latents allows our model, SIMONe, to represent object attributes in an allocentric manner which does not depend on viewpoint. Moreover, it allows us to disentangle object dynamics and summarize their trajectories as time-abstracted, view-invariant, per-object properties. We demonstrate these capabilities, as well as the model's performance in terms of view synthesis and instance segmentation, across three procedurally generated video datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "$\\alpha$-IoU", "Title": "A Family of Power Intersection over Union Losses for Bounding Box Regression", "Abstract": "Bounding box (bbox) regression is a fundamental task in computer vision. So far, the most commonly used loss functions for bbox regression are the Intersection over Union (IoU) loss and its variants. In this paper, we generalize existing IoU-based losses to a new family of power IoU losses that have a power IoU term and an additional power regularization term with a single power parameter $\\alpha$. We call this new family of losses the $\\alpha$-IoU losses and analyze properties such as order preservingness and loss/gradient reweighting. Experiments on multiple object detection benchmarks and models demonstrate that $\\alpha$-IoU losses, 1) can surpass existing IoU-based losses by a noticeable performance margin; 2) offer detectors more flexibility in achieving different levels of bbox regression accuracy by modulating $\\alpha$; and 3) are more robust to small datasets and noisy bboxes."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BCORLE($\\lambda$)", "Title": "An Offline Reinforcement Learning and Evaluation Framework for Coupons Allocation in E-commerce Market", "Abstract": "Coupons allocation is an important tool for enterprises to increase the activity and loyalty of users on the e-commerce market. One fundamental problem related is how to allocate coupons within a fixed budget while maximizing users' retention on the e-commerce platform. The online e-commerce environment is complicated and ever changing, so it requires the coupons allocation policy learning can quickly adapt to the changes of the company's business strategy. Unfortunately, existing studies with a huge computation overhead can hardly satisfy the requirements of real-time and fast-response in the real world. Specifically, the problem of coupons allocation within a fixed budget is usually formulated as a Lagrangian problem. Existing solutions need to re-learn the policy once the value of Lagrangian multiplier variable $\\lambda$ is updated, causing a great computation overhead. Besides, a mature e-commerce market often faces tens of millions of users and dozens of types of coupons which construct the huge policy space, further increasing the difficulty of solving the problem. To tackle with above problems, we propose a budget constrained offline reinforcement learning and evaluation with $\\lambda$-generalization (BCORLE($\\lambda$)) framework. The proposed method can help enterprises develop a coupons allocation policy which greatly improves users' retention rate on the platform while ensuring the cost does not exceed the budget. Specifically, $\\lambda$-generalization method is proposed to lead the policy learning process can be executed according to different $\\lambda$ values adaptively, avoiding re-learning new polices from scratch. Thus the computation overhead is greatly reduced. Further, a novel offline reinforcement learning method and an off-policy evaluation algorithm are proposed for policy learning and policy evaluation, respectively. Finally, experiments on the simulation platform and real-world e-commerce market validate the effectiveness of our approach."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The best of both worlds", "Title": "stochastic and adversarial episodic MDPs with unknown transition", "Abstract": "We consider the best-of-both-worlds problem for learning an episodic Markov Decision Process through $T$ episodes, with the goal of achieving $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret when the losses are adversarial and simultaneously $\\mathcal{O}(\\log T)$ regret when the losses are (almost) stochastic. Recent work by [Jin and Luo, 2020]  achieves this goal when the fixed transition is known, and leaves the case of unknown transition as a major open question. In this work, we resolve this open problem by using the same Follow-the-Regularized-Leader (FTRL) framework together with a set of new techniques. Specifically, we first propose a loss-shifting trick in the FTRL analysis, which greatly simplifies the approach of [Jin and Luo, 2020] and already improves their results for the known transition case. Then, we extend this idea to the unknown transition case and develop a novel analysis which upper bounds the transition estimation error by the regret itself in the stochastic setting, a key property to ensure $\\mathcal{O}(\\log T)$ regret."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Interesting Object, Curious Agent", "Title": "Learning Task-Agnostic Exploration", "Abstract": "Common approaches for task-agnostic exploration learn tabula-rasa --the agent assumes isolated environments and no prior knowledge or experience. However, in the real world, agents learn in many environments and always come with prior experiences as they explore new ones. Exploration is a lifelong process. In this paper, we propose a paradigm change in the formulation and evaluation of task-agnostic exploration. In this setup, the agent first learns to explore across many environments without any extrinsic goal in a task-agnostic manner.Later on, the agent effectively transfers the learned exploration policy to better explore new environments when solving tasks. In this context, we evaluate several baseline exploration strategies and present a simple yet effective approach to learning task-agnostic exploration policies. Our key idea is that there are two components of exploration: (1) an agent-centric component encouraging exploration of unseen parts of the environment based on an agent’s belief; (2) an environment-centric component encouraging exploration of inherently interesting objects. We show that our formulation is effective and provides the most consistent exploration across several training-testing environment pairs. We also introduce benchmarks and metrics for evaluating task-agnostic exploration strategies. The source code is available at https://github.com/sparisi/cbet/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SimiGrad", "Title": "Fine-Grained Adaptive Batching for Large Scale Training using Gradient Similarity Measurement", "Abstract": "Large scale training requires massive parallelism to finish the training within a reasonable amount of time. To support massive parallelism, large batch training is the key enabler but often at the cost of generalization performance. Existing works explore adaptive batching or hand-tuned static large batching, in order to strike a balance between the computational efficiency and the performance. However, these methods can provide only coarse-grained adaption (e.g., at a epoch level) due to the intrinsic expensive calculation or hand tuning requirements. In this paper, we propose a fully automated and lightweight adaptive batching methodology to enable fine-grained batch size adaption (e.g., at a mini-batch level) that can achieve state-of-the-art performance with record breaking batch sizes. The core component of our method is a lightweight yet efficient representation of the critical gradient noise information. We open-source the proposed methodology by providing a plugin tool that supports mainstream machine learning frameworks. Extensive evaluations on popular benchmarks (e.g., CIFAR10, ImageNet, and BERT-Large) demonstrate that the proposed methodology outperforms state-of-the-art methodologies using adaptive batching approaches or hand-tuned static strategies in both performance and batch size. Particularly, we achieve a new state-of-the-art batch size of 78k in BERT-Large pretraining with SQuAD score 90.69 compared to 90.58 reported in previous state-of-the-art with 59k batch size."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STORM+", "Title": "Fully Adaptive SGD with Recursive Momentum for Nonconvex Optimization", "Abstract": "In this work we investigate stochastic non-convex optimization problems where the objective is an expectation over smooth loss functions, and the goal is to find an approximate stationary point. The most popular approach to handling such problems is variance reduction techniques, which are also known to obtain tight convergence rates, matching the lower bounds in this case. Nevertheless, these techniques require a careful maintenance of anchor points in conjunction with appropriately selected ``mega-batchsizes\". This leads to a challenging hyperparameter tuning problem, that weakens their practicality. Recently, [Cutkosky and Orabona, 2019] have shown that one can employ recursive momentum in order to avoid the use of anchor points and large batchsizes, and still obtain the optimal rate for this setting. Yet, their method called $\\rm{STORM}$ crucially relies on the knowledge of the smoothness, as well a bound on the gradient norms. In this work we propose $\\rm{STORM}^{+}$, a new method that is completely parameter-free, does not require large batch-sizes, and obtains the optimal $O(1/T^{1/3})$ rate for finding an approximate stationary point. Our work builds on the $\\rm{STORM}$ algorithm, in conjunction with a novel approach to adaptively set the learning rate and momentum parameters."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Skipping the Frame-Level", "Title": "Event-Based Piano Transcription With Neural Semi-CRFs", "Abstract": "Piano transcription systems are typically optimized to estimate pitch activity at each frame of audio. They are often followed by carefully designed heuristics and post-processing algorithms to estimate note events from the frame-level predictions. Recent methods have also framed piano transcription as a multi-task learning problem, where the activation of different stages of a note event are estimated independently. These practices are not well aligned with the desired outcome of the task, which is the specification of note intervals as holistic events, rather than the aggregation of disjoint observations. In this work, we propose a novel formulation of piano transcription, which is optimized to directly predict note events. Our method is based on Semi-Markov Conditional Random Fields (semi-CRF), which produce scores for intervals rather than individual frames. When formulating piano transcription in this way, we eliminate the need to rely on disjoint frame-level estimates for different stages of a note event. We conduct experiments on the MAESTRO dataset and demonstrate that the proposed model surpasses the current state-of-the-art for piano transcription. Our results suggest that the semi-CRF output layer, while still quadratic in complexity, is a simple, fast and well-performing solution for event-based prediction, and may lead to similar success in other areas which currently rely on frame-level estimates."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deep Learning on a Data Diet", "Title": "Finding Important Examples Early in Training", "Abstract": "Recent success in deep learning has partially been driven by training increasingly overparametrized networks on ever larger datasets. It is therefore natural to ask: how much of the data is superfluous, which examples are important for generalization, and how do we find them? In this work, we make the striking observation that, in standard vision datasets, simple scores averaged over several weight initializations can be used to identify important examples very early in training. We propose two such scores—the Gradient Normed (GraNd) and the Error L2-Norm (EL2N) scores—and demonstrate their efficacy on a range of architectures and datasets by pruning significant fractions of training data without sacrificing test accuracy. In fact, using EL2N scores calculated a few epochs into training, we can prune half of the CIFAR10 training set while slightly improving test accuracy. Furthermore, for a given dataset, EL2N scores from one architecture or hyperparameter configuration generalize to other configurations. Compared to recent work that prunes data by discarding examples that are rarely forgotten over the course of training, our scores use only local information early in training. We also use our scores to detect noisy examples and study training dynamics through the lens of important examples—we investigate how the data distribution shapes the loss surface and identify subspaces of the model’s data representation that are relatively stable over training."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BNS", "Title": "Building Network Structures Dynamically for Continual Learning", "Abstract": "Continual learning (CL) of a sequence of tasks is often accompanied with the catastrophic forgetting(CF) problem. Existing research has achieved remarkable results in overcoming CF, especially for task continual learning. However, limited work has been done to achieve another important goal of CL,knowledge transfer.In this paper, we propose a technique (called BNS) to do both.  The novelty of BNS is that it dynamically builds a network to learn each new task to overcome CF and to transfer knowledge across tasks at the same time. Experimental results show that when the tasks are different (with little shared knowledge), BNS can already outperform the state-of-the-art baselines. When the tasks are similar and have shared knowledge, BNS outperforms the baselines substantially by a large margin due to its knowledge transfer capability."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Uniform Convergence of Interpolators", "Title": "Gaussian Width, Norm Bounds and Benign Overfitting", "Abstract": "We consider interpolation learning in high-dimensional linear regression with Gaussian data, and prove a generic uniform convergence guarantee on the generalization error of interpolators in an arbitrary hypothesis class in terms of the class’s Gaussian width.  Applying the generic bound to Euclidean norm balls recovers the consistency result of Bartlett et al. (2020) for minimum-norm interpolators, and confirms a prediction of Zhou et al. (2020) for near-minimal-norm interpolators in the special case of Gaussian data.  We demonstrate the generality of the bound by applying it to the simplex, obtaining a novel consistency result for minimum $\\ell_1$-norm interpolators (basis pursuit). Our results show how norm-based generalization bounds can explain and be used to analyze benign overfitting, at least in some settings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DominoSearch", "Title": "Find layer-wise fine-grained N:M sparse schemes from dense neural networks", "Abstract": "Neural pruning is a widely-used compression technique for Deep Neural Networks (DNNs). Recent innovations in Hardware Architectures (e.g. Nvidia Ampere Sparse Tensor Core) and N:M fine-grained Sparse Neural Network algorithms (i.e. every M-weights contains N non-zero values) reveal a promising research line of neural pruning. However, the existing N:M algorithms only address the challenge of how to train N:M sparse neural networks in a uniform fashion (i.e. every layer has the same N:M sparsity) and suffer from a significant accuracy drop for high sparsity (i.e. when sparsity > 80\\%). To tackle this problem, we present a novel technique -- \\textbf{\\textit{DominoSearch}} to find mixed N:M sparsity schemes from pre-trained dense deep neural networks to achieve higher accuracy than the uniform-sparsity scheme with equivalent complexity constraints (e.g. model size or FLOPs). For instance, for the same model size with 2.1M parameters (87.5\\% sparsity), our layer-wise N:M sparse ResNet18 outperforms its uniform counterpart by 2.1\\% top-1 accuracy, on the large-scale ImageNet dataset. For the same computational complexity of 227M FLOPs, our layer-wise sparse ResNet18 outperforms the uniform one by 1.3\\% top-1 accuracy. Furthermore, our layer-wise fine-grained N:M sparse ResNet50 achieves 76.7\\% top-1 accuracy with 5.0M parameters. {This is competitive to the results achieved by layer-wise unstructured sparsity} that is believed to be the upper-bound of Neural Network pruning with respect to the accuracy-sparsity trade-off. We believe that our work can build a strong baseline for further sparse DNN research and encourage future hardware-algorithm co-design work. Our code and models are publicly available at \\url{https://github.com/NM-sparsity/DominoSearch}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Object DGCNN", "Title": "3D Object Detection using Dynamic Graphs", "Abstract": "3D object detection often involves complicated training and testing pipelines, which require substantial domain knowledge about individual datasets. Inspired by recent non-maximum suppression-free 2D object detection models, we propose a 3D object detection architecture on point clouds. Our method models 3D object detection as message passing on a dynamic graph, generalizing the DGCNN framework to predict a set of objects. In our construction, we remove the necessity of post-processing via object confidence aggregation or non-maximum suppression. To facilitate object detection from sparse point clouds, we also propose a set-to-set distillation approach customized to 3D detection. This approach aligns the outputs of the teacher model and the student model in a permutation-invariant fashion, significantly simplifying knowledge distillation for the 3D detection task. Our method achieves state-of-the-art performance on autonomous driving benchmarks. We also provide abundant analysis of the detection model and distillation framework."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Cockpit", "Title": "A Practical Debugging Tool for the Training of Deep Neural Networks", "Abstract": "When engineers train deep learning models, they are very much \"flying blind\". Commonly used methods for real-time training diagnostics, such as monitoring the train/test loss, are limited. Assessing a network's training process solely through these performance indicators is akin to debugging software without access to internal states through a debugger. To address this, we present Cockpit, a collection of instruments that enable a closer look into the inner workings of a learning machine, and a more informative and meaningful status report for practitioners. It facilitates the identification of learning phases and failure modes, like ill-chosen hyperparameters. These instruments leverage novel higher-order information about the gradient distribution and curvature, which has only recently become efficiently accessible. We believe that such a debugging tool, which we open-source for PyTorch, is a valuable help in troubleshooting the training process. By revealing new insights, it also more generally contributes to explainability and interpretability of deep nets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MEST", "Title": "Accurate and Fast Memory-Economic Sparse Training Framework on the Edge", "Abstract": "Recently, a new trend of exploring sparsity for accelerating neural network training has emerged, embracing the paradigm of training on the edge. This paper proposes a novel Memory-Economic Sparse Training (MEST) framework targeting for accurate and fast execution on edge devices. The proposed MEST framework consists of enhancements by Elastic Mutation (EM) and Soft Memory Bound (&S) that ensure superior accuracy at high sparsity ratios. Different from the existing works for sparse training, this current work reveals the importance of sparsity schemes on the performance of sparse training in terms of accuracy as well as training speed on real edge devices. On top of that, the paper proposes to employ data efficiency for further acceleration of sparse training. Our results suggest that unforgettable examples can be identified in-situ even during the dynamic exploration of sparsity masks in the sparse training process, and therefore can be removed for further training speedup on edge devices. Comparing with state-of-the-art (SOTA) works on accuracy, our MEST increases Top-1 accuracy significantly on ImageNet when using the same unstructured sparsity scheme. Systematical evaluation on accuracy, training speed, and memory footprint are conducted, where the proposed MEST framework consistently outperforms representative SOTA works. A reviewer strongly against our work based on his false assumptions and misunderstandings. On top of the previous submission, we employ data efficiency for further acceleration of sparse training. And we explore the impact of model sparsity, sparsity schemes, and sparse training algorithms on the number of removable training examples. Our codes are publicly available at: https://github.com/boone891214/MEST."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RED ", "Title": "Looking for Redundancies for Data-FreeStructured Compression of Deep Neural Networks", "Abstract": "Deep Neural Networks (DNNs) are ubiquitous in today's computer vision landscape, despite involving considerable computational costs. The mainstream approaches for runtime acceleration consist in pruning connections (unstructured pruning) or, better, filters (structured pruning), both often requiring data to retrain the model.  In this paper, we present RED, a data-free, unified approach to tackle structured pruning. First, we propose a novel adaptive hashing of the scalar DNN weight distribution densities to increase the number of identical neurons represented by their weight vectors. Second, we prune the network by merging redundant neurons based on their relative similarities, as defined by their distance. Third, we propose a novel uneven depthwise separation technique to further prune convolutional layers. We demonstrate through a large variety of benchmarks that RED largely outperforms other data-free pruning methods, often reaching performance similar to unconstrained, data-driven methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TestRank", "Title": "Bringing Order into Unlabeled Test Instances for Deep Learning Tasks", "Abstract": "Deep learning (DL) systems are notoriously difficult to test and debug due to the lack of correctness proof and the huge test input space to cover. Given the ubiquitous unlabeled test data and high labeling cost, in this paper, we propose a novel test prioritization technique, namely TestRank, which aims at revealing more model failures with less labeling effort. TestRank brings order into the unlabeled test data according to their likelihood of being a failure, i.e., their failure-revealing capabilities. Different from existing solutions, TestRank leverages both intrinsic and contextual attributes of the unlabeled test data when prioritizing them. To be specific, we first build a similarity graph on both unlabeled test samples and labeled samples (e.g., training or previously labeled test samples). Then, we conduct graph-based semi-supervised learning to extract contextual features from the correctness of similar labeled samples. For a particular test instance, the contextual features extracted with the graph neural network and the intrinsic features obtained with the DL model itself are combined to predict its failure-revealing capability. Finally, TestRank prioritizes unlabeled test inputs in descending order of the above probability value. We evaluate TestRank on three popular image classification datasets, and results show that TestRank significantly outperforms existing test prioritization techniques."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Large Scale Learning on Non-Homophilous Graphs", "Title": "New Benchmarks and Strong Simple Methods", "Abstract": "Many widely used datasets for graph machine learning tasks have generally been homophilous, where nodes with similar labels connect to each other. Recently, new Graph Neural Networks (GNNs) have been developed that move beyond the homophily regime; however, their evaluation has often been conducted on small graphs with limited application domains. We collect and introduce diverse non-homophilous datasets from a variety of application areas that have up to 384x more nodes and 1398x more edges than prior datasets. We further show that existing scalable graph learning and graph minibatching techniques lead to performance degradation on these non-homophilous datasets, thus highlighting the need for further work on scalable non-homophilous methods. To address these concerns, we introduce LINKX --- a strong simple method that admits straightforward minibatch training and inference. Extensive experimental results with representative simple methods and GNNs across our proposed datasets show that LINKX achieves state-of-the-art performance for learning on non-homophilous graphs. Our codes and data are available at https://github.com/CUAI/Non-Homophily-Large-Scale."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Catch-A-Waveform", "Title": "Learning to Generate Audio from a Single Short Example", "Abstract": "Models for audio generation are typically trained on hours of recordings. Here, we illustrate that capturing the essence of an audio source is typically possible from as little as a few tens of seconds from a single training signal. Specifically, we present a GAN-based generative model that can be trained on one short audio signal from any domain (e.g. speech, music, etc.) and does not require pre-training or any other form of external supervision. Once trained, our model can generate random  samples of arbitrary duration that maintain semantic similarity to the training waveform, yet exhibit new compositions of its audio primitives. This enables a long line of interesting applications, including generating new jazz improvisations or new a-cappella rap variants based on a single short example, producing coherent modifications to famous songs (e.g. adding a new verse to a Beatles song based solely on the original recording), filling-in of missing parts (inpainting), extending the bandwidth of a speech signal (super-resolution), and enhancing old recordings without access to any clean training example. We show that in all cases, no more than 20 seconds of training audio commonly suffice for our model to achieve state-of-the-art results. This is despite its complete lack of prior knowledge about the nature of audio signals in general."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Data-Efficient GAN Training Beyond (Just) Augmentations", "Title": "A Lottery Ticket Perspective", "Abstract": "Training generative adversarial networks (GANs) with limited real image data generally results in deteriorated performance and collapsed models. To conquer this challenge, we are inspired by the latest observation, that one can discover independently trainable and highly sparse subnetworks (a.k.a., lottery tickets) from GANs. Treating this as an inductive prior, we suggest a brand-new angle towards data-efficient GAN training: by first identifying the lottery ticket from the original GAN using the small training set of real images; and then focusing on training that sparse subnetwork by re-using the same set. We find our coordinated framework to offer orthogonal gains to existing real image data augmentation methods, and we additionally present a new feature-level augmentation that can be applied together with them. Comprehensive experiments endorse the effectiveness of our proposed framework, across various GAN architectures (SNGAN, BigGAN, and StyleGAN-V2) and diverse datasets (CIFAR-10, CIFAR-100, Tiny-ImageNet, ImageNet, and multiple few-shot generation datasets). Codes are available at: https://github.com/VITA-Group/Ultra-Data-Efficient-GAN-Training."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TOHAN", "Title": "A One-step Approach towards Few-shot Hypothesis Adaptation", "Abstract": "In few-shot domain adaptation (FDA), classifiers for the target domain are trained with \\emph{accessible} labeled data in the source domain (SD) and few labeled data in the target domain (TD). However, data usually contain private information in the current era, e.g., data distributed on personal phones. Thus, the private data will be leaked if we directly access data in SD to train a target-domain classifier (required by FDA methods). In this paper, to prevent privacy leakage in SD, we consider a very challenging problem setting, where the classifier for the TD has to be trained using few labeled target data and a well-trained SD classifier, named few-shot hypothesis adaptation (FHA). In FHA, we cannot access data in SD, as a result, the private information in SD will be protected well. To this end, we propose a target-oriented hypothesis adaptation network (TOHAN) to solve the FHA problem, where we generate highly-compatible unlabeled data (i.e., an intermediate domain) to help train a target-domain classifier. TOHAN maintains two deep networks simultaneously, in which one focuses on learning an intermediate domain and the other takes care of the intermediate-to-target distributional adaptation and the target-risk minimization. Experimental results show that TOHAN outperforms competitive baselines significantly."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Accelerated Sparse Neural Training", "Title": "A Provable and Efficient Method to Find N:M Transposable Masks", "Abstract": "Unstructured pruning reduces the memory footprint in deep neural networks (DNNs). Recently, researchers proposed different types of structural pruning intending to reduce also the computation complexity. In this work, we first suggest a new measure called mask-diversity which correlates with the expected accuracy of the different types of structural pruning. We focus on the recently suggested N:M fine-grained block sparsity mask, in which for each block of M weights, we have at least N zeros. While N:M fine-grained block sparsity allows acceleration in actual modern hardware, it can be used only to accelerate the inference phase. In order to allow for similar accelerations in the training phase, we suggest a novel transposable fine-grained sparsity mask, where the same mask can be used for both forward and backward passes. Our transposable mask guarantees that both the weight matrix and its transpose follow the same sparsity pattern; thus, the matrix multiplication required for passing the error backward can also be accelerated. We formulate the problem of finding the optimal transposable-mask as a minimum-cost flow problem. Additionally, to speed up the minimum-cost flow computation, we also introduce a  fast linear-time approximation that can be used when the masks dynamically change during training. Our experiments suggest a 2x speed-up in the matrix multiplications with no accuracy degradation over vision and language models. Finally, to solve the problem of switching between different structure constraints, we suggest a method to convert a pre-trained model with unstructured sparsity to an N:M fine-grained block sparsity model with little to no training.  A reference implementation can be found at https://github.com/papers-submission/structuredtransposablemasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepReduce", "Title": "A Sparse-tensor Communication Framework for Federated Deep Learning", "Abstract": "Sparse tensors appear frequently in federated deep learning, either as a direct artifact of the deep neural network’s gradients, or as a result of an explicit sparsification process.  Existing communication primitives are agnostic to the peculiarities of deep learning; consequently, they impose unnecessary communication overhead. This paper introduces DeepReduce, a versatile framework for the compressed communication of sparse tensors, tailored to federated deep learning. DeepReduce decomposes sparse tensors into two sets,  values and indices,  and allows both independent and combined compression of these sets.  We support a variety of common compressors, such as Deflate for values, or run-length encoding for indices. We also propose two novel compression schemes that achieve superior results: curve fitting-based for values, and bloom filter-based for indices.  DeepReduce is orthogonal to existing gradient sparsifiers and can be applied in conjunction with them, transparently to the end-user, to significantly lower the communication overhead. As proof of concept, we implement our approach on TensorFlow and PyTorch. Our experiments with large real models demonstrate that DeepReduce transmits 320% less data than existing sparsifiers, without affecting accuracy. Code is available at https://github.com/hangxu0304/DeepReduce."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PARP", "Title": "Prune, Adjust and Re-Prune for Self-Supervised Speech Recognition", "Abstract": "Self-supervised speech representation learning (speech SSL) has demonstrated the benefit of scale in learning rich representations for Automatic Speech Recognition (ASR) with limited paired data, such as wav2vec 2.0. We investigate the existence of sparse subnetworks in pre-trained speech SSL models that achieve even better low-resource ASR results. However, directly applying widely adopted pruning methods such as the Lottery Ticket Hypothesis (LTH) is suboptimal in the computational cost needed. Moreover, we show that the discovered subnetworks yield minimal performance gain compared to the original dense network.We present Prune-Adjust-Re-Prune (PARP), which discovers and finetunes subnetworks for much better performance, while only requiring a single downstream ASR finetuning run. PARP is inspired by our surprising observation that subnetworks pruned for pre-training tasks need merely a slight adjustment to achieve a sizeable performance boost in downstream ASR tasks. Extensive experiments on low-resource ASR verify (1) sparse subnetworks exist in mono-lingual/multi-lingual pre-trained speech SSL, and (2) the computational advantage and performance gain of PARP over baseline pruning methods.In particular, on the 10min Librispeech split without LM decoding, PARP discovers subnetworks from wav2vec 2.0 with an absolute 10.9%/12.6% WER decrease compared to the full model. We further demonstrate the effectiveness of PARP via: cross-lingual pruning without any phone recognition degradation, the discovery of a multi-lingual subnetwork for 10 spoken languages in 1 finetuning run, and its applicability to pre-trained BERT/XLNet for natural language tasks1."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SOFT", "Title": "Softmax-free Transformer with Linear Complexity", "Abstract": "Vision transformers (ViTs) have pushed the state-of-the-art for various visual recognition tasks by patch-wise image tokenization followed by self-attention. However, the employment of self-attention modules results in a quadratic complexity in both computation and memory usage. Various attempts on approximating the self-attention computation with linear complexity have been made in Natural Language Processing. However, an in-depth analysis in this work shows that they are either theoretically flawed or empirically ineffective for visual recognition. We further identify that their limitations are rooted in keeping the softmax self-attention during approximations.  Specifically, conventional self-attention is computed by normalizing the scaled dot-product between token feature vectors. Keeping this softmax operation challenges any subsequent linearization efforts. Based on this insight, for the first time, a softmax-free transformer or  SOFT is proposed. To remove softmax in self-attention,  Gaussian kernel function is used to replace the dot-product similarity without further normalization. This enables a full self-attention matrix to be approximated via a low-rank  matrix decomposition. The robustness of the approximation is achieved by calculating its Moore-Penrose inverse using  a  Newton-Raphson method. Extensive experiments on ImageNet show that our SOFT significantly improves the computational efficiency of existing ViT variants. Crucially, with a linear complexity, much longer token sequences are permitted in SOFT, resulting in superior trade-off between accuracy and complexity."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Flows", "Title": "Efficient Alternative to Neural ODEs", "Abstract": "Neural ordinary differential equations describe how values change in time. This is the reason why they gained importance in modeling sequential data, especially when the observations are made at irregular intervals. In this paper we propose an alternative by directly modeling the solution curves - the flow of an ODE - with a neural network. This immediately eliminates the need for expensive numerical solvers while still maintaining the modeling capability of neural ODEs. We propose several flow architectures suitable for different applications by establishing precise conditions on when a function defines a valid flow. Apart from computational efficiency, we also provide empirical evidence of favorable generalization performance via applications in time series modeling, forecasting, and density estimation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Online Matching in Sparse Random Graphs", "Title": "Non-Asymptotic Performances of Greedy Algorithm", "Abstract": "Motivated by sequential budgeted allocation problems, we investigate  online matching problems where connections between vertices are not i.i.d., but they have fixed degree distributions -- the so-called configuration model. We estimate the competitive ratio of the simplest algorithm, GREEDY, by approximating some relevant stochastic discrete processes by their continuous counterparts, that are solutions of an explicit system of partial differential equations. This technique gives precise bounds on the estimation  errors,  with arbitrarily high probability as the problem size increases. In particular, it allows the formal comparison between different configuration models. We also prove that, quite surprisingly,  GREEDY can have  better performance guarantees than RANKING, another celebrated algorithm for online matching that usually outperforms the former."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SILG", "Title": "The Multi-domain Symbolic Interactive Language Grounding Benchmark", "Abstract": "Existing work in language grounding typically study single environments. How do we build unified models that apply across multiple environments? We propose the multi-environment Symbolic Interactive Language Grounding benchmark (SILG), which unifies a collection of diverse grounded language learning environments under a common interface. SILG consists of grid-world environments that require generalization to new dynamics, entities, and partially observed worlds (RTFM, Messenger, NetHack), as well as symbolic counterparts of visual worlds that re- quire interpreting rich natural language with respect to complex scenes (ALFWorld, Touchdown). Together, these environments provide diverse grounding challenges in richness of observation space, action space, language specification, and plan com- plexity. In addition, we propose the first shared model architecture for RL on these environments, and evaluate recent advances such as egocentric local convolution, recurrent state-tracking, entity-centric attention, and pretrained LM using SILG. Our shared architecture achieves comparable performance to environment-specific architectures. Moreover, we find that many recent modelling advances do not result in significant gains on environments other than the one they were designed for. This highlights the need for a multi-environment benchmark. Finally, the best models significantly underperform humans on SILG, which suggests ample room for future work. We hope SILG enables the community to quickly identify new methodolo- gies for language grounding that generalize to a diverse set of environments and their associated challenges."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeRV", "Title": "Neural Representations for Videos", "Abstract": "We propose a novel neural representation for videos (NeRV) which encodes videos in neural networks. Unlike conventional representations that treat videos as frame sequences, we represent videos as neural networks taking frame index as input. Given a frame index, NeRV  outputs the corresponding RGB image. Video encoding in NeRV is simply fitting a neural network to video frames and decoding process is a simple feedforward operation.  As an image-wise implicit representation, NeRV output the whole image and shows great efficiency compared to pixel-wise implicit representation, improving the encoding speed by $\\textbf{25}\\times$ to $\\textbf{70}\\times$, the decoding speed by $\\textbf{38}\\times$ to $\\textbf{132}\\times$, while achieving better video quality.  With such a representation, we can treat videos as neural networks, simplifying several video-related tasks. For example, conventional video compression methods are restricted by a long and complex pipeline, specifically designed for the task. In contrast, with NeRV, we can use any neural network compression method as a proxy for video compression, and achieve comparable performance to traditional frame-based video compression approaches (H.264, HEVC \\etc). Besides compression, we demonstrate the generalization of NeRV for video denoising. The source code and pre-trained model can be found at https://github.com/haochen-rye/NeRV.git."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generative vs. Discriminative", "Title": "Rethinking The Meta-Continual Learning", "Abstract": "Deep neural networks have achieved human-level capabilities in various learning tasks. However, they generally lose performance in more realistic scenarios like learning in a continual manner. In contrast, humans can incorporate their prior knowledge to learn new concepts efficiently without forgetting older ones. In this work, we leverage meta-learning to encourage the model to learn how to learn continually. Inspired by human concept learning, we develop a generative classifier that efficiently uses data-driven experience to learn new concepts even from few samples while being immune to forgetting. Along with cognitive and theoretical insights, extensive experiments on standard benchmarks demonstrate the effectiveness of the proposed method. The ability to remember all previous concepts, with negligible computational and structural overheads, suggests that generative models provide a natural way for alleviating catastrophic forgetting, which is a major drawback of discriminative models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Model, sample, and epoch-wise descents", "Title": "exact solution of gradient flow in the random feature model", "Abstract": "Recent evidence has shown the existence of a so-called double-descent and even triple-descent behavior for the generalization error of deep-learning models. This important phenomenon commonly appears in implemented neural network architectures, and also seems to emerge in epoch-wise curves during the training process. A recent line of research has highlighted that random matrix tools can be used to obtain precise analytical asymptotics of the generalization (and training) errors of the random feature model. In this contribution, we analyze the whole temporal behavior of the generalization and training errors under gradient flow for the random feature model. We show that in the asymptotic limit of large system size the full time-evolution path of both errors can be calculated analytically. This allows us to observe how the double and triple descents develop over time, if and when early stopping is an option, and also observe time-wise descent structures. Our techniques are based on Cauchy complex integral representations of the errors together with recent random matrix methods based on linear pencils."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Perceptual Score", "Title": "What Data Modalities Does Your Model Perceive?", "Abstract": "Machine learning advances in the last decade have relied significantly on large-scale datasets that continue to grow in size. Increasingly, those datasets also contain different data modalities. However, large multi-modal datasets are hard to annotate, and annotations may contain biases that we are often unaware of. Deep-net-based classifiers, in turn, are prone to exploit those biases and to find shortcuts. To study and quantify this concern, we introduce the perceptual score, a metric that assesses the degree to which a model relies on the different subsets of the input features, i.e., modalities. Using the perceptual score, we find a surprisingly consistent trend across four popular datasets: recent, more accurate state-of-the-art multi-modal models for visual question-answering or visual dialog tend to perceive the visual data less than their predecessors. This is concerning as answers are hence increasingly inferred from textual cues only. Using the perceptual score also helps to analyze model biases by decomposing the score into data subset contributions. We hope to spur a discussion on the perceptiveness of multi-modal models and also hope to encourage the community working on multi-modal classifiers to start quantifying perceptiveness via the proposed perceptual score."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PiRank", "Title": "Scalable Learning To Rank via Differentiable Sorting", "Abstract": "A key challenge with machine learning approaches for ranking is the gap between the performance metrics of interest and the surrogate loss functions that can be optimized with gradient-based methods. This gap arises because ranking metrics typically involve a sorting operation which is not differentiable w.r.t. the model parameters. Prior works have proposed surrogates that are loosely related to ranking metrics or simple smoothed versions thereof, and often fail to scale to real-world applications. We propose PiRank, a new class of differentiable surrogates for ranking, which employ a continuous, temperature-controlled relaxation to the sorting operator based on NeuralSort [1]. We show that PiRank exactly recovers the desired metrics in the limit of zero temperature and further propose a divide-and-conquer extension that scales favorably to large list sizes, both in theory and practice. Empirically, we demonstrate the role of larger list sizes during training and show that PiRank significantly improves over comparable approaches on publicly available Internet-scale learning-to-rank benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Deceive D", "Title": "Adaptive Pseudo Augmentation for GAN Training with Limited Data", "Abstract": "Generative adversarial networks (GANs) typically require ample data for training in order to synthesize high-fidelity images. Recent studies have shown that training GANs with limited data remains formidable due to discriminator overfitting, the underlying cause that impedes the generator's convergence. This paper introduces a novel strategy called Adaptive Pseudo Augmentation (APA) to encourage healthy competition between the generator and the discriminator. As an alternative method to existing approaches that rely on standard data augmentations or model regularization, APA alleviates overfitting by employing the generator itself to augment the real data distribution with generated images, which deceives the discriminator adaptively. Extensive experiments demonstrate the effectiveness of APA in improving synthesis quality in the low-data regime. We provide a theoretical analysis to examine the convergence and rationality of our new training strategy. APA is simple and effective. It can be added seamlessly to powerful contemporary GANs, such as StyleGAN2, with negligible computational cost. Code: https://github.com/EndlessSora/DeceiveD."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoFrNets", "Title": "Interpretable Neural Architecture Inspired by Continued Fractions", "Abstract": "In recent years there has been a considerable amount of research on local post hoc explanations for neural networks. However, work on building interpretable neural architectures has been relatively sparse. In this paper, we present a novel neural architecture, CoFrNet, inspired by the form of continued fractions which are known to have many attractive properties in number theory, such as fast convergence of approximations to real numbers. We show that CoFrNets can be efficiently trained as well as interpreted leveraging their particular functional form. Moreover, we prove that such architectures are universal approximators based on a proof strategy that is different than the typical strategy used to prove universal approximation results for neural networks based on infinite width (or depth), which is likely to be of independent interest. We experiment on nonlinear synthetic functions and are able to accurately model as well as estimate feature attributions and even higher order terms in some cases, which is a testament to the representational power as well as interpretability of such architectures. To further showcase the power of CoFrNets, we experiment on seven real datasets spanning tabular, text and image modalities, and show that they are either comparable or significantly better than other interpretable models and multilayer perceptrons, sometimes approaching the accuracies of state-of-the-art models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FastCorrect", "Title": "Fast Error Correction with Edit Alignment for Automatic Speech Recognition", "Abstract": "Error correction techniques have been used to refine the output sentences from automatic speech recognition (ASR) models and achieve a lower word error rate (WER) than original ASR outputs. Previous works usually use a sequence-to-sequence model to correct an ASR output sentence autoregressively, which causes large latency and cannot be deployed in online ASR services. A straightforward solution to reduce latency, inspired by non-autoregressive (NAR) neural machine translation, is to use an NAR sequence generation model for ASR error correction, which, however, comes at the cost of significantly increased ASR error rate. In this paper, observing distinctive error patterns and correction operations (i.e., insertion, deletion, and substitution) in ASR, we propose FastCorrect, a novel NAR error correction model based on edit alignment. In training, FastCorrect aligns each source token from an ASR output sentence to the target tokens from the corresponding ground-truth sentence based on the edit distance between the source and target sentences, and extracts the number of target tokens corresponding to each source token during edition/correction, which is then used to train a length predictor and to adjust the source tokens to match the length of the target sentence for parallel generation. In inference, the token number predicted by the length predictor is used to adjust the source tokens for target sequence generation. Experiments on the public AISHELL-1 dataset and an internal industrial-scale ASR dataset show the effectiveness of FastCorrect for ASR error correction: 1) it speeds up the inference by 6-9 times and maintains the accuracy (8-14% WER reduction) compared with the autoregressive correction model; and 2) it outperforms the popular NAR models adopted in neural machine translation and text edition by a large margin."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SNIPS", "Title": "Solving Noisy Inverse Problems Stochastically", "Abstract": "In this work we introduce a novel stochastic algorithm dubbed SNIPS, which draws samples from the posterior distribution of any linear inverse problem, where the observation is assumed to be contaminated by additive white Gaussian noise. Our solution incorporates ideas from Langevin dynamics and Newton's method, and exploits a pre-trained minimum mean squared error (MMSE) Gaussian denoiser. The proposed approach relies on an intricate derivation of the posterior score function that includes a singular value decomposition (SVD) of the degradation operator, in order to obtain a tractable iterative algorithm for the desired sampling. Due to its stochasticity, the algorithm can produce multiple high perceptual quality samples for the same noisy observation. We demonstrate the abilities of the proposed paradigm for image deblurring, super-resolution, and compressive sensing. We show that the samples produced are sharp, detailed and consistent with the given measurements, and their diversity exposes the inherent uncertainty in the inverse problem being solved."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond the Signs", "Title": "Nonparametric Tensor Completion via Sign Series", "Abstract": "We consider the problem of tensor estimation from noisy observations with possibly missing entries. A nonparametric approach to tensor completion is developed based on a new model which we coin as sign representable tensors. The model represents the signal tensor of interest using a series of structured sign tensors. Unlike earlier methods, the sign series representation effectively addresses both low- and high-rank signals, while encompassing many existing tensor models---including CP models, Tucker models, single index models, structured tensors with repeating entries---as special cases. We provably reduce the tensor estimation problem to a series of structured classification tasks, and we develop a learning reduction machinery to empower existing low-rank tensor algorithms for more challenging high-rank estimation. Excess risk bounds, estimation errors, and sample complexities are established. We demonstrate the outperformance of our approach over previous methods on two datasets, one on human brain connectivity networks and the other on topic data mining."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TTT++", "Title": "When Does Self-Supervised Test-Time Training Fail or Thrive?", "Abstract": "Test-time training (TTT) through self-supervised learning (SSL) is an emerging paradigm to tackle distributional shifts. Despite encouraging results, it remains unclear when this approach thrives or fails. In this work, we first provide an in-depth look at its limitations and show that TTT can possibly deteriorate, instead of improving, the test-time performance in the presence of severe distribution shifts. To address this issue, we introduce a test-time feature alignment strategy utilizing offline feature summarization and online moment matching, which regularizes adaptation without revisiting training data. We further scale this strategy in the online setting through batch-queue decoupling to enable robust moment estimates even with limited batch size. Given aligned feature distributions, we then shed light on the strong potential of TTT by theoretically analyzing its performance post adaptation. This analysis motivates our use of more informative self-supervision in the form of contrastive learning for visual recognition problems. We empirically demonstrate that our modified version of test-time training, termed TTT++, outperforms state-of-the-art methods by significant margins on several benchmarks. Our result indicates that storing and exploiting extra information, in addition to model parameters, can be a promising direction towards robust test-time adaptation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SOLQ", "Title": "Segmenting Objects by Learning Queries", "Abstract": "In this paper, we propose an end-to-end framework for instance segmentation. Based on the recently introduced DETR, our method, termed SOLQ, segments objects by learning unified queries. In SOLQ, each query represents one object and has multiple representations: class, location and mask. The object queries learned perform classification, box regression and mask encoding simultaneously in an unified vector form. During training phase, the mask vectors encoded are supervised by the compression coding of raw spatial masks. In inference time,mask vectors produced can be directly transformed to spatial masks by the inverse process of compression coding. Experimental results show that SOLQ can achieve state-of-the-art performance, surpassing most of existing approaches. Moreover, the joint learning of unified query representation can greatly improve the detection performance of DETR. We hope our SOLQ can serve as a strong baseline for the Transformer-based instance segmentation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Robust Optimal Transport", "Title": "Computational Complexity and Barycenter Computation", "Abstract": "We consider robust variants of the standard optimal transport, named robust optimal transport, where marginal constraints are relaxed via Kullback-Leibler divergence. We show that Sinkhorn-based algorithms can approximate the optimal cost of robust optimal transport in $\\widetilde{\\mathcal{O}}(\\frac{n^2}{\\varepsilon})$ time, in which $n$ is the number of supports of the probability distributions and $\\varepsilon$ is the desired error. Furthermore, we investigate a fixed-support robust barycenter problem between $m$ discrete probability distributions with at most $n$ number of supports and develop an approximating algorithm based on iterative Bregman projections (IBP). For the specific case $m = 2$, we show that this algorithm can approximate the optimal barycenter value in $\\widetilde{\\mathcal{O}}(\\frac{mn^2}{\\varepsilon})$ time, thus being better than the previous complexity $\\widetilde{\\mathcal{O}}(\\frac{mn^2}{\\varepsilon^2})$ of the IBP algorithm for approximating the Wasserstein barycenter."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DropGNN", "Title": "Random Dropouts Increase the Expressiveness of Graph Neural Networks", "Abstract": "This paper studies Dropout Graph Neural Networks (DropGNNs), a new approach that aims to overcome the limitations of standard GNN frameworks. In DropGNNs, we execute multiple runs of a GNN on the input graph, with some of the nodes randomly and independently dropped in each of these runs. Then, we combine the results of these runs to obtain the final result. We prove that DropGNNs can distinguish various graph neighborhoods that cannot be separated by message passing GNNs. We derive theoretical bounds for the number of runs required to ensure a reliable distribution of dropouts, and we prove several properties regarding the expressive capabilities and limits of DropGNNs. We experimentally validate our theoretical findings on expressiveness. Furthermore, we show that DropGNNs perform competitively on established GNN benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeuroMLR", "Title": "Robust & Reliable Route Recommendation on Road Networks", "Abstract": "Predicting the most likely route from a source location to a destination is a core functionality in mapping services. Although the problem has been studied in the literature, two key limitations remain to be addressed. First, our study reveals that a significant portion of the routes recommended by existing methods fail to reach the destination. Second, existing techniques are transductive in nature; hence, they fail to recommend routes if unseen roads are encountered at inference time. In this paper, we address these limitations through an inductive algorithm called NeuroMLR. NeuroMLR learns a generative model from historical trajectories by conditioning on three explanatory factors: the current location, the destination, and real-time traffic conditions. The conditional distributions are learned through a novel combination of Lipschitz embedding with Graph Convolutional Networks (GCN) using historical trajectory data. Through in-depth experiments on real-world datasets, we establish that NeuroMLR imparts significant improvement in accuracy over the state of the art. More importantly, NeuroMLR generalizes dramatically better to unseen data and the recommended routes reach the destination with much higher likelihood than existing techniques."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Averaging on the Bures-Wasserstein manifold", "Title": "dimension-free convergence of gradient descent", "Abstract": "We study first-order optimization algorithms for computing the barycenter of Gaussian distributions with respect to the optimal transport metric. Although the objective is geodesically non-convex, Riemannian gradient descent empirically converges rapidly, in fact faster than off-the-shelf methods such as Euclidean gradient descent and SDP solvers. This stands in stark contrast to the best-known theoretical results, which depend exponentially on the dimension. In this work, we prove new geodesic convexity results which provide stronger control of the iterates, yielding a dimension-free convergence rate. Our techniques also enable the analysis of two related notions of averaging, the entropically-regularized barycenter and the geometric median, providing the first convergence guarantees for these problems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DECAF", "Title": "Generating Fair Synthetic Data Using Causally-Aware Generative Networks", "Abstract": "Machine learning models have been criticized for reflecting unfair biases in the training data.  Instead of solving for this by introducing fair learning algorithms directly, we focus on generating fair synthetic data, such that any downstream learner is fair. Generating fair synthetic data from unfair data - while remaining truthful to the underlying data-generating process (DGP) - is non-trivial. In this paper, we introduce DECAF: a GAN-based fair synthetic data generator for tabular data.  With DECAF we embed the DGP explicitly as a structural causal model in the input layers of the generator, allowing each variable to be reconstructed conditioned on its causal parents.  This procedure enables inference time debiasing, where biased edges can be strategically removed for satisfying user-defined fairness requirements. The DECAF framework is versatile and compatible with several popular definitions of fairness. In our experiments, we show that DECAF successfully removes undesired bias and - in contrast to existing methods - is capable of generating high-quality synthetic data. Furthermore, we provide theoretical guarantees on the generator's convergence and the fairness of downstream models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "EvoGrad", "Title": "Efficient Gradient-Based Meta-Learning and Hyperparameter Optimization", "Abstract": "Gradient-based meta-learning and hyperparameter optimization have seen significant progress recently, enabling practical end-to-end training of neural networks together with many hyperparameters. Nevertheless, existing approaches are relatively expensive as they need to compute second-order derivatives and store a longer computational graph. This cost prevents scaling them to larger network architectures. We present EvoGrad, a new approach to meta-learning that draws upon evolutionary techniques to more efficiently compute hypergradients. EvoGrad estimates hypergradient with respect to hyperparameters without calculating second-order gradients, or storing a longer computational graph, leading to significant improvements in  efficiency. We evaluate EvoGrad on three substantial recent meta-learning applications, namely cross-domain few-shot learning with feature-wise transformations, noisy label learning with Meta-Weight-Net and low-resource cross-lingual learning with meta representation transformation. The results show that EvoGrad significantly improves efficiency and enables scaling meta-learning to bigger architectures such as from ResNet10 to ResNet34."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Correlated Stochastic Block Models", "Title": "Exact Graph Matching with Applications to Recovering Communities", "Abstract": "We consider the task of learning latent community structure from multiple correlated networks. First, we study the problem of learning the latent vertex correspondence between two edge-correlated stochastic block models, focusing on the regime where the average degree is logarithmic in the number of vertices. We derive the precise information-theoretic threshold for exact recovery: above the threshold there exists an estimator that outputs the true correspondence with probability close to 1, while below it no estimator can recover the true correspondence with probability bounded away from 0. As an application of our results, we show how one can exactly recover the latent communities using \\emph{multiple} correlated graphs in parameter regimes where it is information-theoretically impossible to do so using just a single graph."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse Deep Learning", "Title": "A New Framework Immune to Local Traps and Miscalibration", "Abstract": "Deep learning has powered recent successes of artificial intelligence (AI). However, the deep neural network, as the basic model of deep learning,  has suffered from issues such as local traps and miscalibration. In this paper, we provide a new framework for sparse deep learning, which has the above issues addressed in a coherent way. In particular, we lay down a theoretical foundation for sparse deep learning and propose prior annealing algorithms for learning sparse neural networks. The former has successfully tamed the sparse deep neural network into the framework of statistical modeling, enabling prediction uncertainty correctly quantified. The latter can be asymptotically guaranteed to converge to the global optimum, enabling the validity of the down-stream statistical inference. Numerical result indicates the superiority of the proposed method compared to the existing ones."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Calibrating Predictions to Decisions", "Title": "A Novel Approach to Multi-Class Calibration", "Abstract": "When facing uncertainty, decision-makers want predictions they can trust. A machine learning provider can convey confidence to decision-makers by guaranteeing their predictions are distribution calibrated--- amongst the inputs that receive a predicted vector of class probabilities q, the actual distribution over classes is given by q. For multi-class prediction problems, however, directly optimizing predictions under distribution calibration tends to be infeasible, requiring sample complexity that grows exponentially in the number of classes C. In this work, we introduce a new notion---decision calibration---that requires the predicted distribution and true distribution over classes to be ``indistinguishable'' to downstream decision-makers. This perspective gives a new characterization of distribution calibration: a predictor is distribution calibrated if and only if it is decision calibrated with respect to all decision-makers. Our main result shows that under a mild restriction, unlike distribution calibration, decision calibration is actually feasible. We design a recalibration algorithm that provably achieves decision calibration efficiently, provided that the decision-makers have a bounded number of actions (e.g., polynomial in C). We validate our recalibration algorithm empirically: compared to existing methods, decision calibration improves decision-making on skin lesion and ImageNet classification with modern neural network predictors."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NORESQA", "Title": "A Framework for Speech Quality Assessment using Non-Matching References", "Abstract": "The perceptual task of speech quality assessment (SQA) is a challenging task for machines to do. Objective SQA methods that rely on the availability of the corresponding clean reference have been the primary go-to approaches for SQA. Clearly, these methods fail in real-world scenarios where the ground truth clean references are not available. In recent years, non-intrusive methods that train neural networks to predict ratings or scores have attracted much attention, but they suffer from several shortcomings such as lack of robustness, reliance on labeled data for training and so on. In this work, we propose a new direction for speech quality assessment. Inspired by human's innate ability to compare and assess the quality of speech signals even when they have non-matching contents, we propose a novel framework that predicts a subjective relative quality score for the given speech signal with respect to any provided reference without using any subjective data. We show that neural networks trained using our framework produce scores that correlate well with subjective mean opinion scores (MOS) and are also competitive to methods such as DNSMOS, which explicitly relies on MOS from humans for training networks. Moreover, our method also provides a natural way to embed quality-related information in neural networks, which we show is helpful for downstream tasks such as speech enhancement."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AFEC", "Title": "Active Forgetting of Negative Transfer in Continual Learning", "Abstract": "Continual learning aims to learn a sequence of tasks from dynamic data distributions. Without accessing to the old training samples, knowledge transfer from the old tasks to each new task is difficult to determine, which might be either positive or negative. If the old knowledge interferes with the learning of a new task, i.e., the forward knowledge transfer is negative, then precisely remembering the old tasks will further aggravate the interference, thus decreasing the performance of continual learning. By contrast, biological neural networks can actively forget the old knowledge that conflicts with the learning of a new experience, through regulating the learning-triggered synaptic expansion and synaptic convergence. Inspired by the biological active forgetting, we propose to actively forget the old knowledge that limits the learning of new tasks to benefit continual learning. Under the framework of Bayesian continual learning, we develop a novel approach named Active Forgetting with synaptic Expansion-Convergence (AFEC). Our method dynamically expands parameters to learn each new task and then selectively combines them, which is formally consistent with the underlying mechanism of biological active forgetting. We extensively evaluate AFEC on a variety of continual learning benchmarks, including CIFAR-10 regression tasks, visual classification tasks and Atari reinforcement tasks, where AFEC effectively improves the learning of new tasks and achieves the state-of-the-art performance in a plug-and-play way."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Heterogeneous Multi-player Multi-armed Bandits", "Title": "Closing the Gap and Generalization", "Abstract": "Despite the significant interests and many progresses in decentralized multi-player multi-armed bandits (MP-MAB) problems in recent years, the regret gap to the natural centralized lower bound in the heterogeneous MP-MAB setting remains open. In this paper, we propose BEACON -- Batched Exploration with Adaptive COmmunicatioN -- that closes this gap. BEACON accomplishes this goal with novel contributions in implicit communication and efficient exploration. For the former, we propose a novel adaptive differential communication (ADC) design that significantly improves the implicit communication efficiency. For the latter, a carefully crafted batched exploration scheme is developed to enable incorporation of the combinatorial upper confidence bound (CUCB) principle. We then generalize the existing linear-reward MP-MAB problems, where the system reward is always the sum of individually collected rewards, to a new MP-MAB problem where the system reward is a general (nonlinear) function of individual rewards. We extend BEACON to solve this problem and prove a logarithmic regret. BEACON bridges the algorithm design and regret analysis of combinatorial MAB (CMAB) and MP-MAB, two largely disjointed areas in MAB, and the results in this paper suggest that this previously ignored connection is worth further investigation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SWAD", "Title": "Domain Generalization by Seeking Flat Minima", "Abstract": "Domain generalization (DG) methods aim to achieve generalizability to an unseen target domain by using only training data from the source domains. Although a variety of DG methods have been proposed, a recent study shows that under a fair evaluation protocol, called DomainBed, the simple empirical risk minimization (ERM) approach works comparable to or even outperforms previous methods. Unfortunately, simply solving ERM on a complex, non-convex loss function can easily lead to sub-optimal generalizability by seeking sharp minima. In this paper, we theoretically show that finding flat minima results in a smaller domain generalization gap. We also propose a simple yet effective method, named Stochastic Weight Averaging Densely (SWAD), to find flat minima. SWAD finds flatter minima and suffers less from overfitting than does the vanilla SWA by a dense and overfit-aware stochastic weight sampling strategy. SWAD shows state-of-the-art performances on five DG benchmarks, namely PACS, VLCS, OfficeHome, TerraIncognita, and DomainNet, with consistent and large margins of +1.6% averagely on out-of-domain accuracy. We also compare SWAD with conventional generalization methods, such as data augmentation and consistency regularization methods, to verify that the remarkable performance improvements are originated from by seeking flat minima, not from better in-domain generalizability. Last but not least, SWAD is readily adaptable to existing DG methods without modification; the combination of SWAD and an existing DG method further improves DG performances. Source code is available at https://github.com/khanrc/swad."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Autoformer", "Title": "Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting", "Abstract": "Extending the forecasting time is a critical demand for real applications, such as extreme weather early warning and long-term energy consumption planning. This paper studies the long-term forecasting problem of time series. Prior Transformer-based models adopt various self-attention mechanisms to discover the long-range dependencies. However, intricate temporal patterns of the long-term future prohibit the model from finding reliable dependencies. Also, Transformers have to adopt the sparse versions of point-wise self-attentions for long series efficiency, resulting in the information utilization bottleneck. Going beyond Transformers, we design Autoformer as a novel decomposition architecture with an Auto-Correlation mechanism. We break with the pre-processing convention of series decomposition and renovate it as a basic inner block of deep models. This design empowers Autoformer with progressive decomposition capacities for complex time series. Further, inspired by the stochastic process theory, we design the Auto-Correlation mechanism based on the series periodicity, which conducts the dependencies discovery and representation aggregation at the sub-series level. Auto-Correlation outperforms self-attention in both efficiency and accuracy. In long-term forecasting, Autoformer yields state-of-the-art accuracy, with a 38% relative improvement on six benchmarks, covering five practical applications: energy, traffic, economics, weather and disease. Code is available at this repository: https://github.com/thuml/Autoformer."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Combiner", "Title": "Full Attention Transformer with Sparse Computation Cost", "Abstract": "Transformers provide a class of expressive architectures that are extremely effective for sequence modeling. However, the key limitation of transformers is their quadratic memory and time complexity $\\mathcal{O}(L^2)$ with respect to the sequence length in attention layers, which restricts application in extremely long sequences. Most existing approaches leverage sparsity or low-rank assumptions in the attention matrix to reduce cost, but sacrifice expressiveness. Instead, we propose Combiner, which provides full attention capability in each attention head while maintaining low computation and memory complexity. The key idea is to treat the self-attention mechanism as a conditional expectation over embeddings at each location, and approximate the conditional distribution with a structured factorization. Each location can attend to all other locations, either via direct attention, or through indirect attention to abstractions, which are again conditional expectations of embeddings from corresponding local regions. We show that most sparse attention patterns used in existing sparse transformers are able to inspire the design of such factorization for full attention, resulting in the same sub-quadratic cost ($\\mathcal{O}(L\\log(L))$ or $\\mathcal{O}(L\\sqrt{L})$). Combiner is a drop-in replacement for attention layers in existing transformers and can be easily implemented in common frameworks. An experimental evaluation on both autoregressive and bidirectional sequence tasks demonstrates the effectiveness of this approach, yielding state-of-the-art results on several image and text modeling tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Sensory Neuron as a Transformer", "Title": "Permutation-Invariant Neural Networks for Reinforcement Learning", "Abstract": "In complex systems, we often observe complex global behavior emerge from a collection of agents interacting with each other in their environment, with each individual agent acting only on locally available information, without knowing the full picture. Such systems have inspired development of artificial intelligence algorithms in areas such as swarm optimization and cellular automata. Motivated by the emergence of collective behavior from complex cellular systems, we build systems that feed each sensory input from the environment into distinct, but identical neural networks, each with no fixed relationship with one another. We show that these sensory networks can be trained to integrate information received locally, and through communication via an attention mechanism, can collectively produce a globally coherent policy. Moreover, the system can still perform its task even if the ordering of its inputs is randomly permuted several times during an episode. These permutation invariant systems also display useful robustness and generalization properties that are broadly applicable. Interactive demo and videos of our results: https://attentionneuron.github.io"}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisiting ResNets", "Title": "Improved Training and Scaling Strategies", "Abstract": "Novel computer vision architectures monopolize the spotlight, but the impact of the model architecture is often conflated with simultaneous changes to training methodology and scaling strategies.Our work revisits the canonical ResNet and studies these three aspects in an effort to disentangle them. Perhaps surprisingly, we find that training and scaling strategies may matter more than architectural changes, and further, that the resulting ResNets match recent state-of-the-art models. We show that the best performing scaling strategy depends on the training regime and offer two new scaling strategies: (1) scale model depth in regimes where overfitting can occur (width scaling is preferable otherwise); (2) increase image resolution more slowly than previously recommended.Using improved training and scaling strategies, we design a family of ResNet architectures, ResNet-RS, which are 1.7x - 2.7x faster than EfficientNets on TPUs, while achieving similar accuracies on ImageNet. In a large-scale semi-supervised learning setup, ResNet-RS achieves 86.2% top-1 ImageNet accuracy, while being 4.7x faster than EfficientNet-NoisyStudent. The training techniques improve transfer performance on a suite of downstream tasks (rivaling state-of-the-art self-supervised algorithms) and extend to video classification on Kinetics-400. We recommend practitioners use these simple revised ResNets as baselines for future research."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sparse Flows", "Title": "Pruning Continuous-depth Models", "Abstract": "Continuous deep learning architectures enable learning of flexible probabilistic models for predictive modeling as neural ordinary differential equations (ODEs), and for generative modeling as continuous normalizing flows. In this work, we design a framework to decipher the internal dynamics of these continuous depth models by pruning their network architectures. Our empirical results suggest that pruning improves generalization for neural ODEs in generative modeling. We empirically show that the improvement is because pruning helps avoid mode-collapse and flatten the loss surface. Moreover, pruning finds efficient neural ODE representations with up to 98% less parameters compared to the original network, without loss of accuracy. We hope our results will invigorate further research into the performance-size trade-offs of modern continuous-depth models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Rate of Convergence of Regularized Learning in Games", "Title": "From Bandits and Uncertainty to Optimism and Beyond", "Abstract": "In this paper, we examine the convergence rate of a wide range of regularized methods for learning in games. To that end, we propose a unified algorithmic template that we call “follow the generalized leader” (FTGL), and which includes asspecial cases the canonical “follow the regularized leader” algorithm, its optimistic variants, extra-gradient schemes, and many others. The proposed framework is also sufficiently flexible to account for several different feedback models – fromfull information to bandit feedback. In this general setting, we show that FTGL algorithms converge locally to strict Nash equilibria at a rate which does not depend on the level of uncertainty faced by the players, but only on the geometry of the regularizer near the equilibrium. In particular, we show that algorithms based on entropic regularization – like the exponential weights algorithm – enjoy a linear convergence rate, while Euclidean projection methods converge to equilibrium in a finite number of iterations, even with bandit feedback."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SLAPS", "Title": "Self-Supervision Improves Structure Learning for Graph Neural Networks", "Abstract": "Graph neural networks (GNNs) work well when the graph structure is provided. However, this structure may not always be available in real-world applications. One solution to this problem is to infer a task-specific latent structure and then apply a GNN to the inferred graph. Unfortunately, the space of possible graph structures grows super-exponentially with the number of nodes and so the task-specific supervision may be insufficient for learning both the structure and the GNN parameters. In this work, we propose the Simultaneous Learning of Adjacency and GNN Parameters with Self-supervision, or SLAPS, a method that provides more supervision for inferring a graph structure through self-supervision. A comprehensive experimental study demonstrates that SLAPS scales to large graphs with hundreds of thousands of nodes and outperforms several models that have been proposed to learn a task-specific graph structure on established benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SSAL", "Title": "Synergizing between Self-Training and Adversarial Learning for Domain Adaptive Object Detection", "Abstract": "We study adapting trained object detectors to unseen domains manifesting significant variations of object appearance, viewpoints and backgrounds. Most current methods align domains by either using image or instance-level feature alignment in an adversarial fashion. This often suffers due to the presence of unwanted background and as such lacks class-specific alignment. A common remedy to promote class-level alignment is to use high confidence predictions on the unlabelled domain as pseudo labels. These high confidence predictions are often fallacious since the model is poorly calibrated under domain shift. In this paper, we propose to leverage model’s predictive uncertainty to strike the right balance between adversarial feature alignment and class-level alignment. Specifically, we measure predictive uncertainty on class assignments and the bounding box predictions. Model predictions with low uncertainty are used to generate pseudo-labels for self-supervision, whereas the ones with higher uncertainty are used to generate tiles for an adversarial feature alignment stage. This synergy between tiling around the uncertain object regions and generating pseudo-labels from highly certain object regions allows us to capture both the image and instance level context during the model adaptation stage. We perform extensive experiments covering various domain shift scenarios. Our approach improves upon existing state-of-the-art methods with visible margins."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stable, Fast and Accurate", "Title": "Kernelized Attention with Relative Positional Encoding", "Abstract": "The attention module, which is a crucial component in Transformer, cannot scale efficiently to long sequences due to its quadratic complexity. Many works focus on approximating the dot-then-exponentiate softmax function in the original attention, leading to sub-quadratic or even linear-complexity Transformer architectures. However, we show that these methods cannot be applied to more powerful attention modules that go beyond the dot-then-exponentiate style, e.g., Transformers with relative positional encoding (RPE). Since in many state-of-the-art models, relative positional encoding is used as default, designing efficient Transformers that can incorporate RPE is appealing. In this paper, we propose a novel way to accelerate attention calculation for Transformers with RPE on top of the kernelized attention. Based upon the observation that relative positional encoding forms a Toeplitz matrix, we mathematically show that kernelized attention with RPE can be calculated efficiently using Fast Fourier Transform (FFT). With FFT, our method achieves $\\mathcal{O}(n\\log n)$ time complexity. Interestingly, we further demonstrate that properly using relative positional encoding can mitigate the training instability problem of vanilla kernelized attention. On a wide range of tasks, we empirically show that our models can be trained from scratch without any optimization issues. The learned model performs better than many efficient Transformer variants and is faster than standard Transformer in the long-sequence regime."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Identification of Partially Observed Linear Causal Models", "Title": "Graphical Conditions for the Non-Gaussian and Heterogeneous Cases", "Abstract": "In causal discovery, linear non-Gaussian acyclic models (LiNGAMs) have been studied extensively. While the causally sufficient case is well understood, in many real problems the observed variables are not causally related. Rather, they are generated by latent variables, such as confounders and mediators, which may themselves be causally related. Existing results on the identification of the causal structure among the latent variables often require very strong graphical assumptions. In this paper, we consider partially observed linear models with either non-Gaussian or heterogeneous errors. In that case we give two graphical conditions which are necessary for identification of the causal structure. These conditions are closely related to sparsity of the causal edges. Together with one additional condition on the coefficients, which holds generically for any graph, the two graphical conditions are also sufficient for identifiability. These new conditions can be satisfied even when there is a large number of latent variables. We demonstrate the validity of our results on synthetic data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DIB-R++", "Title": "Learning to Predict Lighting and Material with a Hybrid Differentiable Renderer", "Abstract": "We consider the challenging problem of predicting intrinsic object properties from a single image by exploiting differentiable renderers. Many previous learning-based approaches for inverse graphics adopt rasterization-based renderers and assume naive lighting and material models, which often fail to account for non-Lambertian, specular reflections commonly observed in the wild. In this work, we propose DIBR++, a hybrid differentiable renderer which supports these photorealistic  effects by combining rasterization and ray-tracing, taking the advantage of their respective strengths---speed and realism. Our renderer incorporates environmental lighting and spatially-varying material models to efficiently approximate light transport, either through direct estimation or via spherical basis functions. Compared to more advanced physics-based differentiable renderers leveraging path tracing, DIBR++ is highly performant due to its compact and expressive shading model, which enables easy integration with learning frameworks for geometry, reflectance and lighting prediction from a single image without requiring any ground-truth. We experimentally demonstrate that our approach achieves superior material and lighting disentanglement on synthetic and real data compared to existing rasterization-based approaches and showcase several artistic applications including material editing and relighting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LADA", "Title": "Look-Ahead Data Acquisition via Augmentation for Deep Active Learning", "Abstract": "Active learning effectively collects data instances for training deep learning models when the labeled dataset is limited and the annotation cost is high. Data augmentation is another effective technique to enlarge the limited amount of labeled instances. The scarcity of labeled dataset leads us to consider the integration of data augmentation and active learning. One possible approach is a pipelined combination, which selects informative instances via the acquisition function and generates virtual instances from the selected instances via augmentation. However, this pipelined approach would not guarantee the informativeness of the virtual instances. This paper proposes Look-Ahead Data Acquisition via augmentation, or LADA framework, that looks ahead the effect of data augmentation in the process of acquisition. LADA jointly considers both 1) unlabeled data instance to be selected and 2) virtual data instance to be generated by data augmentation, to construct the acquisition function. Moreover, to generate maximally informative virtual instances, LADA optimizes the data augmentation policy to maximize the predictive acquisition score, resulting in the proposal of InfoSTN and InfoMixup. The experimental results of LADA show a significant improvement over the recent augmentation and acquisition baselines that were independently applied."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Policy Optimization in Adversarial MDPs", "Title": "Improved Exploration via Dilated Bonuses", "Abstract": "Policy optimization is a widely-used method in reinforcement learning. Due to its local-search nature, however, theoretical guarantees on global optimality often rely on extra assumptions on the Markov Decision Processes (MDPs) that bypass the challenge of global exploration. To eliminate the need of such assumptions, in this work, we develop a general solution that adds dilated bonuses to the policy update to facilitate global exploration. To showcase the power and generality of this technique, we apply it to several episodic MDP settings with adversarial losses and bandit feedback, improving and generalizing the state-of-the-art. Specifically, in the tabular case, we obtain $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret where $T$ is the number of episodes, improving the $\\widetilde{\\mathcal{O}}({T}^{\\frac{2}{3}})$ regret bound by Shani et al. [2020]. When the number of states is infinite, under the assumption that the state-action values are linear in some low-dimensional features, we obtain $\\widetilde{\\mathcal{O}}({T}^{\\frac{2}{3}})$ regret with the help of a simulator, matching the result of Neu and Olkhovskaya [2020] while importantly removing the need of an exploratory policy that their algorithm requires. To our knowledge, this is the first algorithm with sublinear regret for linear function approximation with adversarial losses, bandit feedback, and no exploratory assumptions. Finally, we also discuss how to further improve the regret or remove the need of a simulator using dilated bonuses, when an exploratory policy is available."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NN-Baker", "Title": "A Neural-network Infused Algorithmic Framework for Optimization Problems on Geometric Intersection Graphs", "Abstract": "Recent years have witnessed a surge of approaches to use neural networks to help tackle combinatorial optimization problems, including graph optimization problems. However, theoretical understanding of such approaches remains limited. In this paper, we consider the geometric setting, where graphs are induced by points in a fixed dimensional Euclidean space. We show that several graph optimization problems can be approximated by an algorithm that is polynomial in graph size n via a framework we propose, call the Baker-paradigm. More importantly, a key advantage of the Baker-paradigm is that it decomposes the input problem into (at most linear number of) small sub-problems of fixed sizes (independent of the size of the input). For the family of such fixed-size sub-problems, we can now design neural networks with universal approximation guarantees to solve them. This leads to a mixed algorithmic-ML framework, which we call NN-Baker that has the capacity to approximately solve a family of graph optimization problems (e.g, maximum independent set and minimum vertex cover) in time linear to input graph size, and only polynomial to approximation parameter. We instantiate our NN-Baker by a CNN version and GNN version, and demonstrate the effectiveness and efficiency of our approach via a range of experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RMIX", "Title": "Learning Risk-Sensitive Policies for Cooperative Reinforcement Learning Agents", "Abstract": "Current value-based multi-agent reinforcement learning methods optimize individual Q values to guide individuals' behaviours via centralized training with decentralized execution (CTDE). However, such expected, i.e., risk-neutral, Q value is not sufficient even with CTDE due to the randomness of rewards and the uncertainty in environments, which causes the failure of these methods to train coordinating agents in complex environments. To address these issues, we propose RMIX, a novel cooperative MARL method with the Conditional Value at Risk (CVaR) measure over the learned distributions of individuals' Q values. Specifically, we first learn the return distributions of individuals to analytically calculate CVaR for decentralized execution. Then, to handle the temporal nature of the stochastic outcomes during executions, we propose a dynamic risk level predictor for risk level tuning. Finally, we optimize the CVaR policies with CVaR values used to estimate the target in TD error during centralized training and the CVaR values are used as auxiliary local rewards to update the local distribution via Quantile Regression loss. Empirically, we show that our method outperforms many state-of-the-art methods on various multi-agent risk-sensitive navigation scenarios and challenging StarCraft II cooperative tasks, demonstrating enhanced coordination and revealing improved sample efficiency."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PLUR", "Title": "A Unifying, Graph-Based View of Program Learning, Understanding, and Repair", "Abstract": "Machine learning for understanding and editing source code has recently attracted significant interest, with many developments in new models, new code representations, and new tasks.This proliferation can appear disparate and disconnected, making each approach seemingly unique and incompatible, thus obscuring the core machine learning challenges and contributions.In this work, we demonstrate that the landscape can be significantly simplified by taking a general approach of mapping a graph to a sequence of tokens and pointers.Our main result is to show that 16 recently published tasks of different shapes can be cast in this form, based on which a single model architecture achieves near or above state-of-the-art results on nearly all tasks, outperforming custom models like code2seq and alternative generic models like Transformers.This unification further enables multi-task learning and a series of cross-cutting experiments about the importance of different modeling choices for code understanding and repair tasks.The full framework, called PLUR, is easily extensible to more tasks, and will be open-sourced (https://github.com/google-research/plur)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COCO-LM", "Title": "Correcting and Contrasting Text Sequences for Language Model Pretraining", "Abstract": "We present a self-supervised learning framework, COCO-LM, that pretrains Language Models by COrrecting and COntrasting corrupted text sequences. Following ELECTRA-style pretraining, COCO-LM employs an auxiliary language model to corrupt text sequences, upon which it constructs two new tasks for pretraining the main model. The first token-level task, Corrective Language Modeling, is to detect and correct tokens replaced by the auxiliary model, in order to better capture token-level semantics. The second sequence-level task, Sequence Contrastive Learning, is to align text sequences originated from the same source input while ensuring uniformity in the representation space. Experiments on GLUE and SQuAD demonstrate that COCO-LM not only outperforms recent state-of-the-art pretrained models in accuracy, but also improves pretraining efficiency. It achieves the MNLI accuracy of ELECTRA with 50% of its pretraining GPU hours. With the same pretraining steps of standard base/large-sized models, COCO-LM outperforms the previous best models by 1+ GLUE average points."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "XDO", "Title": "A Double Oracle Algorithm for Extensive-Form Games", "Abstract": "Policy Space Response Oracles (PSRO) is a reinforcement learning (RL) algorithm for two-player zero-sum games that has been empirically shown to find approximate Nash equilibria in large games. Although PSRO is guaranteed to converge to an approximate Nash equilibrium and can handle continuous actions, it may take an exponential number of iterations as the number of information states (infostates) grows. We propose Extensive-Form Double Oracle (XDO), an extensive-form double oracle algorithm for two-player zero-sum games that is guaranteed to converge to an approximate Nash equilibrium linearly in the number of infostates. Unlike PSRO, which mixes best responses at the root of the game, XDO mixes best responses at every infostate. We also introduce Neural XDO (NXDO), where the best response is learned through deep RL. In tabular experiments on Leduc poker, we find that XDO achieves an approximate Nash equilibrium in a number of iterations an order of magnitude smaller than PSRO. Experiments on a modified Leduc poker game and Oshi-Zumo show that tabular XDO achieves a lower exploitability than CFR with the same amount of computation. We also find that NXDO outperforms PSRO and NFSP on a sequential multidimensional continuous-action game. NXDO is the first deep RL method that can find an approximate Nash equilibrium in high-dimensional continuous-action sequential games."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Closing the loop in medical decision support by understanding clinical decision-making", "Title": "A case study on organ transplantation", "Abstract": "Significant effort has been placed on developing decision support tools to improve patient care. However, drivers of real-world clinical decisions in complex medical scenarios are not yet well-understood, resulting in substantial gaps between these tools and practical applications. In light of this, we highlight that more attention on understanding clinical decision-making is required both to elucidate current clinical practices and to enable effective human-machine interactions. This is imperative in high-stakes scenarios with scarce available resources. Using organ transplantation as a case study, we formalize the desiderata of methods for understanding clinical decision-making. We show that most existing machine learning methods are insufficient to meet these requirements and propose iTransplant, a novel data-driven framework to learn the factors affecting decisions on organ offers in an instance-wise fashion directly from clinical data, as a possible solution. Through experiments on real-world liver transplantation data from OPTN, we demonstrate the use of iTransplant to: (1) discover which criteria are most important to clinicians for organ offer acceptance; (2) identify patient-specific organ preferences of clinicians allowing automatic patient stratification;  and (3) explore variations in transplantation practices between different transplant centers. Finally, we emphasize that the insights gained by iTransplant can be used to inform the development of future decision support tools."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Fair Sparse Regression with Clustering", "Title": "An Invex Relaxation for a Combinatorial Problem", "Abstract": "In this paper, we study the problem of fair sparse regression on a biased dataset where bias depends upon a hidden binary attribute. The presence of a hidden attribute adds an extra layer of complexity to the problem by combining sparse regression and clustering with unknown binary labels. The corresponding optimization problem is combinatorial, but we propose a novel relaxation of it as an invex optimization problem. To the best of our knowledge, this is the first invex relaxation for a combinatorial problem. We show that the inclusion of the debiasing/fairness constraint in our model has no adverse effect on the performance. Rather, it enables the recovery of the hidden attribute. The support of our recovered regression parameter vector matches exactly with the true parameter vector. Moreover, we simultaneously solve the clustering problem by recovering the exact value of the hidden attribute for each sample. Our method uses carefully constructed primal dual witnesses to provide theoretical guarantees for the combinatorial problem. To that end, we show that the sample complexity of our method is logarithmic in terms of the dimension of the regression parameter vector."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PartialFed", "Title": "Cross-Domain Personalized Federated Learning via Partial Initialization", "Abstract": "The burst of applications empowered by massive data have aroused unprecedented privacy concerns in AI society. Currently, data confidentiality protection has been one core issue during deep model training. Federated Learning (FL), which enables privacy-preserving training across multiple silos, gained rising popularity for its parameter-only communication. However, previous works have shown that FL revealed a significant performance drop if the data distributions are heterogeneous among different clients, especially when the clients have cross-domain characteristic, such as traffic, aerial and in-door. To address this challenging problem, we propose a novel idea, PartialFed, which loads a subset of the global model’s parameters rather than loading the entire model used in most previous works. We first validate our algorithm with manually decided loading strategies inspired by various expert priors, named PartialFed-Fix. Then we develop PartialFed-Adaptive, which automatically selects personalized loading strategy for each client. The superiority of our algorithm is proved by demonstrating the new state-of-the-art results on cross-domain federated classification and detection. In particular, solely by initializing a small fraction of layers locally, we improve the performance of FedAvg on Office-Home and UODB by 4.88% and 2.65%, respectively. Further studies show that the adaptive strategy performs significantly better on domains with large deviation, e.g. improves AP50 by 4.03% and 4.89% on aerial and medical image detection compared to FedAvg."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Contrast and Mix", "Title": "Temporal Contrastive Video Domain Adaptation with Background Mixing", "Abstract": "Unsupervised domain adaptation which aims to adapt models trained on a labeled source domain to a completely unlabeled target domain has attracted much attention in recent years. While many domain adaptation techniques have been proposed for images, the problem of unsupervised domain adaptation in videos remains largely underexplored. In this paper, we introduce Contrast and Mix (CoMix), a new contrastive learning framework that aims to learn discriminative invariant feature representations for unsupervised video domain adaptation. First, unlike existing methods that rely on adversarial learning for feature alignment, we utilize temporal contrastive learning to bridge the domain gap by maximizing the similarity between encoded representations of an unlabeled video at two different speeds as well as minimizing the similarity between different videos played at different speeds. Second, we propose a novel extension to the temporal contrastive loss by using background mixing that allows additional positives per anchor, thus adapting contrastive learning to leverage action semantics shared across both domains. Moreover, we also integrate a supervised contrastive learning objective using target pseudo-labels to enhance discriminability of the latent space for video domain adaptation. Extensive experiments on several benchmark datasets demonstrate the superiority of our proposed approach over state-of-the-art methods. Project page: https://cvir.github.io/projects/comix."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Flip Side of the Reweighted Coin", "Title": "Duality of Adaptive Dropout and Regularization", "Abstract": "Among the most successful methods for sparsifying deep (neural) networks are those that adaptively mask the network weights throughout training. By examining this masking, or dropout, in the linear case, we uncover a duality between such adaptive methods and regularization through the so-called “η-trick” that casts both as iteratively reweighted optimizations. We show that any dropout strategy that adapts to the weights in a monotonic way corresponds to an effective subquadratic regularization penalty, and therefore leads to sparse solutions. We obtain the effective penalties for several popular sparsification strategies, which are remarkably similar to classical penalties commonly used in sparse optimization. Considering variational dropout as a case study, we demonstrate similar empirical behavior between the adaptive dropout method and classical methods on the task of deep network sparsification, validating our theory."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Differentiable Spike", "Title": "Rethinking Gradient-Descent for Training Spiking Neural Networks", "Abstract": "Spiking Neural Networks (SNNs) have emerged as a biology-inspired method mimicking the spiking nature of brain neurons. This bio-mimicry derives SNNs' energy efficiency of inference on neuromorphic hardware. However, it also causes an intrinsic disadvantage in training high-performing SNNs from scratch since the discrete spike prohibits the gradient calculation. To overcome this issue, the surrogate gradient (SG) approach has been proposed as a continuous relaxation. Yet the heuristic choice of SG leaves it vacant how the SG benefits the SNN training. In this work, we first theoretically study the gradient descent problem in SNN training and introduce finite difference gradient to quantitatively analyze the training behavior of SNN. Based on the introduced finite difference gradient, we propose a new family of Differentiable Spike (Dspike) functions that can adaptively evolve during training to find the optimal shape and smoothness for gradient estimation. Extensive experiments over several popular network structures show that training SNN with Dspike consistently outperforms the state-of-the-art training methods. For example, on the CIFAR10-DVS classification task, we can train a spiking ResNet-18 and achieve 75.4% top-1 accuracy with 10 time steps."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rebooting ACGAN", "Title": "Auxiliary Classifier GANs with Stable Training", "Abstract": "Conditional Generative Adversarial Networks (cGAN) generate realistic images by incorporating class information into GAN. While one of the most popular cGANs is an auxiliary classifier GAN with softmax cross-entropy loss (ACGAN), it is widely known that training ACGAN is challenging as the number of classes in the dataset increases. ACGAN also tends to generate easily classifiable samples with a lack of diversity. In this paper, we introduce two cures for ACGAN. First, we identify that gradient exploding in the classifier can cause an undesirable collapse in early training, and projecting input vectors onto a unit hypersphere can resolve the problem. Second, we propose the Data-to-Data Cross-Entropy loss (D2D-CE) to exploit relational information in the class-labeled dataset. On this foundation, we propose the Rebooted Auxiliary Classifier Generative Adversarial Network (ReACGAN). The experimental results show that ReACGAN achieves state-of-the-art generation results on CIFAR10, Tiny-ImageNet, CUB200, and ImageNet datasets. We also verify that ReACGAN benefits from differentiable augmentations and that D2D-CE harmonizes with StyleGAN2 architecture. Model weights and a software package that provides implementations of representative cGANs and all experiments in our paper are available at https://github.com/POSTECH-CVLab/PyTorch-StudioGAN."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sampling  with Trusthworthy Constraints", "Title": "A Variational Gradient Framework", "Abstract": "Sampling-based inference and learning techniques, especially Bayesian inference, provide an essential approach to handling uncertainty in machine learning (ML). As these techniques are increasingly used in daily life, it becomes essential to safeguard the ML systems with various trustworthy-related constraints, such as fairness, safety, interpretability. Mathematically, enforcing these constraints in probabilistic inference can be cast into sampling from intractable distributions subject to general nonlinear constraints, for which practical efficient algorithms are still largely missing. In this work, we propose a family of constrained sampling algorithms which generalize Langevin Dynamics (LD) and Stein Variational Gradient Descent (SVGD) to incorporate a moment constraint specified by a general nonlinear function. By exploiting the gradient flow structure of LD and SVGD, we derive two types of algorithms for handling constraints, including a primal-dual gradient approach and the constraint controlled gradient descent approach. We investigate the continuous-time mean-field limit of these algorithms and show that they have O(1/t) convergence under mild conditions. Moreover, the LD variant converges linearly assuming that a log Sobolev like inequality holds. Various numerical experiments are conducted to demonstrate the efficiency of our algorithms in trustworthy settings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MERLOT", "Title": "Multimodal Neural Script Knowledge Models", "Abstract": "As humans, we understand events in the visual world contextually, performing multimodal reasoning across time to make inferences about the past, present, and future. We introduce MERLOT, a model that learns multimodal script knowledge by watching millions of YouTube videos with transcribed speech -- in an entirely label-free, self-supervised manner. By pretraining with a mix of both frame-level (spatial) and video-level (temporal) objectives, our model not only learns to match images to temporally corresponding words, but also to contextualize what is happening globally over time. As a result, MERLOT exhibits strong out-of-the-box representations of temporal commonsense, and achieves state-of-the-art performance on 12 different video QA datasets when finetuned. It also transfers well to the world of static images, allowing models to reason about the dynamic context behind visual scenes. On Visual Commonsense Reasoning, MERLOT~answers questions correctly with 80.6\\% accuracy, outperforming state-of-the-art models of similar size by over 3\\%, even those that make heavy use of auxiliary supervised data (like object bounding boxes).Ablation analyses demonstrate the complementary importance of: 1) training on videos versus static images; 2) scaling the magnitude and diversity of the pretraining video corpus; and 3) using diverse objectives that encourage full-stack multimodal reasoning, from the recognition to cognition level."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Risk Minimization", "Title": "Learning to Adapt to Domain Shift", "Abstract": "A fundamental assumption of most machine learning algorithms is that the training and test data are drawn from the same underlying distribution. However, this assumption is violated in almost all practical applications: machine learning systems are regularly tested under distribution shift, due to changing temporal correlations, atypical end users, or other factors. In this work, we consider the problem setting of domain generalization, where the training data are structured into domains and there may be multiple test time shifts, corresponding to new domains or domain distributions. Most prior methods aim to learn a single robust model or invariant feature space that performs well on all domains. In contrast, we aim to learn models that adapt at test time to domain shift using unlabeled test points. Our primary contribution is to introduce the framework of adaptive risk minimization (ARM), in which models are directly optimized for effective adaptation to shift by learning to adapt on the training domains. Compared to prior methods for robustness, invariance, and adaptation, ARM methods provide performance gains of 1-4% test accuracy on a number of image classification problems exhibiting domain shift."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mixability made efficient", "Title": "Fast online multiclass logistic regression", "Abstract": "Mixability has been shown to be a powerful tool to obtain algorithms with optimal regret. However, the resulting methods often suffer from high computational complexity which has reduced their practical applicability. For example, in the case of multiclass logistic regression, the aggregating forecaster (see Foster et al. 2018) achieves a regret of $O(\\log(Bn))$ whereas Online Newton Step achieves $O(e^B\\log(n))$ obtaining a double exponential gain in $B$ (a bound on the norm of comparative functions). However, this high statistical performance is at the price of a prohibitive computational complexity $O(n^{37})$.In this paper, we use quadratic surrogates to make aggregating forecasters more efficient. We show that the resulting algorithm has still high statistical performance for a large class of losses. In particular, we derive an algorithm for multiclass regression with a regret bounded by $O(B\\log(n))$ and computational complexity of only $O(n^4)$."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MIRACLE", "Title": "Causally-Aware Imputation via Learning Missing Data Mechanisms", "Abstract": "Missing data is an important problem in machine learning practice. Starting from the premise that imputation methods should preserve the causal structure of the data, we develop a regularization scheme that encourages any baseline imputation method to be causally consistent with the underlying data generating mechanism. Our proposal is a causally-aware imputation algorithm (MIRACLE). MIRACLE iteratively refines the imputation of a baseline by simultaneously modeling the missingness generating mechanism, encouraging imputation to be consistent with the causal structure of the data. We conduct extensive experiments on synthetic and a variety of publicly available datasets to show that MIRACLE is able to consistently improve imputation over a variety of benchmark methods across all three missingness scenarios: at random, completely at random, and not at random."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Small random initialization is akin to spectral learning", "Title": "Optimization and generalization guarantees for overparameterized low-rank matrix reconstruction", "Abstract": "Recently there has been significant theoretical progress on understanding the convergence and generalization of gradient-based methods on nonconvex losses with overparameterized models. Nevertheless, many aspects of optimization and generalization and in particular the critical role of small random initialization are not fully understood. In this paper, we take a step towards demystifying this role by proving that small random initialization followed by a few iterations of gradient descent behaves akin to popular spectral methods. We also show that this implicit spectral bias from small random initialization, which is provably more prominent for overparameterized models, also puts the gradient descent iterations on a particular trajectory towards solutions that are not only globally optimal but also generalize well. Concretely, we focus on the problem of reconstructing a low-rank matrix from a few measurements via a natural nonconvex formulation. In this setting, we show that the trajectory of the gradient descent iterations from small random initialization can be approximately decomposed into three phases: (I) a spectral or alignment phase where we show that that the iterates have an implicit spectral bias akin to spectral initialization allowing us to show that at the end of this phase the column space of the iterates and the underlying low-rank matrix are sufficiently aligned, (II) a saddle avoidance/refinement phase where we show that the trajectory of the gradient iterates moves away from certain degenerate saddle points, and (III) a local refinement phase where we show that after avoiding the saddles the iterates converge quickly to the underlying low-rank matrix. Underlying our analysis are insights for the analysis of overparameterized nonconvex optimization schemes that may have implications for computational problems beyond low-rank reconstruction."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CoFiNet", "Title": "Reliable Coarse-to-fine Correspondences for Robust PointCloud Registration", "Abstract": "We study the problem of extracting correspondences between a pair of point clouds for registration. For correspondence retrieval, existing works benefit from matching sparse keypoints detected from dense points but usually struggle to guarantee their repeatability. To address this issue, we present CoFiNet - Coarse-to-Fine Network which extracts hierarchical correspondences from coarse to fine without keypoint detection. On a coarse scale and guided by a weighting scheme, our model firstly learns to match down-sampled nodes whose vicinity points share more overlap, which significantly shrinks the search space of a consecutive stage. On a finer scale, node proposals are consecutively expanded to patches that consist of groups of points together with associated descriptors. Point correspondences are then refined from the overlap areas of corresponding patches, by a density-adaptive matching module capable to deal with varying point density. Extensive evaluation of CoFiNet on both indoor and outdoor standard benchmarks shows our superiority over existing methods. Especially on 3DLoMatch where point clouds share less overlap, CoFiNet significantly outperforms state-of-the-art approaches by at least 5% on Registration Recall, with at most two-third of their parameters."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "LLC", "Title": "Accurate, Multi-purpose Learnt Low-dimensional Binary Codes", "Abstract": "Learning binary representations of instances and classes is a classical problem with several high potential applications. In modern settings, the compression of high-dimensional neural representations to low-dimensional binary codes is a challenging task and often require large bit-codes to be accurate. In this work, we propose a novel method for $\\textbf{L}$earning $\\textbf{L}$ow-dimensional binary $\\textbf{C}$odes $(\\textbf{LLC})$ for instances as well as classes. Our method does ${\\textit{not}}$ require any side-information, like annotated attributes or label meta-data, and learns extremely low-dimensional binary codes ($\\approx 20$ bits for ImageNet-1K). The learnt codes are super-efficient while still ensuring $\\textit{nearly optimal}$ classification accuracy for ResNet50 on ImageNet-1K. We demonstrate that the learnt codes capture intrinsically important features in the data, by discovering an intuitive taxonomy over classes. We further quantitatively measure the quality of our codes by applying it to the efficient image retrieval as well as out-of-distribution (OOD) detection problems. For ImageNet-100 retrieval problem, our learnt binary codes outperform $16$ bit HashNet using only $10$ bits and also are as accurate as $10$ dimensional real representations. Finally, our learnt binary codes can perform OOD detection, out-of-the-box, as accurately as a baseline that needs $\\approx3000$ samples to tune its threshold, while we require ${\\textit{none}}$. Code is open-sourced at https://github.com/RAIVNLab/LLC."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "POODLE", "Title": "Improving Few-shot Learning via Penalizing Out-of-Distribution Samples", "Abstract": "In this work, we propose to use out-of-distribution samples, i.e., unlabeled samples coming from outside the target classes, to improve few-shot learning. Specifically, we exploit the easily available out-of-distribution samples to drive the classifier to avoid irrelevant features by maximizing the distance from prototypes to out-of-distribution samples while minimizing that of in-distribution samples (i.e., support, query data). Our approach is simple to implement, agnostic to feature extractors, lightweight without any additional cost for pre-training, and applicable to both inductive and transductive settings. Extensive experiments on various standard benchmarks demonstrate that the proposed method consistently improves the performance of pretrained networks with different architectures."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Snowflake", "Title": "Scaling GNNs to high-dimensional continuous control via parameter freezing", "Abstract": "Recent research has shown that graph neural networks (GNNs) can learn policies for locomotion control that are as effective as a typical multi-layer perceptron (MLP), with superior transfer and multi-task performance. However, results have so far been limited to training on small agents, with the performance of GNNs deteriorating rapidly as the number of sensors and actuators grows. A key motivation for the use of GNNs in the supervised learning setting is their applicability to large graphs, but this benefit has not yet been realised for locomotion control. We show that poor scaling in GNNs is a result of increasingly unstable policy updates, caused by overfitting in parts of the network during training. To combat this, we introduce Snowflake, a GNN training method for high-dimensional continuous control that freezes parameters in selected parts of the network. Snowflake significantly boosts the performance of GNNs for locomotion control on large agents, now matching the performance of MLPs while offering superior transfer properties."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VAST", "Title": "Value Function Factorization with Variable Agent Sub-Teams", "Abstract": "Value function factorization (VFF) is a popular approach to cooperative multi-agent reinforcement learning in order to learn local value functions from global rewards. However, state-of-the-art VFF is limited to a handful of agents in most domains. We hypothesize that this is due to the flat factorization scheme, where the VFF operator becomes a performance bottleneck with an increasing number of agents. Therefore, we propose VFF with variable agent sub-teams (VAST). VAST approximates a factorization for sub-teams which can be defined in an arbitrary way and vary over time, e.g., to adapt to different situations. The sub-team values are then linearly decomposed for all sub-team members. Thus, VAST can learn on a more focused and compact input representation of the original VFF operator. We evaluate VAST in three multi-agent domains and show that VAST can significantly outperform state-of-the-art VFF, when the number of agents is sufficiently large."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DiBS", "Title": "Differentiable Bayesian Structure Learning", "Abstract": "Bayesian structure learning allows inferring Bayesian network structure from data while reasoning about the epistemic uncertainty---a key element towards enabling active causal discovery and designing interventions in real world systems. In this work, we propose a general, fully differentiable framework for Bayesian structure learning (DiBS) that operates in the continuous space of a latent probabilistic graph representation. Contrary to existing work, DiBS is agnostic to the form of the local conditional distributions and allows for joint posterior inference of both the graph structure and the conditional distribution parameters. This makes our formulation directly applicable to posterior inference of nonstandard Bayesian network models, e.g., with nonlinear dependencies encoded by neural networks. Using DiBS, we devise an efficient, general purpose variational inference method for approximating distributions over structural models. In evaluations on simulated and real-world data, our method significantly outperforms related approaches to joint posterior inference."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Residual2Vec", "Title": "Debiasing graph embedding with random graphs", "Abstract": "Graph embedding maps a graph into a convenient vector-space representation for graph analysis and machine learning applications. Many graph embedding methods hinge on a sampling of context nodes based on random walks. However, random walks can be a biased sampler due to the structural properties of graphs. Most notably, random walks are biased by the degree of each node, where a node is sampled proportionally to its degree. The implication of such biases has not been clear, particularly in the context of graph representation learning. Here, we investigate the impact of the random walks' bias on graph embedding and propose residual2vec, a general graph embedding method that can debias various structural biases in graphs by using random graphs. We demonstrate that this debiasing not only improves link prediction and clustering performance but also allows us to explicitly model salient structural properties in graph embedding."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Benign Overfitting in Multiclass Classification", "Title": "All Roads Lead to Interpolation", "Abstract": "The growing literature on \"benign overfitting\" in overparameterized models has been mostly restricted to regression or binary classification settings; however, most success stories of modern machine learning have been recorded in multiclass settings. Motivated by this discrepancy, we study benign overfitting in multiclass linear classification. Specifically, we consider the following popular training algorithms on separable data: (i) empirical risk minimization (ERM) with cross-entropy loss, which converges to the multiclass support vector machine (SVM) solution; (ii) ERM with least-squares loss, which converges to the min-norm interpolating (MNI) solution; and, (iii) the one-vs-all SVM classifier. Our first key finding is that under a simple sufficient condition, all three algorithms lead to classifiers that interpolate the training data and have equal accuracy. When the data is generated from Gaussian mixtures or a multinomial logistic model, this condition holds under high enough effective overparameterization. Second, we derive novel error bounds on the accuracy of the MNI classifier, thereby showing that all three training algorithms lead to benign overfitting under sufficient overparameterization. Ultimately, our analysis shows that good generalization is possible for SVM solutions beyond the realm in which typical margin-based bounds apply."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VATT", "Title": "Transformers for Multimodal Self-Supervised Learning from Raw Video, Audio and Text", "Abstract": "We present a framework for learning multimodal representations from unlabeled data using convolution-free Transformer architectures. Specifically, our Video-Audio-Text Transformer (VATT) takes raw signals as inputs and extracts multimodal representations that are rich enough to benefit a variety of downstream tasks. We train VATT end-to-end from scratch using multimodal contrastive losses and evaluate its performance by the downstream tasks of video action recognition, audio event classification, image classification, and text-to-video retrieval. Furthermore, we study a modality-agnostic single-backbone Transformer by sharing weights among the three modalities. We show that the convolution-free VATT outperforms state-of-the-art ConvNet-based architectures in the downstream tasks. Especially, VATT's vision Transformer achieves the top-1 accuracy of 82.1% on Kinetics-400, 83.6% on Kinetics-600, 72.7% on Kinetics-700, and 41.1% on Moments in Time, new records while avoiding supervised pre-training. Transferring to image classification leads to 78.7% top-1 accuracy on ImageNet compared to 64.7% by training the same Transformer from scratch, showing the generalizability of our model despite the domain gap between videos and images. VATT's audio Transformer also sets a new record on waveform-based audio event recognition by achieving the mAP of 39.4% on AudioSet without any supervised pre-training."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MLP-Mixer", "Title": "An all-MLP Architecture for Vision", "Abstract": "Convolutional Neural Networks (CNNs) are the go-to model for computer vision. Recently, attention-based networks, such as the Vision Transformer, have also become popular. In this paper we show that while convolutions and attention are both sufficient for good performance, neither of them are necessary. We present MLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs). MLP-Mixer contains two types of layers: one with MLPs applied independently to image patches (i.e. \"mixing\" the per-location features), and one with MLPs applied across patches (i.e. \"mixing\" spatial information). When trained on large datasets, or with modern regularization schemes, MLP-Mixer attains competitive scores on image classification benchmarks, with pre-training and inference cost comparable to state-of-the-art models. We hope that these results spark further research beyond the realms of well established CNNs and Transformers."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "One Loss for All", "Title": "Deep Hashing with a Single Cosine Similarity based Learning Objective", "Abstract": "A deep hashing model typically has two main learning objectives: to make the learned binary hash codes discriminative and to minimize a quantization error. With further constraints such as bit balance and code orthogonality, it is not uncommon for existing models to employ a large number (>4) of losses. This leads to difficulties in model training and subsequently impedes their effectiveness. In this work, we propose a novel deep hashing model with only $\\textit{a single learning objective}$. Specifically,  we show that maximizing the cosine similarity between the continuous codes and their corresponding $\\textit{binary orthogonal codes}$ can ensure both hash code discriminativeness and quantization error minimization. Further, with this learning objective, code balancing can be achieved by simply using a  Batch Normalization (BN) layer and multi-label classification is also straightforward with label smoothing. The result is a one-loss deep hashing model that removes all the hassles of tuning the weights of various losses. Importantly,  extensive experiments show that our model is highly effective, outperforming the state-of-the-art multi-loss hashing models on three large-scale instance retrieval benchmarks, often by significant margins."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Communication-efficient SGD", "Title": "From Local SGD to One-Shot Averaging", "Abstract": "We consider speeding up stochastic gradient descent (SGD) by parallelizing it across multiple workers. We assume the same data set is shared among $N$ workers, who can take SGD steps and coordinate with a central server. While it is possible to obtain a linear reduction in the variance by averaging all the stochastic gradients at every step, this requires a lot of communication between the workers and the server, which can dramatically reduce the gains from parallelism.The Local SGD method, proposed and analyzed in the earlier literature, suggests machines should make many local steps between such communications. While the initial analysis of Local SGD showed it needs $\\Omega ( \\sqrt{T} )$ communications for $T$ local gradient steps in order for the error to scale proportionately to $1/(NT)$, this has been successively improved in a string of papers, with the state of the art requiring  $\\Omega \\left( N \\left( \\mbox{ poly} (\\log T) \\right) \\right)$ communications. In this paper, we suggest a Local SGD scheme that communicates less overall by communicating less frequently as the number of iterations grows.  Our analysis shows that this can achieve an error that scales as $1/(NT)$ with a number of communications that is completely independent of $T$. In particular, we show that $\\Omega(N)$ communications are sufficient. Empirical evidence suggests this bound is close to tight as we further show that $\\sqrt{N}$ or $N^{3/4}$ communications fail to achieve linear speed-up in simulations. Moreover, we show that under mild assumptions, the main of which is twice differentiability on any neighborhood of the optimal solution, one-shot averaging which only uses a single round of communication can also achieve the optimal convergence rate asymptotically."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Stochastic Online Linear Regression", "Title": "the Forward Algorithm to Replace Ridge", "Abstract": "We consider the problem of online linear regression in the stochastic setting. We derive high probability regret bounds for online $\\textit{ridge}$ regression and the $\\textit{forward}$ algorithm. This enables us to compare online regression algorithms more accurately and eliminate assumptions of bounded observations and predictions. Our study advocates for the use of the forward algorithm in lieu of ridge due to its enhanced bounds and robustness to the regularization parameter. Moreover, we explain how to integrate it in algorithms involving linear function approximation to remove a boundedness assumption without deteriorating theoretical bounds. We showcase this modification in linear bandit settings where it yields improved regret bounds. Last, we provide numerical experiments to illustrate our results and endorse our intuitions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dr Jekyll & Mr Hyde", "Title": "the strange case of off-policy policy updates", "Abstract": "The policy gradient theorem states that the policy should only be updated in states that are visited by the current policy, which leads to insufficient planning in the off-policy states, and thus to convergence to suboptimal policies. We tackle this planning issue by extending the policy gradient theory to policy updates with respect to any state density. Under these generalized policy updates, we show convergence to optimality under a necessary and sufficient condition on the updates’ state densities, and thereby solve the aforementioned planning issue. We also prove asymptotic convergence rates that significantly improve those in the policy gradient literature. To implement the principles prescribed by our theory, we propose an agent, Dr Jekyll & Mr Hyde (J&H), with a double personality: Dr Jekyll purely exploits while Mr Hyde purely explores. J&H’s independent policies allow to record two separate replay buffers: one on-policy (Dr Jekyll’s) and one off-policy (Mr Hyde’s), and therefore to update J&H’s models with a mixture of on-policy and off-policy updates. More than an algorithm, J&H defines principles for actor-critic algorithms to satisfy the requirements we identify in our analysis. We extensively test on finite MDPs where J&H demonstrates a superior ability to recover from converging to a suboptimal policy without impairing its speed of convergence. We also implement a deep version of the algorithm and test it on a simple problem where it shows promising results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "VidLanKD", "Title": "Improving Language Understanding via Video-Distilled Knowledge Transfer", "Abstract": "Since visual perception can give rich information beyond text descriptions for world understanding, there has been increasing interest in leveraging visual grounding for language learning. Recently, vokenization (Tan and Bansal, 2020) has attracted attention by using the predictions of a text-to-image retrieval model as labels for language model supervision. Despite its success, the method suffers from approximation error of using finite image labels and the lack of vocabulary diversity of a small image-text dataset. To overcome these limitations, we present VidLanKD, a video-language knowledge distillation method for improving language understanding. We train a multi-modal teacher model on a video-text dataset, and then transfer its knowledge to a student language model with a text dataset. To avoid approximation error, we propose to use different knowledge distillation objectives. In addition, the use of a large-scale video-text dataset helps learn diverse and richer vocabularies. In our experiments, VidLanKD achieves consistent improvements over text-only language models and vokenization models, on several downstream language understanding tasks including GLUE, SQuAD, and SWAG. We also demonstrate the improved world knowledge, physical reasoning, and temporal reasoning capabilities of our model by evaluating on the GLUE-diagnostics, PIQA, and TRACIE datasets. Lastly, we present comprehensive ablation studies as well as visualizations of the learned text-to-video grounding results of our teacher and student language models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Detecting Individual Decision-Making Style", "Title": "Exploring Behavioral Stylometry in Chess", "Abstract": "The advent of machine learning models that surpass human decision-making ability in complex domains has initiated a movement towards building AI systems that interact with humans. Many building blocks are essential for this activity, with a central one being the algorithmic characterization of human behavior. While much of the existing work focuses on aggregate human behavior, an important long-range goal is to develop behavioral models that specialize to individual people and can differentiate among them.To formalize this process, we study the problem of behavioral stylometry, in which the task is to identify a decision-maker from their decisions alone. We present a transformer-based approach to behavioral stylometry in the context of chess, where one attempts to identify the player who played a set of games. Our method operates in a few-shot classification framework, and can correctly identify a player from among thousands of candidate players with 98% accuracy given only 100 labeled games. Even when trained on amateur play, our method generalises to out-of-distribution samples of Grandmaster players, despite the dramatic differences between amateur and world-class players. Finally, we consider more broadly what our resulting embeddings reveal about human style in chess, as well as the potential ethical implications of powerful methods for identifying individuals from behavioral data."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AutoGEL", "Title": "An Automated Graph Neural Network with Explicit Link Information", "Abstract": "Recently, Graph Neural Networks (GNNs) have gained popularity in a variety of real-world scenarios. Despite the great success, the architecture design of GNNs heavily relies on manual labor. Thus, automated graph neural network (AutoGNN) has attracted interest and attention from the research community, which makes significant performance improvements in recent years. However, existing AutoGNN works mainly adopt an implicit way to model and leverage the link information in the graphs, which is not well regularized to the link prediction task on graphs, and limits the performance of AutoGNN for other graph tasks. In this paper, we present a novel AutoGNN work that explicitly models the link information, abbreviated to AutoGEL. In such a way, AutoGEL can handle the link prediction task and improve the performance of AutoGNNs on the node classification and graph classification task. Moreover, AutoGEL proposes a novel search space containing various design dimensions at both intra-layer and inter-layer designs and adopts a more robust differentiable search algorithm to further improve efficiency and effectiveness. Experimental results on benchmark data sets demonstrate the superiority of AutoGEL on several tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RL for Latent MDPs", "Title": "Regret Guarantees and a Lower Bound", "Abstract": "In this work, we consider the regret minimization problem for reinforcement learning in latent Markov Decision Processes (LMDP). In an LMDP, an MDP is randomly drawn from a set of $M$ possible MDPs at the beginning of the interaction, but the identity of the chosen MDP is not revealed to the agent. We first show that a general instance of LMDPs requires at least $\\Omega((SA)^M)$ episodes to even approximate the optimal policy. Then, we consider sufficient assumptions under which learning good policies requires polynomial number of episodes. We show that the key link is a notion of separation between the MDP system dynamics. With sufficient separation, we provide an efficient algorithm with local guarantee, {\\it i.e.,} providing a sublinear regret guarantee when we are given a good initialization. Finally, if we are given standard statistical sufficiency assumptions common in the Predictive State Representation (PSR) literature (e.g., \\cite{boots2011online}) and a reachability assumption, we show that the need for initialization can be removed."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Structured in Space, Randomized in Time", "Title": "Leveraging Dropout in RNNs for Efficient Training", "Abstract": "Recurrent Neural Networks (RNNs), more specifically their Long Short-Term Memory (LSTM) variants, have been widely used as a deep learning tool for tackling sequence-based learning tasks in text and speech. Training of such LSTM applications is computationally intensive due to the recurrent nature of hidden state computation that repeats for each time step. While sparsity in Deep Neural Nets has been widely seen as an opportunity for reducing computation time in both training and inference phases, the usage of non-ReLU activation in LSTM RNNs renders the opportunities for such dynamic sparsity associated with neuron activation and gradient values to be limited or non-existent. In this work, we identify dropout induced sparsity for LSTMs as a suitable mode of computation reduction. Dropout is a widely used regularization mechanism, which randomly drops computed neuron values during each iteration of training. We propose to structure dropout patterns, by dropping out the same set of physical neurons within a batch, resulting in column (row) level hidden state sparsity, which are well amenable to computation reduction at run-time in general-purpose SIMD hardware as well as systolic arrays. We provide a detailed analysis of how the dropout-induced sparsity propagates through the different stages of network training and how it can be leveraged in each stage. More importantly, our proposed approach works as a direct replacement for existing dropout-based application settings. We conduct our experiments for three representative NLP tasks: language modelling on the PTB dataset, OpenNMT based machine translation using the IWSLT De-En and En-Vi datasets, and named entity recognition sequence labelling using the CoNLL-2003 shared task. We demonstrate that our proposed approach can be used to translate dropout-based computation reduction into reduced training time, with improvement ranging from 1.23$\\times$ to 1.64$\\times$, without sacrificing the target metric."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CHIP", "Title": "CHannel Independence-based Pruning for Compact Neural Networks", "Abstract": "Filter pruning has been widely used for neural network compression because of its enabled practical acceleration. To date, most of the existing filter pruning works explore the importance of filters via using intra-channel information. In this paper, starting from an inter-channel perspective, we propose to perform efficient filter pruning using Channel Independence, a metric that measures the correlations among different feature maps. The less independent feature map is interpreted as containing less useful information$/$knowledge, and hence its corresponding filter can be pruned without affecting model capacity. We systematically investigate the quantification metric, measuring scheme and sensitiveness$/$reliability of channel independence in the context of filter pruning. Our evaluation results for different models on various datasets show the superior performance of our approach. Notably, on CIFAR-10 dataset our solution can bring $0.75\\%$ and $0.94\\%$ accuracy increase over baseline ResNet-56 and ResNet-110 models, respectively, and meanwhile the model size and FLOPs are reduced by  $42.8\\%$ and  $47.4\\%$ (for ResNet-56) and $48.3\\%$ and $52.1\\%$ (for ResNet-110), respectively. On ImageNet dataset, our approach can achieve $40.8\\%$ and $44.8\\%$ storage and computation reductions, respectively, with $0.15\\%$ accuracy increase over the baseline ResNet-50 model. The code is available at https://github.com/Eclipsess/CHIP_NeurIPS2021."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unsupervised Representation Transfer for Small Networks", "Title": "I Believe I Can Distill On-the-Fly", "Abstract": "A current remarkable improvement of unsupervised visual representation learning is based on heavy networks with large-batch training. While recent methods have greatly reduced the gap between supervised and unsupervised performance of deep models such as ResNet-50, this development has been relatively limited for small models. In this work, we propose a novel unsupervised learning framework for small networks that combines deep self-supervised representation learning and knowledge distillation within one-phase training. In particular, a teacher model is trained to produce consistent cluster assignments between different views of the same image. Simultaneously, a student model is encouraged to mimic the prediction of on-the-fly self-supervised teacher. For effective knowledge transfer, we adopt the idea of domain classifier so that student training is guided by discriminative features invariant to the representational space shift between teacher and student. We also introduce a network driven multi-view generation paradigm to capture rich feature information contained in the network itself. Extensive experiments show that our student models surpass state-of-the-art offline distilled networks even from stronger self-supervised teachers as well as top-performing self-supervised models. Notably, our ResNet-18, trained with ResNet-50 teacher, achieves 68.3% ImageNet Top-1 accuracy on frozen feature linear evaluation, which is only 1.5% below the supervised baseline."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rot-Pro", "Title": "Modeling Transitivity by Projection in Knowledge Graph Embedding", "Abstract": "Knowledge graph embedding models learn the representations of entities and relations in the knowledge graphs for predicting missing links (relations) between entities. Their effectiveness are deeply affected by the ability of modeling and inferring different relation patterns such as symmetry, asymmetry, inversion, composition and transitivity. Although existing models are already able to model many of these relations patterns, transitivity, a very common relation pattern, is still not been fully supported. In this paper, we first theoretically show that the transitive relations can be modeled with projections. We then propose the Rot-Pro model which combines the projection and relational rotation together. We prove that Rot-Pro can infer all the above relation patterns. Experimental results show that the proposed Rot-Pro model  effectively learns the transitivity pattern and achieves the state-of-the-art results on the link prediction task in the datasets containing transitive relations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PLUGIn", "Title": "A simple algorithm for inverting generative models with recovery guarantees", "Abstract": "We consider the problem of recovering an unknown latent code vector under a known generative model. For a $d$-layer deep generative network $\\mathcal{G}:\\mathbb{R}^{n_0}\\rightarrow \\mathbb{R}^{n_d}$ with ReLU activation functions, let the observation be $\\mathcal{G}(x)+\\epsilon$ where $\\epsilon$ is noise. We introduce a simple novel algorithm, Partially Linearized Update for Generative Inversion (PLUGIn), to estimate $x$ (and thus $\\mathcal{G}(x)$). We prove that, when weights are Gaussian and layer widths $n_i \\gtrsim 5^i n_0$ (up to log factors), the algorithm converges geometrically to a neighbourhood of $x$ with high probability. Note the inequality on layer widths allows $n_i>n_{i+1}$ when $i\\geq 1$. To our knowledge, this is the first such result for networks with some contractive layers. After a sufficient number of iterations, the estimation errors for both $x$ and $\\mathcal{G}(x)$ are at most in the order of $\\sqrt{4^dn_0/n_d} \\|\\epsilon\\|$. Thus, the algorithm can denoise when the expansion ratio $n_d/n_0$ is large. Numerical experiments on synthetic data and real data are provided to validate our theoretical results and to illustrate that the algorithm can effectively remove artifacts in an image."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Human Performer", "Title": "Learning Generalizable Radiance Fields for Human Performance Rendering", "Abstract": "In this paper, we aim at synthesizing a free-viewpoint video of an arbitrary human performance using sparse multi-view cameras. Recently, several works have addressed this problem by learning person-specific neural radiance fields (NeRF) to capture the appearance of a particular human. In parallel, some work proposed to use pixel-aligned features to generalize radiance fields to arbitrary new scenes and objects. Adopting such generalization approaches to humans, however, is highly challenging due to the heavy occlusions and dynamic articulations of body parts. To tackle this, we propose Neural Human Performer, a novel approach that learns generalizable neural radiance fields based on a parametric human body model for robust performance capture. Specifically, we first introduce a temporal transformer that aggregates tracked visual features based on the skeletal body motion over time. Moreover, a multi-view transformer is proposed to perform cross-attention between the temporally-fused features and the pixel-aligned features at each time step to integrate observations on the fly from multiple views. Experiments on the ZJU-MoCap and AIST datasets show that our method significantly outperforms recent generalizable NeRF methods on unseen identities and poses."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Adaptive Ensemble Q-learning", "Title": "Minimizing Estimation Bias via Error Feedback", "Abstract": "The ensemble method is a promising way to mitigate the overestimation issue in Q-learning, where multiple function approximators are used to estimate the action values. It is known that the estimation bias hinges heavily on the ensemble size (i.e., the number of  Q-function approximators used in the target), and that determining the 'right' ensemble size is highly nontrivial, because of the time-varying nature of the function approximation errors during the learning process. To tackle this challenge, we first derive an upper bound and a lower bound on the  estimation bias, based on which the ensemble size is  adapted to drive the bias to be nearly zero, thereby coping with the impact of the time-varying approximation errors accordingly. Motivated by the theoretic findings, we advocate that the ensemble method can be combined with Model Identification Adaptive Control (MIAC) for effective ensemble size adaptation. Specifically, we devise Adaptive Ensemble Q-learning (AdaEQ), a generalized ensemble method with two key steps: (a) approximation error characterization which serves as the feedback for flexibly controlling the ensemble size, and (b) ensemble size adaptation tailored towards minimizing the estimation bias.   Extensive experiments are carried out to show that AdaEQ can  improve the learning performance than the existing methods for the MuJoCo benchmark."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Domain Adaptation with Invariant Representation Learning", "Title": "What Transformations to Learn?", "Abstract": "Unsupervised domain adaptation, as a prevalent transfer learning setting, spans many real-world applications. With the increasing representational power and applicability of neural networks, state-of-the-art domain adaptation methods make use of deep architectures to map the input features $X$ to a latent representation $Z$ that has the same marginal  distribution across domains. This has been shown to be insufficient for generating optimal representation for classification, and to find conditionally invariant representations, usually strong assumptions are needed. We provide reasoning why when the supports of the source and target data from overlap, any map of $X$ that is fixed across domains may not be suitable for domain adaptation via invariant features. Furthermore, we develop an efficient technique in which  the optimal map from $X$ to $Z$ also takes domain-specific information as input, in addition to the features $X$. By using the property of minimal changes of causal mechanisms across domains, our model also takes into account the domain-specific information to ensure that the latent representation $Z$ does not discard valuable information about $Y$. We demonstrate the efficacy of our method via synthetic and real-world data experiments. The code is available at: \\texttt{https://github.com/DMIRLAB-Group/DSAN}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CSDI", "Title": "Conditional Score-based Diffusion Models for Probabilistic Time Series Imputation", "Abstract": "The imputation of missing values in time series has many applications in healthcare and finance. While autoregressive models are natural candidates for time series imputation, score-based diffusion models have recently outperformed existing counterparts including autoregressive models in many tasks such as image generation and audio synthesis, and would be promising for time series imputation. In this paper, we propose Conditional Score-based Diffusion model (CSDI), a novel time series imputation method that utilizes score-based diffusion models conditioned on observed data. Unlike existing score-based approaches, the conditional diffusion model is explicitly trained for imputation and can exploit correlations between observed values. On healthcare and environmental data, CSDI improves by 40-65% over existing probabilistic imputation methods on popular performance metrics. In addition, deterministic imputation by CSDI reduces the error by 5-20% compared to the state-of-the-art deterministic imputation methods. Furthermore, CSDI can also be applied to time series interpolation and probabilistic forecasting, and is competitive with existing baselines. The code is available at https://github.com/ermongroup/CSDI."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Piper", "Title": "Multidimensional Planner for DNN Parallelization", "Abstract": "The rapid increase in sizes of state-of-the-art DNN models, and consequently the increase in the compute and memory requirements of model training, has led to the development of many execution schemes such as data parallelism, pipeline model parallelism, tensor (intra-layer) model parallelism, and various memory-saving optimizations. However, no prior work has tackled the highly complex problem of optimally partitioning the DNN computation graph across many accelerators while combining all these parallelism modes and optimizations.In this work, we introduce Piper, an efficient optimization algorithm for this problem that is based on a two-level dynamic programming approach. Our two-level approach is driven by the insight that being given tensor-parallelization techniques for individual layers (e.g., Megatron-LM's splits for transformer layers) significantly reduces the search space and makes the global problem tractable, compared to considering tensor-parallel configurations for the entire DNN operator graph."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Local Signal Adaptivity", "Title": "Provable Feature Learning in Neural Networks Beyond Kernels", "Abstract": "Neural networks have been shown to outperform kernel methods in practice (including neural tangent kernels). Most theoretical explanations of this performance gap focus on learning a complex hypothesis class; in some cases, it is unclear whether this hypothesis class captures realistic data. In this work, we propose a related, but alternative, explanation for this performance gap in the image classification setting, based on finding a sparse signal in the presence of noise. Specifically, we prove that, for a simple data distribution with sparse signal amidst high-variance noise, a simple convolutional neural network trained using stochastic gradient descent learns to threshold out the noise and find the signal. On the other hand, the corresponding neural tangent kernel, with a fixed set of predetermined features, is unable to adapt to the signal in this manner. We supplement our theoretical results by demonstrating this phenomenon empirically: in CIFAR-10 and MNIST images with various backgrounds, as the background noise increases in intensity, a CNN's performance stays relatively robust, whereas its corresponding neural tangent kernel sees a notable drop in performance. We therefore propose the \"local signal adaptivity\" (LSA) phenomenon as one explanation for the superiority of neural networks over kernel methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "IA-RED$^2$", "Title": "Interpretability-Aware Redundancy Reduction for Vision Transformers", "Abstract": "The self-attention-based model, transformer, is recently becoming the leading backbone in the field of computer vision. In spite of the impressive success made by transformers in a variety of vision tasks, it still suffers from heavy computation and intensive memory costs. To address this limitation, this paper presents an Interpretability-Aware REDundancy REDuction framework (IA-RED$^2$). We start by observing a large amount of redundant computation, mainly spent on uncorrelated input patches, and then introduce an interpretable module to dynamically and gracefully drop these redundant patches. This novel framework is then extended to a hierarchical structure, where uncorrelated tokens at different stages are gradually removed, resulting in a considerable shrinkage of computational cost. We include extensive experiments on both image and video tasks, where our method could deliver up to 1.4x speed-up for state-of-the-art models like DeiT and TimeSformer, by only sacrificing less than 0.7% accuracy. More importantly, contrary to other acceleration approaches, our method is inherently interpretable with substantial visual evidence, making vision transformer closer to a more human-understandable architecture while being lighter. We demonstrate that the interpretability that naturally emerged in our framework can outperform the raw attention learned by the original visual transformer, as well as those generated by off-the-shelf interpretation methods, with both qualitative and quantitative results. Project Page: http://people.csail.mit.edu/bpan/ia-red/."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Choose a Transformer", "Title": "Fourier or Galerkin", "Abstract": "In this paper, we apply the self-attention from the state-of-the-art Transformer in Attention Is All You Need for the first time to a data-driven operator learning problem related to partial differential equations. An effort is put together to explain the heuristics of, and to improve the efficacy of the attention mechanism. By employing the operator approximation theory in Hilbert spaces, it is demonstrated for the first time that the softmax normalization in the scaled dot-product attention is sufficient but not necessary. Without softmax, the approximation capacity of a linearized Transformer variant can be proved to be comparable to a Petrov-Galerkin projection layer-wise, and the estimate is independent with respect to the sequence length. A new layer normalization scheme mimicking the Petrov-Galerkin projection is proposed to allow a scaling to propagate through attention layers, which helps the model achieve remarkable accuracy in operator learning tasks with unnormalized data. Finally, we present three operator learning experiments, including the viscid Burgers' equation, an interface Darcy flow, and an inverse interface coefficient identification problem. The newly proposed simple attention-based operator learner, Galerkin Transformer, shows significant improvements in both training cost and evaluation accuracy over its softmax-normalized counterparts."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dual Adaptivity", "Title": "A Universal Algorithm for Minimizing the Adaptive Regret of Convex Functions", "Abstract": "To deal with changing environments, a new performance measure—adaptive regret, defined as the maximum static regret over any interval, was proposed in online learning. Under the setting of online convex optimization, several algorithms have been successfully developed to minimize the adaptive regret. However, existing algorithms lack universality in the sense that they can only handle one type of convex functions and need apriori knowledge of parameters. By contrast, there exist universal algorithms, such as MetaGrad, that attain optimal static regret for multiple types of convex functions simultaneously. Along this line of research, this paper presents the first universal algorithm for minimizing the adaptive regret of convex functions. Specifically, we borrow the idea of maintaining multiple learning rates in MetaGrad to handle the uncertainty of functions, and utilize the technique of sleeping experts to capture changing environments. In this way, our algorithm automatically adapts to the property of functions (convex, exponentially concave, or strongly convex), as well as the nature of environments (stationary or changing). As a by product, it also allows the type of functions to switch between rounds."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Hard Optimization Problems", "Title": "A Data Generation Perspective", "Abstract": "Optimization problems are ubiquitous in our societies and are present in almost every segment of the economy. Most of these optimization problems are NP-hard and computationally demanding, often requiring approximate solutions for large-scale instances. Machine learning frameworks that learn to approximate solutions to such hard optimization problems are a potentially promising avenue to address these difficulties, particularly when many closely related problem instances must be solved repeatedly. Supervised learning frameworks can train a model using the outputs of pre-solved instances. However, when the outputs are themselves approximations, when the optimization problem has symmetric solutions, and/or when the solver uses randomization, solutions to closely related instances may exhibit large differences and the learning task can become inherently more difficult. This paper demonstrates this critical challenge, connects the volatility of the training data to the ability of a model to approximate it, and proposes a method for producing (exact or approximate) solutions to optimization problems that are more amenable to supervised learning tasks.  The effectiveness of the method is tested on hard non-linear nonconvex and discrete combinatorial problems."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Canonical Capsules", "Title": "Self-Supervised Capsules in Canonical Pose", "Abstract": "We propose a self-supervised capsule architecture for 3D point clouds. We compute capsule decompositions of objects through permutation-equivariant attention, and self-supervise the process by training with pairs of randomly rotated objects. Our key idea is to aggregate the attention masks into semantic keypoints, and use these to supervise a decomposition that satisfies the capsule invariance/equivariance properties. This not only enables the training of a semantically consistent decomposition, but also allows us to learn a canonicalization operation that enables object-centric reasoning. To train our neural network we require neither classification labels nor manually-aligned training datasets. Yet, by learning an object-centric representation in a self-supervised manner, our method outperforms the state-of-the-art on 3D point cloud reconstruction, canonicalization, and unsupervised classification."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scallop", "Title": "From Probabilistic Deductive Databases to Scalable Differentiable Reasoning", "Abstract": "Deep learning and symbolic reasoning are complementary techniques for an intelligent system. However, principled combinations of these techniques have limited scalability, rendering them ill-suited for real-world applications. We propose Scallop, a system that builds upon probabilistic deductive databases, to bridge this gap. The key insight underlying Scallop is a provenance framework that introduces a tunable parameter to specify the level of reasoning granularity. Scallop thereby i) generalizes exact probabilistic reasoning, ii) asymptotically reduces computational cost, and iii) provides relative accuracy guarantees. On a suite of tasks that involve mathematical and logical reasoning, Scallop scales significantly better without sacrificing accuracy compared to DeepProbLog, a principled neural logic programming approach. We also create and evaluate on a real-world Visual Question Answering (VQA) benchmark that requires multi-hop reasoning. Scallop outperforms two VQA-tailored models, a Neural Module Networks based and a transformer based model, by 12.42% and 21.66% respectively."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NovelD", "Title": "A Simple yet Effective Exploration Criterion", "Abstract": "Efficient exploration under sparse rewards remains a key challenge in deep reinforcement learning. Previous exploration methods (e.g., RND) have achieved strong results in multiple hard tasks. However, if there are multiple novel areas to explore, these methods often focus quickly on one without sufficiently trying others (like a depth-wise first search manner). In some scenarios (e.g., four corridor environment in Sec 4.2), we observe they explore in one corridor for long and fail to cover all the states. On the other hand, in theoretical RL, with optimistic initialization and the inverse square root of visitation count as a bonus, it won't suffer from this and explores different novel regions alternatively (like a breadth-first search manner). In this paper, inspired by this, we propose a simple but effective criterion called NovelD by weighting every novel area approximately equally. Our algorithm is very simple but yet shows comparable performance or even outperforms multiple SOTA exploration methods in many hard exploration tasks. Specifically, NovelD solves all the static procedurally-generated tasks in Mini-Grid with just 120M environment steps, without any curriculum learning. In comparison, the previous SOTA only solves 50% of them. NovelD also achieves SOTA on multiple tasks in NetHack, a rogue-like game that contains more challenging procedurally-generated environments. In multiple Atari games (e.g., MonteZuma's Revenge, Venture, Gravitar), NovelD outperforms RND. We analyze NovelD thoroughly in MiniGrid and found that empirically it helps the agent explore the environment more uniformly with a focus on exploring beyond the boundary."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Closing the Gap", "Title": "Tighter Analysis of Alternating Stochastic Gradient Methods for Bilevel Problems", "Abstract": "Stochastic nested optimization, including stochastic compositional, min-max, and bilevel optimization, is gaining popularity in many machine learning applications. While the three problems share a nested structure, existing works often treat them separately, thus developing problem-specific algorithms and analyses. Among various exciting developments, simple SGD-type updates (potentially on multiple variables) are still prevalent in solving this class of nested problems, but they are believed to have a slower convergence rate than non-nested problems. This paper unifies several SGD-type updates for stochastic nested problems into a single SGD approach that we term ALternating Stochastic gradient dEscenT (ALSET) method. By leveraging the hidden smoothness of the problem, this paper presents a tighter analysis of ALSET for stochastic nested problems. Under the new analysis, to achieve an $\\epsilon$-stationary point of the nested problem, it requires ${\\cal O}(\\epsilon^{-2})$ samples in total. Under certain regularity conditions, applying our results to stochastic compositional, min-max, and reinforcement learning problems either improves or matches the best-known sample complexity in the respective cases. Our results explain why simple SGD-type algorithms in stochastic nested problems all work very well in practice without the need for further modifications."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Reusing Combinatorial Structure", "Title": "Faster Iterative Projections over Submodular Base Polytopes", "Abstract": "Optimization algorithms such as projected Newton's method, FISTA,  mirror descent and its variants enjoy near-optimal regret bounds and convergence rates, but suffer from a computational bottleneck of computing ``projections\" in potentially each iteration (e.g., $O(T^{1/2})$ regret of online mirror descent). On the other hand, conditional gradient variants solve a linear optimization in each iteration, but result in suboptimal rates (e.g., $O(T^{3/4})$ regret of online Frank-Wolfe). Motivated by this trade-off in runtime v/s convergence rates, we consider iterative projections of close-by points over widely-prevalent submodular base polytopes $B(f)$. We develop a toolkit to speed up the computation of projections using both discrete and continuous perspectives. We subsequently adapt the away-step Frank-Wolfe algorithm to use this information and enable early termination. For the special case of cardinality based submodular polytopes, we improve the runtime of computing certain Bregman projections by a factor of $\\Omega(n/\\log(n))$. Our theoretical results show orders of magnitude reduction in runtime in preliminary computational experiments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Why Generalization in RL is Difficult", "Title": "Epistemic POMDPs and Implicit Partial Observability", "Abstract": "Generalization is a central challenge for the deployment of reinforcement learning (RL) systems in the real world. In this paper, we show that the sequential structure of the RL problem necessitates new approaches to generalization beyond the well-studied techniques used in supervised learning. While supervised learning methods can generalize effectively without explicitly accounting for epistemic uncertainty, we describe why appropriate uncertainty handling can actually be essential in RL. We show that generalization to unseen test conditions from a limited number of training conditions induces a kind of implicit partial observability, effectively turning even fully-observed MDPs into POMDPs. Informed by this observation, we recast the problem of generalization in RL as solving the induced partially observed Markov decision process, which we call the epistemic POMDP. We demonstrate the failure modes of algorithms that do not appropriately handle this partial observability, and suggest a simple ensemble-based technique for approximately solving the partially observed problem. Empirically, we demonstrate that our simple algorithm derived from the epistemic POMDP achieves significant gains in generalization over current methods on the Procgen benchmark suite."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Best of Both Worlds", "Title": "Practical and Theoretically Optimal Submodular Maximization in Parallel", "Abstract": "For the problem of maximizing a monotone, submodular function with respect to a cardinality constraint $k$ on a ground set of size $n$, we provide an algorithm that achieves the state-of-the-art in both its empirical performance and its theoretical properties, in terms of adaptive complexity, query complexity, and approximation ratio; that is, it obtains, with high probability, query complexity of $O(n)$ in expectation, adaptivity of $O(\\log(n))$, and approximation ratio of nearly $1-1/e$. The main algorithm is assembled from two components which may be of independent interest. The first component of our algorithm, LINEARSEQ, is useful as a preprocessing algorithm to improve the query complexity of many algorithms. Moreover, a variant of LINEARSEQ is shown to have adaptive complexity of $O( \\log (n / k) )$ which is smaller than that of any previous algorithm in the literature. The second component is a parallelizable thresholding procedure THRESHOLDSEQ for adding elements with gain above a constant threshold. Finally, we demonstrate that our main algorithm empirically outperforms, in terms of runtime, adaptive rounds, total queries, and objective values, the previous state-of-the-art algorithm FAST in a comprehensive evaluation with six submodular objective functions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SyMetric", "Title": "Measuring the Quality of Learnt Hamiltonian Dynamics Inferred from Vision", "Abstract": "A recently proposed class of models attempts to learn latent dynamics from high-dimensional observations, like images, using priors informed by Hamiltonian mechanics. While these models have important potential applications in areas like robotics or autonomous driving, there is currently no good way to evaluate their performance: existing methods primarily rely on image reconstruction quality, which does not always reflect the quality of the learnt latent dynamics. In this work, we empirically highlight the problems with the existing measures and develop a set of new measures, including a binary indicator of whether the underlying Hamiltonian dynamics have been faithfully captured, which we call Symplecticity Metric or SyMetric. Our measures take advantage of the known properties of Hamiltonian dynamics and are more discriminative of the model's ability to capture the underlying dynamics than reconstruction error. Using SyMetric, we identify a set of architectural choices that significantly improve the performance of a previously proposed model for inferring latent dynamics from pixels, the Hamiltonian Generative Network (HGN). Unlike the original HGN, the new SyMetric is able to discover an interpretable phase space with physically meaningful latents on some datasets. Furthermore, it is stable for significantly longer rollouts on a diverse range of 13 datasets,  producing rollouts of essentially infinite length both forward and backwards in time with no degradation in quality on a subset of the datasets."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Barrier Certificates", "Title": "Towards Safe Reinforcement Learning with Zero Training-time Violations", "Abstract": "Training-time safety violations have been a major concern when we deploy reinforcement learning algorithms in the real world.This paper explores the possibility of safe RL algorithms with zero training-time safety violations in the challenging setting where we are only given a safe but trivial-reward initial policy without any prior knowledge of the dynamics and additional offline data.We propose an algorithm, Co-trained Barrier Certificate for Safe RL (CRABS), which iteratively learns barrier certificates, dynamics models, and policies. The barrier certificates are learned via adversarial training and ensure the policy's safety assuming calibrated learned dynamics. We also add a regularization term to encourage larger certified regions to enable better exploration. Empirical simulations show that zero safety violations are already challenging for a suite of simple environments with only 2-4 dimensional state space, especially if high-reward policies have to visit regions near the safety boundary.  Prior methods require hundreds of violations to achieve decent rewards on these tasks,  whereas our proposed algorithms incur zero violations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Noether’s Learning Dynamics", "Title": "Role of Symmetry Breaking in Neural Networks", "Abstract": "In nature, symmetry governs regularities, while symmetry breaking brings texture. In artificial neural networks, symmetry has been a central design principle to efficiently capture regularities in the world, but the role of symmetry breaking is not well understood. Here, we develop a theoretical framework to study the \"geometry of learning dynamics\" in neural networks, and reveal a key mechanism of explicit symmetry breaking behind the efficiency and stability of modern neural networks. To build this understanding, we model the discrete learning dynamics of gradient descent using a continuous-time Lagrangian formulation, in which the learning rule corresponds to the kinetic energy and the loss function corresponds to the potential energy. Then, we identify \"kinetic symmetry breaking\" (KSB), the condition when the kinetic energy explicitly breaks the symmetry of the potential function. We generalize Noether’s theorem known in physics to take into account KSB and derive the resulting motion of the Noether charge: \"Noether's Learning Dynamics\" (NLD). Finally, we apply NLD to neural networks with normalization layers and reveal how KSB introduces a mechanism of implicit adaptive optimization, establishing an analogy between learning dynamics induced by normalization layers and RMSProp. Overall, through the lens of Lagrangian mechanics, we have established a theoretical foundation to discover geometric design principles for the learning dynamics of neural networks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Smoothness Matrices Beat Smoothness Constants", "Title": "Better  Communication Compression Techniques for Distributed Optimization", "Abstract": "Large scale distributed optimization has become the default tool for the training of supervised machine learning models with a large number of parameters and training data. Recent advancements in the field provide several mechanisms for speeding up the training, including {\\em compressed communication}, {\\em variance reduction} and {\\em acceleration}. However, none of these methods is capable of exploiting the inherently rich data-dependent smoothness structure of the local losses beyond standard smoothness constants. In this paper, we argue that when training supervised models,  {\\em smoothness matrices}---information-rich generalizations of the ubiquitous smoothness constants---can and should be exploited for further dramatic gains, both in theory and practice. In order to further alleviate the communication burden inherent in distributed optimization, we propose a novel communication sparsification strategy that can take full advantage of the smoothness matrices associated with local losses. To showcase the power of this tool, we describe how our sparsification technique can be adapted to three distributed optimization algorithms---DCGD, DIANA and ADIANA---yielding significant savings in terms of communication complexity.  The new methods always outperform the baselines, often dramatically so."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Implicit Deep Adaptive Design", "Title": "Policy-Based Experimental Design without Likelihoods", "Abstract": "We introduce implicit Deep Adaptive Design (iDAD), a new method for performing adaptive experiments in real-time with implicit models. iDAD amortizes the cost of Bayesian optimal experimental design (BOED) by learning a design policy network upfront, which can then be deployed quickly at the time of the experiment. The iDAD network can be trained on any model which simulates differentiable samples, unlike previous design policy work that requires a closed form likelihood and conditionally independent experiments. At deployment, iDAD allows design decisions to be made in milliseconds, in contrast to traditional BOED approaches that require heavy computation during the experiment itself. We illustrate the applicability of iDAD on a number of experiments, and show that it provides a fast and effective mechanism for performing adaptive design with implicit models."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SBO-RNN", "Title": "Reformulating Recurrent Neural Networks via Stochastic Bilevel Optimization", "Abstract": "In this paper we consider the training stability of recurrent neural networks (RNNs) and propose a family of RNNs, namely SBO-RNN, that can be formulated using stochastic bilevel optimization (SBO). With the help of stochastic gradient descent (SGD), we manage to convert the SBO problem into an RNN where the feedforward and backpropagation solve the lower and upper-level optimization for learning hidden states and their hyperparameters, respectively. We prove that under mild conditions there is no vanishing or exploding gradient in training SBO-RNN. Empirically we demonstrate our approach with superior performance on several benchmark datasets, with fewer parameters, less training data, and much faster convergence. Code is available at https://zhang-vislab.github.io."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization Bounds For Meta-Learning", "Title": "An Information-Theoretic Analysis", "Abstract": "We derive a novel information-theoretic analysis of the generalization property of meta-learning algorithms. Concretely, our analysis proposes a generic understanding in both the conventional learning-to-learn framework \\citep{amit2018meta} and the modern model-agnostic meta-learning (MAML) algorithms \\citep{finn2017model}.Moreover, we provide a data-dependent generalization bound for the stochastic variant of MAML, which is \\emph{non-vacuous} for deep few-shot learning. As compared to previous bounds that depend on the square norms of gradients, empirical validations on both simulated data and a well-known few-shot benchmark show that our bound is orders of magnitude tighter in most conditions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "OpenMatch", "Title": "Open-Set Semi-supervised Learning with Open-set Consistency Regularization", "Abstract": "Semi-supervised learning (SSL) is an effective means to leverage unlabeled data to improve a model’s performance. Typical SSL methods like FixMatch assume that labeled and unlabeled data share the same label space. However, in practice, unlabeled data can contain categories unseen in the labeled set, i.e., outliers, which can significantly harm the performance of SSL algorithms.  To address this problem, we propose a novel Open-set Semi-Supervised Learning (OSSL) approach called OpenMatch.Learning representations of inliers while rejecting outliers is essential for the success of OSSL. To this end, OpenMatch unifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers. The OVA-classifier outputs the confidence score of a sample being an inlier, providing a threshold to detect outliers. Another key contribution is an open-set soft-consistency regularization loss, which enhances the smoothness of the OVA-classifier with respect to input transformations and greatly improves outlier detection. \\ours achieves state-of-the-art performance on three datasets, and even outperforms a fully supervised model in detecting outliers unseen in unlabeled data on CIFAR10. The code is available at \\url{https://github.com/VisionLearningGroup/OP_Match}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PatchGame", "Title": "Learning to Signal Mid-level Patches in Referential Games", "Abstract": "We study a referential game (a type of signaling game) where two agents communicate with each other via a discrete bottleneck to achieve a common goal. In our referential game, the goal of the speaker is to compose a message or a symbolic representation of \"important\" image patches, while the task for the listener is to match the speaker's message to a different view of the same image. We show that it is indeed possible for the two agents to develop a communication protocol without explicit or implicit supervision. We further investigate the developed protocol and show the applications in speeding up recent Vision Transformers by using only important patches, and as pre-training for downstream recognition tasks (e.g., classification)."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Unintended Selection", "Title": "Persistent Qualification Rate Disparities and Interventions", "Abstract": "Realistically---and equitably---modeling the dynamics of group-level disparities in machine learning remains an open problem. In particular, we desire models that do not suppose inherent differences between artificial groups of people---but rather endogenize disparities by appeal to unequal initial conditions of insular subpopulations. In this paper, agents each have a real-valued feature $X$ (e.g., credit score) informed by a ``true'' binary label $Y$ representing qualification (e.g., for a loan). Each agent alternately (1) receives a binary classification label $\\hat{Y}$ (e.g., loan approval) from a Bayes-optimal machine learning classifier observing $X$ and (2) may update their qualification $Y$ by imitating successful strategies (e.g., seek a raise) within an isolated group $G$ of agents to which they belong. We consider the disparity of qualification rates $\\Pr(Y=1)$ between different groups and how this disparity changes subject to a sequence of Bayes-optimal classifiers repeatedly retrained on the global population. We model the evolving qualification rates of each subpopulation (group) using the replicator equation, which derives from a class of imitation processes. We show that differences in qualification rates between subpopulations can persist indefinitely for a set of non-trivial equilibrium states due to uniformed classifier deployments, even when groups are identical in all aspects except initial qualification densities. We next simulate the effects of commonly proposed fairness interventions on this dynamical system along with a new feedback control mechanism capable of permanently eliminating group-level qualification rate disparities. We conclude by discussing the limitations of our model and findings and by outlining potential future work."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Morié Attack (MA)", "Title": "A New Potential Risk of Screen Photos", "Abstract": "Images, captured by a camera, play a critical role in training Deep Neural Networks (DNNs). Usually, we assume the images acquired by cameras are consistent with the ones perceived by human eyes. However, due to the different physical mechanisms between human-vision and computer-vision systems, the final perceived images could be very different in some cases, for example shooting on digital monitors. In this paper, we find a special phenomenon in digital image processing, the moiré effect, that could cause unnoticed security threats to DNNs. Based on it, we propose a Moiré Attack (MA) that generates the physical-world moiré pattern adding to the images by mimicking the shooting process of digital devices. Extensive experiments demonstrate that our proposed digital Moiré Attack (MA) is a perfect camouflage for attackers to tamper with DNNs with a high success rate ($100.0\\%$ for untargeted and $97.0\\%$ for targeted attack with the noise budget $\\epsilon=4$), high transferability rate across different models, and high robustness under various defenses. Furthermore, MA owns great stealthiness because the moiré effect is unavoidable due to the camera's inner physical structure, which therefore hardly attracts the awareness of humans. Our code is available at https://github.com/Dantong88/Moire_Attack."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Provable Model-based Nonlinear Bandit and Reinforcement Learning", "Title": "Shelve Optimism, Embrace Virtual Curvature", "Abstract": "This paper studies model-based bandit and reinforcement learning (RL) with nonlinear function approximations. We propose to study convergence to approximate local maxima because we show that global convergence is statistically intractable even for one-layer neural net bandit with a deterministic reward. For both nonlinear bandit and RL, the paper presents a model-based algorithm, Virtual Ascent with Online Model Learner (ViOlin), which provably converges to a local maximum with sample complexity that only depends on the sequential Rademacher complexity of the model class. Our results imply novel global or local regret bounds on several concrete settings such as linear bandit with finite or sparse model class, and two-layer neural net bandit. A key algorithmic insight is that optimism may lead to over-exploration even for two-layer neural net model class. On the other hand, for convergence to local maxima, it suffices to maximize the virtual return if the model can also reasonably predict the gradient and Hessian of the real return."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "You Only Look at One Sequence", "Title": "Rethinking Transformer in Vision through Object Detection", "Abstract": "Can Transformer perform $2\\mathrm{D}$ object- and region-level recognition from a pure sequence-to-sequence perspective with minimal knowledge about the $2\\mathrm{D}$ spatial structure? To answer this question, we present You Only Look at One Sequence (YOLOS), a series of object detection models based on the vanilla Vision Transformer with the fewest possible modifications, region priors, as well as inductive biases of the target task. We find that YOLOS pre-trained on the mid-sized ImageNet-$1k$ dataset only can already achieve quite competitive performance on the challenging COCO object detection benchmark, e.g., YOLOS-Base directly adopted from BERT-Base architecture can obtain $42.0$ box AP on COCO val. We also discuss the impacts as well as limitations of current pre-train schemes and model scaling strategies for Transformer in vision through YOLOS. Code and pre-trained models are available at https://github.com/hustvl/YOLOS."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TöRF", "Title": "Time-of-Flight Radiance Fields for Dynamic Scene View Synthesis", "Abstract": "Neural networks can represent and accurately reconstruct radiance fields for static 3D scenes (e.g., NeRF). Several works extend these to dynamic scenes captured with monocular video, with promising performance. However, the monocular setting is known to be an under-constrained problem, and so methods rely on data-driven priors for reconstructing dynamic content. We replace these priors with measurements from a time-of-flight (ToF) camera, and introduce a neural representation based on an image formation model for continuous-wave ToF cameras. Instead of working with processed depth maps, we model the raw ToF sensor measurements to improve reconstruction quality and avoid issues with low reflectance regions, multi-path interference, and a sensor's limited unambiguous depth range. We show that this approach improves robustness of dynamic scene reconstruction to erroneous calibration and large motions, and discuss the benefits and limitations of integrating RGB+ToF sensors now available on modern smartphones."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Exploration-Exploitation in Multi-Agent Competition", "Title": "Convergence with Bounded Rationality", "Abstract": "The interplay between exploration and exploitation in competitive multi-agent learning is still far from being well understood. Motivated by this, we study smooth Q-learning, a prototypical learning model that explicitly captures the balance between game rewards and exploration costs. We show that Q-learning always converges to the unique quantal-response equilibrium (QRE), the standard solution concept for games under bounded rationality, in weighted zero-sum polymatrix games with heterogeneous learning agents using positive exploration rates. Complementing recent results about convergence in weighted potential games [16,34], we show that fast convergence of Q-learning in competitive settings obtains regardless of the number of agents and without any need for parameter fine-tuning. As showcased by our experiments in network zero-sum games, these theoretical results provide the necessary guarantees for an algorithmic approach to the currently open problem of equilibrium selection in competitive multi-agent settings."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning from Inside", "Title": "Self-driven Siamese Sampling and Reasoning for Video Question Answering", "Abstract": "Recent advances in the video question answering (i.e., VideoQA) task have achieved strong success by following the paradigm of fine-tuning each clip-text pair independently on the pretrained transformer-based model via supervised learning. Intuitively, multiple samples (i.e., clips) should be interdependent to capture similar visual and key semantic information in the same video. To consider the interdependent knowledge between contextual clips into the network inference, we propose a Siamese Sampling and Reasoning (SiaSamRea) approach, which consists of a siamese sampling mechanism to generate sparse and similar clips (i.e., siamese clips) from the same video, and a novel reasoning strategy for integrating the interdependent knowledge between contextual clips into the network. The reasoning strategy contains two modules: (1) siamese knowledge generation to learn the inter-relationship among clips; (2) siamese knowledge reasoning to produce the refined soft label by propagating the weights of inter-relationship to the predicted candidates of all clips. Finally, our SiaSamRea can endow the current multimodal reasoning paradigm with the ability of learning from inside via the guidance of soft labels. Extensive experiments demonstrate our SiaSamRea achieves state-of-the-art performance on five VideoQA benchmarks, e.g., a significant +2.1% gain on MSRVTT-QA, +2.9% on MSVD-QA, +1.0% on ActivityNet-QA, +1.8% on How2QA and +4.3% (action) on TGIF-QA."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "To Beam Or Not To Beam", "Title": "That is a Question of Cooperation for Language GANs", "Abstract": "Due to the discrete nature of words, language GANs require to be optimized from rewards provided by discriminator networks, via reinforcement learning methods. This is a much harder setting than for continuous tasks, which enjoy gradient flows from discriminators to generators, usually leading to dramatic learning instabilities.   However, we claim that this can be solved by making discriminator and generator networks cooperate to produce output sequences during training. These cooperative outputs, inherently built to obtain higher discrimination scores, not only provide denser rewards for training but also form a more compact artificial set for discriminator training, hence improving its accuracy and stability.In this paper, we show that our SelfGAN framework, built on this cooperative principle, outperforms Teacher Forcing and obtains state-of-the-art results on two challenging tasks, Summarization and Question Generation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shapley Residuals", "Title": "Quantifying the limits of the Shapley value for explanations", "Abstract": "Popular feature importance techniques compute additive approximations to nonlinear models by first defining a cooperative game describing the value of different subsets of the model's features, then calculating the resulting game's Shapley values to attribute credit additively between the features. However, the specific modeling settings in which the Shapley values are a poor approximation for the true game have not been well-described. In this paper we utilize an interpretation of Shapley values as the result of an orthogonal projection between vector spaces to calculate a residual representing the kernel component of that projection. We provide an algorithm for computing these residuals, characterize different modeling settings based on the value of the residuals, and demonstrate that they capture information about model predictions that Shapley values cannot. Shapley residuals can thus act as a warning to practitioners against overestimating the degree to which Shapley-value-based explanations give them insight into a model."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "No RL, No Simulation", "Title": "Learning to Navigate without Navigating", "Abstract": "Most prior methods for learning navigation policies require access to simulation environments, as they need online policy interaction and rely on ground-truth maps for rewards. However, building simulators is expensive (requires manual effort for each and every scene) and creates challenges in transferring learned policies to robotic platforms in the real-world, due to the sim-to-real domain gap. In this paper, we pose a simple question: Do we really need active interaction, ground-truth maps or even reinforcement-learning (RL) in order to solve the image-goal navigation task? We propose a self-supervised approach to learn to navigate from only passive videos of roaming. Our approach, No RL, No Simulator (NRNS), is simple and scalable, yet highly effective. NRNS outperforms RL-based formulations by a significant margin. We present NRNS as a strong baseline for any future image-based navigation tasks that use RL or Simulation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analogous to Evolutionary Algorithm", "Title": "Designing a Unified Sequence Model", "Abstract": "Inspired by biological evolution, we explain the rationality of Vision Transformer by analogy with the proven practical Evolutionary Algorithm (EA) and derive that both of them have consistent mathematical representation. Analogous to the dynamic local population in EA, we improve the existing transformer structure and propose a more efficient EAT model, and design task-related heads to deal with different tasks more flexibly. Moreover, we introduce the spatial-filling curve into the current vision transformer to sequence image data into a uniform sequential format. Thus we can design a unified EAT framework to address multi-modal tasks, separating the network architecture from the data format adaptation. Our approach achieves state-of-the-art results on the ImageNet classification task compared with recent vision transformer works while having smaller parameters and greater throughput. We further conduct multi-modal tasks to demonstrate the superiority of the unified EAT, \\eg, Text-Based Image Retrieval, and our approach improves the rank-1 by +3.7 points over the baseline on the CSS dataset."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SurvITE", "Title": "Learning Heterogeneous Treatment Effects from Time-to-Event Data", "Abstract": "We study the problem of inferring heterogeneous treatment effects from time-to-event data. While both the related problems of (i) estimating treatment effects for binary or continuous outcomes and (ii) predicting survival outcomes have been well studied in the recent machine learning literature, their combination -- albeit of high practical relevance -- has received considerably less attention. With the ultimate goal of reliably estimating the effects of treatments on instantaneous risk and survival probabilities, we focus on the problem of learning (discrete-time) treatment-specific conditional hazard functions. We find that unique challenges arise in this context due to a variety of covariate shift issues that go beyond a mere combination of well-studied confounding and censoring biases. We theoretically analyse their effects by adapting recent generalization bounds from domain adaptation and treatment effect estimation to our setting and discuss implications for model design. We use the resulting insights to propose a novel deep learning method for treatment-specific hazard estimation based on balancing representations. We investigate performance across a range of experimental settings and empirically confirm that our method outperforms baselines by addressing covariate shifts from various sources."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Rank Overspecified Robust Matrix Recovery", "Title": "Subgradient Method and Exact Recovery", "Abstract": "We study the robust recovery of a low-rank matrix from sparsely and grossly corrupted Gaussian measurements, with no prior knowledge on the intrinsic rank. We consider the robust matrix factorization approach. We employ a robust $\\ell_1$ loss function and deal with the challenge of the unknown rank by using an overspecified factored representation of the matrix variable. We then solve the associated nonconvex nonsmooth problem using a subgradient method with diminishing stepsizes. We show that under a regularity condition on the sensing matrices and corruption, which we call restricted direction preserving property (RDPP), even with rank overspecified, the subgradient method converges to the exact low-rank solution at a sublinear rate. Moreover, our result is more general in the sense that it automatically speeds up to a linear rate once the factor rank matches the unknown rank. On the other hand, we show that the RDPP condition holds under generic settings, such as Gaussian measurements under independent or adversarial sparse corruptions, where the result could be of independent interest. Both the exact recovery and the convergence rate of the proposed subgradient method are numerically verified in the overspecified regime. Moreover, our experiment further shows that our particular design of diminishing stepsize effectively prevents overfitting for robust recovery under overparameterized models, such as robust matrix sensing and learning robust deep image prior. This regularization effect is worth further investigation."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "PolarStream", "Title": "Streaming Object Detection and Segmentation with Polar Pillars", "Abstract": "Recent works recognized lidars as an inherently streaming data source and showed that the end-to-end latency of lidar perception models can be reduced significantly by operating on wedge-shaped point cloud sectors rather then the full point cloud. However, due to use of cartesian coordinate systems these methods  represent the sectors as rectangular regions, wasting memory and compute. In this work we propose using a polar coordinate system and make two key improvements on this design. First, we increase the spatial context by using multi-scale padding from neighboring sectors: preceding sector from the current scan and/or the following sector from the past scan. Second, we improve the core polar convolutional architecture by introducing feature undistortion and range stratified convolutions. Experimental results on the nuScenes dataset show significant improvements over other streaming based methods. We also achieve comparable results to existing non-streaming methods but with lower latencies."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Representation Costs of Linear Neural Networks", "Title": "Analysis and Design", "Abstract": "For different parameterizations (mappings from parameters to predictors), we study the regularization cost in predictor space induced by $l_2$ regularization on the parameters (weights).  We focus on linear neural networks as parameterizations of linear predictors.  We identify the representation cost of certain sparse linear ConvNets and residual networks.  In order to get a better understanding of how the architecture and parameterization affect the representation cost, we also study the reverse problem, identifying which regularizers on linear predictors (e.g., $l_p$ norms, group norms, the $k$-support-norm, elastic net) can be the representation cost induced by simple $l_2$ regularization, and designing the parameterizations that do so."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MAU", "Title": "A Motion-Aware Unit for Video Prediction and Beyond", "Abstract": "Accurately predicting inter-frame motion information plays a key role in video prediction tasks. In this paper, we propose a Motion-Aware Unit (MAU) to capture reliable inter-frame motion information by broadening the temporal receptive field of the predictive units. The MAU consists of two modules, the attention module and the fusion module. The attention module aims to learn an attention map based on the correlations between the current spatial state and the historical spatial states. Based on the learned attention map, the historical temporal states are aggregated to an augmented motion information (AMI). In this way, the predictive unit can perceive more temporal dynamics from a wider receptive field. Then, the fusion module is utilized to further aggregate the augmented motion information (AMI) and current appearance information (current spatial state) to the final predicted frame. The computation load of MAU is relatively low and the proposed unit can be easily applied to other predictive models. Moreover, an information recalling scheme is employed into the encoders and decoders to help preserve the visual details of the predictions. We evaluate the MAU on both video prediction and early action recognition tasks. Experimental results show that the MAU outperforms the state-of-the-art methods on both tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The staircase property", "Title": "How hierarchical structure can guide deep learning", "Abstract": "This paper identifies a structural property of data distributions that enables deep neural networks to learn hierarchically. We define the ``staircase'' property for functions over the Boolean hypercube, which posits that high-order Fourier coefficients are reachable from lower-order Fourier coefficients along increasing chains. We prove that functions satisfying this  property can be learned in polynomial time using layerwise  stochastic coordinate descent on regular neural networks -- a class of network architectures and initializations that have homogeneity properties. Our analysis shows that for such staircase functions and neural networks, the gradient-based algorithm learns high-level features by greedily combining lower-level features along the depth of the network. We further back our theoretical results with experiments showing that staircase functions are learnable by more standard ResNet architectures with stochastic gradient descent. Both the theoretical and experimental results support the fact that the staircase property has a role to play in understanding the capabilities of gradient-based learning on regular networks, in contrast to general polynomial-size networks that can emulate any Statistical Query or PAC algorithm, as recently shown."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MagNet", "Title": "A Neural Network for Directed Graphs", "Abstract": "The prevalence of graph-based data has spurred the rapid development of graph neural networks (GNNs) and related machine learning algorithms. Yet, despite the many datasets naturally modeled as directed graphs, including citation, website, and traffic networks, the vast majority of this research focuses on undirected graphs. In this paper, we propose MagNet, a GNN for directed graphs based on a complex Hermitian matrix known as the magnetic Laplacian. This matrix encodes undirected geometric structure in the magnitude of its entries and directional information in their phase. A charge parameter attunes spectral information to variation among directed cycles. We apply our network to a variety of directed graph node classification and link prediction tasks showing that MagNet performs well on all tasks and that its performance exceeds all other methods on a  majority of such tasks. The underlying principles of MagNet are such that it can be adapted to other GNN architectures."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GRIN", "Title": "Generative Relation and Intention Network for Multi-agent Trajectory Prediction", "Abstract": "Learning the distribution of future trajectories conditioned on the past is a crucial problem for understanding multi-agent systems. This is challenging because humans make decisions based on complex social relations and personal intents, resulting in highly complex uncertainties over trajectories. To address this problem, we propose a conditional deep generative model that combines advances in graph neural networks. The prior and recognition model encodes two types of latent codes for each agent: an inter-agent latent code to represent social relations and an intra-agent latent code to represent agent intentions. The decoder is carefully devised to leverage the codes in a disentangled way to predict multi-modal future trajectory distribution. Specifically, a graph attention network built upon inter-agent latent code is used to learn continuous pair-wise relations, and an agent's motion is controlled by its latent intents and its observations of all other agents. Through experiments on both synthetic and real-world datasets, we show that our model outperforms previous work in multiple performance metrics. We also show that our model generates realistic multi-modal trajectories."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeuS", "Title": "Learning Neural Implicit Surfaces by Volume Rendering for Multi-view Reconstruction", "Abstract": "We present a novel neural surface reconstruction method, called NeuS, for reconstructing objects and scenes with high fidelity from 2D image inputs. Existing neural surface reconstruction approaches, such as DVR [Niemeyer et al., 2020] and IDR [Yariv et al., 2020], require foreground mask as supervision, easily get trapped in local minima, and therefore struggle with the reconstruction of objects with severe self-occlusion or thin structures. Meanwhile, recent neural methods for novel view synthesis, such as NeRF [Mildenhall et al., 2020] and its variants, use volume rendering to produce a neural scene representation with robustness of optimization, even for highly complex objects. However, extracting high-quality surfaces from this learned implicit representation is difficult because there are not sufficient surface constraints in the representation. In NeuS, we propose to represent a surface as the zero-level set of a signed distance function (SDF) and develop a new volume rendering method to train a neural SDF representation. We observe that the conventional volume rendering method causes inherent geometric errors (i.e. bias) for surface reconstruction, and therefore propose a new formulation that is free of bias in the first order of approximation, thus leading to more accurate surface reconstruction even without the mask supervision. Experiments on the DTU dataset and the BlendedMVS dataset show that NeuS outperforms the state-of-the-arts in high-quality surface reconstruction, especially for objects and scenes with complex structures and self-occlusion."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "UFC-BERT", "Title": "Unifying Multi-Modal Controls for Conditional Image Synthesis", "Abstract": "Conditional image synthesis aims to create an image according to some multi-modal guidance in the forms of textual descriptions, reference images, and image blocks to preserve, as well as their combinations. In this paper, instead of investigating these control signals separately, we propose a new two-stage architecture, UFC-BERT, to unify any number of multi-modal controls. In UFC-BERT, both the diverse control signals and the synthesized image are uniformly represented as a sequence of discrete tokens to be processed by Transformer. Different from existing two-stage autoregressive approaches such as DALL-E and VQGAN, UFC-BERT adopts non-autoregressive generation (NAR) at the second stage to enhance the holistic consistency of the synthesized image, to support preserving specified image blocks, and to improve the synthesis speed. Further, we design a progressive algorithm that iteratively improves the non-autoregressively generated image, with the help of two estimators developed for evaluating the compliance with the controls and evaluating the fidelity of the synthesized image, respectively. Extensive experiments on a newly collected large-scale clothing dataset M2C-Fashion and a facial dataset Multi-Modal CelebA-HQ verify that UFC-BERT can synthesize high-fidelity images that comply with flexible multi-modal controls."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BARTScore", "Title": "Evaluating Generated Text as Text Generation", "Abstract": "A wide variety of NLP applications, such as machine translation, summarization, and dialog, involve text generation. One major challenge for these applications is how to evaluate whether such generated texts are actually fluent, accurate, or effective. In this work, we conceptualize the evaluation of generated text as a text generation problem, modeled using pre-trained sequence-to-sequence models. The general idea is that models trained to convert the generated text to/from a reference output or the source text will achieve higher scores when the generated text is better. We operationalize this idea using BART, an encoder-decoder based pre-trained model, and propose a metric BARTScore with a number of variants that can be flexibly applied in an unsupervised fashion to evaluation of text from different perspectives (e.g. informativeness, fluency, or factuality). BARTScore is conceptually simple and empirically effective. It can outperform existing top-scoring metrics in 16 of 22 test settings, covering evaluation of 16 datasets (e.g., machine translation, text summarization) and 7 different perspectives (e.g., informativeness, factuality). Code to calculate BARTScore is available at https://github.com/neulab/BARTScore, and we have released an interactive leaderboard for meta-evaluation at http://explainaboard.nlpedia.ai/leaderboard/task-meval/ on the ExplainaBoard platform, which allows us to interactively understand the strengths, weaknesses, and complementarity of each metric."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "General Low-rank Matrix Optimization", "Title": "Geometric Analysis and Sharper Bounds", "Abstract": "This paper considers the global geometry of general low-rank minimization problems via the Burer-Monterio factorization approach. For the rank-$1$ case, we prove that there is no spurious second-order critical point for both symmetric and asymmetric problems if the rank-$2$ RIP constant $\\delta$ is less than $1/2$. Combining with a counterexample with $\\delta=1/2$, we show that the derived bound is the sharpest possible. For the arbitrary rank-$r$ case, the same property is established when the rank-$2r$ RIP constant $\\delta$ is at most $1/3$. We design a counterexample to show that the non-existence of spurious second-order critical points may not hold if $\\delta$ is at least $1/2$. In addition, for any problem with $\\delta$ between $1/3$ and $1/2$, we prove that all second-order critical points have a positive correlation to the ground truth. Finally, the strict saddle property, which can lead to the polynomial-time global convergence of various algorithms, is established for both the symmetric and asymmetric problems when the rank-$2r$ RIP constant $\\delta$ is less than $1/3$. The results of this paper significantly extend several existing bounds in the literature."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Policy Finetuning", "Title": "Bridging Sample-Efficient Offline and Online Reinforcement Learning", "Abstract": "Recent theoretical work studies sample-efficient reinforcement learning (RL) extensively in two settings: learning interactively in the environment (online RL), or learning from an offline dataset (offline RL). However, existing algorithms and theories for learning near-optimal policies in these two settings are rather different and disconnected. Towards bridging this gap, this paper initiates the theoretical study of *policy finetuning*, that is, online RL where the learner has additional access to a \"reference policy\" $\\mu$ close to the optimal policy $\\pi_\\star$ in a certain sense. We consider the policy finetuning problem in episodic Markov Decision Processes (MDPs) with $S$ states, $A$ actions, and horizon length $H$. We first design a sharp *offline reduction* algorithm---which simply executes $\\mu$ and runs offline policy optimization on the collected dataset---that finds an $\\varepsilon$ near-optimal policy within $\\widetilde{O}(H^3SC^\\star/\\varepsilon^2)$ episodes, where $C^\\star$ is the single-policy concentrability coefficient between $\\mu$ and $\\pi_\\star$. This offline result is the first that matches the sample complexity lower bound in this setting, and resolves a recent open question in offline RL. We then establish an $\\Omega(H^3S\\min\\{C^\\star, A\\}/\\varepsilon^2)$ sample complexity lower bound for *any* policy finetuning algorithm, including those that can adaptively explore the environment. This implies that---perhaps surprisingly---the optimal policy finetuning algorithm is either offline reduction or a purely online RL algorithm that does not use $\\mu$. Finally, we design a new hybrid offline/online algorithm for policy finetuning that achieves better sample complexity than both vanilla offline reduction and purely online RL algorithms, in a relaxed setting where $\\mu$ only satisfies concentrability partially up to a certain time step. Overall, our results offer a quantitative understanding on the benefit of a good reference policy, and make a step towards bridging offline and online RL."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SGD", "Title": "The Role of Implicit Regularization, Batch-size and Multiple-epochs", "Abstract": "Multi-epoch, small-batch, Stochastic Gradient Descent (SGD) has been the method of choice for learning with large over-parameterized models. A popular theory for explaining why SGD works well in practice is that the algorithm has an implicit regularization that biases its output towards a good solution. Perhaps the theoretically most well understood learning setting for SGD is that of Stochastic Convex Optimization (SCO), where it is well known that SGD learns at a rate of $O(1/\\sqrt{n})$, where $n$ is the number of samples. In this paper, we consider the problem of SCO and explore the role of implicit regularization, batch size and multiple epochs for SGD. Our main contributions are threefold: * We show that for any regularizer, there is an SCO problem for which Regularized Empirical Risk Minimzation fails to learn. This automatically rules out any implicit regularization based explanation for the success of SGD.* We provide a separation between SGD and learning via Gradient Descent on empirical loss (GD) in terms of sample complexity. We show that there is an SCO problem such that GD with any step size and number of iterations can only learn at a suboptimal rate: at least $\\widetilde{\\Omega}(1/n^{5/12})$.*  We present a multi-epoch variant of SGD commonly used in practice. We prove that this algorithm is at least as good as single pass SGD in the worst case. However, for certain SCO problems, taking multiple passes over the dataset can significantly outperform single pass SGD. We extend our results to the general learning setting by showing a problem which is learnable for any data distribution, and for this problem, SGD is strictly better than RERM for any regularization function. We conclude by discussing the implications of our results for deep learning, and show a separation between SGD and ERM for two layer diagonal neural networks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "AC-GC", "Title": "Lossy Activation Compression with Guaranteed Convergence", "Abstract": "Parallel hardware devices (e.g., graphics processor units) have limited high-bandwidth memory capacity.This negatively impacts the training of deep neural networks (DNNs) by increasing runtime and/or decreasing accuracy when reducing model and/or batch size to fit this capacity. Lossy compression is a promising approach to tackling memory capacity constraints, but prior approaches rely on hyperparameter search to achieve a suitable trade-off between convergence and compression, negating runtime benefits. In this paper we build upon recent developments on Stochastic Gradient Descent convergence to prove an upper bound on the expected loss increase when training with compressed activation storage. We then express activation compression error in terms of this bound, allowing the compression rate to adapt to training conditions automatically. The advantage of our approach, called AC-GC, over existing lossy compression frameworks is that, given a preset allowable increase in loss, significant compression without significant increase in error can be achieved with a single training run. When combined with error-bounded methods, AC-GC achieves 15.1x compression with an average accuracy change of 0.1% on text and image datasets. AC-GC functions on any model composed of the layers analyzed and, by avoiding compression rate search, reduces overall training time by 4.6x over SuccessiveHalving."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DeepSITH", "Title": "Efficient Learning via Decomposition of What and When Across Time Scales", "Abstract": "Extracting temporal relationships over a range of scales is a hallmark ofhuman perception and cognition---and thus it is a critical feature of machinelearning applied to real-world problems.  Neural networks are either plaguedby the exploding/vanishing gradient problem in recurrent neural networks(RNNs) or must adjust their parameters to learn the relevant time scales(e.g., in LSTMs). This paper introduces DeepSITH, a deep network comprisingbiologically-inspired Scale-Invariant Temporal History (SITH) modules inseries with dense connections between layers. Each SITH module is simply aset of time cells coding what happened when with a geometrically-spaced set oftime lags.  The dense connections between layers change the definition of whatfrom one layer to the next.  The geometric series of time lags implies thatthe network codes time on a logarithmic scale, enabling DeepSITH network tolearn problems requiring memory over a wide range of time scales. We compareDeepSITH to LSTMs and other recent RNNs on several time series prediction anddecoding tasks. DeepSITH achieves results comparable to state-of-the-artperformance on these problems and continues to perform well even as the delaysare increased."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DNN-based Topology Optimisation", "Title": "Spatial Invariance and Neural Tangent Kernel", "Abstract": "We study the Solid Isotropic Material Penalization (SIMP) method with a density field generated by a fully-connected neural network, taking the coordinates as inputs. In the large width limit, we show that the use of DNNs leads to a filtering effect similar to traditional filtering techniques for SIMP, with a filter described by the Neural Tangent Kernel (NTK). This filter is however not invariant under translation, leading to visual artifacts and non-optimal shapes. We propose two embeddings of the input coordinates, which lead  to (approximate) spatial invariance of the NTK and of the filter. We empirically confirm our theoretical observations and study how the filter size is affected by the architecture of the network. Our solution can easily be applied to any other coordinates-based generation method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Baleen", "Title": "Robust Multi-Hop Reasoning at Scale via Condensed Retrieval", "Abstract": "Multi-hop reasoning (i.e., reasoning across two or more documents) is a key ingredient for NLP models that leverage large corpora to exhibit broad knowledge. To retrieve evidence passages, multi-hop models must contend with a fast-growing search space across the hops, represent complex queries that combine multiple information needs, and resolve ambiguity about the best order in which to hop between training passages. We tackle these problems via Baleen, a system that improves the accuracy of multi-hop retrieval while learning robustly from weak training signals in the many-hop setting. To tame the search space, we propose condensed retrieval, a pipeline that summarizes the retrieved passages after each hop into a single compact context. To model complex queries, we introduce a focused late interaction retriever that allows different parts of the same query representation to match disparate relevant passages. Lastly, to infer the hopping dependencies among unordered training passages, we devise latent hop ordering, a weak-supervision strategy in which the trained retriever itself selects the sequence of hops. We evaluate Baleen on retrieval for two-hop question answering and many-hop claim verification, establishing state-of-the-art performance."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Learning Interpretable Decision Rule Sets", "Title": "A Submodular Optimization Approach", "Abstract": "Rule sets are highly interpretable logical models in which the predicates for decision are expressed in disjunctive normal form (DNF, OR-of-ANDs), or, equivalently, the overall model comprises an unordered collection of if-then decision rules. In this paper, we consider a submodular optimization based approach for learning rule sets. The learning problem is framed as a subset selection task in which a subset of all possible rules needs to be selected to form an accurate and interpretable rule set. We employ an objective function that exhibits submodularity and thus is amenable to submodular optimization techniques. To overcome the difficulty arose from dealing with the exponential-sized ground set of rules, the subproblem of searching a rule is casted as another subset selection task that asks for a subset of features. We show it is possible to write the induced objective function for the subproblem as a difference of two submodular (DS) functions to make it approximately solvable by DS optimization algorithms. Overall, the proposed approach is simple, scalable, and likely to be benefited from further research on submodular optimization. Experiments on real datasets demonstrate the effectiveness of our method."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "You Are the Best Reviewer of Your Own Papers", "Title": "An Owner-Assisted Scoring Mechanism", "Abstract": "I consider the setting where reviewers offer very noisy scores for a number of items for the selection of high-quality ones (e.g., peer review of large conference proceedings) whereas the owner of these items knows the true underlying scores but prefers not to provide this information. To address this withholding of information, in this paper, I introduce the Isotonic Mechanism, a simple and efficient approach to improving on the imprecise raw scores by leveraging certain information that the owner is incentivized to provide. This mechanism takes as input the ranking of the items from best to worst provided by the owner, in addition to the raw scores provided by the reviewers. It reports adjusted scores for the items by solving a convex optimization problem. Under certain conditions, I show that the owner's optimal strategy is to honestly report the true ranking of the items to her best knowledge in order to maximize the expected utility. Moreover, I prove that the adjusted scores provided by this owner-assisted mechanism are indeed significantly moreaccurate than the raw scores provided by the reviewers. This paper concludes with several extensions of the Isotonic Mechanism and some refinements of the mechanism for practical considerations."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Garment4D", "Title": "Garment Reconstruction from Point Cloud Sequences", "Abstract": "Learning to reconstruct 3D garments is important for dressing 3D human bodies of different shapes in different poses. Previous works typically rely on 2D images as input, which however suffer from the scale and pose ambiguities. To circumvent the problems caused by 2D images, we propose a principled framework, Garment4D, that uses 3D point cloud sequences of dressed humans for garment reconstruction. Garment4D has three dedicated steps: sequential garments registration, canonical garment estimation, and posed garment reconstruction. The main challenges are two-fold: 1) effective 3D feature learning for fine details, and 2) capture of garment dynamics caused by the interaction between garments and the human body, especially for loose garments like skirts. To unravel these problems, we introduce a novel Proposal-Guided Hierarchical Feature Network and Iterative Graph Convolution Network, which integrate both high-level semantic features and low-level geometric features for fine details reconstruction. Furthermore, we propose a Temporal Transformer for smooth garment motions capture. Unlike non-parametric methods, the reconstructed garment meshes by our method are separable from the human body and have strong interpretability, which is desirable for downstream tasks. As the first attempt at this task, high-quality reconstruction results are qualitatively and quantitatively illustrated through extensive experiments. Codes are available at https://github.com/hongfz16/Garment4D."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shift-Robust GNNs", "Title": "Overcoming the Limitations of Localized Graph Training data", "Abstract": "There has been a recent surge of interest in designing Graph Neural Networks (GNNs) for semi-supervised learning tasks. Unfortunately this work has assumed that the nodes labeled for use in training were selected uniformly at random (i.e. are an IID sample). However in many real world scenarios gathering labels for graph nodes is both expensive and inherently biased -- so this assumption can not be met. GNNs can suffer poor generalization when this occurs, by overfitting to superfluous regularities present in the training data. In this work we present a method, Shift-Robust GNN (SR-GNN), designed to account for distributional differences between biased training data and the graph's true inference distribution. SR-GNN adapts GNN models for the presence of distributional shifts between the nodes which have had labels provided for training and the rest of the dataset. We illustrate the effectiveness of SR-GNN in a variety of experiments with biased training datasets on common GNN benchmark datasets for semi-supervised learning, where we see that SR-GNN outperforms other GNN baselines by accuracy, eliminating at least (~40%) of the negative effects introduced by biased training data. On the largest dataset we consider, ogb-arxiv, we observe an 2% absolute improvement over the baseline and reduce 30% of the negative effects."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "RIM", "Title": "Reliable Influence-based Active Learning on Graphs", "Abstract": "Message passing is the core of most graph models such as Graph Convolutional Network (GCN) and Label Propagation (LP), which usually require a large number of clean labeled data to smooth out the neighborhood over the graph. However, the labeling process can be tedious, costly, and error-prone in practice. In this paper, we propose to unify active learning (AL) and message passing towards minimizing labeling costs, e.g., making use of few and unreliable labels that can be obtained cheaply. We make two contributions towards that end. First, we open up a perspective by drawing a connection between AL enforcing message passing and social influence maximization, ensuring that the selected samples effectively improve the model performance. Second, we propose an extension to the influence model that incorporates an explicit quality factor to model label noise. In this way, we derive a fundamentally new AL selection criterion for GCN and LP--reliable influence maximization (RIM)--by considering quantity and quality of influence simultaneously. Empirical studies on public datasets show that RIM significantly outperforms current AL methods in terms of accuracy and efficiency."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Natural continual learning", "Title": "success is a journey, not (just) a destination", "Abstract": "Biological agents are known to learn many different tasks over the course of their lives, and to be able to revisit previous tasks and behaviors with little to no loss in performance. In contrast, artificial agents are prone to ‘catastrophic forgetting’ whereby performance on previous tasks deteriorates rapidly as new ones are acquired. This shortcoming has recently been addressed using methods that encourage parameters to stay close to those used for previous tasks. This can be done by (i) using specific parameter regularizers that map out suitable destinations in parameter space, or (ii) guiding the optimization journey by projecting gradients into subspaces that do not interfere with previous tasks. However, these methods often exhibit subpar performance in both feedforward and recurrent neural networks, with recurrent networks being of interest to the study of neural dynamics supporting biological continual learning. In this work, we propose Natural Continual Learning (NCL), a new method that unifies weight regularization and projected gradient descent. NCL uses Bayesian weight regularization to encourage good performance on all tasks at convergence and combines this with gradient projection using the prior precision, which prevents catastrophic forgetting during optimization. Our method outperforms both standard weight regularization techniques and projection based approaches when applied to continual learning problems in feedforward and recurrent networks. Finally, the trained networks evolve task-specific dynamics that are strongly preserved as new tasks are learned, similar to experimental findings in biological circuits."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ASSANet", "Title": "An Anisotropic Separable Set Abstraction for Efficient Point Cloud Representation Learning", "Abstract": "Access to 3D point cloud representations has been widely facilitated by LiDAR sensors embedded in various mobile devices. This has led to an emerging need for fast and accurate point cloud processing techniques. In this paper, we revisit and dive deeper into PointNet++, one of the most influential yet under-explored networks, and develop faster and more accurate variants of the model. We first present a novel Separable Set Abstraction (SA) module that disentangles the vanilla SA module used in PointNet++ into two separate learning stages: (1) learning channel correlation and (2) learning spatial correlation. The Separable SA module is significantly faster than the vanilla version, yet it achieves comparable performance.  We then introduce a new Anisotropic Reduction function into our Separable SA module and propose an Anisotropic Separable SA (ASSA) module that substantially increases the network's accuracy. We later replace the vanilla SA modules in PointNet++ with the proposed ASSA modules, and denote the modified network as ASSANet. Extensive experiments on point cloud classification, semantic segmentation, and part segmentation show that ASSANet outperforms PointNet++ and other methods, achieving much higher accuracy and faster speeds. In particular, ASSANet outperforms PointNet++ by $7.4$ mIoU on S3DIS Area 5, while maintaining $1.6 \\times $ faster inference speed on a single NVIDIA 2080Ti GPU. Our scaled ASSANet variant achieves $66.8$ mIoU and outperforms KPConv, while being more than $54 \\times$ faster."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ScaleCert", "Title": "Scalable Certified Defense against Adversarial Patches with Sparse Superficial Layers", "Abstract": "Adversarial patch attacks that craft the pixels in a confined region of the input images show their powerful attack effectiveness in physical environments even with noises or deformations. Existing certified defenses towards adversarial patch attacks work well on small images like MNIST and CIFAR-10 datasets, but achieve very poor certified accuracy on higher-resolution images like ImageNet. It is urgent to design both robust and effective defenses against such a practical and harmful attack in industry-level larger images. In this work, we propose the certified defense methodology that achieves high provable robustness for high-resolution images and largely improves the practicality for real adoption of the certified defense. The basic insight of our work is that the adversarial patch intends to leverage localized superficial important neurons (SIN) to manipulate the prediction results. Hence, we leverage the SIN-based DNN compression techniques to significantly improve the certified accuracy, by reducing the adversarial region searching overhead and filtering the prediction noises. Our experimental results show that the certified accuracy is increased from 36.3%  (the state-of-the-art certified detection)  to 60.4%on the ImageNet dataset, largely pushing the certified defenses for practical use."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Towards mental time travel", "Title": "a hierarchical memory for reinforcement learning agents", "Abstract": "Reinforcement learning agents often forget details of the past, especially after delays or distractor tasks. Agents with common memory architectures struggle to recall and integrate across multiple timesteps of a past event, or even to recall the details of a single timestep that is followed by distractor tasks. To address these limitations, we propose a Hierarchical Chunk Attention Memory (HCAM), that helps agents to remember the past in detail. HCAM stores memories by dividing the past into chunks, and recalls by first performing high-level attention over coarse summaries of the chunks, and then performing detailed attention within only the most relevant chunks. An agent with HCAM can therefore \"mentally time-travel\"--remember past events in detail without attending to all intervening events. We show that agents with HCAM substantially outperform agents with other memory architectures at tasks requiring long-term recall, retention, or reasoning over memory. These include recalling where an object is hidden in a 3D environment, rapidly learning to navigate efficiently in a new neighborhood, and rapidly learning and retaining new words. Agents with HCAM can extrapolate to task sequences much longer than they were trained on, and can even generalize zero-shot from a meta-learning setting to maintaining knowledge across episodes. HCAM improve agent sample efficiency, generalization, and generality (by solving tasks that previously required specialized architectures). Our work is a step towards agents that can learn, interact, and adapt in complex and temporally-extended environments."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beyond Tikhonov", "Title": "faster learning with self-concordant losses, via iterative regularization", "Abstract": "The theory of spectral filtering is a remarkable tool to understand the statistical properties of learning with kernels. For least squares, it allows to derive various regularization schemes that yield faster convergence rates of the excess risk than with Tikhonov regularization. This is typically achieved by leveraging classical assumptions called source and capacity conditions, which characterize the difficulty of the learning task. In order to understand estimators derived from other loss functions, Marteau-Ferey et al. have extended the theory of Tikhonov regularization to generalized self concordant loss functions (GSC), which contain, e.g., the logistic loss. In this paper, we go a step further and show that fast and optimal rates can be achieved for GSC by using the iterated Tikhonov regularization scheme, which is intrinsically related to the proximal point method in optimization, and overcomes the limitation of the classical Tikhonov regularization."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CBP", "Title": "backpropagation with constraint on weight precision using a pseudo-Lagrange multiplier method", "Abstract": "Backward propagation of errors (backpropagation) is a method to minimize objective functions (e.g., loss functions) of deep neural networks by identifying optimal sets of weights and biases. Imposing constraints on weight precision is often required to alleviate prohibitive workloads on hardware. Despite the remarkable success of backpropagation, the algorithm itself is not capable of considering such constraints unless additional algorithms are applied simultaneously. To address this issue, we propose the constrained backpropagation (CBP) algorithm based on the pseudo-Lagrange multiplier method to obtain the optimal set of weights that satisfy a given set of constraints. The defining characteristic of the proposed CBP algorithm is the utilization of a Lagrangian function (loss function plus constraint function) as its objective function. We considered various types of constraints — binary, ternary, one-bit shift, and two-bit shift weight constraints. As a post-training method, CBP applied to AlexNet, ResNet-18, ResNet-50, and GoogLeNet on ImageNet, which were pre-trained using the conventional backpropagation. For most cases, the proposed algorithm outperforms the state-of-the-art methods on ImageNet, e.g., 66.6\\%, 74.4\\%, and 64.0\\% top-1 accuracy for ResNet-18, ResNet-50, and GoogLeNet with binary weights, respectively. This highlights CBP as a learning algorithm to address diverse constraints with the minimal performance loss by employing appropriate constraint functions. The code for CBP is publicly available at \\url{https://github.com/dooseokjeong/CBP}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Implicit Sparse Regularization", "Title": "The Impact of Depth and Early Stopping", "Abstract": "In this paper, we study the implicit bias of gradient descent for sparse regression. We extend results on regression with quadratic parametrization, which amounts to depth-2 diagonal linear networks, to more general depth-$N$ networks, under more realistic settings of noise and correlated designs. We show that early stopping is crucial for gradient descent to converge to a sparse model, a phenomenon that we call \\emph{implicit sparse regularization}. This result is in sharp contrast to known results for noiseless and uncorrelated-design cases.   We characterize the impact of depth and early stopping and show that for a general depth parameter $N$, gradient descent with early stopping achieves minimax optimal sparse recovery with sufficiently small initialization $w_0$ and step size $\\eta$. In particular, we show that increasing depth enlarges the scale of working initialization and the early-stopping window so that this implicit sparse regularization effect is more likely to take place."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Continual World", "Title": "A Robotic Benchmark For Continual Reinforcement Learning", "Abstract": "Continual learning (CL) --- the ability to continuously learn, building on previously acquired knowledge --- is a natural requirement for long-lived autonomous reinforcement learning (RL) agents. While building such agents, one needs to balance opposing desiderata, such as constraints on capacity and compute, the ability to not catastrophically forget, and to exhibit positive transfer on new tasks. Understanding the right trade-off is conceptually and computationally challenging, which we argue has led the community to overly focus on catastrophic forgetting.  In response to these issues, we advocate for the need to prioritize forward transfer and propose Continual World, a benchmark consisting of realistic and meaningfully diverse robotic tasks built on top of Meta-World  as a testbed. Following an in-depth empirical evaluation of existing CL methods, we pinpoint their limitations and highlight unique algorithmic challenges in the RL setting. Our benchmark aims to provide a meaningful and computationally inexpensive challenge for the community and thus help better understand the performance of existing and future solutions. Information about the benchmark, including the open-source code, is available at https://sites.google.com/view/continualworld."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ViTAE", "Title": "Vision Transformer Advanced by Exploring Intrinsic Inductive Bias", "Abstract": "Transformers have shown great potential in various computer vision tasks owing to their strong capability in modeling long-range dependency using the self-attention mechanism. Nevertheless, vision transformers treat an image as 1D sequence of visual tokens, lacking an intrinsic inductive bias (IB) in modeling local visual structures and dealing with scale variance. Alternatively, they require large-scale training data and longer training schedules to learn the IB implicitly. In this paper, we propose a new Vision Transformer Advanced by Exploring intrinsic IB from convolutions, i.e., ViTAE. Technically, ViTAE has several spatial pyramid reduction modules to downsample and embed the input image into tokens with rich multi-scale context by using multiple convolutions with different dilation rates. In this way, it acquires an intrinsic scale invariance IB and is able to learn robust feature representation for objects at various scales. Moreover, in each transformer layer, ViTAE has a convolution block in parallel to the multi-head self-attention module, whose features are fused and fed into the feed-forward network. Consequently, it has the intrinsic locality IB and is able to learn local features and global dependencies collaboratively. Experiments on ImageNet as well as downstream tasks prove the superiority of ViTAE over the baseline transformer and concurrent works. Source code and pretrained models will be available at https://github.com/Annbless/ViTAE."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Revisiting Discriminator in GAN Compression", "Title": "A Generator-discriminator Cooperative Compression Scheme", "Abstract": "Recently, a series of algorithms have been explored for GAN compression, which aims to reduce tremendous computational overhead and memory usages when deploying GANs on resource-constrained edge devices. However, most of the existing GAN compression work only focuses on how to compress the generator, while fails to take the discriminator into account. In this work, we revisit the role of discriminator in GAN compression and design a novel generator-discriminator cooperative compression scheme for GAN compression, termed GCC. Within GCC, a selective activation discriminator automatically selects and activates convolutional channels according to a local capacity constraint and a global coordination constraint, which help maintain the Nash equilibrium with the lightweight generator during the adversarial training and avoid mode collapse. The original generator and discriminator are also optimized from scratch, to play as a teacher model to progressively refine the pruned generator and the selective activation discriminator. A novel online collaborative distillation scheme is designed to take full advantage of the intermediate feature of the teacher generator and discriminator to further boost the performance of the lightweight generator. Extensive experiments on various GAN-based generation tasks demonstrate the effectiveness and generalization of GCC. Among them, GCC contributes to reducing 80% computational costs while maintains comparable performance in image translation tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MobILE", "Title": "Model-Based Imitation Learning From Observation Alone", "Abstract": "This paper studies Imitation Learning from Observations alone (ILFO) where the learner is presented with expert demonstrations that consist only of states visited by an expert (without access to actions taken by the expert). We present a provably efficient model-based framework MobILE to solve the ILFO problem. MobILE involves carefully trading off exploration against imitation - this is achieved by integrating the idea of optimism in the face of uncertainty into the distribution matching imitation learning (IL) framework. We provide a unified analysis for MobILE, and demonstrate that MobILE enjoys strong performance guarantees for classes of MDP dynamics that satisfy certain well studied notions of complexity. We also show that the ILFO problem is strictly harder than the standard IL problem by reducing ILFO to a multi-armed bandit problem indicating that exploration is necessary for solving ILFO efficiently. We complement  these theoretical results with experimental simulations on benchmark OpenAI Gym tasks that indicate the efficacy of MobILE. Code for implementing the MobILE framework is available at https://github.com/rahulkidambi/MobILE-NeurIPS2021."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On Path Integration of Grid Cells", "Title": "Group Representation and Isotropic Scaling", "Abstract": "Understanding how grid cells perform path integration calculations remains a fundamental problem. In this paper, we conduct theoretical analysis of a general representation model of path integration by grid cells, where the 2D self-position is encoded as a higher dimensional vector, and the 2D self-motion is represented by a general transformation of the vector. We identify two conditions on the transformation. One is a group representation condition that is necessary for path integration. The other is an isotropic scaling condition that ensures locally conformal embedding, so that the error in the vector representation translates conformally to the error in the 2D self-position. Then we investigate the simplest transformation, i.e., the linear transformation, uncover its explicit algebraic and geometric structure as matrix Lie group of rotation, and explore the connection between the isotropic scaling condition and a special class of hexagon grid patterns. Finally, with our optimization-based approach, we manage to learn hexagon grid patterns that share similar properties of the grid cells in the rodent brain. The learned model is capable of accurate long distance path integration. Code is available at https://github.com/ruiqigao/grid-cell-path."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Self-Attention Between Datapoints", "Title": "Going Beyond Individual Input-Output Pairs in Deep Learning", "Abstract": "We challenge a common assumption underlying most supervised deep learning: that a model makes a prediction depending only on its parameters and the features of a single input. To this end, we introduce a general-purpose deep learning architecture that takes as input the entire dataset instead of processing one datapoint at a time. Our approach uses self-attention to reason about relationships between datapoints explicitly, which can be seen as realizing non-parametric models using parametric attention mechanisms. However, unlike conventional non-parametric models, we let the model learn end-to-end from the data how to make use of other datapoints for prediction. Empirically, our models solve cross-datapoint lookup and complex reasoning tasks unsolvable by traditional deep learning models. We show highly competitive results on tabular data, early results on CIFAR-10, and give insight into how the model makes use of the interactions between points."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Your head is there to move you around", "Title": "Goal-driven models of the primate dorsal pathway", "Abstract": "Neurons in the dorsal visual pathway of the mammalian brain are selective for motion stimuli, with the complexity of stimulus representations increasing along the hierarchy. This progression is similar to that of the ventral visual pathway, which is well characterized by artificial neural networks (ANNs) optimized for object recognition. In contrast, there are no image-computable models of the dorsal stream with comparable explanatory power. We hypothesized that the properties of dorsal stream neurons could be explained by a simple learning objective: the need for an organism to orient itself during self-motion. To test this hypothesis, we trained a 3D ResNet to predict an agent's self-motion parameters from visual stimuli in a simulated environment. We found that the responses in this network accounted well for the selectivity of neurons in a large database of single-neuron recordings from the dorsal visual stream of non-human primates. In contrast, ANNs trained on an action recognition dataset through supervised or self-supervised learning  could not explain responses in the dorsal stream, despite also being trained on naturalistic videos with moving objects. These results demonstrate that an ecologically relevant cost function can account for dorsal stream properties in the primate brain."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "GraphFormers", "Title": "GNN-nested Transformers for Representation Learning on Textual Graph", "Abstract": "The representation learning on textual graph is to generate low-dimensional embeddings for the nodes based on the individual textual features and the neighbourhood information. Recent breakthroughs on pretrained language models and graph neural networks push forward the development of corresponding techniques. The existing works mainly rely on the cascaded model architecture: the textual features of nodes are independently encoded by language models at first; the textual embeddings are aggregated by graph neural networks afterwards. However, the above architecture is limited due to the independent modeling of textual features. In this work, we propose GraphFormers, where layerwise GNN components are nested alongside the transformer blocks of language models. With the proposed architecture, the text encoding and the graph aggregation are fused into an iterative workflow, making each node's semantic accurately comprehended from the global perspective. In addition, a progressive learning strategy is introduced, where the model is successively trained on manipulated data and original data to reinforce its capability of integrating information on graph. Extensive evaluations are conducted on three large-scale benchmark datasets, where GraphFormers outperform the SOTA baselines with comparable running efficiency. The source code is released at https://github.com/microsoft/GraphFormers ."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Scalars are universal", "Title": "Equivariant machine learning, structured like classical physics", "Abstract": "There has been enormous progress in the last few years in designing  neural networks that respect the fundamental symmetries and coordinate freedoms of physical law. Some of these frameworks make use of irreducible representations, some make use of high-order tensor objects, and some apply symmetry-enforcing constraints. Different physical laws obey different combinations of fundamental symmetries, but a large fraction (possibly all) of classical physics is equivariant to translation, rotation, reflection (parity), boost (relativity), and permutations. Here we show that it is simple to parameterize universally approximating polynomial functions that are equivariant under these symmetries, or under the Euclidean, Lorentz, and Poincaré groups, at any dimensionality $d$. The key observation is that nonlinear O($d$)-equivariant (and related-group-equivariant) functions can be universally expressed in terms of a lightweight collection of scalars---scalar products and scalar contractions of the scalar, vector, and tensor inputs. We complement our theory with numerical examples that show that the scalar-based method is simple, efficient, and scalable."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Powerpropagation", "Title": "A sparsity inducing weight reparameterisation", "Abstract": "The training of sparse neural networks is becoming an increasingly important tool for reducing the computational footprint of models at training and evaluation, as well enabling the effective scaling up of models. Whereas much work over the years has been dedicated to specialised pruning techniques, little attention has been paid to the inherent effect of gradient based training on model sparsity. Inthis work, we introduce Powerpropagation, a new weight-parameterisation for neural networks that leads to inherently sparse models. Exploiting the behaviour of gradient descent, our method gives rise to weight updates exhibiting a “rich get richer” dynamic, leaving low-magnitude parameters largely unaffected by learning. Models trained in this manner exhibit similar performance, but have a distributionwith markedly higher density at zero, allowing more parameters to be pruned safely. Powerpropagation is general, intuitive, cheap and straight-forward to implement and can readily be combined with various other techniques. To highlight its versatility, we explore it in two very different settings: Firstly, following a recent line of work, we investigate its effect on sparse training for resource-constrained settings. Here, we combine Powerpropagation with a traditional weight-pruning technique as well as recent state-of-the-art sparse-to-sparse algorithms, showing superior performance on the ImageNet benchmark. Secondly, we advocate the useof sparsity in overcoming catastrophic forgetting, where compressed representations allow accommodating a large number of tasks at fixed model capacity. In all cases our reparameterisation considerably increases the efficacy of the off-the-shelf methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Convolutional Normalization", "Title": "Improving Deep Convolutional Network Robustness and Training", "Abstract": "Normalization techniques have become a basic component in modern convolutional neural networks (ConvNets). In particular, many recent works demonstrate that promoting the orthogonality of the weights helps train deep models and improve robustness. For ConvNets, most existing methods are based on penalizing or normalizing weight matrices derived from concatenating or flattening the convolutional kernels. These methods often destroy or ignore the benign convolutional structure of the kernels; therefore, they are often expensive or impractical for deep ConvNets. In contrast, we introduce a simple and efficient ``Convolutional Normalization'' (ConvNorm) method that can fully exploit the convolutional structure in the Fourier domain and serve as a simple plug-and-play module to be conveniently incorporated into any ConvNets. Our method is inspired by recent work on preconditioning methods for convolutional sparse coding and can effectively promote each layer's channel-wise isometry. Furthermore, we show that our ConvNorm can reduce the layerwise spectral norm of the weight matrices and hence improve the Lipschitzness of the network, leading to easier training and improved robustness for deep ConvNets. Applied to classification under noise corruptions and generative adversarial network (GAN), we show that the ConvNorm improves the robustness of common ConvNets such as ResNet and the performance of GAN. We verify our findings via numerical experiments on CIFAR and ImageNet. Our implementation is available online at \\url{https://github.com/shengliu66/ConvNorm}."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "COMBO", "Title": "Conservative Offline Model-Based Policy Optimization", "Abstract": "Model-based reinforcement learning (RL) algorithms, which learn a dynamics model from logged experience and perform conservative planning under the learned model, have emerged as a promising paradigm for offline reinforcement learning (offline RL). However, practical variants of such model-based algorithms rely on explicit uncertainty quantification for incorporating conservatism. Uncertainty estimation with complex models, such as deep neural networks, can be difficult and unreliable. We empirically find that uncertainty estimation is not accurate and leads to poor performance in certain scenarios in offline model-based RL. We overcome this limitation by developing a new model-based offline RL algorithm, COMBO, that trains a value function using both the offline dataset and data generated using rollouts under the model while also additionally regularizing the value function on out-of-support state-action tuples generated via model rollouts. This results in a conservative estimate of the value function for out-of-support state-action tuples, without requiring explicit uncertainty estimation. Theoretically, we show that COMBO satisfies a policy improvement guarantee in the offline setting. Through extensive experiments, we find that COMBO attains greater performance compared to prior offline RL on problems that demand generalization to related but previously unseen tasks, and also consistently matches or outperforms prior offline RL methods on widely studied offline RL benchmarks, including image-based tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TAAC", "Title": "Temporally Abstract Actor-Critic for Continuous Control", "Abstract": "We present temporally abstract actor-critic (TAAC), a simple but effective off-policy RL algorithm that incorporates closed-loop temporal abstraction into the actor-critic framework. TAAC adds a second-stage binary policy to choose between the previous action and a new action output by an actor. Crucially, its \"act-or-repeat\" decision hinges on the actually sampled action instead of the expected behavior of the actor. This post-acting switching scheme let the overall policy make more informed decisions. TAAC has two important features: a) persistent exploration, and b) a new compare-through Q operator for multi-step TD backup, specially tailored to the action repetition scenario. We demonstrate TAAC's advantages over several strong baselines across 14 continuous control tasks. Our surprising finding reveals that while achieving top performance, TAAC is able to \"mine\" a significant number of repeated actions with the trained policy even on continuous tasks whose problem structures on the surface seem to repel action repetition. This suggests that aside from encouraging persistent exploration, action repetition can find its place in a good policy behavior. Code is available at https://github.com/hnyu/taac."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "STEP", "Title": "Out-of-Distribution Detection in the Presence of Limited In-Distribution Labeled Data", "Abstract": "Existing semi-supervised learning (SSL) studies typically assume that unlabeled and test data are drawn from the same distribution as labeled data. However, in many real-world applications, it is desirable to have SSL algorithms that not only classify the samples drawn from the same distribution of labeled data but also detect out-of-distribution (OOD) samples drawn from an unknown distribution. In this paper, we study a setting called semi-supervised OOD detection. Two main challenges compared with previous OOD detection settings are i) the lack of labeled data and in-distribution data; ii) OOD samples could be unseen during training. Efforts on this direction remain limited. In this paper, we present an approach STEP significantly improving OOD detection performance by introducing a new technique: Structure-Keep Unzipping. It learns a new representation space in which OOD samples could be separated well. An efficient optimization algorithm is derived to solve the objective. Comprehensive experiments across various OOD detection benchmarks clearly show that our STEP approach outperforms other methods by a large margin and achieves remarkable detection performance on several benchmarks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Tailoring", "Title": "encoding inductive biases by optimizing unsupervised objectives at prediction time", "Abstract": "From CNNs to attention mechanisms, encoding inductive biases into neural networks has been a fruitful source of improvement in machine learning. Adding auxiliary losses to the main objective function is a general way of encoding biases that can help networks learn better representations. However, since auxiliary losses are minimized only on training data, they suffer from the same generalization gap as regular task losses. Moreover, by adding a term to the loss function, the model optimizes a different objective than the one we care about. In this work we address both problems: first, we take inspiration from transductive learning and note that after receiving an input but before making a prediction, we can fine-tune our networks on any unsupervised loss. We call this process tailoring, because we customize the model to each input to ensure our prediction satisfies the inductive bias. Second, we formulate meta-tailoring, a nested optimization similar to that in meta-learning, and train our models to perform well on the task objective after adapting them using an unsupervised loss. The advantages of tailoring and meta-tailoring are discussed theoretically and demonstrated empirically on a diverse set of examples."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Implicit Bias of SGD for Diagonal Linear Networks", "Title": "a Provable Benefit of Stochasticity", "Abstract": "Understanding the implicit bias of training algorithms is of crucial importance in order to explain the success of overparametrised neural networks. In this paper, we study the dynamics of stochastic gradient descent over diagonal linear networks through its continuous time version, namely stochastic gradient flow. We explicitly characterise the solution chosen by the stochastic flow and prove that it always enjoys better generalisation properties than that of gradient flow.Quite surprisingly, we show that the convergence speed of the training loss controls the magnitude of the biasing effect: the slower the convergence, the better the bias. To fully complete our analysis, we provide convergence guarantees for the dynamics. We also give experimental results which support our theoretical claims. Our findings highlight the fact that structured noise can induce better generalisation and they help explain the greater performances of stochastic gradient  descent over gradient descent observed in practice."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DRONE", "Title": "Data-aware Low-rank Compression for Large NLP Models", "Abstract": "The representations learned by large-scale NLP models such as BERT have been widely used in various tasks. However, the increasing model size of the pre-trained models also brings efficiency challenges, including inference speed and model size when deploying models on mobile devices. Specifically, most operations in BERT consist of matrix multiplications. These matrices are not low-rank and thus canonical matrix decomposition could not find an efficient approximation. In this paper, we observe that the learned representation of each layer lies in a low-dimensional space. Based on this observation, we propose DRONE (data-aware low-rank compression), a provably optimal low-rank decomposition of weight matrices, which has a simple closed form solution that can be efficiently computed. DRONE can be applied to both fully connected and self-attention layers appearing in the BERT model. In addition to compressing standard models, out method can also be used on distilled BERT models to further improve compression rate. Experimental results show that DRONE is able to improve both model size and inference speed with limited loss in accuracy. Specifically, DRONE alone achieves 1.92x speedup on the MRPC task with only 1.5% loss in accuracy, and when DRONE is combined with distillation, it further achieves over 12.3x speedup on various natural language inference tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "DSelect-k", "Title": "Differentiable Selection in the Mixture of Experts with Applications to Multi-Task Learning", "Abstract": "The Mixture-of-Experts (MoE) architecture is showing promising results in improving parameter sharing in multi-task learning (MTL) and in scaling high-capacity neural networks. State-of-the-art MoE models use a trainable \"sparse gate'\" to select a subset of the experts for each input example. While conceptually appealing, existing sparse gates, such as Top-k, are not smooth. The lack of smoothness can lead to convergence and statistical performance issues when training with gradient-based methods. In this paper, we develop DSelect-k: a continuously differentiable and sparse gate for MoE, based on a novel binary encoding formulation. The gate can be trained using first-order methods, such as stochastic gradient descent, and offers explicit control over the number of experts to select. We demonstrate the effectiveness of DSelect-k on both synthetic and real MTL datasets with up to 128 tasks. Our experiments indicate that DSelect-k can achieve statistically significant improvements in prediction and expert selection over popular MoE gates. Notably, on a real-world, large-scale recommender system, DSelect-k achieves over 22% improvement in predictive performance compared to Top-k. We provide an open-source implementation of DSelect-k."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Mind the Gap", "Title": "Assessing Temporal Generalization in Neural Language Models", "Abstract": "Our world is open-ended, non-stationary, and constantly evolving; thus what we talk about and how we talk about it change over time. This inherent dynamic nature of language contrasts with the current static language modelling paradigm, which trains and evaluates models on utterances from overlapping time periods. Despite impressive recent progress, we demonstrate that Transformer-XL language models perform worse in the realistic setup of predicting future utterances from beyond their training period, and that model performance becomes increasingly worse with time. We find that, while increasing model size alone—a key driver behind recent progress—does not solve this problem, having models that continually update their knowledge with new information can indeed mitigate this performance degradation over time. Hence, given the compilation of ever-larger language modelling datasets, combined with the growing list of language-model-based NLP applications that require up-to-date factual knowledge about the world, we argue that now is the right time to rethink the static way in which we currently train and evaluate our language models, and develop adaptive language models that can remain up-to-date with respect to our ever-changing and non-stationary world. We publicly release our dynamic, streaming language modelling benchmarks for WMT and arXiv to facilitate language model evaluation that takes temporal dynamics into account."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "FMMformer", "Title": "Efficient and Flexible Transformer via Decomposed Near-field and Far-field Attention", "Abstract": "We propose FMMformers, a class of efficient and flexible transformers inspired by the celebrated fast multipole method (FMM) for accelerating interacting particle simulation. FMM decomposes particle-particle interaction into near-field and far-field components and then performs direct and coarse-grained computation, respectively. Similarly, FMMformers decompose the attention into near-field and far-field attention, modeling the near-field attention by a banded matrix and the far-field attention by a low-rank matrix. Computing the attention matrix for FMMformers requires linear complexity in computational time and memory footprint with respect to the sequence length. In contrast, standard transformers suffer from quadratic complexity. We analyze and validate the advantage of FMMformers over the standard transformer on the Long Range Arena and language modeling benchmarks. FMMformers can even outperform the standard transformer in terms of accuracy by a significant margin. For instance, FMMformers achieve an average classification accuracy of $60.74\\%$ over the five Long Range Arena tasks, which is significantly better than the standard transformer's average accuracy of $58.70\\%$."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Square Root Principal Component Pursuit", "Title": "Tuning-Free Noisy Robust Matrix Recovery", "Abstract": "We propose a new framework -- Square Root Principal Component Pursuit -- for low-rank matrix recovery from observations corrupted with noise and outliers. Inspired by the square root Lasso, this new formulation does not require prior knowledge of the noise level. We show that a single, universal choice of the regularization parameter suffices to achieve reconstruction error proportional to the (a priori unknown) noise level. In comparison, previous formulations such as stable PCP rely on noise-dependent parameters to achieve similar performance, and are therefore challenging to deploy in applications where the noise level is unknown. We validate the effectiveness of our new method through experiments on simulated and real datasets. Our simulations corroborate the claim that a universal choice of the regularization parameter yields near optimal performance across a range of noise levels, indicating that the proposed method outperforms the (somewhat loose) bound proved here."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Bellman-Ford Networks", "Title": "A General Graph Neural Network Framework for Link Prediction", "Abstract": "Link prediction is a very fundamental task on graphs. Inspired by traditional path-based methods, in this paper we propose a general and flexible representation learning framework based on paths for link prediction. Specifically, we define the representation of a pair of nodes as the generalized sum of all path representations, with each path representation as the generalized product of the edge representations in the path. Motivated by the Bellman-Ford algorithm for solving the shortest path problem, we show that the proposed path formulation can be efficiently solved by the generalized Bellman-Ford algorithm. To further improve the capacity of the path formulation, we propose the Neural Bellman-Ford Network (NBFNet), a general graph neural network framework that solves the path formulation with learned operators in the generalized Bellman-Ford algorithm. The NBFNet parameterizes the generalized Bellman-Ford algorithm with 3 neural components, namely Indicator, Message and Aggregate functions, which corresponds to the boundary condition, multiplication operator, and summation operator respectively. The NBFNet covers many traditional path-based methods, and can be applied to both homogeneous graphs and multi-relational graphs (e.g., knowledge graphs) in both transductive and inductive settings. Experiments on both homogeneous graphs and knowledge graphs show that the proposed NBFNet outperforms existing methods by a large margin in both transductive and inductive settings, achieving new state-of-the-art results."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "CorticalFlow", "Title": "A Diffeomorphic Mesh Transformer Network for Cortical Surface Reconstruction", "Abstract": "In this paper, we introduce CorticalFlow, a new geometric deep-learning model that, given a 3-dimensional image, learns to deform a reference template towards a targeted object. To conserve the template mesh’s topological properties, we train our model over a set of diffeomorphic transformations. This new implementation of a flow Ordinary Differential Equation (ODE) framework benefits from a small GPU memory footprint, allowing the generation of surfaces with several hundred thousand vertices. To reduce topological errors introduced by its discrete resolution, we derive numeric conditions which improve the manifoldness of the predicted triangle mesh. To exhibit the utility of CorticalFlow, we demonstrate its performance for the challenging task of brain cortical surface reconstruction. In contrast to the current state-of-the-art, CorticalFlow produces superior surfaces while reducing the computation time from nine and a half minutes to one second. More significantly, CorticalFlow enforces the generation of anatomically plausible surfaces; the absence of which has been a major impediment restricting the clinical relevance of such surface reconstruction methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SLOE", "Title": "A Faster Method for Statistical Inference in High-Dimensional Logistic Regression", "Abstract": "Logistic regression remains one of the most widely used tools in applied statistics, machine learning and data science. However, in moderately high-dimensional problems, where the number of features $d$ is a non-negligible fraction of the sample size $n$, the logistic regression maximum likelihood estimator (MLE), and statistical procedures based the large-sample approximation of its distribution, behave poorly. Recently, Sur and Candès (2019) showed that these issues can be corrected by applying a new approximation of the MLE's sampling distribution in this high-dimensional regime. Unfortunately, these corrections are difficult to implement in practice, because they require an estimate of the \\emph{signal strength}, which is a function of the underlying parameters $\\beta$ of the logistic regression. To address this issue, we propose SLOE, a fast and straightforward approach to estimate the signal strength in logistic regression. The key insight of SLOE is that the Sur and Candès (2019) correction can be reparameterized in terms of the corrupted signal strength, which is only a function of the estimated parameters $\\widehat \\beta$. We propose an estimator for this quantity, prove that it is consistent in the relevant high-dimensional regime, and show that dimensionality correction using SLOE is accurate in finite samples. Compared to the existing ProbeFrontier heuristic, SLOE is conceptually simpler and orders of magnitude faster, making it suitable for routine use. We demonstrate the importance of routine dimensionality correction in the Heart Disease dataset from the UCI repository, and a genomics application using data from the UK Biobank."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "ELLA", "Title": "Exploration through Learned Language Abstraction", "Abstract": "Building agents capable of understanding language instructions is critical to effective and robust human-AI collaboration. Recent work focuses on training these agents via reinforcement learning in environments with synthetic language; however, instructions often define long-horizon, sparse-reward tasks, and learning policies requires many episodes of experience. We introduce ELLA: Exploration through Learned Language Abstraction, a reward shaping approach geared towards boosting sample efficiency in sparse reward environments by correlating high-level instructions with simpler low-level constituents. ELLA has two key elements: 1) A termination classifier that identifies when agents complete low-level instructions, and 2) A relevance classifier that correlates low-level instructions with success on high-level tasks. We learn the termination classifier offline from pairs of instructions and terminal states. Notably, in departure from prior work in language and abstraction, we learn the relevance classifier online, without relying on an explicit decomposition of high-level instructions to low-level instructions. On a suite of complex BabyAI environments with varying instruction complexities and reward sparsity, ELLA shows gains in sample efficiency relative to language-based shaping and traditional RL methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "On the Role of Optimization in Double Descent", "Title": "A Least Squares Study", "Abstract": "Empirically it has been observed that the performance of deep neural networks steadily improves with increased model size, contradicting the classical view on overfitting and generalization. Recently, the double descent phenomenon has been proposed to reconcile this observation with theory, suggesting that the test error has a second descent when the model becomes sufficiently overparameterized, as the model size itself acts as an implicit regularizer. In this paper we add to the growing body of work in this space, providing a careful study of learning dynamics as a function of model size for the least squares scenario. We show an excess risk bound for the gradient descent solution of the least squares objective. The bound depends on the smallest non-zero eigenvalue of the sample covariance matrix of the input features, via a functional form that has the double descent behaviour. This gives a new perspective on the double descent curves reported in the literature, as our analysis of the excess risk allows to decouple the effect of optimization and generalization error. In particular, we find that in the case of noiseless regression, double descent is explained solely by optimization-related quantities, which was missed in studies focusing on the Moore-Penrose pseudoinverse solution. We believe that our derivation provides an alternative view compared to existing works, shedding some light on a possible cause of this phenomenon, at least in the considered least squares setting. We empirically explore if our predictions hold for neural networks, in particular whether the spectrum of the sample covariance of features at intermediary hidden layers has a similar behaviour as the one predicted by our derivations in the least squares setting."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Automatic and Harmless  Regularization  with Constrained and Lexicographic Optimization", "Title": "A Dynamic Barrier Approach", "Abstract": "Many machine learning tasks have to make a trade-off between two loss functions, typically the main data-fitness loss and an auxiliary loss. The most widely used approach is to optimize the linear combination of the objectives, which, however, requires manual tuning of the combination coefficient and is theoretically unsuitable for non-convex functions. In this work, we consider constrained optimization as a more principled approach for trading off two losses, with a special emphasis on lexicographic optimization, a degenerated limit of constrained optimization which optimizes a secondary loss inside the optimal set of the main loss. We propose a dynamic barrier gradient descent algorithm which provides a unified solution of both constrained and lexicographic optimization. We establish the convergence of the method for general non-convex functions."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "BlendGAN", "Title": "Implicitly GAN Blending for Arbitrary Stylized Face Generation", "Abstract": "Generative Adversarial Networks (GANs) have made a dramatic leap in high-fidelity image synthesis and stylized face generation. Recently, a layer-swapping mechanism has been developed to improve the stylization performance. However, this method is incapable of fitting arbitrary styles in a single model and requires hundreds of style-consistent training images for each style. To address the above issues, we propose BlendGAN for arbitrary stylized face generation by leveraging a flexible blending strategy and a generic artistic dataset. Specifically, we first train a self-supervised style encoder on the generic artistic dataset to extract the representations of arbitrary styles. In addition, a weighted blending module (WBM) is proposed to blend face and style representations implicitly and control the arbitrary stylization effect. By doing so, BlendGAN can gracefully fit arbitrary styles in a unified model while avoiding case-by-case preparation of style-consistent training images. To this end, we also present a novel large-scale artistic face dataset AAHQ. Extensive experiments demonstrate that BlendGAN outperforms state-of-the-art methods in terms of visual quality and style diversity for both latent-guided and reference-guided stylized face synthesis."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "NeRS", "Title": "Neural Reflectance Surfaces for Sparse-view 3D Reconstruction in the Wild", "Abstract": "Recent history has seen a tremendous growth of work exploring implicit representations of geometry and radiance, popularized through Neural Radiance Fields (NeRF).  Such works are fundamentally based on a (implicit) {\\em volumetric} representation of occupancy, allowing them to model diverse scene structure including translucent objects and atmospheric obscurants. But because the vast majority of real-world scenes are composed of well-defined surfaces, we introduce a {\\em surface} analog of such implicit models called Neural Reflectance Surfaces (NeRS). NeRS learns a neural shape representation of a closed surface that is diffeomorphic to a sphere, guaranteeing water-tight reconstructions. Even more importantly, surface parameterizations allow NeRS to learn (neural) bidirectional surface reflectance functions (BRDFs) that factorize view-dependent appearance into environmental illumination, diffuse color (albedo), and specular “shininess.” Finally, rather than illustrating our results on synthetic scenes or controlled in-the-lab capture, we assemble a novel dataset of multi-view images from online marketplaces for selling goods. Such “in-the-wild” multi-view image sets pose a number of challenges, including a small number of views with unknown/rough camera estimates. We demonstrate that surface-based neural reconstructions enable learning from such data, outperforming volumetric neural rendering-based reconstructions. We hope that NeRS serves as a first step toward building scalable, high-quality libraries of real-world shape, materials, and illumination."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Beta-CROWN", "Title": "Efficient Bound Propagation with Per-neuron Split Constraints for Neural Network Robustness Verification", "Abstract": "Bound propagation based incomplete neural network verifiers such as CROWN are very efficient and can significantly accelerate branch-and-bound (BaB) based complete verification of neural networks. However, bound propagation cannot fully handle the neuron split constraints introduced by BaB commonly handled by expensive linear programming (LP) solvers, leading to loose bounds and hurting verification efficiency. In this work, we develop $\\beta$-CROWN, a new bound propagation based method that can fully encode neuron splits via optimizable parameters $\\beta$ constructed from either primal or dual space. When jointly optimized in intermediate layers, $\\beta$-CROWN generally produces better bounds than typical LP verifiers with neuron split constraints, while being as efficient and parallelizable as CROWN on GPUs. Applied to complete robustness verification benchmarks, $\\beta$-CROWN with BaB is up to three orders of magnitude faster than LP-based BaB methods, and is notably faster than all existing approaches while producing lower timeout rates. By terminating BaB early, our method can also be used for efficient incomplete verification.  We consistently achieve higher verified accuracy in many settings compared to powerful incomplete verifiers, including those based on convex barrier breaking techniques. Compared to the typically tightest but very costly semidefinite programming (SDP) based incomplete verifiers, we obtain higher verified accuracy with three orders of magnitudes less verification time. Our algorithm empowered the $\\alpha,\\!\\beta$-CROWN (alpha-beta-CROWN) verifier, the winning tool in VNN-COMP 2021. Our code is available at http://PaperCode.cc/BetaCROWN."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Autobahn", "Title": "Automorphism-based Graph Neural Nets", "Abstract": "We introduce Automorphism-based graph neural networks (Autobahn), a new family of graph neural networks. In an Autobahn, we decompose the graph into a collection of subgraphs and apply local convolutions that are equivariant to each subgraph's automorphism group. Specific choices of local neighborhoods and subgraphs recover existing architectures such as message passing neural networks. Our formalism also encompasses novel architectures: as an example, we introduce a graph neural network that decomposes the graph into paths and cycles. The resulting convolutions reflect the natural way that parts of the graph can transform, preserving the intuitive meaning of convolution without sacrificing global permutation equivariance. We validate our approach by applying Autobahn to molecular graphs, where it achieves results competitive with state-of-the-art message passing algorithms."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Shape from Blur", "Title": "Recovering Textured 3D Shape and Motion of Fast Moving Objects", "Abstract": "We address the novel task of jointly reconstructing the 3D shape, texture, and motion of an object from a single motion-blurred image. While previous approaches address the deblurring problem only in the 2D image domain, our proposed rigorous modeling of all object properties in the 3D domain enables the correct description of arbitrary object motion. This leads to significantly better image decomposition and sharper deblurring results. We model the observed appearance of a motion-blurred object as a combination of the background and a 3D object with constant translation and rotation. Our method minimizes a loss on reconstructing the input image via differentiable rendering with suitable regularizers. This enables estimating the textured 3D mesh of the blurred object with high fidelity. Our method substantially outperforms competing approaches on several benchmarks for fast moving objects deblurring. Qualitative results show that the reconstructed 3D mesh generates high-quality temporal super-resolution and novel views of the deblurred object."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Delayed Gradient Averaging", "Title": "Tolerate the Communication Latency for Federated Learning", "Abstract": "Federated Learning is an emerging direction in distributed machine learning that en-ables jointly training a model without sharing the data. Since the data is distributed across many edge devices through wireless / long-distance connections, federated learning suffers from inevitable high communication latency. However, the latency issues are undermined in the current literature [15] and existing approaches suchas FedAvg [27] become less efficient when the latency increases.  To over comethe problem, we propose \\textbf{D}elayed \\textbf{G}radient \\textbf{A}veraging (DGA), which delays the averaging step to improve efficiency and allows local computation in parallel tocommunication. We theoretically prove that DGA attains a similar convergence rate as FedAvg, and empirically show that our algorithm can tolerate high network latency without compromising accuracy. Specifically, we benchmark the training speed on various vision (CIFAR, ImageNet) and language tasks (Shakespeare),with both IID and non-IID partitions, and show DGA can bring 2.55$\\times$ to 4.07$\\times$ speedup. Moreover, we built a 16-node Raspberry Pi cluster and show that DGA can consistently speed up real-world federated learning applications."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MICo", "Title": "Improved representations via sampling-based state similarity for Markov decision processes", "Abstract": "We present a new behavioural distance over the state space of a Markov decision process, and demonstrate the use of this distance as an effective means of shaping the learnt representations of deep reinforcement learning agents. While existing notions of state similarity are typically difficult to learn at scale due to high computational cost and lack of sample-based algorithms, our newly-proposed distance addresses both of these issues. In addition to providing detailed theoretical analyses, we provide empirical evidence that learning this distance alongside the value function yields structured and informative representations, including strong results on the Arcade Learning Environment benchmark."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "SmoothMix", "Title": "Training Confidence-calibrated Smoothed Classifiers for Certified Robustness", "Abstract": "Randomized smoothing is currently a state-of-the-art method to construct a certifiably robust classifier from neural networks against $\\ell_2$-adversarial perturbations. Under the paradigm, the robustness of a classifier is aligned with the prediction confidence, i.e., the higher confidence from a smoothed classifier implies the better robustness. This motivates us to rethink the fundamental trade-off between accuracy and robustness in terms of calibrating confidences of a smoothed classifier. In this paper, we propose a simple training scheme, coined SmoothMix, to control the robustness of smoothed classifiers via self-mixup: it trains on convex combinations of samples along the direction of adversarial perturbation for each input. The proposed procedure effectively identifies over-confident, near off-class samples as a cause of limited robustness in case of smoothed classifiers, and offers an intuitive way to adaptively set a new decision boundary between these samples for better robustness. Our experimental results demonstrate that the proposed method can significantly improve the certified $\\ell_2$-robustness of smoothed classifiers compared to existing state-of-the-art robust training methods."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "MobTCast", "Title": "Leveraging Auxiliary Trajectory Forecasting for Human Mobility Prediction", "Abstract": "Human mobility prediction is a core functionality in many location-based services and applications. However, due to the sparsity of mobility data, it is not an easy task to predict future POIs (place-of-interests) that are going to be visited. In this paper, we propose MobTCast, a Transformer-based context-aware network for mobility prediction. Specifically, we explore the influence of four types of context in mobility prediction: temporal, semantic, social, and geographical contexts. We first design a base mobility feature extractor using the Transformer architecture, which takes both the history POI sequence and the semantic information as input. It handles both the temporal and semantic contexts. Based on the base extractor and the social connections of a user, we employ a self-attention module to model the influence of the social context. Furthermore, unlike existing methods, we introduce a location prediction branch in MobTCast as an auxiliary task to model the geographical context and predict the next location. Intuitively, the geographical distance between the location of the predicted POI and the predicted location from the auxiliary branch should be as close as possible. To reflect this relation, we design a consistency loss to further improve the POI prediction performance. In our experimental results, MobTCast outperforms other state-of-the-art next POI prediction methods. Our approach illustrates the value of including different types of context in next POI prediction."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "InfoGCL", "Title": "Information-Aware Graph Contrastive Learning", "Abstract": "Various graph contrastive learning models have been proposed to improve the performance of tasks on graph datasets in recent years. While effective and prevalent, these models are usually carefully customized. In particular, despite all recent work create two contrastive views, they differ in a variety of view augmentations, architectures, and objectives. It remains an open question how to build your graph contrastive learning model from scratch for particular graph tasks and datasets. In this work, we aim to fill this gap by studying how graph information is transformed and transferred during the contrastive learning process, and proposing an information-aware graph contrastive learning framework called InfoGCL. The key to the success of the proposed framework is to follow the Information Bottleneck principle to reduce the mutual information between contrastive parts while keeping task-relevant information intact at both the levels of the individual module and the entire framework so that the information loss during graph representation learning can be minimized. We show for the first time that all recent graph contrastive learning methods can be unified by our framework. Based on theoretical and empirical analysis on benchmark graph datasets, we show that InfoGCL achieves state-of-the-art performance in the settings of both graph classification and node classification tasks."}
{"Type": "conference", "Year": "2021", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Causal-BALD", "Title": "Deep Bayesian Active Learning of Outcomes to Infer Treatment-Effects from Observational Data", "Abstract": "Estimating personalized treatment effects from high-dimensional observational data is essential in situations where experimental designs are infeasible, unethical, or expensive. Existing approaches rely on fitting deep models on outcomes observed for treated and control populations. However, when measuring individual outcomes is costly, as is the case of a tumor biopsy, a sample-efficient strategy for acquiring each result is required. Deep Bayesian active learning provides a framework for efficient data acquisition by selecting points with high uncertainty. However, existing methods bias training data acquisition towards regions of non-overlapping support between the treated and control populations. These are not sample-efficient because the treatment effect is not identifiable in such regions. We introduce causal, Bayesian acquisition functions grounded in information theory that bias data acquisition towards regions with overlapping support to maximize sample efficiency for learning personalized treatment effects. We demonstrate the performance of the proposed acquisition strategies on synthetic and semi-synthetic datasets IHDP and CMNIST and their extensions, which aim to simulate common dataset biases and pathologies."}
