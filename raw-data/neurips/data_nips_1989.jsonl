{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Development and Regeneration of Eye-Brain Maps", "Title": "A Computational Model", "Abstract": "We outline a computational model  of the development and regenera(cid:173) tion of specific eye-brain circuits. The model comprises a self-organiz(cid:173) ing map-forming network which uses local Hebb rules. constrained by  molecular markers.  Various  simulations of the development of eye(cid:173) brain maps in fish and frogs are described."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Predicting Weather Using a Genetic Memory", "Title": "A Combination of Kanerva's Sparse Distributed Memory with Holland's Genetic Algorithms", "Abstract": "Kanerva's  sparse distributed  memory  (SDM)  is  an  associative-memo(cid:173) ry  model  based  on  the  mathematical  properties  of  high-dimensional  binary address  spaces.  Holland's genetic  algorithms are  a  search  tech(cid:173) nique  for  high-dimensional  spaces  inspired  by  evolutionary  processes  of DNA.  \"Genetic  Memory\"  is  a  hybrid  of the  above  two  systems,  in  which  the  memory  uses  a  genetic  algorithm  to  dynamically  recon(cid:173) figure  its  physical  storage  locations  to  reflect  correlations  between  the  stored  addresses  and  data.  For  example,  when  presented  with  raw  weather station  data,  the  Genetic  Memory  discovers  specific  fea(cid:173) tures  in  the  weather  data  which  correlate  well  with  upcoming  rain,  and  reconfigures  the  memory  to  utilize  this  information  effectively.  This  architecture  is  designed  to  maximize  the  ability  of the  system  to scale-up to handle real-world problems."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Networks", "Title": "The Early Days", "Abstract": "A short account is  given of various  investigations of neural  network  properties,  beginning  with  the  classic  work of McCulloch  & Pitts.  Early work on neurodynamics and statistical mechanics, analogies with  magnetic materials, fault tolerance via parallel distributed processing,  memory, learning,  and pattern recognition,  is described."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Acoustic-Imaging Computations by Echolocating Bats", "Title": "Unification of Diversely-Represented Stimulus Features into Whole Images", "Abstract": "the  same  psychological"}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neuronal Group Selection Theory", "Title": "A Grounding in Robotics", "Abstract": "(1 - p)N  (see  Fig.  1)."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Computational Efficiency", "Title": "A Common Organizing Principle for Parallel Computer Maps and Brain Maps?", "Abstract": "It is  well-known  that  neural  responses  in  particular  brain  regions  are  spatially  organized,  but  no  general  principles  have  been  de(cid:173) veloped  that  relate  the structure of a  brain  map  to  the nature of  the associated computation.  On parallel computers, maps of a sort  quite similar to brain maps arise when a computation is distributed  across  multiple  processors.  In  this  paper  we  will  discuss  the rela(cid:173) tionship  between  maps and computations on these  computers and  suggest how similar considerations might also apply to maps in the  brain."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Generalization and Parameter Estimation in Feedforward Nets", "Title": "Some Experiments", "Abstract": "We have done an empirical study of the relation of the number of  parameters (weights) in a feedforward net to generalization perfor(cid:173) mance. Two experiments are reported. In one, we use simulated data  sets with well-controlled parameters, such as the signal-to-noise ratio  of continuous-valued data. In the second, we train the network on  vector-quantized mel cepstra from real speech samples. In each case,  we use back-propagation to train the feedforward net to discriminate in  a multiple class pattern classification problem. We report the results of  these studies, and show the application of cross-validation techniques  to prevent overfitting."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Sigma-Pi Learning", "Title": "On Radial Basis Functions and Cortical Associative Learning", "Abstract": "The  goal  in  this  work  has  been  to  identify  the  neuronal  elements  of the cortical column that are most likely to support  the learning  of nonlinear associative  maps.  We show that  a  particular style  of  network learning algorithm based on locally-tuned  receptive fields  maps  naturally  onto cortical  hardware,  and  gives  coherence  to  a  variety of features  of cortical anatomy,  physiology,  and  biophysics  whose  relations to learning remain poorly understood."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Effect of Catecholamines on Performance", "Title": "From Unit to System Behavior", "Abstract": "At the level of individual neurons. catecholamine release increases  the  responsivity  of cells  to  excitatory and  inhibitory  inputs.  We  present a  model  of catecholamine effects  in  a  network  of neural-like  elements.  We  argue  that  changes  in  the  responsivity  of individual  elements  do  not  affect  their  ability  to  detect  a  signal  and  ignore  noise.  However.  the same changes in cell responsivity in a network of such elements do  improve the signal detection performance of the network as a whole.  We  show how  this result can be used in a computer simulation of behavior  to  account  for  the  effect  of eNS  stimulants  on  the  signal  detection  performance of human subjects."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Dataflow Architectures", "Title": "Flexible Platforms for Neural Network Simulation", "Abstract": "Dataflow Architectures:  Flexible Platforms for Neural Network Simulation"}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Asymptotic Convergence of Backpropagation", "Title": "Numerical Experiments", "Abstract": "We  have  calculated, both analytically and in simulations,  the rate  of convergence  at  long  times  in  the  backpropagation learning  al(cid:173) gorithm  for  networks  with  and  without  hidden  units.  Our  basic  finding for units using the standard sigmoid transfer function is  lit  convergence of the  error for  large t,  with  at most logarithmic cor(cid:173) rections  for  networks  with  hidden  units.  Other transfer functions  may lead to a  8lower polynomial rate of convergence.  Our analytic  calculations were presented in (Tesauro, He &  Ahamd, 1989).  Here  we  focus  in more detail on our empirical measurements of the con(cid:173) vergence rate in numerical simulations,  which  confirm our analytic  results."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Analog Neural Networks of Limited Precision I", "Title": "Computing with Multilinear Threshold Functions", "Abstract": "703"}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "Neural Implementation of Motivated Behavior", "Title": "Feeding in an Artificial Insect", "Abstract": "Most  complex  behaviors  appear  to be governed  by  internal  moti(cid:173) vational  states or  drives  that  modify  an  animal's  responses  to  its  environment.  It is  therefore of considerable  interest to understand  the  neural basis of these  motivational states.  Drawing upon work  on  the  neural  basis  of feeding  in  the  marine  mollusc  Aplysia,  we  have  developed  a  heterogeneous  artificial  neural  network  for  con(cid:173) trolling the feeding behavior of a simulated insect.  We demonstrate  that feeding in this artificial insect shares many characteristics with  the motivated behavior of natural animals."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "The Cocktail Party Problem", "Title": "Speech/Data Signal Separation Comparison between Backpropagation and SONN", "Abstract": "This  work  introduces  a  new  method  called  Self  Organizing  Neural  Network  (SONN)  algorithm  and  compares  its  performance  with Back  Propagation  in  a  signal  separation  application.  The  problem  is  to  separate  two  signals;  a  modem  data signal  and  a  male  speech  signal,  added and transmitted  through  a  4 khz  channel.  The signals  are sam(cid:173) pled  at  8  khz,  and  using  supervised  learning,  an  attempt  is  made  to  reconstruct  them.  The  SONN  is  an  algorithm  that  constructs  its  own  network  topology  during  training,  which  is  shown  to  be  much  smaller  than  the  BP  network,  faster  to  trained,  and  free  from  the  trial-and(cid:173) error network design that characterize BP."}
{"Type": "conference", "Year": "1989", "Area": "AI", "Where": "NeurIPS", "Abbreviation": "TRAFFIC", "Title": "Recognizing Objects Using Hierarchical Reference Frame Transformations", "Abstract": "We  describe a model that can recognize  two-dimensional shapes in  an  unsegmented  image,  independent  of their orientation,  position,  and scale.  The model,  called TRAFFIC, efficiently  represents  the  structural  relation  between  an  object  and  each  of its  component  features  by  encoding  the fixed  viewpoint-invariant transformation  from the feature's reference frame to the object's in the weights of a  connectionist  network.  Using  a  hierarchy  of such  transformations,  with increasing complexity of features  at each successive  layer,  the  network  can  recognize  multiple objects  in parallel.  An implemen(cid:173) tation  of TRAFFIC  is  described,  along with  experimental  results  demonstrating  the  network's  ability to  recognize  constellations  of  stars in  a viewpoint-invariant manner."}
