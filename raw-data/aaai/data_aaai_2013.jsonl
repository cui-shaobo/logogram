{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "OpenEval", "Title": "Web Information Query Evaluation", "Abstract": "In this paper, we investigate information validation tasks that are initiated as queries from either automated agents or humans.  We introduce OpenEval, a new online information validation technique, which uses  information on the web to automatically evaluate the truth of queries that are stated as multi-argument predicate instances (e.g., DrugHasSideEffect(Aspirin,GI Bleeding)).  OpenEval gets a small number of instances of a predicate as seed positive examples and automatically learns how to evaluate the truth of a new predicate instance by querying the web and processing the retrieved unstructured web pages. We show that OpenEval is able to respond to the queries within a limited amount of time while also achieving high F1 score. In addition, we show that the accuracy of responses provided by OpenEval is increased as more time is given for evaluation.  We have extensively tested our model and shown empirical results that illustrate the effectiveness of our approach compared to related techniques."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "TONIC", "Title": "Target Oriented Network Intelligence Collection for the Social Web", "Abstract": "In this paper we introduce the Target Oriented Network Intelligence Collection (TONIC) problem, which is the problem of finding profiles in a social network that contain information about a given target via automated crawling. We formalize TONIC as a search problem and a best-first approach is proposed for solving it.Several heuristics are presented to guide this search.These heuristics are based on the topology of the currently known part of the social network.The efficiency of the proposed heuristics and the effect of the graph topology on their performance is experimentally evaluated on the Google+ social network."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Not Quite the Same", "Title": "Identity Constraints for the Web of Linked Data", "Abstract": "Linked Data is based on the idea that information from different sources can flexibly be connected to enable novel applications that individual datasets do not support on their own. This hinges upon the existence of links between datasets that would otherwise be isolated. The most notable form, sameAs links, are intended to express that two identifiers are equivalent in all respects. Unfortunately, many existing ones do not reflect such genuine identity. This study provides a novel method to analyse this phenomenon, based on a thorough theoretical analysis, as well as a novel graph-based method to resolve such issues to some extent. Our experiments on a representative Web-scale set of sameAs links from the Web of Data show that our method can identify and remove hundreds of thousands of constraint violations.Linked Data is based on the idea that information from different sources can flexibly be connected to enable novel applications that individual datasets do not support on their own. This hinges upon the existence of links between datasets that would otherwise be isolated. The most notable form, sameAs links, are intended to express that two identifiers are equivalent in all respects. Unfortunately, many existing ones do not reflect such genuine identity. This study provides a novel method to analyse this phenomenon, based on a thorough theoretical analysis, as well as a novel graph-based method to resolve such issues to some extent. Our experiments on a representative Web-scale set of sameAs links from the Web of Data show that our method can identify and remove hundreds of thousands of constraint violations."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "LA-CTR", "Title": "A Limited Attention Collaborative Topic Regression for Social Media", "Abstract": "Probabilistic models can learn users' preferences from the history of their item adoptions on a social media site, and in turn, recommend new items to users based on learned preferences. However, current models ignore psychological factors that play an important role in shaping online social behavior. One such factor is attention, the mechanism that integrates perceptual and cognitive features to select the items the user will consciously process and may eventually adopt. Recent research has shown that people have finite attention, which constrains their online interactions, and that they divide their limited attention non-uniformly over other people. We propose a collaborative topic regression model that incorporates limited, non-uniformly divided attention. We show that the proposed model is able to learn more accurate user preferences than state-of-art models, which do not take human cognitive factors into account. Specifically we analyze voting on news items on the social news aggregator and show that our model is better able to predict held out votes than alternate models. Our study demonstrates that psycho-socially motivated models are better able to describe and predict observed behavior than models which only consider latent social structure and content."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "SALL-E", "Title": "Situated Agent for Language Learning", "Abstract": "We describe ongoing research towards building a cognitively plausible system for near one-shot learning of the meanings of attribute words and object names, by grounding them in a sensory model. The system learns incrementally from human demonstrations recorded with the Microsoft Kinect, in which the demonstrator can use unrestricted natural language descriptions. We achieve near-one shot learning of simple objects and attributes by focusing solely on examples where the learning agent is confident, ignoring the rest of the data. We evaluate the system's learning ability by having it generate descriptions of presented objects, including objects it has never seen before, and comparing the system response against collected human descriptions of the same objects. We propose that our method of retrieving object examples with a k-nearest neighbor classifier using Mahalanobis distance corresponds to a cognitively plausible representation of objects. Our initial results show promise for achieving rapid, near one-shot, incremental learning of word meanings."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Adaptive Spatio-Temporal Exploratory Models", "Title": "Hemisphere-wide species distributions from massively crowdsourced eBird data", "Abstract": "Broad-scale spatiotemporal processes in conservation and sustainability science, such as continent-wide animal movement, occur across a range of spatial and temporal scales. Understanding these processes at multiple scales is crucial for developing and coordinating conservation strategies across national boundaries. In this paper we propose a general class of models we call AdaSTEM, for Adaptive Spatio-Temporal Exploratory Models, that are able to exploit variation in the density of observations while adapting to multiple scales in space and time. We show that this framework is able to efficiently discover multiscale structure when it is present, while retaining predictive performance when absent. We provide an empirical comparison and analysis, offer theoretical insights from the ensemble loss decomposition, and deploy AdaSTEM to estimate the spatiotemporal distribution of Barn Swallow (Hirundo rustica) across the Western Hemisphere using massively crowdsourced eBird data."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "PAC Optimal Planning for Invasive Species Management", "Title": "Improved Exploration for Reinforcement Learning from Simulator-Defined MDPs", "Abstract": "Often the most practical way to define a Markov Decision Process (MDP) is as a simulator that, given a state and an action, produces a resulting state and immediate reward sampled from the corresponding distributions.  Simulators in natural resource management can be very expensive to execute, so that the time required to solve such MDPs is dominated by the number of calls to the simulator. This paper presents an algorithm, DDV, that combines improved confidence intervals on the Q values (as in interval estimation) with a novel upper bound on the discounted state occupancy probabilities to intelligently choose state-action pairs to explore. We prove that this algorithm terminates with a policy whose value is within epsilon of the optimal policy (with probability 1-delta) after making only polynomially-many calls to the simulator.  Experiments on one benchmark MDP and on an MDP for invasive species management show very large reductions in the number of simulator calls required."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "A Temporal Motif Mining Approach to Unsupervised Energy Disaggregation", "Title": "Applications to Residential and Commercial Buildings", "Abstract": "Non-intrusive appliance load monitoring has emerged as an attractive approach to study energy consumption patterns without instrumenting every device in a building. The ensuing computational problem is to disaggregate total energy usage into usage by specific devices, to gain insight into consumption patterns. We exploit the temporal ordering implicit in on/off events of devices to uncover motifs (episodes) corresponding to the operation of individual devices. Extracted motifs are then subjected to a sequence of constraint checks to ensure that the resulting episodes are interpretable. Our results reveal that motif mining is adept at distinguishing devices with multiple power levels and at disentangling the combinatorial operation of devices. With suitably configured processing steps, we demonstrate the applicability of our method to both residential and commercial buildings."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Multiple Hypothesis Object Tracking For Unsupervised Self-Learning", "Title": "An Ocean Eddy Tracking Application", "Abstract": "Mesoscale ocean eddies transport heat, salt, energy, and nutrients across oceans. As a result, accurately identifying and tracking such phenomena are crucial for understanding ocean dynamics and marine ecosystem sustainability. Traditionally, ocean eddies are monitored through two phases: identification and tracking. A major challenge for such an approach is that the tracking phase is dependent on the performance of the identification scheme, which can be susceptible to noise and sampling errors. In this paper, we focus on tracking, and introduce the concept of multiple hypothesis assignment (MHA), which extends traditional multiple hypothesis tracking for cases where the features tracked are noisy or uncertain. Under this scheme, features are assigned to multiple potential tracks, and the final assignment is deferred until more data are available to make a relatively unambiguous decision. Unlike the most widely used methods in the eddy tracking literature, MHA uses contextual spatio-temporal information to take corrective measures autonomously on the detection step a pos- teriori and performs significantly better in the presence of noise. This study is also the first to empirically analyze the relative robustness of eddy tracking algorithms."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Enabling E-Mobility", "Title": "Facility Location for Battery Loading Stations", "Abstract": "The short cruising range due to the limited battery supply of current Electric Vehicles (EVs) is one of the main obstacles for a complete transition to E-mobility. Until batteries ofhigher energy storage density have been developed, it is of utmost importance to deliberately plan the locations of new loading stations for best possible coverage. Ideally the network of loading stations should allow driving from anywhere to anywhere (and back) without running out of energy. We show that minimizing the number of necessary loading stations to achieve this goal is NP-hard and even worse, we can rule out polynomial-time constant approximation algorithms. Hence algorithms with better approximation guarantees have to make use of the special structure of road networks (which is not obvious how to do it). On the positive side, we show with instance based lower bounds that our heuris-tic algorithms achieve provably good solutions on real-world problem instances."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Online Optimization with Dynamic Temporal Uncertainty", "Title": "Incorporating Short Term Predictions for Renewable Integration in Intelligent Energy Systems", "Abstract": "Growing costs, environmental awareness and government directives have set the stage for an increase in the fraction of electricity supplied using intermittent renewable sources such as solar and wind energy. To compensate for the increased variability in supply and demand, we need algorithms for online energy resource allocation under temporal uncertainty of future consumption and availability. Recent advances in prediction algorithms offer hope that a reduction in future uncertainty, through short term predictions, will increase the worth of the renewables. Predictive information is then revealed incrementally in an online manner, leading to what we call dynamic temporal uncertainty. We demonstrate the non-triviality of this problem and provide online algorithms, both randomized and deterministic, to handle time varying uncertainty in future rewards for non-stationary MDPs in general and for energy resource allocation in particular. We derive theoretical upper and lower bounds that hold even for a finite horizon, and establish that, in the deterministic case, discounting future rewards can be used as a strategy to maximize the total (undiscounted) reward. We also corroborate the efficacy of our methodology using wind and demand traces."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Negotiated Learning for Smart Grid Agents", "Title": "Entity Selection based on Dynamic Partially Observable Features", "Abstract": "An attractive approach to managing electricity demand in the Smart Grid relies on real-time pricing (RTP) tariffs, where customers are incentivized to quickly adapt to changes in the cost of supply. However, choosing amongst competitive RTP tariffs is difficult when tariff prices change rapidly. The problem is further complicated when we assume that the price changes for a tariff are published in real-time only to those customers who are currently subscribed to that tariff, thus making the prices partially observable. We present models and learning algorithms for autonomous agents that can address the tariff selection problem on behalf of customers. We introduce 'Negotiated Learning', a general algorithm that enables a self-interested sequential decision-making agent to periodically select amongst a variable set of 'entities' (e.g., tariffs) by negotiating with other agents in the environment to gather information about dynamic partially observable entity 'features' (e.g., tariff prices) that affect the entity selection decision. We also contribute a formulation of the tariff selection problem as a 'Negotiable Entity Selection Process', a novel representation. We support our contributions with intuitive justification and simulation experiments based on real data on an open Smart Grid simulation platform."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Autonomous Agents in Future Energy Markets", "Title": "The 2012 Power Trading Agent Competition", "Abstract": "Sustainable energy systems of the future will need more than efficient, clean, and low-cost energy sources. They will also need efficient price signals that motivate sustainable energy consumption behaviors and a tight real-time alignment of energy demand with supply from renewable and traditional sources. The Power Trading Agent Competition (Power TAC) is a rich, competitive, open-source simulation platform for future retail power markets built on real-world data and state-of-the-art customer models. Its purpose is to help researchers understand the dynamics of customer and retailer decision-making as well as the robustness of proposed market designs. Power TAC invites researchers to develop autonomous electricity broker agents and to pit them against best-in-class strategies in global  competitions, the first of which will be held at AAAI 2013. Power TAC competitions provide compelling, actionable information for policy makers and industry leaders. We describe the competition scenario, demonstrate the realism of the Power TAC platform, and analyze key characteristics of successful brokers in one of our 2012 pilot competitions between seven research groups from five different countries."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Simplified Lattice Models for Protein Structure Prediction", "Title": "How Good Are They?", "Abstract": "In this paper, we present a local search framework for lattice fit problem of proteins. Our algorithm significantly improves state-of-the-art results and justifies the significance of the lattice models. In addition to these, our analysis reveals the weakness of several energy functions used."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "An Effective Approach for Imbalanced Classification", "Title": "Unevenly Balanced Bagging", "Abstract": "Learning from imbalanced data is an important problem in data mining research. Much research has addressed the problem of imbalanced data by using sampling methods to generate an equally balanced training set to improve the performance of the prediction models, but it is unclear what ratio of class distribution is best for training a prediction model. Bagging is one of the most popular and effective ensemble learning methods for improving the performance of prediction models; however, there is a major drawback on extremely imbalanced data-sets. It is unclear under which conditions bagging is outperformed by other sampling schemes in terms of imbalanced classification. These issues motivate us to propose a novel approach, unevenly balanced bagging (UBagging) to boost the performance of the prediction model for imbalanced binary classification. Our experimental results demonstrate that UBagging is effective and statistically significantly superior to single learner decision trees J48 (SingleJ48), bagging, and equally balanced bagging (BBagging) on 32 imbalanced data-sets."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Locate the Hate", "Title": "Detecting Tweets against Blacks", "Abstract": "Although the social medium Twitter grants users freedom of speech, its instantaneous nature and retweeting features also amplify hate speech. Because Twitter has a sizeable black constituency, racist tweets against blacks are especially detrimental in the Twitter community, though this effect may not be obvious against a backdrop of half a billion tweets a day.1 We apply a supervised machine learning approach, employing inexpensively acquired labeled data from diverse Twitter accounts to learn a binary classifier for the labels “racist” and “nonracist.” The classifier has a 76% average accuracy on individual tweets, suggesting that with further improvements, our work can contribute data on the sources of anti-black hate speech."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Inferring Robot Task Plans from Human Team Meetings", "Title": "A Generative Modeling Approach with Logic-Based Prior", "Abstract": "We aim to reduce the burden of programming and deploying autonomous systems to work in concert with people in time-critical domains, such as military field operations and disaster response. Deployment plans for these operations are frequently negotiated on-the-fly by teams of human planners. A human operator then translates the agreed upon plan into machine instructions for the robots. We present an algorithm that reduces this translation burden by inferring the final plan from a processed form of the human team's planning conversation. Our approach combines probabilistic generative modeling with logical plan validation used to compute a highly structured prior over possible plans. This hybrid approach enables us to overcome the challenge of performing inference over the large solution space with only a small amount of noisy data from the team planning session. We validate the algorithm through human subject experimentation and show we are able to infer a human team's final plan with 83% accuracy on average. We also describe a robot demonstration in which two people plan and execute a first-response collaborative task with a PR2 robot. To the best of our knowledge, this is the first work that integrates a logical planning technique within a generative model to perform plan inference."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Assumption-Based Planning", "Title": "Generating Plans and Explanations under Incomplete Knowledge", "Abstract": "Many practical planning problems necessitate the generation of a plan under incomplete information about the state of the world. In this paper we propose the notion of Assumption-Based Planning. Unlike conformant planning, which attempts to find a plan under all possible completions of the initial state, an assumption-based plan supports the assertion of additional assumptions about the state of the world, often resulting in high quality plans where no conformant plan exists. We are interested in this paradigm of planning for two reasons: 1) it captures a compelling form of emph{commonsense planning}, and 2) it is of great utility in the generation of explanations, diagnoses, and counter-examples -- tasks which share a computational core with We formalize the notion of assumption-based planning, establishing a relationship between assumption-based and conformant planning, and prove properties of such plans. We further provide for the scenario where some assumptions are more preferred than others. Exploiting the correspondence with conformant planning, we propose a means of computing assumption-based plans via a translation to classical planning. Our translation is an extension of the popular approach proposed by Palacios and Geffner and realized in their T0 planner. We have implemented our planner, A0, as a variant of T0 and tested it on a number of expository domains drawn from the International Planning Competition. Our results illustrate the utility of this new planning paradigm."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Ties Matter", "Title": "Complexity of Manipulation when Tie-Breaking with a Random Vote", "Abstract": "We study the impact on strategic voting of tie-breaking by means of considering the order of tied candidates within a random vote. We compare this to another non deterministic tie-breaking rule where we simply choose candidate uniformly at random. In general, we demonstrate that there is no connection between the computational complexity of computing a manipulating vote with the two different types of tie-breaking. However, we prove that for some scoring rules, the computational complexity of computing a manipulation can increase from polynomial to NP-hard. We also discuss the relationship with the computational complexity of computing a manipulating vote when we ask for a candidate to be the unique winner, or to be among the set of co-winners."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Truncated Incremental Search", "Title": "Faster Replanning by Exploiting Suboptimality", "Abstract": "Incremental heuristic searches try to reuse their previous search efforts whenever these are available. As a result, they can often solve a sequence of similar planning problems much faster than planning from scratch. State-of-the-art incremental heuristic searches such as LPA*, D* and D* Lite all work by propagating cost changes to all the states on the search tree whose g-values (the costs of computed paths from the start) are no longer optimal. While such a complete propagation of cost changes is required to ensure optimality, the propagations can be stopped much earlier if we are looking for solutions within a given suboptimality bound. We present a framework called Truncated Incremental Search that builds on this observation, and uses a target suboptimality bound to efficiently restrict the cost propagations. Using this framework, we develop two algorithms, Truncated LPA* (TLPA*) and Truncated D* Lite (TD* Lite). We discuss their analytical properties and present experimental results for 2D and 3D (x, y, heading) path planning that show significant improvement in runtime over existing incremental heuristic searches when searching for close-to-optimal solutions. In addition, unlike typical incremental searches, Truncated Incremental Search is much less dependent on the proximity of the cost changes to the goal of the search due to the early termination of the cost change propagation."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Radial Restraint", "Title": "A Semantically Clean Approach to Bounded Rationality for Logic Programs", "Abstract": "Declarative logic programs (LP) based on the well-founded semantics (WFS) are widely used for knowledge representation (KR).  Logical functions are desirable expressively in KR, but when present make LP inferencing become undecidable. In this paper, we present radial restraint: a novel approach to bounded rationality in LP. Radial restraint is parameterized by a norm that measures the syntactic complexity of a term, along with an abstraction function based on that norm.  When a term exceeds a bound for the norm, the term is assigned the WFS's third truth-value of undefined.  If the norm is finitary, radial restraint guarantees finiteness of models and decidability of inferencing, even when logical functions are present.  It further guarantees soundness, even when non-monotonicity is present.  We give a fixed-point semantics for radially  restrained well-founded models which soundly approximate well-founded models.  We also show how to perform correct inferencing relative to such models, via SLG_ABS, an extension of tabled SLG resolution that uses norm-based abstraction functions.  Finally we discuss how SLG_ABS is implemented in the engine of XSB Prolog, and scales to knowledge bases with more than 10^8 rules and facts."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Resolution and Parallelizability", "Title": "Barriers to the Efficient Parallelization of SAT Solvers", "Abstract": "Recent attempts to create versions of Satisfiability (SAT) solversthat exploit parallel hardware and information sharing have met withlimited success. In fact,the most successful parallel solvers in recent competitions were basedon portfolio approaches with little to no exchange of informationbetween processors. This experience contradicts the apparentparallelizability of exploring a combinatorial search space. Wepresent evidence that this discrepancy can be explained by studyingSAT solvers through a proof complexity lens, as resolution refutationengines. Starting with theobservation that a recently studied measure of resolution proofs,namely depth, provides a (weak) upper bound to the best possiblespeedup achievable by such solvers, we empirically show the existenceof bottlenecks to parallelizability that resolution proofs typicallygenerated by SAT solvers exhibit. Further, we propose a new measureof parallelizability based on the best-case makespan of an offlineresource constrained scheduling problem. This measureexplicitly accounts for a bounded number of parallel processors andappears to empirically correlate with parallel speedups observed inpractice. Our findings suggest that efficient parallelization of SATsolvers is not simply a matter of designing the right clause sharingheuristics; even in the best case, it can be --- and indeed is ---hindered by the structure of the resolution proofs current SAT solverstypically produce."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "HC-Search", "Title": "Learning Heuristics and Cost Functions for Structured Prediction", "Abstract": "Structured prediction is the problem of learning a function from  structured inputs to structured outputs with prototypical examples being  part-of-speech tagging and image labeling. Inspired by the recent  successes of search-based structured prediction, we introduce a new  framework for structured prediction called {em HC-Search}. Given a  structured input, the framework uses a search procedure guided by a  learned heuristic H to uncover high quality candidate outputs and then  uses a separate learned cost function C to select a final prediction  among those outputs. We can decompose the regret of the overall approach  into the loss due to H not leading to high quality outputs, and the  loss due to C not selecting the best among the generated outputs. Guided  by this decomposition, we minimize the overall regret in a greedy  stage-wise manner by first training H to quickly uncover high quality  outputs via imitation learning, and then training C to correctly rank  the outputs generated via H according to their true losses. Experiments  on several benchmark domains show that our approach significantly  outperforms the state-of-the-art methods."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Reduce and Re-Lift", "Title": "Bootstrapped Lifted Likelihood Maximization for MAP", "Abstract": "By handling whole sets of indistinguishable objects together, lifted belief propagation approaches have rendered large, previously intractable, probabilistic inference problems quickly solvable. In this paper, we show that Kumar and Zilberstein's likelihood maximization (LM) approach to MAP inference is liftable, too, and actually provides additional structure for optimization. Specifically, it has been recognized that some pseudo marginals may converge quickly, turning intuitively into pseudo evidence. This additional evidence typically changes the structure of the lifted network: it may expand or reduce it. The current lifted network, however, can be viewed as an upper bound on the size of the lifted network required to finish likelihood maximization. Consequently, we re-lift the network only if the pseudo evidence yields a reduced network, which can efficiently be computed on the current lifted network. Our experimental results on Ising models, image segmentation and relational entity resolution demonstrate that this bootstrapped LM via \"reduce and re-lift\" finds MAP assignments comparable to those found by the original LM approach, but in a fraction of the time."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "SMILe", "Title": "Shuffled Multiple-Instance Learning", "Abstract": "Resampling techniques such as bagging are often used in supervised learning to produce more accurate classifiers. In this work, we show that multiple-instance learning admits a different form of resampling, which we call \"shuffling.\" In shuffling, we resample instances in such a way that the resulting bags are likely to be correctly labeled. We show that resampling results in both a reduction of bag label noise and a propagation of additional informative constraints to a multiple-instance classifier. We empirically evaluate shuffling in the context of multiple-instance classification and multiple-instance active learning and show that the approach leads to significant improvements in accuracy."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Composition Games for Distributed Systems", "Title": "The EU Grant Games", "Abstract": "We analyze ways by which people decompose into groups in distributed systems. We are interested in systems in which an agent can increase its utility by connecting to other agents, but must also pay a cost that increases with the size of the system. The right balance is achieved by the right size group of agents. We formulate and analyze three intuitive and realistic games and show how simple changes in the protocol can drastically improve the price of anarchy of these games. In particular, we identify two important properties for a low price of anarchy: agreement in joining the system, and the possibility of appealing a rejection from a system. We show that the latter property is especially important if there are some pre-existing constraints regarding who may collaborate (or communicate) with whom."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "GiSS", "Title": "Combining Gibbs Sampling and SampleSearch for Inference in Mixed Probabilistic and Deterministic Graphical Models", "Abstract": "Mixed probabilistic and deterministic graphical models are ubiquitous in real-world applications. Unfortunately, Gibbs sampling, a popular MCMC technique, does not converge to the correct answers in presence of determinism and therefore cannot be used for inference in such models. In this paper, we propose to remedy this problem by combining Gibbs sampling with SampleSearch, an advanced importance sampling technique which leverages complete SAT/CSP solvers to generate high quality samples from hard deterministic spaces. We call the resulting algorithm, GiSS. Unlike Gibbs sampling which yields unweighted samples, GiSS yields weighted samples. Computing these weights exactly can be computationally expensive and therefore we propose several approximations. We show that our approximate weighting schemes yield consistent estimates and demonstrate experimentally that GiSS is competitive in terms of accuracy with state-of-the-art algorithms such as SampleSearch, MC-SAT and Belief propagation."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "From Interest to Function", "Title": "Location Estimation in Social Media", "Abstract": "Recent years have witnessed the tremendous development of social media, which attracts a vast number of Internet users. The high-dimension content generated by these users provides an unique opportunity to understand their behavior deeply. As one of the most fundamental topics, location estimation attracts more and more research efforts. Different from the previous literature, we find that user's location is strongly related to user interest. Based on this, we first build a detection model to mine user interest from short text. We then establish the mapping between location function and user interest before presenting an efficient framework to predict the user's location with convincing fidelity. Thorough evaluations and comparisons on an authentic data set show that our proposed model significantly outperforms the state-of-the-arts approaches. Moreover, the high efficiency of our model also guarantees its applicability in real-world scenarios."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "m-Transportability", "Title": "Transportability of a Causal Effect from Multiple Environments", "Abstract": "We study m-transportability, a generalization of transportability, which offers a license to use causal information elicited from experiments and observations in m>=1 source environments to estimate a causal effect in a given targetenvironment. We provide a novel characterization of m-transportability that directly exploits the completeness of do-calculus to obtain the necessary and sufficient conditions for m-transportability. We provide an algorithm for deciding m-transportability that determines whether a causal relation is m-transportable; and if it is, produces a transport formula, that is, a recipe for estimating the desired causal effect by combining experimental information from m source environments with observational information from the target environment."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "RockIt", "Title": "Exploiting Parallelism and Symmetry for MAP Inference in Statistical Relational Models", "Abstract": "RockIt is a maximum a-posteriori (MAP) query engine for statistical relational models. MAP inference in graphical models is an optimization problem which can be compiled to integer linear programs (ILPs).We describe several advances in translating MAP queries to ILP instances  and present the novel meta-algorithm cutting plane aggregation (CPA). CPA exploits local context-specific symmetries and bundles up sets of  linear constraints. The resulting counting constraints lead to more compact ILPs and make the symmetry of the ground model more explicit to state-of-the-art ILP solvers. Moreover, RockIt parallelizes most parts of the MAP inference pipeline taking advantage of ubiquitous shared-memory multi-core architectures. We report on extensive experiments with Markov logic network (MLN) benchmarks showing that RockIt outperforms the state-of-the-art systems Alchemy, Markov TheBeast, and Tuffy both in terms of efficiency and quality of results."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Gradient Networks", "Title": "Explicit Shape Matching Without Extracting Edges", "Abstract": "We present a novel framework for shape-based template matching in images.  While previous approaches required brittle contour extraction, considered only local information, or used coarse statistics, we propose to match the shape explicitly on low-level gradients by formulating the problem as traversing paths in a gradient network.  We evaluate our algorithm on a challenging dataset of objects in cluttered environments and demonstrate significant improvement over state-of-the-art methods for shape matching and object detection."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Reasoning about Saturated Conditional Independence Under Uncertainty", "Title": "Axioms, Algorithms, and Levesque’s Situations to the Rescue", "Abstract": "The implication problem of probabilistic conditional independencies is investigated in the presence of missing data. Here, graph separation axioms fail to hold for saturated conditional independencies, unlike the known idealized case with no missing data. Several axiomatic, algorithmic, and logical characterizations of the implication problem for saturated conditional independencies are established. In particular, equivalences are shown to the implication problem of a propositional fragment under Levesque's situations, and that of Lien's class of multivalued database dependencies under null values."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "The Wisdom of Crowds in Bioinformatics", "Title": "What Can We Learn (and Gain) from Ensemble Predictions?", "Abstract": "The combination of distinct algorithms expertise to improve prediction accuracy, inspired by the theory of wisdom of crowds, has been increasingly discussed in literature. However, its application to bioinformatics-related tasks is still in its infancy. This thesis aims at investigating the potential and limitations of ensemble-based solutions for two bioinformatics prediction tasks, namely inference of gene regulatory networks and prediction of microRNAs targets, as well as propose new integration methods. We approach this by considering heterogeneity in the contexts of data and methods, and adopting machine learning methods and concepts from multiagent systems, such as social choice functions, for integration purposes."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "GRADE", "Title": "Machine Learning Support for Graduate Admissions", "Abstract": "This paper describes GRADE, a statistical machine learning system developed to support the work of the graduate admissions committee at the University of Texas at Austin Department of Computer Science (UTCS). In recent years, the number of applications to the UTCS PhD program has become too large to manage with a traditional review process. GRADE uses historical admissions data to predict how likely the committee is to admit each new applicant. It reports each prediction as a score similar to those used by human reviewers, and accompanies each by an explanation of what applicant features most influenced its prediction. GRADE makes the review process more efficient by enabling reviewers to spend most of their time on applicants near the decision boundary and by focusing their attention on parts of each applicant’s file that matter the most. An evaluation over two seasons of PhD admissions indicates that the system leads to dramatic time savings, reducing the total time spent on reviews by at least 74%."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "USI Answers", "Title": "Natural Language Question Answering Over (Semi-) Structured Industry Data", "Abstract": "This paper describes USI Answers a natural language question answering system for semi-structured industry data. The paper reports on the progress towards the goal of offering easy access to enterprise data to a large number of business users, most of whom are not familiar with the specific syntax or semantics of the underlying data sources. Additional complications come from the nature of the data, which comes both as structured and unstructured. The proposed solution allows users to express questions in natural language, makes apparent the system’s interpretation of the query, and allows easy query adjustment and reformulation. The application is in use by more than 1500 users from Siemens Energy. We evaluate our approach on a data set consisting of fleet data."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Multiagent Router Throttling", "Title": "Decentralized Coordinated Response Against DDoS Attacks", "Abstract": "Distributed denial of service (DDoS) attacks constitute a rapidly evolving threat in the current Internet. In this paper we introduce Multiagent Router Throttling, a decentralized DDoS response mechanism in which a set of upstream routers independently learn to throttle traffic towards a victim server. We compare our approach against a baseline and a popular throttling technique from the literature, and we show that our proposed approach is more secure, reliable and cost-effective. Furthermore, our approach outperforms the baseline technique and either outperforms or has the same performance as the popular one."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Timed Probabilistic Automaton", "Title": "A Bridge between Raven and Song Scope for Automatic Species Recognition", "Abstract": "Raven and Song Scope are two, state-of-the-art automated sound analysis tools, based on machine learning techniques for detection of species vocalisations. Individually, these systems have been the subject of a number of reviews; however, to date there have been no comparisons made of their relative performance. This paper compares the tools based on six aspects: theory, software interface, ease of use, detection targets, detection accuracy, and potential applications. Examining these tools, we identified that they fail to detect both syllables and call structures, since Raven only aims to detect syllables while Song Scope targets call structures. Therefore, a Timed Probabilistic Automata (TPA) system is proposed which separates syllables and clusters them into complex structures."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "Learning about Representational Modality", "Title": "Design and Programming Projects for Knowledge-Based AI", "Abstract": "Many AI courses include design and programming projects that provide students with opportunities for experiential learning. Design and programming projects in courses on knowledge-based AI typically explore topics in knowledge, memory, reasoning, and learning. Traditional AI curricula, however, seldom highlight issues of modality of representations, often focusing solely on propositional representations. In this paper, we report on an investigation into learning about representational modality through a series of projects based around geometric analogy problems similar to the Raven’s Progressive Matrices test of intelligence. We conducted this experiment over three years, from Fall 2010 through Fall 2012, in a class on knowledge-based AI. We used the methodology of action research in which the teacher is also the researcher. We discovered that students found these projects motivating, engaging, and challenging, in several cases investing significant time and posting their work online. From our perspective, the projects accomplished the goal of learning about representational modality in addition to knowledge representation and reasoning."}
{"Type": "conference", "Year": "2013", "Area": "AI", "Where": "AAAI", "Abbreviation": "SEPIA", "Title": "A Scalable Game Environment for Artificial Intelligence Teaching and Research", "Abstract": "We describe a game environment we have developed that we call the Strategy Engine for Programming Intelligent Agents (SEPIA). SEPIA is based on real-time strategy games, but modified extensively to preferentially support the development of artificial agents rather than human play. Through flexible configuration options, SEPIA is designed to be pedagogically scalable: suitable for use at the undergraduate and graduate levels, and also as a research testbed. We also describe assignments and our experiences with this environment in undergraduate and graduate classes."}
