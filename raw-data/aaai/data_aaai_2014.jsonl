{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Saturated Path-Constrained MDP", "Title": "Planning under Uncertainty and Deterministic Model-Checking Constraints", "Abstract": "In many probabilistic planning scenarios, a system’s behavior needs to not only maximize the expected utility but also obey certain restrictions. This paper presents Saturated Path-Constrained Markov Decision Processes (SPC MDPs), a new MDP type for planning under uncertainty with deterministic model-checking constraints, e.g., \"state s must be visited befores s'\", \"the system must end up in s\", or \"the system must never enter s\". We present a mathematical analysis of SPCMDPs, showing that although SPC MDPs generally have no optimal policies, every instance of this class has an epsilon-optimal randomized policy for any > 0. We propose a dynamic programming-based algorithm for finding such policies, and empirically demonstrate this algorithm to be orders of magnitude faster than its next-best alternative."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Oversubscription Planning", "Title": "Complexity and Compilability", "Abstract": "Many real-world planning problems are oversubscription problems where all goals are not simultaneously achievable and the planner needs to find a feasible subset. We present complexity results for the so-called partial satisfaction and net benefit problems under various restrictions; this extends previous work by van den Briel et al. Our results reveal strong connections between these problems and with classical planning. We also present a method for efficiently compiling oversubscription problems into the ordinary plan existence problem; this can be viewed as a continuation of earlier work by Keyder & Geffner."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "GP-Localize", "Title": "Persistent Mobile Robot Localization Using Online Sparse Gaussian Process Observation Model", "Abstract": "Central to robot exploration and mapping is the task of persistent localization in environmental fields characterized by spatially correlated measurements. This paper presents a Gaussian process localization (GP-Localize) algorithm that, in contrast to existing works, can exploit the spatially correlated field measurements taken during a robot's exploration (instead of relying on prior training data) for efficiently and scalably learning the GP observation model online through our proposed novel online sparse GP. As a result, GP-Localize is capable of achieving constant time and memory (i.e., independent of the size of the data) per filtering step, which demonstrates the practical feasibility of using GPs for persistent robot localization and autonomy. Empirical evaluation via simulated experiments with real-world datasets and a real robot experiment shows that GP-Localize outperforms existing GP localization algorithms."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "R2", "Title": "An Efficient MCMC Sampler for Probabilistic Programs", "Abstract": "We present a new Markov Chain Monte Carlo (MCMC) sampling algorithm for probabilistic programs. Our approach and tool, called R2, has the unique feature of employing program analysis in order to improve the efficiencyof MCMC sampling. Given an input program P, R2 propagates observations in P backwards to obtaina semantically equivalent program P' in which every probabilistic assignment is immediately followed by an observe statement. Inference is performed by a suitably modified version of the Metropolis-Hastings algorithm that exploits the structure of the program P'. This has the overall effect of preventing rejections due to program executions that fail to satisfy observations in P. We formalize the semantics of probabilistic programs and rigorously prove the correctness of R2. We also empirically demonstrate the effectiveness of R2—in particular, we show that R2 is able to produce results of similar quality as the CHURCH and STAN probabilistic programming tools with much shorter execution time."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Relational One-Class Classification", "Title": "A Non-Parametric Approach", "Abstract": "One-class classification approaches have been proposed in the literature to learn classifiers from examples of only one class. But these approaches are not directly applicable to relational domains due to their reliance on a feature vector or a distance measure. We propose a non-parametric relational one-class classification approach based on first-order trees. We learn a tree-based distance measure that iteratively introduces new relational features to differentiate relational examples. We update the distance measure so as to maximize the one-class classification performance of our model. We also relate our model definition to existing work on probabilistic combination functions and density estimation. We experimentally show that our approach can discover relevant features and outperform three baseline approaches."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Tractability through Exchangeability", "Title": "A New Perspective on Efficient Probabilistic Inference", "Abstract": "Exchangeability is a central notion in statistics and probability theory. The assumption that an infinite sequence of data points is exchangeable is at the core of Bayesian statistics. However, finite exchangeability as a statistical property that renders probabilistic inference tractable is less well-understood. We develop a theory of finite exchangeability and its relation to tractable probabilistic inference. The theory is complementary to that of independence and conditional independence. We show that tractable inference in probabilistic models with high treewidth and millions of variables can be explained with the notion of finite (partial) exchangeability. We also show that existing lifted inference algorithms implicitly utilize a combination of conditional independence and partial exchangeability."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Inference Graphs", "Title": "A New Kind of Hybrid Reasoning System", "Abstract": "Hybrid reasoners combine multiple types of reasoning, usually subsumption and Prolog-style resolution. We outline a system which combines natural deduction and subsumption reasoning using Inference Graphs implementing a Logic of Arbitrary and Indefinite Objects."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Converting Instance Checking to Subsumption", "Title": "A Rethink for Object Queries over Practical Ontologies", "Abstract": "Instance checking is considered a central service for data retrieval from description logic (DL) ontologies. In this paper, we propose a revised most specific concept (MSC) method for DL SHI}, which converts instance checking into subsumption problems. This revised method can generate small concepts that are specific-enough to answer a given query, and allow reasoning to explore only a subset of the ABox data to achieve efficiency. Experiments show effectiveness of our proposed method in terms of concept size reduction and the improvement in reasoning efficiency."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Identifying Domain-Dependent Influential Microblog Users", "Title": "A Post-Feature Based Approach", "Abstract": "Users of a social network like to follow the posts published by influential users. Such posts usually are delivered quickly and thus will produce a strong influence on public opinions. In this paper, we focus on the problem of identifying domain-dependent influential users(or topic experts). Some of traditional approaches are based on the post contents of users user’s to identify influential users, which may be biased by spammers who try to make posts related to some topics through a simple copy and paste. Others make use of user authentication information given by a service platform or user self description (introduction or label) in finding influential users. However, what users have published is not necessarily related to what they have registed and described. In addition, if there is no comments from other users, it’s less objective to assess a user’s post quality. To improve effectiveness of recognizing influential users in a topic of microblogs, we propose a post-feature based approach which is supplementary to post-content based approaches. Our experimental results show that the post-feature based approach produces relatively higher precision than that of the content based approach."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "LSDH", "Title": "A Hashing Approach for Large-Scale Link Prediction in Microblogs", "Abstract": "One challenge of link prediction in online social networks is the large scale of many such networks. The measures used by existing work lack a computational consideration in the large scale setting. We propose the notion of social distance in a multi-dimensional form to measure the closeness among a group of people in Microblogs. We proposed a fast hashing approach called Locality-sensitive Social Distance Hashing (LSDH), which works in an unsupervised setup and performs approximate near neighbor search without high-dimensional distance computation. Experiments were applied over a Twitter dataset and the preliminary results testified the effectiveness of LSDH in predicting the likelihood of future associations between people."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "RepRev", "Title": "Mitigating the Negative Effects of Misreported Ratings", "Abstract": "Reputation models depend on the ratings provided by buyers togauge the reliability of sellers in multi-agent based e-commerce environment. However, there is no prevention forthe cases in which a buyer misjudges a seller, and provides a negative rating to an original satisfactory transaction. In this case,how should the seller get his reputation repaired andutility loss recovered? In this work, we propose a mechanism to mitigate the negativeeffect of the misreported ratings. It temporarily inflates the reputation of thevictim seller with a certain value for a period of time. This allows the seller to recover hisutility loss due to lost opportunities caused by the misreported ratings. Experiments demonstrate the necessity and effectiveness of the proposed mechanism."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "DJAO", "Title": "A Communication-Constrained DCOP Algorithm that Combines Features of ADOPT and Action-GDL", "Abstract": "In this paper we propose a novel DCOP algorithm, called DJAO, that is able toefficiently find a solution with low communication overhead; this algorithm can be used for optimal and bounded approximate solutions by appropriately setting the error bounds. Our approach builds on distributed junction trees used in Action-GDL to represent independence relationsamong variables. We construct an AND/OR search space based on these junction trees.This new type of search space results in higher degrees for each OR node, consequently yielding a more efficient search graph in the distributed settings. DJAO uses a branch-and-bound search algorithm to distributedly find solutions within this search graph. We introduce heuristics to compute the upper and lower boundestimates that the search starts with, which is integral to our approach for reducing communication overhead. We empirically evaluate our approach in various settings."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Deep Salience", "Title": "Visual Salience Modeling via Deep Belief Propagation", "Abstract": "Visual salience is an intriguing phenomenon observed in biological neural systems. Numerous attempts have been made to model visual salience mathematically using various feature contrasts, either locally or globally. However, these algorithmic models tend to ignore the problem’s biological solutions, in which visual salience appears to arise during the propagation of visual stimuli along the visual cortex. In this paper, inspired by the conjecture that salience arises from deep propagation along the visual cortex, we present a Deep Salience model where a multi-layer model based on successive Markov random fields (sMRF) is proposed to analyze the input image successively through its deep belief propagation. As a result, the foreground object can be automatically separated from the background in a fully unsupervised way. Experimental evaluation on the benchmark dataset validated that our Deep Salience model can consistently outperform many state-of-the-art salience models, yielding the higher rates in the precision-recall tests and attaining the better scores in F-measure and mean-square error tests."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Towards Topological-Transformation Robust Shape Comparison", "Title": "A Sparse Representation Based Manifold Embedding Approach", "Abstract": "Non-rigid shape comparison based on manifold embeddingusing Generalized Multidimensional Scaling(GMDS) has attracted much attention for its highaccuracy. However, this method requires that shape surfaceis not elastic. In other words, it is sensitive totopological transformations such as stretching and compressing.To tackle this problem, we propose a new approachthat constructs a high-dimensional space to embedthe manifolds of shapes based on sparse representation,which is able to completely withstand rigid transformationsand considerably tolerate topological transformations.Experiments on TOSCA shapes validate theproposed approach."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "TopicMF", "Title": "Simultaneously Exploiting Ratings and Reviews for Recommendation", "Abstract": "Although users' preference is semantically reflected in the free-form review texts, this wealth of information was not fully exploited for learning recommender models. Specifically, almost all existing recommendation algorithms only exploit rating scores in order to find users' preference, but ignore the review texts accompanied with rating information. In this paper, we propose a novel matrix factorization model (called TopicMF) which simultaneously considers the ratings and accompanied review texts. Experimental results on 22 real-world datasets show the superiority of our model over the state-of-the-art models, demonstrating its effectiveness for recommendation tasks."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "CoreCluster", "Title": "A Degeneracy Based Graph Clustering Framework", "Abstract": "Graph clustering or community detection constitutes an important task forinvestigating the internal structure of graphs, with a plethora of applications in several domains. Traditional tools for graph clustering, such asspectral methods, typically suffer from high time and space complexity. In thisarticle, we present  CoreCluster, an efficient  graph clusteringframework based on the concept of graph degeneracy, that can be used  along withany known graph clustering algorithm. Our approach capitalizes on processing thegraph in a hierarchical manner provided by its core expansion sequence, anordered partition of the graph into different levels according to the k-coredecomposition. Such a partition provides a way to process the graph inan incremental manner that preserves its clustering structure, whilemaking the execution of the chosen clustering algorithm much faster due to thesmaller size of the graph's partitions onto which the algorithm operates."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "ARIA", "Title": "Asymmetry Resistant Instance Alignment", "Abstract": "We study the problem of instance alignment between knowledge bases (KBs). Existing approaches, exploiting the “symmetry” of structure and information across KBs, suffer in the presence of asymmetry, which is frequent as KBs are independently built. Specifically, we observe three types of asymmetries (in concepts, in features, and in structures). Our goal is to identify key techniques to reduce accuracy loss caused by each type of asymmetry, then design Asymmetry-Resistant Instance Alignment framework (ARIA). ARIA uses two-phased blocking methods considering concept and feature asymmetries, with a novel similarity measure overcoming structure asymmetry. Compared to a state-of-the-art method, ARIA increased precision by 19% and recall by 2%, and decreased processing time by more than 80% in matching large-scale real-life KBs."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "GenEth", "Title": "A General Ethical Dilemma Analyzer", "Abstract": "We contend that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. To provide assistance in developing these ethical principles, we have developed GenEth, a general ethical dilemma analyzer that, through a dialog with ethicists, codifies ethical principles in any given domain.  GenEth has been used to codify principles in a number of domains pertinent to the behavior of autonomous systems and these principles have been verified using an Ethical Turing Test."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "k-CoRating", "Title": "Filling Up Data to Obtain Privacy and Utility", "Abstract": "For datasets in Collaborative Filtering (CF) recommendations, even if the identifier is deleted and some trivial perturbation operations are applied to ratings before they are released, there are research results claiming that the adversary could discriminate the individual's identity with a little bit of information. In this paper, we propose $k$-coRating, a novel privacy-preserving model, to retain data privacy by replacing some null ratings with \"well-predicted\" scores. They do not only mask the original ratings such that a $k$-anonymity-like data privacy is preserved, but also enhance the data utility (measured by prediction accuracy in this paper), which shows that the traditional assumption that accuracy and privacy are two goals in conflict is not necessarily correct. We show that the optimal $k$-coRated mapping is an NP-hard problem and design a naive but efficient algorithm to achieve $k$-coRating. All claims are verified by experimental results."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Social Planning", "Title": "Achieving Goals by Altering Others’ Mental States", "Abstract": "In this paper, we discuss a computational approach to the cognitivetask of social planning. First, we specify a class of planningproblems that involve an agent who attempts to achieve its goalsby altering other agents' mental states. Next, we describe SFPS,a flexible problem solver that generates social plans of this sort,including ones that include deception and reasoning about otheragents' beliefs. We report the results for experiments on socialscenarios that involve different levels of sophistication and thatdemonstrate both SFPS's capabilities and the sources of its power.Finally, we discuss how our approach to social planning has beeninformed by earlier work in the area and propose directions foradditional research on the topic."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Placement of Loading Stations for Electric Vehicles", "Title": "No Detours Necessary!", "Abstract": "Compared to conventional cars, electric vehicles still suffer from a considerably shorter cruising range. Combined with the sparsity of battery loading stations, the complete transition to E-mobility still seems a long way to go. In this paper, we consider the problem of placing as few loading stations as possible such that on any shortest path there are enough to guarantee sufficient energy supply. This means, that EV owners no longer have to plan their trips ahead incorporating loading station locations, and are no longer forced to accept long detours to reach their destinations. We show how to model this problem and introduce heuristics which provide close-to-optimal solutions even in large road networks."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "TacTex’13", "Title": "A Champion Adaptive Power Trading Agent", "Abstract": "Sustainable energy systems of the future will no longer be able to rely on the current paradigm that energy supply follows demand. Many of the renewable energy resources do not produce power on demand, and therefore there is a need for new market structures that motivate sustainable behaviors by participants.  The Power Trading Agent Competition (Power TAC) is a new annual competition that focuses on the design and operation of future retail power markets, specifically in smart grid environments with renewable energy production, smart metering, and autonomous agents acting on behalf of customers and retailers. It uses a rich, open-source simulation platform that is based on real-world data and state-of-the-art customer models. Its purpose is to help researchers understand the dynamics of customer and retailer decision-making, as well as the robustness of proposed market designs. This paper introduces TacTex'13, the champion agent from the inaugural competition in 2013. TacTex'13 learns and adapts to the environment in which it operates, by heavily relying on reinforcement learning and prediction methods. This paper describes the constituent components of TacTex'13 and examines its success through analysis of competition results and subsequent controlled experiments."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Analogy Tutor", "Title": "A Tutoring System for Promoting Conceptual Learning via Comparison", "Abstract": "A major challenge in artificial intelligence is building intelligent, interactive learning environments that can support students in human-like ways.  Analogical reasoning can be a catalyst for conceptual learning, yet very few systems support analogical reasoning as an instructional activity.  In my thesis, I plan to demonstrate that an analogy tutor can assist conceptual learning by guiding students through instructional comparisons."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Living and Searching in the World", "Title": "Object-Based State Estimation for Mobile Robots", "Abstract": "Mobile-manipulation robots performing service tasks in human-centric indoor environments has long been a dream for developers of autonomous agents. Tasks such as cooking and cleaning require interaction with the environment, hence robots need to know relevant aspects of their spatial surroundings. However, unlike the structured settings that industrial robots operate in, service robots typically have little prior information about their environment. Even if this information was given, due to the involvement of many other agents (e.g., humans moving objects), uncertainty in the complete state of the world is inevitable over time. Additionally, most information about the world is irrelevant to any particular task at hand. Mobile manipulation robots therefore need to continuously perform the task of state estimation, using perceptual information to maintain the state, and its uncertainty, of task-relevant aspects of the world. Because indoor tasks frequently require the use of objects, objects should be given critical emphasis in spatial representations for service robots. Compared to occupancy grids and feature-based maps often used in navigation and SLAM, object-based representations are arguably still in their infancy. In my thesis, I propose a representation framework based on objects, their 'semantic' attributes, and their geometric realizations in the physical world."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Beat the Cheater", "Title": "Computing Game-Theoretic Strategies for When to Kick a Gambler out of a Casino", "Abstract": "Gambles in casinos are usually set up so that the casino makes a profit in expectation -- as long as gamblers play honestly. However, some gamblers are able to cheat, reducing the casino’s profit. How should the casino address this? A common strategy is to selectively kick gamblers out, possibly even without being sure that they were cheating. In this paper, we address the following question: Based solely on a gambler’s track record,when is it optimal for the casino to kick the gambler out? Because cheaters will adapt to the casino’s policy, this is a game-theoretic question. Specifically, we model the problem as a Bayesian game in which the casino is a Stackelberg leader that can commit to a (possibly randomized) policy for when to kick gamblers out, and we provide efficient algorithms for computing the optimal policy. Besides being potentially useful to casinos, we imagine that similar techniques could be useful for addressing related problems -- for example, illegal trades in financial markets."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Incentivizing High-Quality Content from Heterogeneous Users", "Title": "On the Existence of Nash Equilibrium", "Abstract": "We study the existence of pure Nash equilibrium (PNE) for the mechanisms used in Internet services (e.g., online reviews and question-answering websites) to incentivize users to generate high-quality content. Most existing work assumes that users are homogeneous and have the same ability. However, real-world users are heterogeneous and their abilities can be very different from each other due to their diversity in background, culture, and profession. In this work, we consider the following setting: (1) the users are heterogeneous and each of them has a private type indicating the best quality of the content he/she can generate; (2) all the users share a fixed total reward. With this setting, we study the existence of pure Nash equilibrium of several mechanisms composed by different allocation rules, action spaces, and information availability. We prove the existence of PNE for some mechanisms and the non-existence for some other mechanisms. We also discuss how to find a PNE (if exists) through either a constructive way or a search algorithm."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "The Fisher Market Game", "Title": "Equilibrium and Welfare", "Abstract": "The Fisher market model is one of the most fundamental resource allocation models in economics. In a Fisher market, the prices and allocations of goods are determined according to the preferences and budgets of buyers to clear the market. In a Fisher market game, however, buyers are strategic and report their preferences over goods; the market-clearing prices and allocations are then determined based on their reported preferences rather than their real preferences. We show that the Fisher market game always has a pure Nash equilibrium, for buyers with linear, Leontief, and Cobb-Douglas utility functions, which are three representative classes of utility functions in the important Constant Elasticity of Substitution (CES) family. Furthermore, to quantify the social efficiency, we prove Price of Anarchy bounds for the game when the utility functions of buyers fall into these three classes respectively."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Modal Ranking", "Title": "A Uniquely Robust Voting Rule", "Abstract": "Motivated by applications to crowdsourcing, we study voting rules that output a correct ranking of alternatives by quality from a large collection of noisy input rankings. We seek voting rules that are supremely robust to noise, in the sense of being correct in the face of any \"reasonable\" type of noise. We show that there is such a voting rule, which we call the modal ranking rule. Moreover, we establish that the modal ranking rule is the unique rule with the preceding robustness property within a large family of voting rules, which includes a slew of well-studied rules."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Dramatis", "Title": "A Computational Model of Suspense", "Abstract": "We introduce Dramatis, a computational model of suspense based on a reformulation of a psychological definition of the suspense phenomenon. In this reformulation, suspense is correlated with the audience’s ability to generate a plan for the protagonist to avoid an impending negative outcome. Dramatis measures the suspense level by generating such a plan and determining its perceived likelihood of success. We report on three evaluations of Dramatis, including a comparison of Dramatis output to the suspense reported by human readers, as well as ablative tests of Dramatis components. In these studies, we found that Dramatis output corresponded to the suspense ratings given by human readers for stories in three separate domains."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Signals in the Silence", "Title": "Models of Implicit Feedback in a Recommendation System for Crowdsourcing", "Abstract": "We exploit the absence of signals as informative observations in the context of providing task recommendations in crowdsourcing. Workers on crowdsourcing platforms do not provide explicit ratings about tasks. We present methods that enable a system to leverage implicit signals about task preferences. These signals include types of tasks that have been available and have been displayed, and the number of tasks workers select and complete. In contrast to previous work, we present a general model that can represent both positive and negative implicit signals.  We introduce algorithms that can learn these models without exceeding the computational complexity of existing approaches. Finally, using data from a high-throughput crowdsourcing platform, we show that reasoning about both positive and negative implicit feedback can improve the quality of task recommendations."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Relaxation Search", "Title": "A Simple Way of Managing Optional Clauses", "Abstract": "A number of problems involve managing a set of optional clauses. For example, the soft clauses in a MAXSAT formula are optional—they can be falsified for a cost. Similarly, when computing a Minimum Correction Set for an unsatisfiable formula, all clauses are optional—some can be falsified in order to satisfy the remaining. In both of these cases the task is to find a subset of the optional clauses that achieves some criteria, and whose removal leaves a satisfiable formula. Relaxation search is a simple method of using a standard SAT solver to solve this task. Relaxation search is easy to implement, sometimes requiring only a simple modification of the variable selection heuristic in the SAT solver; it offers considerable flexibility and control over the order in which subsets of optional clauses are examined; and it automatically exploits clause learning to exchange information between the two phases of finding a suitable subset of optional clauses and checking if their removal yields satisfiability. We demonstrate how relaxation search can be used to solve MAXSAT and to compute Minimum Correction Sets. In both cases relaxation search is able to achieve state-of-the-art performance and solve some instances other solvers are not able to solve."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Pathway Specification and Comparative Queries", "Title": "A High Level Language with Petri Net Semantics", "Abstract": "Understanding biological pathways is an important activity in the biological domain for drug development. Due to the parallelism and complexity inherent in pathways, computer models that can answer queries about pathways are needed. A researcher may ask `what-if' questions comparing alternate scenarios, that require deeper understanding of the underlying model. In this paper, we present overview of such a system we developed and an English-like high level language to express pathways and queries. Our language is inspired by high level action and query languages and it uses Petri Net execution semantics."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "PREGO", "Title": "An Action Language for Belief-Based Cognitive Robotics in Continuous Domains", "Abstract": "The area of cognitive robotics is often subject to the criticism that the proposals investigated in the literature are too far removed from the kind of continuous uncertainty and noise seen in actual real-world robotics. This paper proposes a new language and an implemented system, called PREGO, based on the situation calculus, that is able to reason effectively about degrees of belief against noisy sensors and effectors in continuous domains. It embodies the representational richness of conventional logic-based action languages, such as context-sensitive successor state axioms, but is still shown to be efficient using a number of empirical evaluations. We believe that PREGO is a powerful framework for exploring real-time reactivity and an interesting bridge between logic and probability for cognitive robotics applications."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "The Most Uncreative Examinee", "Title": "A First Step toward Wide Coverage Natural Language Math Problem Solving", "Abstract": "We report on a project aiming at developing a system that solves a wide range of math problems written in natural language. In the system, formal analysis of natural language semantics is coupled with automated reasoning technologies including computer algebra, using logic as their common language. We have developed a prototype system that accepts as its input a linguistically annotated problem text. Using the prototype system as a reference point, we analyzed real university entrance examination problems from the viewpoint of end-to-end automated reasoning. Further, evaluation on entrance exam mock tests revealed that an optimistic estimate of the system’s performance already matches human averages on a few test sets."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Reasoning on LTL on Finite Traces", "Title": "Insensitivity to Infiniteness", "Abstract": "In this paper we study when an LTL formula on finite traces (LTLf formula) is insensitive to infiniteness, that is, it can be correctly handled as a formula on infinite traces under the assumption that at a certain point the infinite trace starts repeating an end event forever, trivializing all other propositions to false. This intuition has been put forward and (wrongly) assumed to hold in general in the literature. We define a necessary and sufficient condition to characterize whether an LTLf formula is insensitive to infiniteness, which can be automatically checked by any LTL reasoner. Then, we show that typical LTLf specification patterns used in process and service modeling in CS, as well as trajectory constraints in Planning and transition-based LTLf specifications of action domains in KR, are indeed very often insensitive to infiniteness. This may help to explain why the assumption of interpreting LTL on finite and on infinite traces has been (wrongly) blurred. Possibly because of this blurring, virtually all literature detours to Buechi automata for constructing the NFA that accepts the traces satisfying an LTLf formula. As a further contribution, we give a simple direct algorithm for computing such NFA."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Data Quality in Ontology-based Data Access", "Title": "The Case of Consistency", "Abstract": "Ontology-based data access (OBDA) is a new paradigm aiming at accessing and managing data by means of an ontology, i.e., a conceptual representation of the domain of interest in the underlying information system. In the last years, this new paradigm has been used for providing users with abstract (independent from technological and system-oriented aspects), effective, and reasoning-intensive mechanisms for querying the data residing at the information system sources. In this paper we argue that OBDA, besides querying data, provides the right principles for devising a formal approach to data quality. In particular, we concentrate on one of the most important dimensions considered both in the literature and in the practice of data quality, namely consistency. We define a general framework for data consistency in OBDA, and present algorithms and complexity analysis for several relevant tasks related to the problem of checking data quality under this dimension, both at the extensional level (content of the data sources), and at the intensional level (schema of the data sources)."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Abduction Framework for Repairing Incomplete EL Ontologies", "Title": "Complexity Results and Algorithms", "Abstract": "In this paper we consider the problem of repairing  missing is-a relations in ontologies. We formalize the problem as a generalized TBox abduction problem (GTAP). Based on this abduction framework, we  present complexity results for the existence, relevance and necessity decision problems for the GTAP with and without some specific preference relations for ontologies that can be represented using a member of the EL family of description logics. Further, we present algorithms for finding solutions, a system as well as experiments."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Give a Hard Problem to a Diverse Team", "Title": "Exploring Large Action Spaces", "Abstract": "Recent work has shown that diverse teams can outperform a uniform team made of copies of the best agent. However, there are fundamental questions that were not asked before. When should we use diverse or uniform teams? How does the performance change as the action space or the teams get larger? Hence, we present a new model of diversity for teams, that is more general than previous models. We prove that the performance of a diverse team improves as the size of the action space gets larger. Concerning the size of the diverse team, we show that the performance converges exponentially fast to the optimal one as we increase the number of agents. We present synthetic experiments that allow us to gain further insights: even though a diverse team outperforms a uniform team when the size of the action space increases, the uniform team will eventually again play better than the diverse team for a large enough action space. We verify our predictions in a system of Go playing agents, where we show a diverse team that improves in performance as the board size increases, and eventually overcomes a uniform team."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Multi-Organ Exchange", "Title": "The Whole Is Greater than the Sum of its Parts", "Abstract": "Kidney exchange, where candidates with organ failure trade incompatible but willing donors, is a life-saving alternative to the deceased donor waitlist, which has inadequate supply to meet demand.  While fielded kidney exchanges see huge benefit from altruistic kidney donors (who give an organ without a paired needy candidate), a significantly higher medical risk to the donor deters similar altruism with livers.  In this paper, we begin by proposing the idea of liver exchange, and show on demographically accurate data that vetted kidney exchange algorithms can be adapted to clear such an exchange at the nationwide level.  We then explore cross-organ donation where kidneys and livers can be bartered for each other.  We show theoretically that this multi-organ exchange provides linearly more transplants than running separate kidney and liver exchanges; this linear gain is a product of altruistic kidney donors creating chains that thread through the liver pool.  We support this result experimentally on demographically accurate multi-organ exchanges.  We conclude with thoughts regarding the fielding of a nationwide liver or joint liver-kidney exchange from a legal and computational point of view."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "On Computing Optimal Strategies in Open List Proportional Representation", "Title": "The Two Parties Case", "Abstract": "Open list proportional representation is an election mechanism used in many elections, including the 2012 Hong Kong Legislative Council Geographical Constituencies election. In this paper, we assume that there are just two parties in the election, and that the number of votes that a list would get is the sum of the numbers of votes that the candidates in the list would get if each of them would go alone in the election. Under these assumptions, we formulate the election as a mostly zero-sum game, and show that while the game always has a pure Nash equilibrium, it is NP-hard to compute it."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Evaluating Trauma Patients", "Title": "Addressing Missing Covariates with Joint Optimization", "Abstract": "Missing values are a common problem when applying classification algorithms to real-world medical data. This is especially true for trauma patients, where the emergent nature of the cases makes it difficult to collect all of the relevant data for each patient. Standard methods for handling missingness first learn a model to estimate missing data values, and subsequently train and evaluate a classifier using data imputed with this model. Recently, several proposed methods have demonstrated the benefits of jointly estimating the imputation model and classifier parameters. However, these methods make assumptions that limit their utility with many real-world medical datasets. For example, the assumption that data elements are missing at random is often invalid. We address this situation by exploring a novel approach for jointly learning the imputation model and classifier. Unlike previous algorithms, our approach makes no assumptions about the missingness of the data, can be used with arbitrary probabilistic data models and classification loss functions, and can be used when both the training and testing data have missing values. We investigate the utility of this approach on the prediction of several patient outcomes in a large national registry of trauma patients, and find that it significantly outperforms standard sequential methods."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "SOML", "Title": "Sparse Online Metric Learning with Application to Image Retrieval", "Abstract": "Image similarity search plays a key role in many multimediaapplications, where multimedia data (such as images and videos) areusually represented in high-dimensional feature space. In thispaper, we propose a novel Sparse Online Metric Learning (SOML)scheme for learning sparse distance functions from large-scalehigh-dimensional data and explore its application to imageretrieval. In contrast to many existing distance metric learningalgorithms that are often designed for low-dimensional data, theproposed algorithms are able to learn sparse distance metrics fromhigh-dimensional data in an efficient and scalable manner. Ourexperimental results show that the proposed method achieves betteror at least comparable accuracy performance than thestate-of-the-art non-sparse distance metric learning approaches, butenjoys a significant advantage in computational efficiency andsparsity, making it more practical for real-world applications."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "SenticNet 3", "Title": "A Common and Common-Sense Knowledge Base for Cognition-Driven Sentiment Analysis", "Abstract": "SenticNet is a publicly available semantic and affective resource for concept-level sentiment analysis. Rather than using graph-mining and dimensionality-reduction techniques, SenticNet 3 makes use of \"energy flows\" to connect various parts of extended common and common-sense knowledge representations to one another. SenticNet 3 models nuanced semantics and sentics (that is, the conceptual and affective information associated with multi-word natural language expressions), representing information with a symbolic opacity of an intermediate nature between that of neural networks and typical symbolic systems."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Mind the Gap", "Title": "Machine Translation by Minimizing the Semantic Gap in Embedding Space", "Abstract": "The conventional statistical machine translation (SMT) methods perform the decoding process by compositing a set of the translation rules which are associated with high probabilities. However, the probabilities of the translation rules are calculated only according to the cooccurrence statistics in the bilingual corpus rather than the semantic meaning similarity. In this paper, we propose a Recursive Neural Network (RNN) based model that converts each translation rule into a compact real-valued vector in the semantic embedding space and performs the decoding process by minimizing the semantic gap between the source language string and its translation candidates at each state in a bottom-up structure. The RNN-based translation model is trained using a max-margin objective function. Extensive experiments on Chinese-to-English translation show that our RNN-based model can significantly improve the translation quality by up to 1.68 BLEU score."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Chinese Overt Pronoun Resolution", "Title": "A Bilingual Approach", "Abstract": "Much research has been done on the problem of English pronoun resolution, but there has been relatively little work on the corresponding problem of Chinese pronoun resolution. While pronoun resolution in both languages remains a challenging task, Chinese pronoun resolution is further complicated by (1) the lack of publicly available Chinese word lists or dictionaries that can be used to look up essential mention attributes such as gender and number; and (2) the relative dearth of Chinese coreference-annotated data. Existing approaches to Chinese pronoun resolution are monolingual, training and testing a pronoun resolver on Chinese data. In contrast, we propose a bilingual approach to Chinese pronoun resolution, aiming to improve the resolution of Chinese pronouns by leveraging the publicly available English dictionaries and coreference annotations. Experiments on the OntoNotes 5.0 corpus demonstrate that our bilingual approach to Chinese pronoun resolution significantly surpasses the performance of state-of-the-art monolingual approaches."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Chinese Zero Pronoun Resolution", "Title": "An Unsupervised Approach Combining Ranking and Integer Linear Programming", "Abstract": "State-of-the-art approaches to Chinese zero pronoun resolution are supervised, requiring training documents with manually resolved zero pronouns. To eliminate the reliance on annotated data, we propose an unsupervised approach to this task. Underlying our approach is the novel idea of employing a model trained on manually resolved overt pronouns to resolve zero pronouns. Experimental results on the OntoNotes 5.0 corpus are encouraging: our unsupervised model surpasses its supervised counterparts in performance."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "SUIT", "Title": "A Supervised User-Item Based Topic Model for Sentiment Analysis", "Abstract": "Probabilistic topic models have been widely used for sentiment analysis. However, most of existing topic methods only model the sentiment text, but do not consider the user, who expresses the sentiment, and the item, which the sentiment is expressed on. Since different users may use different sentiment expressions for different items, we argue that it is better to incorporate the user and item information into the topic model for sentiment analysis. In this paper, we propose a new Supervised User-Item based Topic model, called SUIT model, for sentiment analysis. It can simultaneously utilize the textual topic and latent user-item factors. Our proposed method uses the tensor outer product of text topic proportion vector, user latent factor and item latent factor to model the sentiment label generalization. Extensive experiments are conducted on two datasets: review dataset and microblog dataset. The results demonstrate the advantages of our model. It shows significant improvement compared with supervised topic models and collaborative filtering methods."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "HC-Search for Multi-Label Prediction", "Title": "An Empirical Study", "Abstract": "Multi-label learning concerns learning multiple, overlapping, and correlated classes. In this paper, we adapt a recent structured prediction framework called HC-Search for multi-label prediction problems. One of the main advantages of this framework is that its training is sensitive to the loss function, unlike the other multi-label approaches that either assume a specific loss function or require a manual adaptation to each loss function. We empirically evaluate our instantiation of the HC-Search framework along with many existing multi-label learning algorithms on a variety of benchmarks by employing diverse task loss functions. Our results demonstrate that the performance of existing algorithms tends to be very similar in most cases, and that the HC-Search approach is comparable and often better than all the other algorithms across different loss functions."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Labeling Complicated Objects", "Title": "Multi-View Multi-Instance Multi-Label Learning", "Abstract": "Multi-Instance Multi-Label (MIML) is a learning framework where an example is associated with multiple labels and represented by a set of feature vectors (multiple instances). In the formalization of MIML learning, instances come from a single source (single view). To leverage multiple information sources (multi-view), we develop a multi-view MIML framework based on hierarchical Bayesian Network, and derive an effective learning algorithm based on variational inference. The model can naturally deal with examples in which some views could be absent (partial examples). On multi-view datasets, it is shown that our method is better than other multi-view and single-view approaches particularly in the presence of partial examples. On single-view benchmarks, extensive evaluation shows that our method is highly competitive or better than other MIML approaches on labeling examples and instances. Moreover, our method can effectively handle datasets with a large number of labels."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Encoding Tree Sparsity in Multi-Task Learning", "Title": "A Probabilistic Framework", "Abstract": "Multi-task learning seeks to improve the generalization performance by sharing common information among multiple related tasks. A key assumption in most MTL algorithms is that all tasks are related, which, however, may not hold in many real-world applications. Existing techniques, which attempt to address this issue, aim to identify groups of related tasks using group sparsity. In this paper, we propose a probabilistic tree sparsity (PTS) model to utilize the tree structure to obtain the sparse solution instead of the group structure. Specifically, each model coefficient in the learning model is decomposed into a product of multiple component coefficients each of which corresponds to a node in the tree. Based on the decomposition, Gaussian and Cauchy distributions are placed on the component coefficients as priors to restrict the model complexity. We devise an efficient expectation maximization algorithm to learn the model parameters. Experiments conducted on both synthetic and real-world problems show the effectiveness of our model compared with state-of-the-art baselines."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "ReLISH", "Title": "Reliable Label Inference via Smoothness Hypothesis", "Abstract": "The smoothness hypothesis is critical for graph-based semi-supervised learning. This paper defines local smoothness, based on which a new algorithm, Reliable Label Inference via Smoothness Hypothesis (ReLISH), is proposed. ReLISH has produced smoother labels than some existing methods for both labeled and unlabeled examples. Theoretical analyses demonstrate good stability and generalizability of ReLISH. Using real-world datasets, our empirical analyses reveal that ReLISH is promising for both transductive and inductive tasks, when compared with representative algorithms, including Harmonic Functions, Local and Global Consistency, Constraint Metric Learning, Linear Neighborhood Propagation, and Manifold Regularization."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "LASS", "Title": "A Simple Assignment Model with Laplacian Smoothing", "Abstract": "We consider the problem of learning soft assignments of N items to K categories given two sources of information: an item-category similarity matrix, which encourages items to be assigned to categories they are similar to (and to not be assigned to categories they are dissimilar to), and an item-item similarity matrix, which encourages similar items to have similar assignments. We propose a simple quadratic programming model that captures this intuition. We give necessary conditions for its solution to be unique, define an out-of-sample mapping, and derive a simple, effective training algorithm based on the alternating direction method of multipliers. The model predicts reasonable assignments from even a few similarity values, and can be seen as a generalization of semisupervised learning. It is particularly useful when items naturally belong to multiple categories, as for example when annotating documents with keywords or pictures with tags, with partially tagged items, or when the categories have complex interrelations (e.g. hierarchical) that are unknown."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Reconsidering Mutual Information Based Feature Selection", "Title": "A Statistical Significance View", "Abstract": "Mutual information (MI) based approaches are a popular feature selection paradigm. Although the stated goal of MI-based feature selection is to identify a subset of features that share the highest mutual information with the class variable, most current MI-based techniques are greedy methods that make use of low dimensional MI quantities. The reason for using low dimensional approximation has been mostly attributed to the difficulty associated with estimating the high dimensional MI from limited samples. In this paper, we argue a different viewpoint that, given a very large amount of data, the high dimensional MI objective is still problematic to be employed as a meaningful optimization criterion, due to its overfitting nature: the MI almost always increases as more features are added, thus leading to a trivial solution which includes all features. We propose a novel approach to the MI-based feature selection problem, in which the overfitting phenomenon is controlled rigourously by means of a statistical test. We develop local and global optimization algorithms for this new feature selection model, and demonstrate its effectiveness in the applications of explaining variables and objects."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "AI-MIX", "Title": "Using Automated Planning to Steer Human Workers Towards Better Crowdsourced Plans", "Abstract": "One subclass of human computation applications are those directed at tasks that involve planning (e.g. tour planning) and scheduling (e.g. conference scheduling). Interestingly, work on these systems shows that even primitive forms of automated oversight on the human contributors helps in significantly improving the effectiveness of the humans/crowd. In this paper, we argue that the automated oversight used in these systems can be viewed as a primitive automated planner, and that there are several opportunities for more sophisticated automated planning in effectively steering the crowd. Straightforward adaptation of current planning technology is however hampered by the mismatch between the capabilities of human workers and automated planners. We identify and partially address two important challenges that need to be overcome before such adaptation of planning technology can occur: (i) interpreting inputs of the human workers (and the requester) and (ii) steering or critiquing plans produced by the human workers, armed only with incomplete domain and preference models. To these ends, we describe the implementation of AI-MIX, a tour plan generation system that uses automated checks and alerts to improve the quality of plans created by human workers; and present a preliminary evaluation of the effectiveness of steering provided by automated planning."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "STREETS", "Title": "Game-Theoretic Traffic Patrolling with Exploration and Exploitation", "Abstract": "To dissuade reckless driving and mitigate accidents, cities deploy resources to patrol roads. In this paper, we present STREETS, an application developed for the city of Singapore, which models the problem of computing randomized traffic patrol strategies as a defenderattacker Stackelberg game. Previous work on Stackelberg security games has focused extensively on counterterrorism settings. STREETS moves beyond counterterrorism and represents the first use of Stackelberg games for traffic patrolling, in the process providing a novel algorithm for solving such games that addresses three major challenges in modeling and scale-up. First, there exists a high degree of unpredictability in travel times through road networks, which we capture using a Markov Decision Process for planning the patrols of the defender (the police) in the game. Second, modeling all possible police patrols and their interactions with a large number of adversaries (drivers) introduces a significant scalability challenge. To address this challenge we apply a compact game representation in a novel fashion combined with adversary and state sampling. Third, patrol strategies must balance exploitation (minimizing violations) with exploration (maximizing omnipresence), a tradeoff we model by solving a biobjective optimization problem. We present experimental results using real-world traffic data from Singapore. This work is done in collaboration with the Singapore Ministry of Home Affairs and is currently being evaluated by the Singapore Police Force."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "StrokeBank", "Title": "Automating Personalized Chinese Handwriting Generation", "Abstract": "Machine learning techniques have been successfully applied to Chinese character recognition; nonetheless, automatic generation of stylized Chinese handwriting remains a challenge. In this paper, we propose StrokeBank, a novel approach to automating personalized Chinese handwriting generation. We use a semi-supervised algorithm to construct a dictionary of component mappings from a small seeding set. Unlike previous work, our approach does not require human supervision in stroke extraction or knowledge of the structure of Chinese characters. This dictionary is used to generate handwriting that preserves stylistic variations, including cursiveness and spatial layout of strokes. We demonstrate the effectiveness of our model by a survey-based evaluation. The results show that our generated characters are nearly indistinguishable from ground truth handwritings."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Swissnoise", "Title": "Online Polls with Game-Theoretic Incentives", "Abstract": "There is much interest in crowdsourcing information that is distributed among many individuals, such as the likelihood of future events, election outcomes, the quality of products, or the consequence of a decision. To obtain accurate outcomes, various game-theoretic incentive schemes have been proposed. However, only prediction markets have been tried in practice. In this paper, we describe an experimental platform, swissnoise, that compares prediction markets with peer prediction schemes developed in recent AI research. It shows that peer prediction schemes can achieve similar performance while being applicable to a much broader range of questions."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "THink", "Title": "Inferring Cognitive Status from Subtle Behaviors", "Abstract": "The Digital Clock Drawing Test is a fielded application that provides a major advance over existing neuropsychological testing technology. It captures and analyzes high precision information about both outcome and process, opening up the possibility of detecting subtle cognitive impairment even when test results appear superficially normal. We describe the design and development of the test, document the role of AI in its capabilities, and report on its use over the past seven years. We outline its potential implications for earlier detection and treatment of neurological disorders. We also set the work in the larger context of the THink project, which is exploring multiple approaches to determining cognitive status through the detection and analysis of subtle behaviors."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "CiteSeerX", "Title": "AI in a Digital Library Search Engine", "Abstract": "CiteSeerX is a digital library search engine that provides access to more than 4 million academic documents with nearly a million users and millions of hits per day. Artificial intelligence (AI) technologies are used in many components of CiteSeerX e.g. to accurately extract metadata, intelligently crawl the web, and ingest documents. We present key AI technologies used in the following components: document classification and deduplication, document and citation clustering, automatic metadata extraction and indexing, and author disambiguation. These AI technologies have been developed by CiteSeerX group members over the past 5–6 years. We also show the usage status, payoff, development challenges, main design concepts, and deployment and maintenance requirements. While it is challenging to rebuild a system like CiteSeerX from scratch, many of these AI technologies are transferable to other digital libraries and/or search engines."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "The Quest Draft", "Title": "an Automated Course Allocation Algorithm", "Abstract": "Course allocation is one of the most complex issues facing any university, due to the sensitive nature of deciding which subset of students should be granted seats in highly-popular (market-scarce) courses. In recent years, researchers have proposed numerous solutions, using techniques in integer programming, combinatorial auction design, and matching theory. In this paper, we present a four-part AI-based course allocation algorithm that was conceived by an undergraduate student, and recently implemented at a small Canadian liberal arts university. This new allocation process, which builds upon the Harvard Business School Draft, has received overwhelming support from students and faculty for its transparency, impartiality, and effectiveness."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Deploying CommunityCommands", "Title": "A Software Command Recommender System Case Study", "Abstract": "In 2009 we presented the idea of using collaborative filtering within a complex software application to help users learn new and relevant commands (Matejka et al. 2009). This project continued to evolve and we explored the design space of a contextual software command recommender system and completed a four-week user study (Li et al. 2011). We then expanded the scope of our project by implementing CommunityCommands, a fully functional and deployable recommender system. CommunityCommands was made available as a publically available plug-in download for Autodesk‟s flagship software application AutoCAD. During a one-year period, the recommender system was used by more than 1100 AutoCAD users. In this paper, we present our system usage data and payoff. We also provide an in-depth discussion of the challenges and design issues associated with developing and deploying the front end AutoCAD plug-in and its back end system. This includes a detailed description of the issues surrounding cold start and privacy. We also discuss how our practical system architecture was designed to leverage Autodesk‟s existing Customer Involvement Program (CIP) data to deliver in-product contextual recommendations to endusers. Our work sets important groundwork for the future development of recommender systems within the domain of end-user software learning assistance."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "DOROTHY", "Title": "Enhancing Bidirectional Communication between a 3D Programming Interface and Mobile Robots", "Abstract": "Dorothy is an integrated 3D/robotics educational tool created by augmenting the Alice programming environment for teaching core computing skills to students without prior programming experience. The tool provides a drag and drop interface to create graphical routines in virtual worlds; these routines are automatically translated into code to provide a real-time or offline enactment on mobile robots in the real world. This paper summarizes the key capabilities of Dorothy, and describes the contributions made to: (a) enhance the bidirectional communication between the virtual interface and robots; and (b) support multirobot collaboration. Specifically, we describe the ability to automatically revise the virtual world based on sensor data obtained from robots, creating or deleting objects in the virtual world based on their observed presence or absence in the real world. Furthermore, we describe the use of visually observed behavior of teammates for collaboration between robots when they cannot communicate with each other. Dorothy thus helps illustrate sophisticated algorithms for fundamental challenges in robotics and AI to teach advanced computing concepts, and to emphasize the importance of computing in real world applications, to beginning programmers."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Shallow Blue", "Title": "Lego-Based Embodied AI as a Platform for Cross-Curricular Project Based Learning", "Abstract": "We report on Shallow Blue (SB), an autonomous chess agent constructed by a small group of faculty and undergraduate students at Canisius College. In addition to pushing the limits of consumer grade components at low cost, SB is a focal point for interdisciplinary student projects spanning computer science, engineering, and physics. We demonstrate that undergraduate students can engage in rich, long-term robotic design and applied Artificial Intelligence (AI) from both hardware and software perspectives. Student outcomes of SB include senior theses, conference presentations, peer-reviewed publications, and admission to graduate programs. Students who participated also report substantial development in skills and knowledge applicable to their post-undergraduate education and careers."}
{"Type": "conference", "Year": "2014", "Area": "AI", "Where": "AAAI", "Abbreviation": "Jim", "Title": "A Platform for Affective AI in an Interdisciplinary Setting", "Abstract": "We report on Jim, an inexpensive student designed platform for embodied affective AI. The project brings together students from backgrounds in computer science, physics, engineering, and Digital Media Arts (DMA) in an informal educational setting. The platform will be used in AI courses and autism treatment studies."}
